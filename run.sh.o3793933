Variable OMP_NUM_THREADS has been set to 24
--------------------
Hostname: rdg1
Thu Aug 15 12:56:02 BST 2024
Free GPU: 2 of 2
--------------------
GPU0: [92mNot in use.[39m
GPU1: [92mNot in use.[39m

User: [91macw572[39m JobID: [91m3793933[39m GPU Allocation: [91m2[39m Queue: [91mshort.q[39m
[91mWarning! GPUs requested but not used![39m
In main
[[36m2024-08-15 12:56:49,206[0m][[34mutils.utils[0m][[32mINFO[0m] - [rank: 0] Enforcing tags! <cfg.extras.enforce_tags=True>[0m
[[36m2024-08-15 12:56:49,211[0m][[34mutils.utils[0m][[32mINFO[0m] - [rank: 0] Printing config tree with Rich! <cfg.extras.print_config=True>[0m
CONFIG
├── data
│   └── _target_: src.data.fsd_datamodule.FSDDataModule                         
│       json_path: /data/scratch/acw572/LHGNN/datafiles/                        
│       data_dir: /data/EECS-MachineListeningLab/datasets/AudioSet              
│       meta_path: /data/EECS-MachineListeningLab/datasets/AudioSet/ground_truth
│       label_csv_pth: /data/scratch/acw572/LHGNN/datafiles/class_labels_indices
│       samplr_csv_pth: /data/scratch/acw572/LHGNN/datafiles/fsd50k_tr_full_weig
│       balance_samplr: true                                                    
│       batch_size: 80                                                          
│       num_workers: 8                                                          
│       pin_memory: true                                                        
│       persistent_workers: true                                                
│       sr: 16000                                                               
│       fmin: 20                                                                
│       fmax: 8000                                                              
│       num_mels: 128                                                           
│       window_type: hanning                                                    
│       target_len: 1024                                                        
│       freqm: 48                                                               
│       timem: 192                                                              
│       mixup: 0.5                                                              
│       norm_mean: -4.6476                                                      
│       norm_std: 4.5699                                                        
│       num_devices: 2                                                          
│                                                                               
├── model
│   └── _target_: src.models.tagging_module_test.TaggingModule                  
│       optimizer:                                                              
│         _target_: torch.optim.Adam                                            
│         _partial_: true                                                       
│         lr: 0.0005                                                            
│         weight_decay: 5.0e-07                                                 
│         eps: 1.0e-08                                                          
│         betas:                                                                
│         - 0.95                                                                
│         - 0.999                                                               
│       scheduler:                                                              
│         _target_: torch.optim.lr_scheduler.MultiStepLR                        
│         _partial_: true                                                       
│         milestones:                                                           
│         - 10                                                                  
│         - 15                                                                  
│         - 20                                                                  
│         - 25                                                                  
│         - 30                                                                  
│         - 35                                                                  
│         - 40                                                                  
│         gamma: 0.5                                                            
│       net:                                                                    
│         _target_: src.models.components.Hypergraph.HGCN                       
│         k: 25                                                                 
│         act: gelu                                                             
│         norm: batch                                                           
│         bias: true                                                            
│         dropout: 0.0                                                          
│         dilation: true                                                        
│         epsilon: 0.2                                                          
│         drop_path: 0.1                                                        
│         size: s                                                               
│         num_class: 200                                                        
│         emb_dims: 1024                                                        
│         freq_num: 128                                                         
│         time_num: 1024                                                        
│       compile: false                                                          
│       loss: bce                                                               
│       opt_warmup: true                                                        
│       learning_rate: 0.0005                                                   
│       lr_rate:                                                                
│       - 0.05                                                                  
│       - 0.02                                                                  
│       - 0.01                                                                  
│       - 0.005                                                                 
│       - 0.002                                                                 
│       - 0.001                                                                 
│       - 0.0005                                                                
│       - 0.0002                                                                
│       lr_scheduler_epoch:                                                     
│       - 10                                                                    
│       - 15                                                                    
│       - 20                                                                    
│       - 25                                                                    
│       - 30                                                                    
│       - 35                                                                    
│       - 50                                                                    
│       - 45                                                                    
│                                                                               
├── callbacks
│   └── model_checkpoint:                                                       
│         _target_: pytorch_lightning.callbacks.ModelCheckpoint                 
│         dirpath: /data/scratch/acw572/LHGNN/logs/train/runs/2024-08-15_12-56-4
│         filename: epoch_{epoch:03d}                                           
│         monitor: val/mAP                                                      
│         verbose: false                                                        
│         save_last: true                                                       
│         save_top_k: 20                                                        
│         mode: max                                                             
│         auto_insert_metric_name: false                                        
│         save_weights_only: false                                              
│         every_n_train_steps: null                                             
│         train_time_interval: null                                             
│         every_n_epochs: null                                                  
│         save_on_train_epoch_end: null                                         
│       early_stopping:                                                         
│         _target_: pytorch_lightning.callbacks.EarlyStopping                   
│         monitor: val/loss                                                     
│         min_delta: 0.0                                                        
│         patience: 5                                                           
│         verbose: false                                                        
│         mode: min                                                             
│         strict: true                                                          
│         check_finite: true                                                    
│         stopping_threshold: null                                              
│         divergence_threshold: null                                            
│         check_on_train_epoch_end: null                                        
│       model_summary:                                                          
│         _target_: pytorch_lightning.callbacks.RichModelSummary                
│         max_depth: -1                                                         
│       tqdm_progress_bar:                                                      
│         _target_: pytorch_lightning.callbacks.TQDMProgressBar                 
│                                                                               
├── logger
│   └── wandb:                                                                  
│         _target_: pytorch_lightning.loggers.WandbLogger                       
│         save_dir: /data/scratch/acw572/LHGNN/logs/train/runs/2024-08-15_12-56-
│         offline: false                                                        
│         id: null                                                              
│         anonymous: null                                                       
│         project: audioset-bal                                                 
│         log_model: false                                                      
│         prefix: ''                                                            
│         group: Tagging                                                        
│         tags:                                                                 
│         - fsd                                                                 
│         - hgcn                                                                
│         job_type: ''                                                          
│                                                                               
├── trainer
│   └── _target_: pytorch_lightning.trainer.Trainer                             
│       default_root_dir: /data/scratch/acw572/LHGNN/logs/train/runs/2024-08-15_
│       num_sanity_val_steps: 0                                                 
│       min_epochs: 3                                                           
│       max_epochs: 5                                                           
│       accelerator: gpu                                                        
│       devices: 2                                                              
│       gradient_clip_val: 0.5                                                  
│       precision: 32                                                           
│       detect_anomaly: false                                                   
│       check_val_every_n_epoch: 1                                              
│       deterministic: false                                                    
│       strategy: ddp                                                           
│       num_nodes: 1                                                            
│       sync_batchnorm: false                                                   
│       use_distributed_sampler: false                                          
│                                                                               
├── paths
│   └── root_dir: /data/home/acw572/hgann/HGANN                                 
│       exp_dir: /data/scratch/acw572                                           
│       data_dir: /data/EECS-MachineListeningLab/datasets/AudioSet              
│       meta_dir: /data/EECS-MachineListeningLab/shubhr/hgann                   
│       log_dir: /data/scratch/acw572/LHGNN/logs/                               
│       output_dir: /data/scratch/acw572/LHGNN/logs/train/runs/2024-08-15_12-56-
│       work_dir: /data/home/acw572/hgann/HGANN                                 
│                                                                               
├── extras
│   └── ignore_warnings: false                                                  
│       enforce_tags: true                                                      
│       print_config: true                                                      
│                                                                               
├── task_name
│   └── train                                                                   
├── pretrained
│   └── img                                                                     
├── tags
│   └── ['dev']                                                                 
├── train
│   └── True                                                                    
├── eval
│   └── True                                                                    
├── wa
│   └── True                                                                    
├── ckpt_path
│   └── /data/EECS-MachineListeningLab/shubhr/imagenet_weights/model_best.pth.ta
└── seed
    └── None                                                                    
[[36m2024-08-15 12:56:49,306[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] In train[0m
[[36m2024-08-15 12:56:49,306[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating datamodule <src.data.fsd_datamodule.FSDDataModule>[0m
[[36m2024-08-15 12:56:50,668[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating model <src.models.tagging_module_test.TaggingModule>[0m
/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/utilities/parsing.py:198: Attribute 'net' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['net'])`.
norm is batch
bias is True
drop_path is 0.1
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
[[36m2024-08-15 12:57:16,364[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Loading img pretrained weights[0m
[[36m2024-08-15 12:57:16,364[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating callbacks...[0m
[[36m2024-08-15 12:57:16,364[0m][[34mutils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>[0m
[[36m2024-08-15 12:57:16,368[0m][[34mutils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <pytorch_lightning.callbacks.EarlyStopping>[0m
[[36m2024-08-15 12:57:16,369[0m][[34mutils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>[0m
[[36m2024-08-15 12:57:16,369[0m][[34mutils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <pytorch_lightning.callbacks.TQDMProgressBar>[0m
[[36m2024-08-15 12:57:16,370[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating loggers...[0m
[[36m2024-08-15 12:57:16,370[0m][[34mutils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating logger <pytorch_lightning.loggers.WandbLogger>[0m
[[36m2024-08-15 12:57:16,590[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating trainer <pytorch_lightning.trainer.Trainer>[0m
Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[[36m2024-08-15 12:57:16,782[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Logging hyperparameters![0m
wandb: Currently logged in as: shubhr. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.6 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.1
wandb: Run data is saved locally in /data/scratch/acw572/LHGNN/logs/train/runs/2024-08-15_12-56-48/wandb/run-20240815_125719-tf8c0w59
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-durian-46
wandb: ⭐️ View project at https://wandb.ai/shubhr/audioset-bal
wandb: 🚀 View run at https://wandb.ai/shubhr/audioset-bal/runs/tf8c0w59
[[36m2024-08-15 12:57:39,292[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Starting training![0m
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━┳━━┓
┃   ┃ Name                                                              ┃ … ┃  ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━╇━━┩
│ 0 │ net                                                               │ … │  │
│ 1 │ net.stem                                                          │ … │  │
│ 2 │ net.stem.convs                                                    │ … │  │
│ 3 │ net.stem.convs.0                                                  │ … │  │
│ 4 │ net.stem.convs.1                                                  │ … │  │
│ 5 │ net.stem.convs.2                                                  │ … │  │
│ 6 │ net.stem.convs.3                                                  │ … │  │
│ 7 │ net.stem.convs.4                                                  │ … │  │
│ 8 │ net.stem.convs.5                                                  │ … │  │
│ 9 │ net.stem.convs.6                                                  │ … │  │
│ … │ net.stem.convs.7                                                  │ … │  │
│ … │ net.backbone                                                      │ … │  │
│ … │ net.backbone.0                                                    │ … │  │
│ … │ net.backbone.0.0                                                  │ … │  │
│ … │ net.backbone.0.0.fc1                                              │ … │  │
│ … │ net.backbone.0.0.fc1.0                                            │ … │  │
│ … │ net.backbone.0.0.fc1.1                                            │ … │  │
│ … │ net.backbone.0.0.graph_conv                                       │ … │  │
│ … │ net.backbone.0.0.graph_conv.gconv                                 │ … │  │
│ … │ net.backbone.0.0.graph_conv.gconv.nn                              │ … │  │
│ … │ net.backbone.0.0.graph_conv.gconv.nn.0                            │ … │  │
│ … │ net.backbone.0.0.graph_conv.gconv.nn.1                            │ … │  │
│ … │ net.backbone.0.0.graph_conv.gconv.nn.2                            │ … │  │
│ … │ net.backbone.0.0.graph_conv.gconv.get_centroids                   │ … │  │
│ … │ net.backbone.0.0.graph_conv.gconv.get_centroids.centers_proposal  │ … │  │
│ … │ net.backbone.0.0.graph_conv.dilated_knn_graph                     │ … │  │
│ … │ net.backbone.0.0.graph_conv.dilated_knn_graph._dilated            │ … │  │
│ … │ net.backbone.0.0.fc2                                              │ … │  │
│ … │ net.backbone.0.0.fc2.0                                            │ … │  │
│ … │ net.backbone.0.0.fc2.1                                            │ … │  │
│ … │ net.backbone.0.0.drop_path                                        │ … │  │
│ … │ net.backbone.0.1                                                  │ … │  │
│ … │ net.backbone.0.1.fc1                                              │ … │  │
│ … │ net.backbone.0.1.fc1.0                                            │ … │  │
│ … │ net.backbone.0.1.fc1.1                                            │ … │  │
│ … │ net.backbone.0.1.act                                              │ … │  │
│ … │ net.backbone.0.1.fc2                                              │ … │  │
│ … │ net.backbone.0.1.fc2.0                                            │ … │  │
│ … │ net.backbone.0.1.fc2.1                                            │ … │  │
│ … │ net.backbone.0.1.conv                                             │ … │  │
│ … │ net.backbone.0.1.conv.conv                                        │ … │  │
│ … │ net.backbone.0.1.drop_path                                        │ … │  │
│ … │ net.backbone.1                                                    │ … │  │
│ … │ net.backbone.1.0                                                  │ … │  │
│ … │ net.backbone.1.0.fc1                                              │ … │  │
│ … │ net.backbone.1.0.fc1.0                                            │ … │  │
│ … │ net.backbone.1.0.fc1.1                                            │ … │  │
│ … │ net.backbone.1.0.graph_conv                                       │ … │  │
│ … │ net.backbone.1.0.graph_conv.gconv                                 │ … │  │
│ … │ net.backbone.1.0.graph_conv.gconv.nn                              │ … │  │
│ … │ net.backbone.1.0.graph_conv.gconv.nn.0                            │ … │  │
│ … │ net.backbone.1.0.graph_conv.gconv.nn.1                            │ … │  │
│ … │ net.backbone.1.0.graph_conv.gconv.nn.2                            │ … │  │
│ … │ net.backbone.1.0.graph_conv.gconv.get_centroids                   │ … │  │
│ … │ net.backbone.1.0.graph_conv.gconv.get_centroids.centers_proposal  │ … │  │
│ … │ net.backbone.1.0.graph_conv.dilated_knn_graph                     │ … │  │
│ … │ net.backbone.1.0.graph_conv.dilated_knn_graph._dilated            │ … │  │
│ … │ net.backbone.1.0.fc2                                              │ … │  │
│ … │ net.backbone.1.0.fc2.0                                            │ … │  │
│ … │ net.backbone.1.0.fc2.1                                            │ … │  │
│ … │ net.backbone.1.0.drop_path                                        │ … │  │
│ … │ net.backbone.1.1                                                  │ … │  │
│ … │ net.backbone.1.1.fc1                                              │ … │  │
│ … │ net.backbone.1.1.fc1.0                                            │ … │  │
│ … │ net.backbone.1.1.fc1.1                                            │ … │  │
│ … │ net.backbone.1.1.act                                              │ … │  │
│ … │ net.backbone.1.1.fc2                                              │ … │  │
│ … │ net.backbone.1.1.fc2.0                                            │ … │  │
│ … │ net.backbone.1.1.fc2.1                                            │ … │  │
│ … │ net.backbone.1.1.conv                                             │ … │  │
│ … │ net.backbone.1.1.conv.conv                                        │ … │  │
│ … │ net.backbone.1.1.drop_path                                        │ … │  │
│ … │ net.backbone.2                                                    │ … │  │
│ … │ net.backbone.2.conv                                               │ … │  │
│ … │ net.backbone.2.conv.0                                             │ … │  │
│ … │ net.backbone.2.conv.1                                             │ … │  │
│ … │ net.backbone.3                                                    │ … │  │
│ … │ net.backbone.3.0                                                  │ … │  │
│ … │ net.backbone.3.0.fc1                                              │ … │  │
│ … │ net.backbone.3.0.fc1.0                                            │ … │  │
│ … │ net.backbone.3.0.fc1.1                                            │ … │  │
│ … │ net.backbone.3.0.graph_conv                                       │ … │  │
│ … │ net.backbone.3.0.graph_conv.gconv                                 │ … │  │
│ … │ net.backbone.3.0.graph_conv.gconv.nn                              │ … │  │
│ … │ net.backbone.3.0.graph_conv.gconv.nn.0                            │ … │  │
│ … │ net.backbone.3.0.graph_conv.gconv.nn.1                            │ … │  │
│ … │ net.backbone.3.0.graph_conv.gconv.nn.2                            │ … │  │
│ … │ net.backbone.3.0.graph_conv.gconv.get_centroids                   │ … │  │
│ … │ net.backbone.3.0.graph_conv.gconv.get_centroids.centers_proposal  │ … │  │
│ … │ net.backbone.3.0.graph_conv.dilated_knn_graph                     │ … │  │
│ … │ net.backbone.3.0.graph_conv.dilated_knn_graph._dilated            │ … │  │
│ … │ net.backbone.3.0.fc2                                              │ … │  │
│ … │ net.backbone.3.0.fc2.0                                            │ … │  │
│ … │ net.backbone.3.0.fc2.1                                            │ … │  │
│ … │ net.backbone.3.0.drop_path                                        │ … │  │
│ … │ net.backbone.3.1                                                  │ … │  │
│ … │ net.backbone.3.1.fc1                                              │ … │  │
│ … │ net.backbone.3.1.fc1.0                                            │ … │  │
│ … │ net.backbone.3.1.fc1.1                                            │ … │  │
│ … │ net.backbone.3.1.act                                              │ … │  │
│ … │ net.backbone.3.1.fc2                                              │ … │  │
│ … │ net.backbone.3.1.fc2.0                                            │ … │  │
│ … │ net.backbone.3.1.fc2.1                                            │ … │  │
│ … │ net.backbone.3.1.conv                                             │ … │  │
│ … │ net.backbone.3.1.conv.conv                                        │ … │  │
│ … │ net.backbone.3.1.drop_path                                        │ … │  │
│ … │ net.backbone.4                                                    │ … │  │
│ … │ net.backbone.4.0                                                  │ … │  │
│ … │ net.backbone.4.0.fc1                                              │ … │  │
│ … │ net.backbone.4.0.fc1.0                                            │ … │  │
│ … │ net.backbone.4.0.fc1.1                                            │ … │  │
│ … │ net.backbone.4.0.graph_conv                                       │ … │  │
│ … │ net.backbone.4.0.graph_conv.gconv                                 │ … │  │
│ … │ net.backbone.4.0.graph_conv.gconv.nn                              │ … │  │
│ … │ net.backbone.4.0.graph_conv.gconv.nn.0                            │ … │  │
│ … │ net.backbone.4.0.graph_conv.gconv.nn.1                            │ … │  │
│ … │ net.backbone.4.0.graph_conv.gconv.nn.2                            │ … │  │
│ … │ net.backbone.4.0.graph_conv.gconv.get_centroids                   │ … │  │
│ … │ net.backbone.4.0.graph_conv.gconv.get_centroids.centers_proposal  │ … │  │
│ … │ net.backbone.4.0.graph_conv.dilated_knn_graph                     │ … │  │
│ … │ net.backbone.4.0.graph_conv.dilated_knn_graph._dilated            │ … │  │
│ … │ net.backbone.4.0.fc2                                              │ … │  │
│ … │ net.backbone.4.0.fc2.0                                            │ … │  │
│ … │ net.backbone.4.0.fc2.1                                            │ … │  │
│ … │ net.backbone.4.0.drop_path                                        │ … │  │
│ … │ net.backbone.4.1                                                  │ … │  │
│ … │ net.backbone.4.1.fc1                                              │ … │  │
│ … │ net.backbone.4.1.fc1.0                                            │ … │  │
│ … │ net.backbone.4.1.fc1.1                                            │ … │  │
│ … │ net.backbone.4.1.act                                              │ … │  │
│ … │ net.backbone.4.1.fc2                                              │ … │  │
│ … │ net.backbone.4.1.fc2.0                                            │ … │  │
│ … │ net.backbone.4.1.fc2.1                                            │ … │  │
│ … │ net.backbone.4.1.conv                                             │ … │  │
│ … │ net.backbone.4.1.conv.conv                                        │ … │  │
│ … │ net.backbone.4.1.drop_path                                        │ … │  │
│ … │ net.backbone.5                                                    │ … │  │
│ … │ net.backbone.5.conv                                               │ … │  │
│ … │ net.backbone.5.conv.0                                             │ … │  │
│ … │ net.backbone.5.conv.1                                             │ … │  │
│ … │ net.backbone.6                                                    │ … │  │
│ … │ net.backbone.6.0                                                  │ … │  │
│ … │ net.backbone.6.0.fc1                                              │ … │  │
│ … │ net.backbone.6.0.fc1.0                                            │ … │  │
│ … │ net.backbone.6.0.fc1.1                                            │ … │  │
│ … │ net.backbone.6.0.graph_conv                                       │ … │  │
│ … │ net.backbone.6.0.graph_conv.gconv                                 │ … │  │
│ … │ net.backbone.6.0.graph_conv.gconv.nn                              │ … │  │
│ … │ net.backbone.6.0.graph_conv.gconv.nn.0                            │ … │  │
│ … │ net.backbone.6.0.graph_conv.gconv.nn.1                            │ … │  │
│ … │ net.backbone.6.0.graph_conv.gconv.nn.2                            │ … │  │
│ … │ net.backbone.6.0.graph_conv.gconv.get_centroids                   │ … │  │
│ … │ net.backbone.6.0.graph_conv.gconv.get_centroids.centers_proposal  │ … │  │
│ … │ net.backbone.6.0.graph_conv.dilated_knn_graph                     │ … │  │
│ … │ net.backbone.6.0.graph_conv.dilated_knn_graph._dilated            │ … │  │
│ … │ net.backbone.6.0.fc2                                              │ … │  │
│ … │ net.backbone.6.0.fc2.0                                            │ … │  │
│ … │ net.backbone.6.0.fc2.1                                            │ … │  │
│ … │ net.backbone.6.0.drop_path                                        │ … │  │
│ … │ net.backbone.6.1                                                  │ … │  │
│ … │ net.backbone.6.1.fc1                                              │ … │  │
│ … │ net.backbone.6.1.fc1.0                                            │ … │  │
│ … │ net.backbone.6.1.fc1.1                                            │ … │  │
│ … │ net.backbone.6.1.act                                              │ … │  │
│ … │ net.backbone.6.1.fc2                                              │ … │  │
│ … │ net.backbone.6.1.fc2.0                                            │ … │  │
│ … │ net.backbone.6.1.fc2.1                                            │ … │  │
│ … │ net.backbone.6.1.conv                                             │ … │  │
│ … │ net.backbone.6.1.conv.conv                                        │ … │  │
│ … │ net.backbone.6.1.drop_path                                        │ … │  │
│ … │ net.backbone.7                                                    │ … │  │
│ … │ net.backbone.7.0                                                  │ … │  │
│ … │ net.backbone.7.0.fc1                                              │ … │  │
│ … │ net.backbone.7.0.fc1.0                                            │ … │  │
│ … │ net.backbone.7.0.fc1.1                                            │ … │  │
│ … │ net.backbone.7.0.graph_conv                                       │ … │  │
│ … │ net.backbone.7.0.graph_conv.gconv                                 │ … │  │
│ … │ net.backbone.7.0.graph_conv.gconv.nn                              │ … │  │
│ … │ net.backbone.7.0.graph_conv.gconv.nn.0                            │ … │  │
│ … │ net.backbone.7.0.graph_conv.gconv.nn.1                            │ … │  │
│ … │ net.backbone.7.0.graph_conv.gconv.nn.2                            │ … │  │
│ … │ net.backbone.7.0.graph_conv.gconv.get_centroids                   │ … │  │
│ … │ net.backbone.7.0.graph_conv.gconv.get_centroids.centers_proposal  │ … │  │
│ … │ net.backbone.7.0.graph_conv.dilated_knn_graph                     │ … │  │
│ … │ net.backbone.7.0.graph_conv.dilated_knn_graph._dilated            │ … │  │
│ … │ net.backbone.7.0.fc2                                              │ … │  │
│ … │ net.backbone.7.0.fc2.0                                            │ … │  │
│ … │ net.backbone.7.0.fc2.1                                            │ … │  │
│ … │ net.backbone.7.0.drop_path                                        │ … │  │
│ … │ net.backbone.7.1                                                  │ … │  │
│ … │ net.backbone.7.1.fc1                                              │ … │  │
│ … │ net.backbone.7.1.fc1.0                                            │ … │  │
│ … │ net.backbone.7.1.fc1.1                                            │ … │  │
│ … │ net.backbone.7.1.act                                              │ … │  │
│ … │ net.backbone.7.1.fc2                                              │ … │  │
│ … │ net.backbone.7.1.fc2.0                                            │ … │  │
│ … │ net.backbone.7.1.fc2.1                                            │ … │  │
│ … │ net.backbone.7.1.conv                                             │ … │  │
│ … │ net.backbone.7.1.conv.conv                                        │ … │  │
│ … │ net.backbone.7.1.drop_path                                        │ … │  │
│ … │ net.backbone.8                                                    │ … │  │
│ … │ net.backbone.8.0                                                  │ … │  │
│ … │ net.backbone.8.0.fc1                                              │ … │  │
│ … │ net.backbone.8.0.fc1.0                                            │ … │  │
│ … │ net.backbone.8.0.fc1.1                                            │ … │  │
│ … │ net.backbone.8.0.graph_conv                                       │ … │  │
│ … │ net.backbone.8.0.graph_conv.gconv                                 │ … │  │
│ … │ net.backbone.8.0.graph_conv.gconv.nn                              │ … │  │
│ … │ net.backbone.8.0.graph_conv.gconv.nn.0                            │ … │  │
│ … │ net.backbone.8.0.graph_conv.gconv.nn.1                            │ … │  │
│ … │ net.backbone.8.0.graph_conv.gconv.nn.2                            │ … │  │
│ … │ net.backbone.8.0.graph_conv.gconv.get_centroids                   │ … │  │
│ … │ net.backbone.8.0.graph_conv.gconv.get_centroids.centers_proposal  │ … │  │
│ … │ net.backbone.8.0.graph_conv.dilated_knn_graph                     │ … │  │
│ … │ net.backbone.8.0.graph_conv.dilated_knn_graph._dilated            │ … │  │
│ … │ net.backbone.8.0.fc2                                              │ … │  │
│ … │ net.backbone.8.0.fc2.0                                            │ … │  │
│ … │ net.backbone.8.0.fc2.1                                            │ … │  │
│ … │ net.backbone.8.0.drop_path                                        │ … │  │
│ … │ net.backbone.8.1                                                  │ … │  │
│ … │ net.backbone.8.1.fc1                                              │ … │  │
│ … │ net.backbone.8.1.fc1.0                                            │ … │  │
│ … │ net.backbone.8.1.fc1.1                                            │ … │  │
│ … │ net.backbone.8.1.act                                              │ … │  │
│ … │ net.backbone.8.1.fc2                                              │ … │  │
│ … │ net.backbone.8.1.fc2.0                                            │ … │  │
│ … │ net.backbone.8.1.fc2.1                                            │ … │  │
│ … │ net.backbone.8.1.conv                                             │ … │  │
│ … │ net.backbone.8.1.conv.conv                                        │ … │  │
│ … │ net.backbone.8.1.drop_path                                        │ … │  │
│ … │ net.backbone.9                                                    │ … │  │
│ … │ net.backbone.9.0                                                  │ … │  │
│ … │ net.backbone.9.0.fc1                                              │ … │  │
│ … │ net.backbone.9.0.fc1.0                                            │ … │  │
│ … │ net.backbone.9.0.fc1.1                                            │ … │  │
│ … │ net.backbone.9.0.graph_conv                                       │ … │  │
│ … │ net.backbone.9.0.graph_conv.gconv                                 │ … │  │
│ … │ net.backbone.9.0.graph_conv.gconv.nn                              │ … │  │
│ … │ net.backbone.9.0.graph_conv.gconv.nn.0                            │ … │  │
│ … │ net.backbone.9.0.graph_conv.gconv.nn.1                            │ … │  │
│ … │ net.backbone.9.0.graph_conv.gconv.nn.2                            │ … │  │
│ … │ net.backbone.9.0.graph_conv.gconv.get_centroids                   │ … │  │
│ … │ net.backbone.9.0.graph_conv.gconv.get_centroids.centers_proposal  │ … │  │
│ … │ net.backbone.9.0.graph_conv.dilated_knn_graph                     │ … │  │
│ … │ net.backbone.9.0.graph_conv.dilated_knn_graph._dilated            │ … │  │
│ … │ net.backbone.9.0.fc2                                              │ … │  │
│ … │ net.backbone.9.0.fc2.0                                            │ … │  │
│ … │ net.backbone.9.0.fc2.1                                            │ … │  │
│ … │ net.backbone.9.0.drop_path                                        │ … │  │
│ … │ net.backbone.9.1                                                  │ … │  │
│ … │ net.backbone.9.1.fc1                                              │ … │  │
│ … │ net.backbone.9.1.fc1.0                                            │ … │  │
│ … │ net.backbone.9.1.fc1.1                                            │ … │  │
│ … │ net.backbone.9.1.act                                              │ … │  │
│ … │ net.backbone.9.1.fc2                                              │ … │  │
│ … │ net.backbone.9.1.fc2.0                                            │ … │  │
│ … │ net.backbone.9.1.fc2.1                                            │ … │  │
│ … │ net.backbone.9.1.conv                                             │ … │  │
│ … │ net.backbone.9.1.conv.conv                                        │ … │  │
│ … │ net.backbone.9.1.drop_path                                        │ … │  │
│ … │ net.backbone.10                                                   │ … │  │
│ … │ net.backbone.10.0                                                 │ … │  │
│ … │ net.backbone.10.0.fc1                                             │ … │  │
│ … │ net.backbone.10.0.fc1.0                                           │ … │  │
│ … │ net.backbone.10.0.fc1.1                                           │ … │  │
│ … │ net.backbone.10.0.graph_conv                                      │ … │  │
│ … │ net.backbone.10.0.graph_conv.gconv                                │ … │  │
│ … │ net.backbone.10.0.graph_conv.gconv.nn                             │ … │  │
│ … │ net.backbone.10.0.graph_conv.gconv.nn.0                           │ … │  │
│ … │ net.backbone.10.0.graph_conv.gconv.nn.1                           │ … │  │
│ … │ net.backbone.10.0.graph_conv.gconv.nn.2                           │ … │  │
│ … │ net.backbone.10.0.graph_conv.gconv.get_centroids                  │ … │  │
│ … │ net.backbone.10.0.graph_conv.gconv.get_centroids.centers_proposal │ … │  │
│ … │ net.backbone.10.0.graph_conv.dilated_knn_graph                    │ … │  │
│ … │ net.backbone.10.0.graph_conv.dilated_knn_graph._dilated           │ … │  │
│ … │ net.backbone.10.0.fc2                                             │ … │  │
│ … │ net.backbone.10.0.fc2.0                                           │ … │  │
│ … │ net.backbone.10.0.fc2.1                                           │ … │  │
│ … │ net.backbone.10.0.drop_path                                       │ … │  │
│ … │ net.backbone.10.1                                                 │ … │  │
│ … │ net.backbone.10.1.fc1                                             │ … │  │
│ … │ net.backbone.10.1.fc1.0                                           │ … │  │
│ … │ net.backbone.10.1.fc1.1                                           │ … │  │
│ … │ net.backbone.10.1.act                                             │ … │  │
│ … │ net.backbone.10.1.fc2                                             │ … │  │
│ … │ net.backbone.10.1.fc2.0                                           │ … │  │
│ … │ net.backbone.10.1.fc2.1                                           │ … │  │
│ … │ net.backbone.10.1.conv                                            │ … │  │
│ … │ net.backbone.10.1.conv.conv                                       │ … │  │
│ … │ net.backbone.10.1.drop_path                                       │ … │  │
│ … │ net.backbone.11                                                   │ … │  │
│ … │ net.backbone.11.0                                                 │ … │  │
│ … │ net.backbone.11.0.fc1                                             │ … │  │
│ … │ net.backbone.11.0.fc1.0                                           │ … │  │
│ … │ net.backbone.11.0.fc1.1                                           │ … │  │
│ … │ net.backbone.11.0.graph_conv                                      │ … │  │
│ … │ net.backbone.11.0.graph_conv.gconv                                │ … │  │
│ … │ net.backbone.11.0.graph_conv.gconv.nn                             │ … │  │
│ … │ net.backbone.11.0.graph_conv.gconv.nn.0                           │ … │  │
│ … │ net.backbone.11.0.graph_conv.gconv.nn.1                           │ … │  │
│ … │ net.backbone.11.0.graph_conv.gconv.nn.2                           │ … │  │
│ … │ net.backbone.11.0.graph_conv.gconv.get_centroids                  │ … │  │
│ … │ net.backbone.11.0.graph_conv.gconv.get_centroids.centers_proposal │ … │  │
│ … │ net.backbone.11.0.graph_conv.dilated_knn_graph                    │ … │  │
│ … │ net.backbone.11.0.graph_conv.dilated_knn_graph._dilated           │ … │  │
│ … │ net.backbone.11.0.fc2                                             │ … │  │
│ … │ net.backbone.11.0.fc2.0                                           │ … │  │
│ … │ net.backbone.11.0.fc2.1                                           │ … │  │
│ … │ net.backbone.11.0.drop_path                                       │ … │  │
│ … │ net.backbone.11.1                                                 │ … │  │
│ … │ net.backbone.11.1.fc1                                             │ … │  │
│ … │ net.backbone.11.1.fc1.0                                           │ … │  │
│ … │ net.backbone.11.1.fc1.1                                           │ … │  │
│ … │ net.backbone.11.1.act                                             │ … │  │
│ … │ net.backbone.11.1.fc2                                             │ … │  │
│ … │ net.backbone.11.1.fc2.0                                           │ … │  │
│ … │ net.backbone.11.1.fc2.1                                           │ … │  │
│ … │ net.backbone.11.1.conv                                            │ … │  │
│ … │ net.backbone.11.1.conv.conv                                       │ … │  │
│ … │ net.backbone.11.1.drop_path                                       │ … │  │
│ … │ net.backbone.12                                                   │ … │  │
│ … │ net.backbone.12.conv                                              │ … │  │
│ … │ net.backbone.12.conv.0                                            │ … │  │
│ … │ net.backbone.12.conv.1                                            │ … │  │
│ … │ net.backbone.13                                                   │ … │  │
│ … │ net.backbone.13.0                                                 │ … │  │
│ … │ net.backbone.13.0.fc1                                             │ … │  │
│ … │ net.backbone.13.0.fc1.0                                           │ … │  │
│ … │ net.backbone.13.0.fc1.1                                           │ … │  │
│ … │ net.backbone.13.0.graph_conv                                      │ … │  │
│ … │ net.backbone.13.0.graph_conv.gconv                                │ … │  │
│ … │ net.backbone.13.0.graph_conv.gconv.nn                             │ … │  │
│ … │ net.backbone.13.0.graph_conv.gconv.nn.0                           │ … │  │
│ … │ net.backbone.13.0.graph_conv.gconv.nn.1                           │ … │  │
│ … │ net.backbone.13.0.graph_conv.gconv.nn.2                           │ … │  │
│ … │ net.backbone.13.0.graph_conv.gconv.get_centroids                  │ … │  │
│ … │ net.backbone.13.0.graph_conv.gconv.get_centroids.centers_proposal │ … │  │
│ … │ net.backbone.13.0.graph_conv.dilated_knn_graph                    │ … │  │
│ … │ net.backbone.13.0.graph_conv.dilated_knn_graph._dilated           │ … │  │
│ … │ net.backbone.13.0.fc2                                             │ … │  │
│ … │ net.backbone.13.0.fc2.0                                           │ … │  │
│ … │ net.backbone.13.0.fc2.1                                           │ … │  │
│ … │ net.backbone.13.0.drop_path                                       │ … │  │
│ … │ net.backbone.13.1                                                 │ … │  │
│ … │ net.backbone.13.1.fc1                                             │ … │  │
│ … │ net.backbone.13.1.fc1.0                                           │ … │  │
│ … │ net.backbone.13.1.fc1.1                                           │ … │  │
│ … │ net.backbone.13.1.act                                             │ … │  │
│ … │ net.backbone.13.1.fc2                                             │ … │  │
│ … │ net.backbone.13.1.fc2.0                                           │ … │  │
│ … │ net.backbone.13.1.fc2.1                                           │ … │  │
│ … │ net.backbone.13.1.conv                                            │ … │  │
│ … │ net.backbone.13.1.conv.conv                                       │ … │  │
│ … │ net.backbone.13.1.drop_path                                       │ … │  │
│ … │ net.backbone.14                                                   │ … │  │
│ … │ net.backbone.14.0                                                 │ … │  │
│ … │ net.backbone.14.0.fc1                                             │ … │  │
│ … │ net.backbone.14.0.fc1.0                                           │ … │  │
│ … │ net.backbone.14.0.fc1.1                                           │ … │  │
│ … │ net.backbone.14.0.graph_conv                                      │ … │  │
│ … │ net.backbone.14.0.graph_conv.gconv                                │ … │  │
│ … │ net.backbone.14.0.graph_conv.gconv.nn                             │ … │  │
│ … │ net.backbone.14.0.graph_conv.gconv.nn.0                           │ … │  │
│ … │ net.backbone.14.0.graph_conv.gconv.nn.1                           │ … │  │
│ … │ net.backbone.14.0.graph_conv.gconv.nn.2                           │ … │  │
│ … │ net.backbone.14.0.graph_conv.gconv.get_centroids                  │ … │  │
│ … │ net.backbone.14.0.graph_conv.gconv.get_centroids.centers_proposal │ … │  │
│ … │ net.backbone.14.0.graph_conv.dilated_knn_graph                    │ … │  │
│ … │ net.backbone.14.0.graph_conv.dilated_knn_graph._dilated           │ … │  │
│ … │ net.backbone.14.0.fc2                                             │ … │  │
│ … │ net.backbone.14.0.fc2.0                                           │ … │  │
│ … │ net.backbone.14.0.fc2.1                                           │ … │  │
│ … │ net.backbone.14.0.drop_path                                       │ … │  │
│ … │ net.backbone.14.1                                                 │ … │  │
│ … │ net.backbone.14.1.fc1                                             │ … │  │
│ … │ net.backbone.14.1.fc1.0                                           │ … │  │
│ … │ net.backbone.14.1.fc1.1                                           │ … │  │
│ … │ net.backbone.14.1.act                                             │ … │  │
│ … │ net.backbone.14.1.fc2                                             │ … │  │
│ … │ net.backbone.14.1.fc2.0                                           │ … │  │
│ … │ net.backbone.14.1.fc2.1                                           │ … │  │
│ … │ net.backbone.14.1.conv                                            │ … │  │
│ … │ net.backbone.14.1.conv.conv                                       │ … │  │
│ … │ net.backbone.14.1.drop_path                                       │ … │  │
│ … │ net.prediction                                                    │ … │  │
│ … │ net.prediction.0                                                  │ … │  │
│ … │ net.prediction.1                                                  │ … │  │
│ … │ net.prediction.2                                                  │ … │  │
│ … │ net.prediction.3                                                  │ … │  │
│ … │ net.prediction.4                                                  │ … │  │
│ … │ criterion                                                         │ … │  │
│ … │ train_loss                                                        │ … │  │
│ … │ val_loss                                                          │ … │  │
│ … │ test_loss                                                         │ … │  │
│ … │ val_mAP                                                           │ … │  │
│ … │ test_mAP                                                          │ … │  │
│ … │ val_mAP_best                                                      │ … │  │
└───┴───────────────────────────────────────────────────────────────────┴───┴──┘
Trainable params: 31.1 M                                                        
Non-trainable params: 12.1 M                                                    
Total params: 43.2 M                                                            
Total estimated model params size (MB): 172                                     
In main
norm is batch
bias is True
drop_path is 0.1
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/459 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/459 [00:00<?, ?it/s] hyperparameters: "compile":            False
"learning_rate":      0.0005
"loss":               bce
"lr_rate":            [0.05, 0.02, 0.01, 0.005, 0.002, 0.001, 0.0005, 0.0002]
"lr_scheduler_epoch": [10, 15, 20, 25, 30, 35, 50, 45]
"net":                HGCN(
  (stem): Stem_conv(
    (convs): Sequential(
      (0): Conv2d(1, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): GELU(approximate='none')
      (3): Conv2d(40, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (4): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): GELU(approximate='none')
      (6): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (backbone): Sequential(
    (0): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): Identity()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
        )
        (drop_path): Identity()
      )
    )
    (1): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
        )
        (drop_path): DropPath()
      )
    )
    (2): DownSample(
      (conv): Sequential(
        (0): Conv2d(80, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(480, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)
        )
        (drop_path): DropPath()
      )
    )
    (4): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(480, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)
        )
        (drop_path): DropPath()
      )
    )
    (5): DownSample(
      (conv): Sequential(
        (0): Conv2d(160, 400, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (7): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (8): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (9): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (10): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (11): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (12): DownSample(
      (conv): Sequential(
        (0): Conv2d(400, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (13): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1920, 1920, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(640, 2560, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(2560, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(2560, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(2560, 2560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2560)
        )
        (drop_path): DropPath()
      )
    )
    (14): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1920, 1920, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(640, 2560, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(2560, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(2560, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(2560, 2560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2560)
        )
        (drop_path): DropPath()
      )
    )
  )
  (prediction): Sequential(
    (0): Conv2d(640, 1024, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): GELU(approximate='none')
    (3): Dropout(p=0.0, inplace=False)
    (4): Conv2d(1024, 200, kernel_size=(1, 1), stride=(1, 1))
  )
)
"opt_warmup":         True
"optimizer":          functools.partial(<class 'torch.optim.adam.Adam'>, lr=0.0005, weight_decay=5e-07, eps=1e-08, betas=[0.95, 0.999])
"scheduler":          functools.partial(<class 'torch.optim.lr_scheduler.MultiStepLR'>, milestones=[10, 15, 20, 25, 30, 35, 40], gamma=0.5)
Epoch 0:   0%|          | 1/459 [00:17<2:12:46,  0.06it/s]Epoch 0:   0%|          | 1/459 [00:17<2:12:47,  0.06it/s, v_num=0w59, train/loss_step=0.771]Epoch 0:   0%|          | 2/459 [00:19<1:12:29,  0.11it/s, v_num=0w59, train/loss_step=0.771]Epoch 0:   0%|          | 2/459 [00:19<1:12:29,  0.11it/s, v_num=0w59, train/loss_step=0.767]Epoch 0:   1%|          | 3/459 [00:20<52:13,  0.15it/s, v_num=0w59, train/loss_step=0.767]  Epoch 0:   1%|          | 3/459 [00:20<52:13,  0.15it/s, v_num=0w59, train/loss_step=0.769]Epoch 0:   1%|          | 4/459 [00:22<42:05,  0.18it/s, v_num=0w59, train/loss_step=0.769]Epoch 0:   1%|          | 4/459 [00:22<42:05,  0.18it/s, v_num=0w59, train/loss_step=0.761]Epoch 0:   1%|          | 5/459 [00:23<35:59,  0.21it/s, v_num=0w59, train/loss_step=0.761]Epoch 0:   1%|          | 5/459 [00:23<35:59,  0.21it/s, v_num=0w59, train/loss_step=0.771]Epoch 0:   1%|▏         | 6/459 [00:25<31:55,  0.24it/s, v_num=0w59, train/loss_step=0.771]Epoch 0:   1%|▏         | 6/459 [00:25<31:55,  0.24it/s, v_num=0w59, train/loss_step=0.764]Epoch 0:   2%|▏         | 7/459 [00:26<29:00,  0.26it/s, v_num=0w59, train/loss_step=0.764]Epoch 0:   2%|▏         | 7/459 [00:26<29:00,  0.26it/s, v_num=0w59, train/loss_step=0.773]Epoch 0:   2%|▏         | 8/459 [00:28<26:49,  0.28it/s, v_num=0w59, train/loss_step=0.773]Epoch 0:   2%|▏         | 8/459 [00:28<26:49,  0.28it/s, v_num=0w59, train/loss_step=0.770]Epoch 0:   2%|▏         | 9/459 [00:30<25:06,  0.30it/s, v_num=0w59, train/loss_step=0.770]Epoch 0:   2%|▏         | 9/459 [00:30<25:06,  0.30it/s, v_num=0w59, train/loss_step=0.757]Epoch 0:   2%|▏         | 10/459 [00:31<23:44,  0.32it/s, v_num=0w59, train/loss_step=0.757]Epoch 0:   2%|▏         | 10/459 [00:31<23:44,  0.32it/s, v_num=0w59, train/loss_step=0.770]Epoch 0:   2%|▏         | 11/459 [00:33<22:36,  0.33it/s, v_num=0w59, train/loss_step=0.770]Epoch 0:   2%|▏         | 11/459 [00:33<22:36,  0.33it/s, v_num=0w59, train/loss_step=0.772]Epoch 0:   3%|▎         | 12/459 [00:34<21:39,  0.34it/s, v_num=0w59, train/loss_step=0.772]Epoch 0:   3%|▎         | 12/459 [00:34<21:39,  0.34it/s, v_num=0w59, train/loss_step=0.757]Epoch 0:   3%|▎         | 13/459 [00:36<20:51,  0.36it/s, v_num=0w59, train/loss_step=0.757]Epoch 0:   3%|▎         | 13/459 [00:36<20:51,  0.36it/s, v_num=0w59, train/loss_step=0.754]Epoch 0:   3%|▎         | 14/459 [00:38<20:09,  0.37it/s, v_num=0w59, train/loss_step=0.754]Epoch 0:   3%|▎         | 14/459 [00:38<20:09,  0.37it/s, v_num=0w59, train/loss_step=0.771]Epoch 0:   3%|▎         | 15/459 [00:39<19:32,  0.38it/s, v_num=0w59, train/loss_step=0.771]Epoch 0:   3%|▎         | 15/459 [00:39<19:32,  0.38it/s, v_num=0w59, train/loss_step=0.765]Epoch 0:   3%|▎         | 16/459 [00:41<19:00,  0.39it/s, v_num=0w59, train/loss_step=0.765]Epoch 0:   3%|▎         | 16/459 [00:41<19:00,  0.39it/s, v_num=0w59, train/loss_step=0.758]Epoch 0:   4%|▎         | 17/459 [00:42<18:31,  0.40it/s, v_num=0w59, train/loss_step=0.758]Epoch 0:   4%|▎         | 17/459 [00:42<18:31,  0.40it/s, v_num=0w59, train/loss_step=0.753]Epoch 0:   4%|▍         | 18/459 [00:44<18:06,  0.41it/s, v_num=0w59, train/loss_step=0.753]Epoch 0:   4%|▍         | 18/459 [00:44<18:06,  0.41it/s, v_num=0w59, train/loss_step=0.751]Epoch 0:   4%|▍         | 19/459 [00:45<17:42,  0.41it/s, v_num=0w59, train/loss_step=0.751]Epoch 0:   4%|▍         | 19/459 [00:45<17:42,  0.41it/s, v_num=0w59, train/loss_step=0.754]Epoch 0:   4%|▍         | 20/459 [00:47<17:21,  0.42it/s, v_num=0w59, train/loss_step=0.754]Epoch 0:   4%|▍         | 20/459 [00:47<17:22,  0.42it/s, v_num=0w59, train/loss_step=0.742]Epoch 0:   5%|▍         | 21/459 [00:49<17:02,  0.43it/s, v_num=0w59, train/loss_step=0.742]Epoch 0:   5%|▍         | 21/459 [00:49<17:02,  0.43it/s, v_num=0w59, train/loss_step=0.749]Epoch 0:   5%|▍         | 22/459 [00:50<16:45,  0.43it/s, v_num=0w59, train/loss_step=0.749]Epoch 0:   5%|▍         | 22/459 [00:50<16:45,  0.43it/s, v_num=0w59, train/loss_step=0.739]Epoch 0:   5%|▌         | 23/459 [00:52<16:29,  0.44it/s, v_num=0w59, train/loss_step=0.739]Epoch 0:   5%|▌         | 23/459 [00:52<16:29,  0.44it/s, v_num=0w59, train/loss_step=0.731]Epoch 0:   5%|▌         | 24/459 [00:53<16:14,  0.45it/s, v_num=0w59, train/loss_step=0.731]Epoch 0:   5%|▌         | 24/459 [00:53<16:14,  0.45it/s, v_num=0w59, train/loss_step=0.738]Epoch 0:   5%|▌         | 25/459 [00:55<16:00,  0.45it/s, v_num=0w59, train/loss_step=0.738]Epoch 0:   5%|▌         | 25/459 [00:55<16:00,  0.45it/s, v_num=0w59, train/loss_step=0.731]Epoch 0:   6%|▌         | 26/459 [00:56<15:47,  0.46it/s, v_num=0w59, train/loss_step=0.731]Epoch 0:   6%|▌         | 26/459 [00:56<15:47,  0.46it/s, v_num=0w59, train/loss_step=0.743]Epoch 0:   6%|▌         | 27/459 [00:58<15:35,  0.46it/s, v_num=0w59, train/loss_step=0.743]Epoch 0:   6%|▌         | 27/459 [00:58<15:35,  0.46it/s, v_num=0w59, train/loss_step=0.734]Epoch 0:   6%|▌         | 28/459 [01:00<15:24,  0.47it/s, v_num=0w59, train/loss_step=0.734]Epoch 0:   6%|▌         | 28/459 [01:00<15:24,  0.47it/s, v_num=0w59, train/loss_step=0.721]Epoch 0:   6%|▋         | 29/459 [01:01<15:13,  0.47it/s, v_num=0w59, train/loss_step=0.721]Epoch 0:   6%|▋         | 29/459 [01:01<15:13,  0.47it/s, v_num=0w59, train/loss_step=0.725]Epoch 0:   7%|▋         | 30/459 [01:03<15:03,  0.47it/s, v_num=0w59, train/loss_step=0.725]Epoch 0:   7%|▋         | 30/459 [01:03<15:03,  0.47it/s, v_num=0w59, train/loss_step=0.713]Epoch 0:   7%|▋         | 31/459 [01:04<14:54,  0.48it/s, v_num=0w59, train/loss_step=0.713]Epoch 0:   7%|▋         | 31/459 [01:04<14:54,  0.48it/s, v_num=0w59, train/loss_step=0.714]Epoch 0:   7%|▋         | 32/459 [01:06<14:45,  0.48it/s, v_num=0w59, train/loss_step=0.714]Epoch 0:   7%|▋         | 32/459 [01:06<14:45,  0.48it/s, v_num=0w59, train/loss_step=0.721]Epoch 0:   7%|▋         | 33/459 [01:07<14:37,  0.49it/s, v_num=0w59, train/loss_step=0.721]Epoch 0:   7%|▋         | 33/459 [01:07<14:37,  0.49it/s, v_num=0w59, train/loss_step=0.717]Epoch 0:   7%|▋         | 34/459 [01:09<14:29,  0.49it/s, v_num=0w59, train/loss_step=0.717]Epoch 0:   7%|▋         | 34/459 [01:09<14:29,  0.49it/s, v_num=0w59, train/loss_step=0.700]Epoch 0:   8%|▊         | 35/459 [01:11<14:21,  0.49it/s, v_num=0w59, train/loss_step=0.700]Epoch 0:   8%|▊         | 35/459 [01:11<14:21,  0.49it/s, v_num=0w59, train/loss_step=0.713]Epoch 0:   8%|▊         | 36/459 [01:12<14:14,  0.50it/s, v_num=0w59, train/loss_step=0.713]Epoch 0:   8%|▊         | 36/459 [01:12<14:14,  0.50it/s, v_num=0w59, train/loss_step=0.689]Epoch 0:   8%|▊         | 37/459 [01:14<14:07,  0.50it/s, v_num=0w59, train/loss_step=0.689]Epoch 0:   8%|▊         | 37/459 [01:14<14:07,  0.50it/s, v_num=0w59, train/loss_step=0.694]Epoch 0:   8%|▊         | 38/459 [01:15<14:00,  0.50it/s, v_num=0w59, train/loss_step=0.694]Epoch 0:   8%|▊         | 38/459 [01:15<14:00,  0.50it/s, v_num=0w59, train/loss_step=0.688]Epoch 0:   8%|▊         | 39/459 [01:17<13:53,  0.50it/s, v_num=0w59, train/loss_step=0.688]Epoch 0:   8%|▊         | 39/459 [01:17<13:53,  0.50it/s, v_num=0w59, train/loss_step=0.683]Epoch 0:   9%|▊         | 40/459 [01:19<13:47,  0.51it/s, v_num=0w59, train/loss_step=0.683]Epoch 0:   9%|▊         | 40/459 [01:19<13:47,  0.51it/s, v_num=0w59, train/loss_step=0.672]Epoch 0:   9%|▉         | 41/459 [01:20<13:41,  0.51it/s, v_num=0w59, train/loss_step=0.672]Epoch 0:   9%|▉         | 41/459 [01:20<13:41,  0.51it/s, v_num=0w59, train/loss_step=0.680]Epoch 0:   9%|▉         | 42/459 [01:22<13:36,  0.51it/s, v_num=0w59, train/loss_step=0.680]Epoch 0:   9%|▉         | 42/459 [01:22<13:36,  0.51it/s, v_num=0w59, train/loss_step=0.666]Epoch 0:   9%|▉         | 43/459 [01:23<13:30,  0.51it/s, v_num=0w59, train/loss_step=0.666]Epoch 0:   9%|▉         | 43/459 [01:23<13:30,  0.51it/s, v_num=0w59, train/loss_step=0.681]Epoch 0:  10%|▉         | 44/459 [01:25<13:25,  0.52it/s, v_num=0w59, train/loss_step=0.681]Epoch 0:  10%|▉         | 44/459 [01:25<13:25,  0.52it/s, v_num=0w59, train/loss_step=0.659]Epoch 0:  10%|▉         | 45/459 [01:26<13:19,  0.52it/s, v_num=0w59, train/loss_step=0.659]Epoch 0:  10%|▉         | 45/459 [01:26<13:19,  0.52it/s, v_num=0w59, train/loss_step=0.663]Epoch 0:  10%|█         | 46/459 [01:28<13:14,  0.52it/s, v_num=0w59, train/loss_step=0.663]Epoch 0:  10%|█         | 46/459 [01:28<13:14,  0.52it/s, v_num=0w59, train/loss_step=0.648]Epoch 0:  10%|█         | 47/459 [01:30<13:09,  0.52it/s, v_num=0w59, train/loss_step=0.648]Epoch 0:  10%|█         | 47/459 [01:30<13:09,  0.52it/s, v_num=0w59, train/loss_step=0.655]Epoch 0:  10%|█         | 48/459 [01:31<13:05,  0.52it/s, v_num=0w59, train/loss_step=0.655]Epoch 0:  10%|█         | 48/459 [01:31<13:05,  0.52it/s, v_num=0w59, train/loss_step=0.645]Epoch 0:  11%|█         | 49/459 [01:33<13:00,  0.53it/s, v_num=0w59, train/loss_step=0.645]Epoch 0:  11%|█         | 49/459 [01:33<13:00,  0.53it/s, v_num=0w59, train/loss_step=0.645]Epoch 0:  11%|█         | 50/459 [01:34<12:56,  0.53it/s, v_num=0w59, train/loss_step=0.645]Epoch 0:  11%|█         | 50/459 [01:34<12:56,  0.53it/s, v_num=0w59, train/loss_step=0.635]Epoch 0:  11%|█         | 51/459 [01:36<12:51,  0.53it/s, v_num=0w59, train/loss_step=0.635]Epoch 0:  11%|█         | 51/459 [01:36<12:51,  0.53it/s, v_num=0w59, train/loss_step=0.647]Epoch 0:  11%|█▏        | 52/459 [01:38<12:47,  0.53it/s, v_num=0w59, train/loss_step=0.647]Epoch 0:  11%|█▏        | 52/459 [01:38<12:47,  0.53it/s, v_num=0w59, train/loss_step=0.625]Epoch 0:  12%|█▏        | 53/459 [01:39<12:43,  0.53it/s, v_num=0w59, train/loss_step=0.625]Epoch 0:  12%|█▏        | 53/459 [01:39<12:43,  0.53it/s, v_num=0w59, train/loss_step=0.623]Epoch 0:  12%|█▏        | 54/459 [01:41<12:39,  0.53it/s, v_num=0w59, train/loss_step=0.623]Epoch 0:  12%|█▏        | 54/459 [01:41<12:39,  0.53it/s, v_num=0w59, train/loss_step=0.624]Epoch 0:  12%|█▏        | 55/459 [01:42<12:35,  0.53it/s, v_num=0w59, train/loss_step=0.624]Epoch 0:  12%|█▏        | 55/459 [01:42<12:35,  0.53it/s, v_num=0w59, train/loss_step=0.645]Epoch 0:  12%|█▏        | 56/459 [01:44<12:32,  0.54it/s, v_num=0w59, train/loss_step=0.645]Epoch 0:  12%|█▏        | 56/459 [01:44<12:32,  0.54it/s, v_num=0w59, train/loss_step=0.601]Epoch 0:  12%|█▏        | 57/459 [01:46<12:28,  0.54it/s, v_num=0w59, train/loss_step=0.601]Epoch 0:  12%|█▏        | 57/459 [01:46<12:28,  0.54it/s, v_num=0w59, train/loss_step=0.600]Epoch 0:  13%|█▎        | 58/459 [01:47<12:24,  0.54it/s, v_num=0w59, train/loss_step=0.600]Epoch 0:  13%|█▎        | 58/459 [01:47<12:24,  0.54it/s, v_num=0w59, train/loss_step=0.603]Epoch 0:  13%|█▎        | 59/459 [01:49<12:21,  0.54it/s, v_num=0w59, train/loss_step=0.603]Epoch 0:  13%|█▎        | 59/459 [01:49<12:21,  0.54it/s, v_num=0w59, train/loss_step=0.595]Epoch 0:  13%|█▎        | 60/459 [01:50<12:17,  0.54it/s, v_num=0w59, train/loss_step=0.595]Epoch 0:  13%|█▎        | 60/459 [01:50<12:17,  0.54it/s, v_num=0w59, train/loss_step=0.591]Epoch 0:  13%|█▎        | 61/459 [01:52<12:14,  0.54it/s, v_num=0w59, train/loss_step=0.591]Epoch 0:  13%|█▎        | 61/459 [01:52<12:14,  0.54it/s, v_num=0w59, train/loss_step=0.575]Epoch 0:  14%|█▎        | 62/459 [01:54<12:11,  0.54it/s, v_num=0w59, train/loss_step=0.575]Epoch 0:  14%|█▎        | 62/459 [01:54<12:11,  0.54it/s, v_num=0w59, train/loss_step=0.573]Epoch 0:  14%|█▎        | 63/459 [01:55<12:08,  0.54it/s, v_num=0w59, train/loss_step=0.573]Epoch 0:  14%|█▎        | 63/459 [01:55<12:08,  0.54it/s, v_num=0w59, train/loss_step=0.569]Epoch 0:  14%|█▍        | 64/459 [01:57<12:04,  0.54it/s, v_num=0w59, train/loss_step=0.569]Epoch 0:  14%|█▍        | 64/459 [01:57<12:04,  0.54it/s, v_num=0w59, train/loss_step=0.567]Epoch 0:  14%|█▍        | 65/459 [01:59<12:01,  0.55it/s, v_num=0w59, train/loss_step=0.567]Epoch 0:  14%|█▍        | 65/459 [01:59<12:01,  0.55it/s, v_num=0w59, train/loss_step=0.555]Epoch 0:  14%|█▍        | 66/459 [02:00<11:58,  0.55it/s, v_num=0w59, train/loss_step=0.555]Epoch 0:  14%|█▍        | 66/459 [02:00<11:58,  0.55it/s, v_num=0w59, train/loss_step=0.558]Epoch 0:  15%|█▍        | 67/459 [02:02<11:55,  0.55it/s, v_num=0w59, train/loss_step=0.558]Epoch 0:  15%|█▍        | 67/459 [02:02<11:55,  0.55it/s, v_num=0w59, train/loss_step=0.556]Epoch 0:  15%|█▍        | 68/459 [02:03<11:52,  0.55it/s, v_num=0w59, train/loss_step=0.556]Epoch 0:  15%|█▍        | 68/459 [02:03<11:52,  0.55it/s, v_num=0w59, train/loss_step=0.542]Epoch 0:  15%|█▌        | 69/459 [02:05<11:49,  0.55it/s, v_num=0w59, train/loss_step=0.542]Epoch 0:  15%|█▌        | 69/459 [02:05<11:49,  0.55it/s, v_num=0w59, train/loss_step=0.542]Epoch 0:  15%|█▌        | 70/459 [02:07<11:46,  0.55it/s, v_num=0w59, train/loss_step=0.542]Epoch 0:  15%|█▌        | 70/459 [02:07<11:46,  0.55it/s, v_num=0w59, train/loss_step=0.533]Epoch 0:  15%|█▌        | 71/459 [02:08<11:43,  0.55it/s, v_num=0w59, train/loss_step=0.533]Epoch 0:  15%|█▌        | 71/459 [02:08<11:43,  0.55it/s, v_num=0w59, train/loss_step=0.529]Epoch 0:  16%|█▌        | 72/459 [02:10<11:40,  0.55it/s, v_num=0w59, train/loss_step=0.529]Epoch 0:  16%|█▌        | 72/459 [02:10<11:40,  0.55it/s, v_num=0w59, train/loss_step=0.520]Epoch 0:  16%|█▌        | 73/459 [02:11<11:37,  0.55it/s, v_num=0w59, train/loss_step=0.520]Epoch 0:  16%|█▌        | 73/459 [02:11<11:37,  0.55it/s, v_num=0w59, train/loss_step=0.534]Epoch 0:  16%|█▌        | 74/459 [02:13<11:34,  0.55it/s, v_num=0w59, train/loss_step=0.534]Epoch 0:  16%|█▌        | 74/459 [02:13<11:34,  0.55it/s, v_num=0w59, train/loss_step=0.521]Epoch 0:  16%|█▋        | 75/459 [02:15<11:31,  0.55it/s, v_num=0w59, train/loss_step=0.521]Epoch 0:  16%|█▋        | 75/459 [02:15<11:31,  0.55it/s, v_num=0w59, train/loss_step=0.509]Epoch 0:  17%|█▋        | 76/459 [02:16<11:29,  0.56it/s, v_num=0w59, train/loss_step=0.509]Epoch 0:  17%|█▋        | 76/459 [02:16<11:29,  0.56it/s, v_num=0w59, train/loss_step=0.510]Epoch 0:  17%|█▋        | 77/459 [02:18<11:26,  0.56it/s, v_num=0w59, train/loss_step=0.510]Epoch 0:  17%|█▋        | 77/459 [02:18<11:26,  0.56it/s, v_num=0w59, train/loss_step=0.514]Epoch 0:  17%|█▋        | 78/459 [02:19<11:23,  0.56it/s, v_num=0w59, train/loss_step=0.514]Epoch 0:  17%|█▋        | 78/459 [02:19<11:23,  0.56it/s, v_num=0w59, train/loss_step=0.511]Epoch 0:  17%|█▋        | 79/459 [02:21<11:21,  0.56it/s, v_num=0w59, train/loss_step=0.511]Epoch 0:  17%|█▋        | 79/459 [02:21<11:21,  0.56it/s, v_num=0w59, train/loss_step=0.516]Epoch 0:  17%|█▋        | 80/459 [02:23<11:18,  0.56it/s, v_num=0w59, train/loss_step=0.516]Epoch 0:  17%|█▋        | 80/459 [02:23<11:18,  0.56it/s, v_num=0w59, train/loss_step=0.492]Epoch 0:  18%|█▊        | 81/459 [02:24<11:15,  0.56it/s, v_num=0w59, train/loss_step=0.492]Epoch 0:  18%|█▊        | 81/459 [02:24<11:15,  0.56it/s, v_num=0w59, train/loss_step=0.491]Epoch 0:  18%|█▊        | 82/459 [02:26<11:13,  0.56it/s, v_num=0w59, train/loss_step=0.491]Epoch 0:  18%|█▊        | 82/459 [02:26<11:13,  0.56it/s, v_num=0w59, train/loss_step=0.488]Epoch 0:  18%|█▊        | 83/459 [02:28<11:10,  0.56it/s, v_num=0w59, train/loss_step=0.488]Epoch 0:  18%|█▊        | 83/459 [02:28<11:10,  0.56it/s, v_num=0w59, train/loss_step=0.486]Epoch 0:  18%|█▊        | 84/459 [02:29<11:08,  0.56it/s, v_num=0w59, train/loss_step=0.486]Epoch 0:  18%|█▊        | 84/459 [02:29<11:08,  0.56it/s, v_num=0w59, train/loss_step=0.465]Epoch 0:  19%|█▊        | 85/459 [02:31<11:05,  0.56it/s, v_num=0w59, train/loss_step=0.465]Epoch 0:  19%|█▊        | 85/459 [02:31<11:05,  0.56it/s, v_num=0w59, train/loss_step=0.470]Epoch 0:  19%|█▊        | 86/459 [02:32<11:03,  0.56it/s, v_num=0w59, train/loss_step=0.470]Epoch 0:  19%|█▊        | 86/459 [02:32<11:03,  0.56it/s, v_num=0w59, train/loss_step=0.465]Epoch 0:  19%|█▉        | 87/459 [02:34<11:00,  0.56it/s, v_num=0w59, train/loss_step=0.465]Epoch 0:  19%|█▉        | 87/459 [02:34<11:00,  0.56it/s, v_num=0w59, train/loss_step=0.463]Epoch 0:  19%|█▉        | 88/459 [02:36<10:58,  0.56it/s, v_num=0w59, train/loss_step=0.463]Epoch 0:  19%|█▉        | 88/459 [02:36<10:58,  0.56it/s, v_num=0w59, train/loss_step=0.459]Epoch 0:  19%|█▉        | 89/459 [02:37<10:55,  0.56it/s, v_num=0w59, train/loss_step=0.459]Epoch 0:  19%|█▉        | 89/459 [02:37<10:55,  0.56it/s, v_num=0w59, train/loss_step=0.455]Epoch 0:  20%|█▉        | 90/459 [02:39<10:53,  0.56it/s, v_num=0w59, train/loss_step=0.455]Epoch 0:  20%|█▉        | 90/459 [02:39<10:53,  0.56it/s, v_num=0w59, train/loss_step=0.446]Epoch 0:  20%|█▉        | 91/459 [02:40<10:50,  0.57it/s, v_num=0w59, train/loss_step=0.446]Epoch 0:  20%|█▉        | 91/459 [02:40<10:50,  0.57it/s, v_num=0w59, train/loss_step=0.440]Epoch 0:  20%|██        | 92/459 [02:42<10:48,  0.57it/s, v_num=0w59, train/loss_step=0.440]Epoch 0:  20%|██        | 92/459 [02:42<10:48,  0.57it/s, v_num=0w59, train/loss_step=0.443]Epoch 0:  20%|██        | 93/459 [02:44<10:46,  0.57it/s, v_num=0w59, train/loss_step=0.443]Epoch 0:  20%|██        | 93/459 [02:44<10:46,  0.57it/s, v_num=0w59, train/loss_step=0.432]Epoch 0:  20%|██        | 94/459 [02:45<10:43,  0.57it/s, v_num=0w59, train/loss_step=0.432]Epoch 0:  20%|██        | 94/459 [02:45<10:43,  0.57it/s, v_num=0w59, train/loss_step=0.433]Epoch 0:  21%|██        | 95/459 [02:47<10:41,  0.57it/s, v_num=0w59, train/loss_step=0.433]Epoch 0:  21%|██        | 95/459 [02:47<10:41,  0.57it/s, v_num=0w59, train/loss_step=0.431]Epoch 0:  21%|██        | 96/459 [02:49<10:39,  0.57it/s, v_num=0w59, train/loss_step=0.431]Epoch 0:  21%|██        | 96/459 [02:49<10:39,  0.57it/s, v_num=0w59, train/loss_step=0.423]Epoch 0:  21%|██        | 97/459 [02:50<10:36,  0.57it/s, v_num=0w59, train/loss_step=0.423]Epoch 0:  21%|██        | 97/459 [02:50<10:36,  0.57it/s, v_num=0w59, train/loss_step=0.412]Epoch 0:  21%|██▏       | 98/459 [02:52<10:34,  0.57it/s, v_num=0w59, train/loss_step=0.412]Epoch 0:  21%|██▏       | 98/459 [02:52<10:34,  0.57it/s, v_num=0w59, train/loss_step=0.416]Epoch 0:  22%|██▏       | 99/459 [02:53<10:32,  0.57it/s, v_num=0w59, train/loss_step=0.416]Epoch 0:  22%|██▏       | 99/459 [02:53<10:32,  0.57it/s, v_num=0w59, train/loss_step=0.409]Epoch 0:  22%|██▏       | 100/459 [02:55<10:29,  0.57it/s, v_num=0w59, train/loss_step=0.409]Epoch 0:  22%|██▏       | 100/459 [02:55<10:29,  0.57it/s, v_num=0w59, train/loss_step=0.412]Epoch 0:  22%|██▏       | 101/459 [02:57<10:27,  0.57it/s, v_num=0w59, train/loss_step=0.412]Epoch 0:  22%|██▏       | 101/459 [02:57<10:27,  0.57it/s, v_num=0w59, train/loss_step=0.399]Epoch 0:  22%|██▏       | 102/459 [02:58<10:25,  0.57it/s, v_num=0w59, train/loss_step=0.399]Epoch 0:  22%|██▏       | 102/459 [02:58<10:25,  0.57it/s, v_num=0w59, train/loss_step=0.385]Epoch 0:  22%|██▏       | 103/459 [03:00<10:23,  0.57it/s, v_num=0w59, train/loss_step=0.385]Epoch 0:  22%|██▏       | 103/459 [03:00<10:23,  0.57it/s, v_num=0w59, train/loss_step=0.394]Epoch 0:  23%|██▎       | 104/459 [03:01<10:20,  0.57it/s, v_num=0w59, train/loss_step=0.394]Epoch 0:  23%|██▎       | 104/459 [03:01<10:20,  0.57it/s, v_num=0w59, train/loss_step=0.387]Epoch 0:  23%|██▎       | 105/459 [03:03<10:18,  0.57it/s, v_num=0w59, train/loss_step=0.387]Epoch 0:  23%|██▎       | 105/459 [03:03<10:18,  0.57it/s, v_num=0w59, train/loss_step=0.374]Epoch 0:  23%|██▎       | 106/459 [03:05<10:16,  0.57it/s, v_num=0w59, train/loss_step=0.374]Epoch 0:  23%|██▎       | 106/459 [03:05<10:16,  0.57it/s, v_num=0w59, train/loss_step=0.375]Epoch 0:  23%|██▎       | 107/459 [03:06<10:14,  0.57it/s, v_num=0w59, train/loss_step=0.375]Epoch 0:  23%|██▎       | 107/459 [03:06<10:14,  0.57it/s, v_num=0w59, train/loss_step=0.376]Epoch 0:  24%|██▎       | 108/459 [03:08<10:12,  0.57it/s, v_num=0w59, train/loss_step=0.376]Epoch 0:  24%|██▎       | 108/459 [03:08<10:12,  0.57it/s, v_num=0w59, train/loss_step=0.360]Epoch 0:  24%|██▎       | 109/459 [03:09<10:09,  0.57it/s, v_num=0w59, train/loss_step=0.360]Epoch 0:  24%|██▎       | 109/459 [03:09<10:09,  0.57it/s, v_num=0w59, train/loss_step=0.356]Epoch 0:  24%|██▍       | 110/459 [03:11<10:07,  0.57it/s, v_num=0w59, train/loss_step=0.356]Epoch 0:  24%|██▍       | 110/459 [03:11<10:07,  0.57it/s, v_num=0w59, train/loss_step=0.345]Epoch 0:  24%|██▍       | 111/459 [03:13<10:05,  0.57it/s, v_num=0w59, train/loss_step=0.345]Epoch 0:  24%|██▍       | 111/459 [03:13<10:05,  0.57it/s, v_num=0w59, train/loss_step=0.352]Epoch 0:  24%|██▍       | 112/459 [03:14<10:03,  0.57it/s, v_num=0w59, train/loss_step=0.352]Epoch 0:  24%|██▍       | 112/459 [03:14<10:03,  0.57it/s, v_num=0w59, train/loss_step=0.393]Epoch 0:  25%|██▍       | 113/459 [03:16<10:01,  0.58it/s, v_num=0w59, train/loss_step=0.393]Epoch 0:  25%|██▍       | 113/459 [03:16<10:01,  0.58it/s, v_num=0w59, train/loss_step=0.336]Epoch 0:  25%|██▍       | 114/459 [03:18<09:59,  0.58it/s, v_num=0w59, train/loss_step=0.336]Epoch 0:  25%|██▍       | 114/459 [03:18<09:59,  0.58it/s, v_num=0w59, train/loss_step=0.331]Epoch 0:  25%|██▌       | 115/459 [03:19<09:57,  0.58it/s, v_num=0w59, train/loss_step=0.331]Epoch 0:  25%|██▌       | 115/459 [03:19<09:57,  0.58it/s, v_num=0w59, train/loss_step=0.328]Epoch 0:  25%|██▌       | 116/459 [03:21<09:55,  0.58it/s, v_num=0w59, train/loss_step=0.328]Epoch 0:  25%|██▌       | 116/459 [03:21<09:55,  0.58it/s, v_num=0w59, train/loss_step=0.335]Epoch 0:  25%|██▌       | 117/459 [03:22<09:52,  0.58it/s, v_num=0w59, train/loss_step=0.335]Epoch 0:  25%|██▌       | 117/459 [03:22<09:52,  0.58it/s, v_num=0w59, train/loss_step=0.321]Epoch 0:  26%|██▌       | 118/459 [03:24<09:50,  0.58it/s, v_num=0w59, train/loss_step=0.321]Epoch 0:  26%|██▌       | 118/459 [03:24<09:50,  0.58it/s, v_num=0w59, train/loss_step=0.323]Epoch 0:  26%|██▌       | 119/459 [03:26<09:48,  0.58it/s, v_num=0w59, train/loss_step=0.323]Epoch 0:  26%|██▌       | 119/459 [03:26<09:48,  0.58it/s, v_num=0w59, train/loss_step=0.326]Epoch 0:  26%|██▌       | 120/459 [03:27<09:46,  0.58it/s, v_num=0w59, train/loss_step=0.326]Epoch 0:  26%|██▌       | 120/459 [03:27<09:46,  0.58it/s, v_num=0w59, train/loss_step=0.312]Epoch 0:  26%|██▋       | 121/459 [03:29<09:44,  0.58it/s, v_num=0w59, train/loss_step=0.312]Epoch 0:  26%|██▋       | 121/459 [03:29<09:44,  0.58it/s, v_num=0w59, train/loss_step=0.313]Epoch 0:  27%|██▋       | 122/459 [03:30<09:42,  0.58it/s, v_num=0w59, train/loss_step=0.313]Epoch 0:  27%|██▋       | 122/459 [03:30<09:42,  0.58it/s, v_num=0w59, train/loss_step=0.303]Epoch 0:  27%|██▋       | 123/459 [03:32<09:40,  0.58it/s, v_num=0w59, train/loss_step=0.303]Epoch 0:  27%|██▋       | 123/459 [03:32<09:40,  0.58it/s, v_num=0w59, train/loss_step=0.301]Epoch 0:  27%|██▋       | 124/459 [03:34<09:38,  0.58it/s, v_num=0w59, train/loss_step=0.301]Epoch 0:  27%|██▋       | 124/459 [03:34<09:38,  0.58it/s, v_num=0w59, train/loss_step=0.294]Epoch 0:  27%|██▋       | 125/459 [03:35<09:36,  0.58it/s, v_num=0w59, train/loss_step=0.294]Epoch 0:  27%|██▋       | 125/459 [03:35<09:36,  0.58it/s, v_num=0w59, train/loss_step=0.292]Epoch 0:  27%|██▋       | 126/459 [03:37<09:34,  0.58it/s, v_num=0w59, train/loss_step=0.292]Epoch 0:  27%|██▋       | 126/459 [03:37<09:34,  0.58it/s, v_num=0w59, train/loss_step=0.290]Epoch 0:  28%|██▊       | 127/459 [03:38<09:32,  0.58it/s, v_num=0w59, train/loss_step=0.290]Epoch 0:  28%|██▊       | 127/459 [03:38<09:32,  0.58it/s, v_num=0w59, train/loss_step=0.284]Epoch 0:  28%|██▊       | 128/459 [03:40<09:30,  0.58it/s, v_num=0w59, train/loss_step=0.284]Epoch 0:  28%|██▊       | 128/459 [03:40<09:30,  0.58it/s, v_num=0w59, train/loss_step=0.268]Epoch 0:  28%|██▊       | 129/459 [03:42<09:28,  0.58it/s, v_num=0w59, train/loss_step=0.268]Epoch 0:  28%|██▊       | 129/459 [03:42<09:28,  0.58it/s, v_num=0w59, train/loss_step=0.264]Epoch 0:  28%|██▊       | 130/459 [03:43<09:26,  0.58it/s, v_num=0w59, train/loss_step=0.264]Epoch 0:  28%|██▊       | 130/459 [03:43<09:26,  0.58it/s, v_num=0w59, train/loss_step=0.257]Epoch 0:  29%|██▊       | 131/459 [03:45<09:24,  0.58it/s, v_num=0w59, train/loss_step=0.257]Epoch 0:  29%|██▊       | 131/459 [03:45<09:24,  0.58it/s, v_num=0w59, train/loss_step=0.252]Epoch 0:  29%|██▉       | 132/459 [03:46<09:22,  0.58it/s, v_num=0w59, train/loss_step=0.252]Epoch 0:  29%|██▉       | 132/459 [03:46<09:22,  0.58it/s, v_num=0w59, train/loss_step=0.246]Epoch 0:  29%|██▉       | 133/459 [03:48<09:20,  0.58it/s, v_num=0w59, train/loss_step=0.246]Epoch 0:  29%|██▉       | 133/459 [03:48<09:20,  0.58it/s, v_num=0w59, train/loss_step=0.244]Epoch 0:  29%|██▉       | 134/459 [03:50<09:18,  0.58it/s, v_num=0w59, train/loss_step=0.244]Epoch 0:  29%|██▉       | 134/459 [03:50<09:18,  0.58it/s, v_num=0w59, train/loss_step=0.232]Epoch 0:  29%|██▉       | 135/459 [03:51<09:16,  0.58it/s, v_num=0w59, train/loss_step=0.232]Epoch 0:  29%|██▉       | 135/459 [03:51<09:16,  0.58it/s, v_num=0w59, train/loss_step=0.231]Epoch 0:  30%|██▉       | 136/459 [03:53<09:14,  0.58it/s, v_num=0w59, train/loss_step=0.231]Epoch 0:  30%|██▉       | 136/459 [03:53<09:14,  0.58it/s, v_num=0w59, train/loss_step=0.226]Epoch 0:  30%|██▉       | 137/459 [03:54<09:12,  0.58it/s, v_num=0w59, train/loss_step=0.226]Epoch 0:  30%|██▉       | 137/459 [03:54<09:12,  0.58it/s, v_num=0w59, train/loss_step=0.218]Epoch 0:  30%|███       | 138/459 [03:56<09:10,  0.58it/s, v_num=0w59, train/loss_step=0.218]Epoch 0:  30%|███       | 138/459 [03:56<09:10,  0.58it/s, v_num=0w59, train/loss_step=0.211]Epoch 0:  30%|███       | 139/459 [03:58<09:08,  0.58it/s, v_num=0w59, train/loss_step=0.211]Epoch 0:  30%|███       | 139/459 [03:58<09:08,  0.58it/s, v_num=0w59, train/loss_step=0.210]Epoch 0:  31%|███       | 140/459 [03:59<09:06,  0.58it/s, v_num=0w59, train/loss_step=0.210]Epoch 0:  31%|███       | 140/459 [03:59<09:06,  0.58it/s, v_num=0w59, train/loss_step=0.203]Epoch 0:  31%|███       | 141/459 [04:01<09:04,  0.58it/s, v_num=0w59, train/loss_step=0.203]Epoch 0:  31%|███       | 141/459 [04:01<09:04,  0.58it/s, v_num=0w59, train/loss_step=0.195]Epoch 0:  31%|███       | 142/459 [04:02<09:02,  0.58it/s, v_num=0w59, train/loss_step=0.195]Epoch 0:  31%|███       | 142/459 [04:02<09:02,  0.58it/s, v_num=0w59, train/loss_step=0.195]Epoch 0:  31%|███       | 143/459 [04:04<09:00,  0.58it/s, v_num=0w59, train/loss_step=0.195]Epoch 0:  31%|███       | 143/459 [04:04<09:00,  0.58it/s, v_num=0w59, train/loss_step=0.194]Epoch 0:  31%|███▏      | 144/459 [04:06<08:58,  0.58it/s, v_num=0w59, train/loss_step=0.194]Epoch 0:  31%|███▏      | 144/459 [04:06<08:58,  0.58it/s, v_num=0w59, train/loss_step=0.183]Epoch 0:  32%|███▏      | 145/459 [04:07<08:56,  0.59it/s, v_num=0w59, train/loss_step=0.183]Epoch 0:  32%|███▏      | 145/459 [04:07<08:56,  0.59it/s, v_num=0w59, train/loss_step=0.178]Epoch 0:  32%|███▏      | 146/459 [04:09<08:54,  0.59it/s, v_num=0w59, train/loss_step=0.178]Epoch 0:  32%|███▏      | 146/459 [04:09<08:54,  0.59it/s, v_num=0w59, train/loss_step=0.174]Epoch 0:  32%|███▏      | 147/459 [04:10<08:52,  0.59it/s, v_num=0w59, train/loss_step=0.174]Epoch 0:  32%|███▏      | 147/459 [04:10<08:52,  0.59it/s, v_num=0w59, train/loss_step=0.166]Epoch 0:  32%|███▏      | 148/459 [04:12<08:50,  0.59it/s, v_num=0w59, train/loss_step=0.166]Epoch 0:  32%|███▏      | 148/459 [04:12<08:50,  0.59it/s, v_num=0w59, train/loss_step=0.165]Epoch 0:  32%|███▏      | 149/459 [04:14<08:48,  0.59it/s, v_num=0w59, train/loss_step=0.165]Epoch 0:  32%|███▏      | 149/459 [04:14<08:48,  0.59it/s, v_num=0w59, train/loss_step=0.164]Epoch 0:  33%|███▎      | 150/459 [04:15<08:46,  0.59it/s, v_num=0w59, train/loss_step=0.164]Epoch 0:  33%|███▎      | 150/459 [04:15<08:46,  0.59it/s, v_num=0w59, train/loss_step=0.158]Epoch 0:  33%|███▎      | 151/459 [04:17<08:45,  0.59it/s, v_num=0w59, train/loss_step=0.158]Epoch 0:  33%|███▎      | 151/459 [04:17<08:45,  0.59it/s, v_num=0w59, train/loss_step=0.153]Epoch 0:  33%|███▎      | 152/459 [04:19<08:43,  0.59it/s, v_num=0w59, train/loss_step=0.153]Epoch 0:  33%|███▎      | 152/459 [04:19<08:43,  0.59it/s, v_num=0w59, train/loss_step=0.144]Epoch 0:  33%|███▎      | 153/459 [04:20<08:41,  0.59it/s, v_num=0w59, train/loss_step=0.144]Epoch 0:  33%|███▎      | 153/459 [04:20<08:41,  0.59it/s, v_num=0w59, train/loss_step=0.143]Epoch 0:  34%|███▎      | 154/459 [04:22<08:39,  0.59it/s, v_num=0w59, train/loss_step=0.143]Epoch 0:  34%|███▎      | 154/459 [04:22<08:39,  0.59it/s, v_num=0w59, train/loss_step=0.141]Epoch 0:  34%|███▍      | 155/459 [04:23<08:37,  0.59it/s, v_num=0w59, train/loss_step=0.141]Epoch 0:  34%|███▍      | 155/459 [04:23<08:37,  0.59it/s, v_num=0w59, train/loss_step=0.135]Epoch 0:  34%|███▍      | 156/459 [04:25<08:35,  0.59it/s, v_num=0w59, train/loss_step=0.135]Epoch 0:  34%|███▍      | 156/459 [04:25<08:35,  0.59it/s, v_num=0w59, train/loss_step=0.133]Epoch 0:  34%|███▍      | 157/459 [04:26<08:33,  0.59it/s, v_num=0w59, train/loss_step=0.133]Epoch 0:  34%|███▍      | 157/459 [04:26<08:33,  0.59it/s, v_num=0w59, train/loss_step=0.135]Epoch 0:  34%|███▍      | 158/459 [04:28<08:31,  0.59it/s, v_num=0w59, train/loss_step=0.135]Epoch 0:  34%|███▍      | 158/459 [04:28<08:31,  0.59it/s, v_num=0w59, train/loss_step=0.130]Epoch 0:  35%|███▍      | 159/459 [04:30<08:29,  0.59it/s, v_num=0w59, train/loss_step=0.130]Epoch 0:  35%|███▍      | 159/459 [04:30<08:29,  0.59it/s, v_num=0w59, train/loss_step=0.121]Epoch 0:  35%|███▍      | 160/459 [04:31<08:27,  0.59it/s, v_num=0w59, train/loss_step=0.121]Epoch 0:  35%|███▍      | 160/459 [04:31<08:27,  0.59it/s, v_num=0w59, train/loss_step=0.121]Epoch 0:  35%|███▌      | 161/459 [04:33<08:25,  0.59it/s, v_num=0w59, train/loss_step=0.121]Epoch 0:  35%|███▌      | 161/459 [04:33<08:25,  0.59it/s, v_num=0w59, train/loss_step=0.115]Epoch 0:  35%|███▌      | 162/459 [04:34<08:23,  0.59it/s, v_num=0w59, train/loss_step=0.115]Epoch 0:  35%|███▌      | 162/459 [04:34<08:23,  0.59it/s, v_num=0w59, train/loss_step=0.116]Epoch 0:  36%|███▌      | 163/459 [04:36<08:22,  0.59it/s, v_num=0w59, train/loss_step=0.116]Epoch 0:  36%|███▌      | 163/459 [04:36<08:22,  0.59it/s, v_num=0w59, train/loss_step=0.117]Epoch 0:  36%|███▌      | 164/459 [04:38<08:20,  0.59it/s, v_num=0w59, train/loss_step=0.117]Epoch 0:  36%|███▌      | 164/459 [04:38<08:20,  0.59it/s, v_num=0w59, train/loss_step=0.112]Epoch 0:  36%|███▌      | 165/459 [04:39<08:18,  0.59it/s, v_num=0w59, train/loss_step=0.112]Epoch 0:  36%|███▌      | 165/459 [04:39<08:18,  0.59it/s, v_num=0w59, train/loss_step=0.111]Epoch 0:  36%|███▌      | 166/459 [04:41<08:16,  0.59it/s, v_num=0w59, train/loss_step=0.111]Epoch 0:  36%|███▌      | 166/459 [04:41<08:16,  0.59it/s, v_num=0w59, train/loss_step=0.113]Epoch 0:  36%|███▋      | 167/459 [04:42<08:14,  0.59it/s, v_num=0w59, train/loss_step=0.113]Epoch 0:  36%|███▋      | 167/459 [04:42<08:14,  0.59it/s, v_num=0w59, train/loss_step=0.113]Epoch 0:  37%|███▋      | 168/459 [04:44<08:12,  0.59it/s, v_num=0w59, train/loss_step=0.113]Epoch 0:  37%|███▋      | 168/459 [04:44<08:12,  0.59it/s, v_num=0w59, train/loss_step=0.101]Epoch 0:  37%|███▋      | 169/459 [04:46<08:10,  0.59it/s, v_num=0w59, train/loss_step=0.101]Epoch 0:  37%|███▋      | 169/459 [04:46<08:10,  0.59it/s, v_num=0w59, train/loss_step=0.0985]Epoch 0:  37%|███▋      | 170/459 [04:47<08:08,  0.59it/s, v_num=0w59, train/loss_step=0.0985]Epoch 0:  37%|███▋      | 170/459 [04:47<08:08,  0.59it/s, v_num=0w59, train/loss_step=0.0979]Epoch 0:  37%|███▋      | 171/459 [04:49<08:07,  0.59it/s, v_num=0w59, train/loss_step=0.0979]Epoch 0:  37%|███▋      | 171/459 [04:49<08:07,  0.59it/s, v_num=0w59, train/loss_step=0.0916]Epoch 0:  37%|███▋      | 172/459 [04:50<08:05,  0.59it/s, v_num=0w59, train/loss_step=0.0916]Epoch 0:  37%|███▋      | 172/459 [04:50<08:05,  0.59it/s, v_num=0w59, train/loss_step=0.0963]Epoch 0:  38%|███▊      | 173/459 [04:52<08:03,  0.59it/s, v_num=0w59, train/loss_step=0.0963]Epoch 0:  38%|███▊      | 173/459 [04:52<08:03,  0.59it/s, v_num=0w59, train/loss_step=0.0899]Epoch 0:  38%|███▊      | 174/459 [04:53<08:01,  0.59it/s, v_num=0w59, train/loss_step=0.0899]Epoch 0:  38%|███▊      | 174/459 [04:53<08:01,  0.59it/s, v_num=0w59, train/loss_step=0.0845]Epoch 0:  38%|███▊      | 175/459 [04:55<07:59,  0.59it/s, v_num=0w59, train/loss_step=0.0845]Epoch 0:  38%|███▊      | 175/459 [04:55<07:59,  0.59it/s, v_num=0w59, train/loss_step=0.0912]Epoch 0:  38%|███▊      | 176/459 [04:57<07:57,  0.59it/s, v_num=0w59, train/loss_step=0.0912]Epoch 0:  38%|███▊      | 176/459 [04:57<07:57,  0.59it/s, v_num=0w59, train/loss_step=0.0812]Epoch 0:  39%|███▊      | 177/459 [04:58<07:55,  0.59it/s, v_num=0w59, train/loss_step=0.0812]Epoch 0:  39%|███▊      | 177/459 [04:58<07:55,  0.59it/s, v_num=0w59, train/loss_step=0.081] Epoch 0:  39%|███▉      | 178/459 [05:00<07:54,  0.59it/s, v_num=0w59, train/loss_step=0.081]Epoch 0:  39%|███▉      | 178/459 [05:00<07:54,  0.59it/s, v_num=0w59, train/loss_step=0.0823]Epoch 0:  39%|███▉      | 179/459 [05:01<07:52,  0.59it/s, v_num=0w59, train/loss_step=0.0823]Epoch 0:  39%|███▉      | 179/459 [05:01<07:52,  0.59it/s, v_num=0w59, train/loss_step=0.0787]Epoch 0:  39%|███▉      | 180/459 [05:03<07:50,  0.59it/s, v_num=0w59, train/loss_step=0.0787]Epoch 0:  39%|███▉      | 180/459 [05:03<07:50,  0.59it/s, v_num=0w59, train/loss_step=0.0774]Epoch 0:  39%|███▉      | 181/459 [05:05<07:48,  0.59it/s, v_num=0w59, train/loss_step=0.0774]Epoch 0:  39%|███▉      | 181/459 [05:05<07:48,  0.59it/s, v_num=0w59, train/loss_step=0.0765]Epoch 0:  40%|███▉      | 182/459 [05:06<07:46,  0.59it/s, v_num=0w59, train/loss_step=0.0765]Epoch 0:  40%|███▉      | 182/459 [05:06<07:46,  0.59it/s, v_num=0w59, train/loss_step=0.0752]Epoch 0:  40%|███▉      | 183/459 [05:08<07:44,  0.59it/s, v_num=0w59, train/loss_step=0.0752]Epoch 0:  40%|███▉      | 183/459 [05:08<07:44,  0.59it/s, v_num=0w59, train/loss_step=0.0782]Epoch 0:  40%|████      | 184/459 [05:09<07:43,  0.59it/s, v_num=0w59, train/loss_step=0.0782]Epoch 0:  40%|████      | 184/459 [05:09<07:43,  0.59it/s, v_num=0w59, train/loss_step=0.0711]Epoch 0:  40%|████      | 185/459 [05:11<07:41,  0.59it/s, v_num=0w59, train/loss_step=0.0711]Epoch 0:  40%|████      | 185/459 [05:11<07:41,  0.59it/s, v_num=0w59, train/loss_step=0.0695]Epoch 0:  41%|████      | 186/459 [05:12<07:39,  0.59it/s, v_num=0w59, train/loss_step=0.0695]Epoch 0:  41%|████      | 186/459 [05:12<07:39,  0.59it/s, v_num=0w59, train/loss_step=0.0661]Epoch 0:  41%|████      | 187/459 [05:14<07:37,  0.59it/s, v_num=0w59, train/loss_step=0.0661]Epoch 0:  41%|████      | 187/459 [05:14<07:37,  0.59it/s, v_num=0w59, train/loss_step=0.0697]Epoch 0:  41%|████      | 188/459 [05:16<07:35,  0.59it/s, v_num=0w59, train/loss_step=0.0697]Epoch 0:  41%|████      | 188/459 [05:16<07:35,  0.59it/s, v_num=0w59, train/loss_step=0.0707]Epoch 0:  41%|████      | 189/459 [05:17<07:33,  0.59it/s, v_num=0w59, train/loss_step=0.0707]Epoch 0:  41%|████      | 189/459 [05:17<07:33,  0.59it/s, v_num=0w59, train/loss_step=0.0679]Epoch 0:  41%|████▏     | 190/459 [05:19<07:31,  0.60it/s, v_num=0w59, train/loss_step=0.0679]Epoch 0:  41%|████▏     | 190/459 [05:19<07:31,  0.60it/s, v_num=0w59, train/loss_step=0.0665]Epoch 0:  42%|████▏     | 191/459 [05:20<07:30,  0.60it/s, v_num=0w59, train/loss_step=0.0665]Epoch 0:  42%|████▏     | 191/459 [05:20<07:30,  0.60it/s, v_num=0w59, train/loss_step=0.0678]Epoch 0:  42%|████▏     | 192/459 [05:22<07:28,  0.60it/s, v_num=0w59, train/loss_step=0.0678]Epoch 0:  42%|████▏     | 192/459 [05:22<07:28,  0.60it/s, v_num=0w59, train/loss_step=0.0679]Epoch 0:  42%|████▏     | 193/459 [05:23<07:26,  0.60it/s, v_num=0w59, train/loss_step=0.0679]Epoch 0:  42%|████▏     | 193/459 [05:23<07:26,  0.60it/s, v_num=0w59, train/loss_step=0.0664]Epoch 0:  42%|████▏     | 194/459 [05:25<07:24,  0.60it/s, v_num=0w59, train/loss_step=0.0664]Epoch 0:  42%|████▏     | 194/459 [05:25<07:24,  0.60it/s, v_num=0w59, train/loss_step=0.0623]Epoch 0:  42%|████▏     | 195/459 [05:27<07:22,  0.60it/s, v_num=0w59, train/loss_step=0.0623]Epoch 0:  42%|████▏     | 195/459 [05:27<07:22,  0.60it/s, v_num=0w59, train/loss_step=0.0642]Epoch 0:  43%|████▎     | 196/459 [05:28<07:21,  0.60it/s, v_num=0w59, train/loss_step=0.0642]Epoch 0:  43%|████▎     | 196/459 [05:28<07:21,  0.60it/s, v_num=0w59, train/loss_step=0.0716]Epoch 0:  43%|████▎     | 197/459 [05:30<07:19,  0.60it/s, v_num=0w59, train/loss_step=0.0716]Epoch 0:  43%|████▎     | 197/459 [05:30<07:19,  0.60it/s, v_num=0w59, train/loss_step=0.064] Epoch 0:  43%|████▎     | 198/459 [05:32<07:17,  0.60it/s, v_num=0w59, train/loss_step=0.064]Epoch 0:  43%|████▎     | 198/459 [05:32<07:17,  0.60it/s, v_num=0w59, train/loss_step=0.0641]Epoch 0:  43%|████▎     | 199/459 [05:33<07:15,  0.60it/s, v_num=0w59, train/loss_step=0.0641]Epoch 0:  43%|████▎     | 199/459 [05:33<07:15,  0.60it/s, v_num=0w59, train/loss_step=0.0611]Epoch 0:  44%|████▎     | 200/459 [05:35<07:14,  0.60it/s, v_num=0w59, train/loss_step=0.0611]Epoch 0:  44%|████▎     | 200/459 [05:35<07:14,  0.60it/s, v_num=0w59, train/loss_step=0.0659]Epoch 0:  44%|████▍     | 201/459 [05:36<07:12,  0.60it/s, v_num=0w59, train/loss_step=0.0659]Epoch 0:  44%|████▍     | 201/459 [05:36<07:12,  0.60it/s, v_num=0w59, train/loss_step=0.0628]Epoch 0:  44%|████▍     | 202/459 [05:38<07:10,  0.60it/s, v_num=0w59, train/loss_step=0.0628]Epoch 0:  44%|████▍     | 202/459 [05:38<07:10,  0.60it/s, v_num=0w59, train/loss_step=0.0648]Epoch 0:  44%|████▍     | 203/459 [05:39<07:08,  0.60it/s, v_num=0w59, train/loss_step=0.0648]Epoch 0:  44%|████▍     | 203/459 [05:39<07:08,  0.60it/s, v_num=0w59, train/loss_step=0.0631]Epoch 0:  44%|████▍     | 204/459 [05:41<07:06,  0.60it/s, v_num=0w59, train/loss_step=0.0631]Epoch 0:  44%|████▍     | 204/459 [05:41<07:06,  0.60it/s, v_num=0w59, train/loss_step=0.0613]Epoch 0:  45%|████▍     | 205/459 [05:43<07:05,  0.60it/s, v_num=0w59, train/loss_step=0.0613]Epoch 0:  45%|████▍     | 205/459 [05:43<07:05,  0.60it/s, v_num=0w59, train/loss_step=0.0639]Epoch 0:  45%|████▍     | 206/459 [05:44<07:03,  0.60it/s, v_num=0w59, train/loss_step=0.0639]Epoch 0:  45%|████▍     | 206/459 [05:44<07:03,  0.60it/s, v_num=0w59, train/loss_step=0.0575]Epoch 0:  45%|████▌     | 207/459 [05:46<07:01,  0.60it/s, v_num=0w59, train/loss_step=0.0575]Epoch 0:  45%|████▌     | 207/459 [05:46<07:01,  0.60it/s, v_num=0w59, train/loss_step=0.0594]Epoch 0:  45%|████▌     | 208/459 [05:47<06:59,  0.60it/s, v_num=0w59, train/loss_step=0.0594]Epoch 0:  45%|████▌     | 208/459 [05:47<06:59,  0.60it/s, v_num=0w59, train/loss_step=0.063] Epoch 0:  46%|████▌     | 209/459 [05:49<06:58,  0.60it/s, v_num=0w59, train/loss_step=0.063]Epoch 0:  46%|████▌     | 209/459 [05:49<06:58,  0.60it/s, v_num=0w59, train/loss_step=0.0575]Epoch 0:  46%|████▌     | 210/459 [05:51<06:56,  0.60it/s, v_num=0w59, train/loss_step=0.0575]Epoch 0:  46%|████▌     | 210/459 [05:51<06:56,  0.60it/s, v_num=0w59, train/loss_step=0.0555]Epoch 0:  46%|████▌     | 211/459 [05:52<06:54,  0.60it/s, v_num=0w59, train/loss_step=0.0555]Epoch 0:  46%|████▌     | 211/459 [05:52<06:54,  0.60it/s, v_num=0w59, train/loss_step=0.0607]Epoch 0:  46%|████▌     | 212/459 [05:54<06:52,  0.60it/s, v_num=0w59, train/loss_step=0.0607]Epoch 0:  46%|████▌     | 212/459 [05:54<06:52,  0.60it/s, v_num=0w59, train/loss_step=0.0619]Epoch 0:  46%|████▋     | 213/459 [05:55<06:51,  0.60it/s, v_num=0w59, train/loss_step=0.0619]Epoch 0:  46%|████▋     | 213/459 [05:55<06:51,  0.60it/s, v_num=0w59, train/loss_step=0.063] Epoch 0:  47%|████▋     | 214/459 [05:57<06:49,  0.60it/s, v_num=0w59, train/loss_step=0.063]Epoch 0:  47%|████▋     | 214/459 [05:57<06:49,  0.60it/s, v_num=0w59, train/loss_step=0.0623]Epoch 0:  47%|████▋     | 215/459 [05:59<06:47,  0.60it/s, v_num=0w59, train/loss_step=0.0623]Epoch 0:  47%|████▋     | 215/459 [05:59<06:47,  0.60it/s, v_num=0w59, train/loss_step=0.0586]Epoch 0:  47%|████▋     | 216/459 [06:00<06:45,  0.60it/s, v_num=0w59, train/loss_step=0.0586]Epoch 0:  47%|████▋     | 216/459 [06:00<06:45,  0.60it/s, v_num=0w59, train/loss_step=0.0597]Epoch 0:  47%|████▋     | 217/459 [06:02<06:43,  0.60it/s, v_num=0w59, train/loss_step=0.0597]Epoch 0:  47%|████▋     | 217/459 [06:02<06:43,  0.60it/s, v_num=0w59, train/loss_step=0.0578]Epoch 0:  47%|████▋     | 218/459 [06:03<06:42,  0.60it/s, v_num=0w59, train/loss_step=0.0578]Epoch 0:  47%|████▋     | 218/459 [06:03<06:42,  0.60it/s, v_num=0w59, train/loss_step=0.0566]Epoch 0:  48%|████▊     | 219/459 [06:05<06:40,  0.60it/s, v_num=0w59, train/loss_step=0.0566]Epoch 0:  48%|████▊     | 219/459 [06:05<06:40,  0.60it/s, v_num=0w59, train/loss_step=0.0561]Epoch 0:  48%|████▊     | 220/459 [06:06<06:38,  0.60it/s, v_num=0w59, train/loss_step=0.0561]Epoch 0:  48%|████▊     | 220/459 [06:06<06:38,  0.60it/s, v_num=0w59, train/loss_step=0.0586]Epoch 0:  48%|████▊     | 221/459 [06:08<06:36,  0.60it/s, v_num=0w59, train/loss_step=0.0586]Epoch 0:  48%|████▊     | 221/459 [06:08<06:36,  0.60it/s, v_num=0w59, train/loss_step=0.0581]Epoch 0:  48%|████▊     | 222/459 [06:10<06:35,  0.60it/s, v_num=0w59, train/loss_step=0.0581]Epoch 0:  48%|████▊     | 222/459 [06:10<06:35,  0.60it/s, v_num=0w59, train/loss_step=0.0538]Epoch 0:  49%|████▊     | 223/459 [06:11<06:33,  0.60it/s, v_num=0w59, train/loss_step=0.0538]Epoch 0:  49%|████▊     | 223/459 [06:11<06:33,  0.60it/s, v_num=0w59, train/loss_step=0.0541]Epoch 0:  49%|████▉     | 224/459 [06:13<06:31,  0.60it/s, v_num=0w59, train/loss_step=0.0541]Epoch 0:  49%|████▉     | 224/459 [06:13<06:31,  0.60it/s, v_num=0w59, train/loss_step=0.0555]Epoch 0:  49%|████▉     | 225/459 [06:14<06:29,  0.60it/s, v_num=0w59, train/loss_step=0.0555]Epoch 0:  49%|████▉     | 225/459 [06:14<06:29,  0.60it/s, v_num=0w59, train/loss_step=0.0607]Epoch 0:  49%|████▉     | 226/459 [06:16<06:28,  0.60it/s, v_num=0w59, train/loss_step=0.0607]Epoch 0:  49%|████▉     | 226/459 [06:16<06:28,  0.60it/s, v_num=0w59, train/loss_step=0.0581]Epoch 0:  49%|████▉     | 227/459 [06:17<06:26,  0.60it/s, v_num=0w59, train/loss_step=0.0581]Epoch 0:  49%|████▉     | 227/459 [06:17<06:26,  0.60it/s, v_num=0w59, train/loss_step=0.0557]Epoch 0:  50%|████▉     | 228/459 [06:19<06:24,  0.60it/s, v_num=0w59, train/loss_step=0.0557]Epoch 0:  50%|████▉     | 228/459 [06:19<06:24,  0.60it/s, v_num=0w59, train/loss_step=0.0553]Epoch 0:  50%|████▉     | 229/459 [06:21<06:22,  0.60it/s, v_num=0w59, train/loss_step=0.0553]Epoch 0:  50%|████▉     | 229/459 [06:21<06:22,  0.60it/s, v_num=0w59, train/loss_step=0.055] Epoch 0:  50%|█████     | 230/459 [06:22<06:21,  0.60it/s, v_num=0w59, train/loss_step=0.055]Epoch 0:  50%|█████     | 230/459 [06:22<06:21,  0.60it/s, v_num=0w59, train/loss_step=0.0614]Epoch 0:  50%|█████     | 231/459 [06:24<06:19,  0.60it/s, v_num=0w59, train/loss_step=0.0614]Epoch 0:  50%|█████     | 231/459 [06:24<06:19,  0.60it/s, v_num=0w59, train/loss_step=0.0526]Epoch 0:  51%|█████     | 232/459 [06:25<06:17,  0.60it/s, v_num=0w59, train/loss_step=0.0526]Epoch 0:  51%|█████     | 232/459 [06:25<06:17,  0.60it/s, v_num=0w59, train/loss_step=0.0575]Epoch 0:  51%|█████     | 233/459 [06:27<06:15,  0.60it/s, v_num=0w59, train/loss_step=0.0575]Epoch 0:  51%|█████     | 233/459 [06:27<06:15,  0.60it/s, v_num=0w59, train/loss_step=0.0544]Epoch 0:  51%|█████     | 234/459 [06:29<06:14,  0.60it/s, v_num=0w59, train/loss_step=0.0544]Epoch 0:  51%|█████     | 234/459 [06:29<06:14,  0.60it/s, v_num=0w59, train/loss_step=0.0562]Epoch 0:  51%|█████     | 235/459 [06:30<06:12,  0.60it/s, v_num=0w59, train/loss_step=0.0562]Epoch 0:  51%|█████     | 235/459 [06:30<06:12,  0.60it/s, v_num=0w59, train/loss_step=0.056] Epoch 0:  51%|█████▏    | 236/459 [06:32<06:10,  0.60it/s, v_num=0w59, train/loss_step=0.056]Epoch 0:  51%|█████▏    | 236/459 [06:32<06:10,  0.60it/s, v_num=0w59, train/loss_step=0.0565]Epoch 0:  52%|█████▏    | 237/459 [06:33<06:08,  0.60it/s, v_num=0w59, train/loss_step=0.0565]Epoch 0:  52%|█████▏    | 237/459 [06:33<06:08,  0.60it/s, v_num=0w59, train/loss_step=0.0549]Epoch 0:  52%|█████▏    | 238/459 [06:35<06:07,  0.60it/s, v_num=0w59, train/loss_step=0.0549]Epoch 0:  52%|█████▏    | 238/459 [06:35<06:07,  0.60it/s, v_num=0w59, train/loss_step=0.052] Epoch 0:  52%|█████▏    | 239/459 [06:36<06:05,  0.60it/s, v_num=0w59, train/loss_step=0.052]Epoch 0:  52%|█████▏    | 239/459 [06:36<06:05,  0.60it/s, v_num=0w59, train/loss_step=0.0523]Epoch 0:  52%|█████▏    | 240/459 [06:38<06:03,  0.60it/s, v_num=0w59, train/loss_step=0.0523]Epoch 0:  52%|█████▏    | 240/459 [06:38<06:03,  0.60it/s, v_num=0w59, train/loss_step=0.0536]Epoch 0:  53%|█████▎    | 241/459 [06:40<06:01,  0.60it/s, v_num=0w59, train/loss_step=0.0536]Epoch 0:  53%|█████▎    | 241/459 [06:40<06:01,  0.60it/s, v_num=0w59, train/loss_step=0.0587]Epoch 0:  53%|█████▎    | 242/459 [06:41<06:00,  0.60it/s, v_num=0w59, train/loss_step=0.0587]Epoch 0:  53%|█████▎    | 242/459 [06:41<06:00,  0.60it/s, v_num=0w59, train/loss_step=0.059] Epoch 0:  53%|█████▎    | 243/459 [06:43<05:58,  0.60it/s, v_num=0w59, train/loss_step=0.059]Epoch 0:  53%|█████▎    | 243/459 [06:43<05:58,  0.60it/s, v_num=0w59, train/loss_step=0.0517]Epoch 0:  53%|█████▎    | 244/459 [06:44<05:56,  0.60it/s, v_num=0w59, train/loss_step=0.0517]Epoch 0:  53%|█████▎    | 244/459 [06:44<05:56,  0.60it/s, v_num=0w59, train/loss_step=0.0527]Epoch 0:  53%|█████▎    | 245/459 [06:46<05:54,  0.60it/s, v_num=0w59, train/loss_step=0.0527]Epoch 0:  53%|█████▎    | 245/459 [06:46<05:54,  0.60it/s, v_num=0w59, train/loss_step=0.0584]Epoch 0:  54%|█████▎    | 246/459 [06:47<05:53,  0.60it/s, v_num=0w59, train/loss_step=0.0584]Epoch 0:  54%|█████▎    | 246/459 [06:47<05:53,  0.60it/s, v_num=0w59, train/loss_step=0.0538]Epoch 0:  54%|█████▍    | 247/459 [06:49<05:51,  0.60it/s, v_num=0w59, train/loss_step=0.0538]Epoch 0:  54%|█████▍    | 247/459 [06:49<05:51,  0.60it/s, v_num=0w59, train/loss_step=0.0503]Epoch 0:  54%|█████▍    | 248/459 [06:51<05:49,  0.60it/s, v_num=0w59, train/loss_step=0.0503]Epoch 0:  54%|█████▍    | 248/459 [06:51<05:49,  0.60it/s, v_num=0w59, train/loss_step=0.0528]Epoch 0:  54%|█████▍    | 249/459 [06:52<05:48,  0.60it/s, v_num=0w59, train/loss_step=0.0528]Epoch 0:  54%|█████▍    | 249/459 [06:52<05:48,  0.60it/s, v_num=0w59, train/loss_step=0.0551]Epoch 0:  54%|█████▍    | 250/459 [06:54<05:46,  0.60it/s, v_num=0w59, train/loss_step=0.0551]Epoch 0:  54%|█████▍    | 250/459 [06:54<05:46,  0.60it/s, v_num=0w59, train/loss_step=0.058] Epoch 0:  55%|█████▍    | 251/459 [06:55<05:44,  0.60it/s, v_num=0w59, train/loss_step=0.058]Epoch 0:  55%|█████▍    | 251/459 [06:55<05:44,  0.60it/s, v_num=0w59, train/loss_step=0.0561]Epoch 0:  55%|█████▍    | 252/459 [06:57<05:42,  0.60it/s, v_num=0w59, train/loss_step=0.0561]Epoch 0:  55%|█████▍    | 252/459 [06:57<05:42,  0.60it/s, v_num=0w59, train/loss_step=0.0546]Epoch 0:  55%|█████▌    | 253/459 [06:58<05:41,  0.60it/s, v_num=0w59, train/loss_step=0.0546]Epoch 0:  55%|█████▌    | 253/459 [06:58<05:41,  0.60it/s, v_num=0w59, train/loss_step=0.0523]Epoch 0:  55%|█████▌    | 254/459 [07:00<05:39,  0.60it/s, v_num=0w59, train/loss_step=0.0523]Epoch 0:  55%|█████▌    | 254/459 [07:00<05:39,  0.60it/s, v_num=0w59, train/loss_step=0.0546]Epoch 0:  56%|█████▌    | 255/459 [07:02<05:37,  0.60it/s, v_num=0w59, train/loss_step=0.0546]Epoch 0:  56%|█████▌    | 255/459 [07:02<05:37,  0.60it/s, v_num=0w59, train/loss_step=0.053] Epoch 0:  56%|█████▌    | 256/459 [07:03<05:36,  0.60it/s, v_num=0w59, train/loss_step=0.053]Epoch 0:  56%|█████▌    | 256/459 [07:03<05:36,  0.60it/s, v_num=0w59, train/loss_step=0.0529]Epoch 0:  56%|█████▌    | 257/459 [07:05<05:34,  0.60it/s, v_num=0w59, train/loss_step=0.0529]Epoch 0:  56%|█████▌    | 257/459 [07:05<05:34,  0.60it/s, v_num=0w59, train/loss_step=0.0528]Epoch 0:  56%|█████▌    | 258/459 [07:06<05:32,  0.60it/s, v_num=0w59, train/loss_step=0.0528]Epoch 0:  56%|█████▌    | 258/459 [07:06<05:32,  0.60it/s, v_num=0w59, train/loss_step=0.0539]Epoch 0:  56%|█████▋    | 259/459 [07:08<05:30,  0.60it/s, v_num=0w59, train/loss_step=0.0539]Epoch 0:  56%|█████▋    | 259/459 [07:08<05:30,  0.60it/s, v_num=0w59, train/loss_step=0.057] Epoch 0:  57%|█████▋    | 260/459 [07:10<05:29,  0.60it/s, v_num=0w59, train/loss_step=0.057]Epoch 0:  57%|█████▋    | 260/459 [07:10<05:29,  0.60it/s, v_num=0w59, train/loss_step=0.0579]Epoch 0:  57%|█████▋    | 261/459 [07:11<05:27,  0.60it/s, v_num=0w59, train/loss_step=0.0579]Epoch 0:  57%|█████▋    | 261/459 [07:11<05:27,  0.60it/s, v_num=0w59, train/loss_step=0.0514]Epoch 0:  57%|█████▋    | 262/459 [07:13<05:25,  0.60it/s, v_num=0w59, train/loss_step=0.0514]Epoch 0:  57%|█████▋    | 262/459 [07:13<05:25,  0.60it/s, v_num=0w59, train/loss_step=0.0502]Epoch 0:  57%|█████▋    | 263/459 [07:14<05:24,  0.60it/s, v_num=0w59, train/loss_step=0.0502]Epoch 0:  57%|█████▋    | 263/459 [07:14<05:24,  0.60it/s, v_num=0w59, train/loss_step=0.0502]Epoch 0:  58%|█████▊    | 264/459 [07:16<05:22,  0.60it/s, v_num=0w59, train/loss_step=0.0502]Epoch 0:  58%|█████▊    | 264/459 [07:16<05:22,  0.60it/s, v_num=0w59, train/loss_step=0.053] Epoch 0:  58%|█████▊    | 265/459 [07:18<05:20,  0.60it/s, v_num=0w59, train/loss_step=0.053]Epoch 0:  58%|█████▊    | 265/459 [07:18<05:20,  0.60it/s, v_num=0w59, train/loss_step=0.052]Epoch 0:  58%|█████▊    | 266/459 [07:19<05:18,  0.61it/s, v_num=0w59, train/loss_step=0.052]Epoch 0:  58%|█████▊    | 266/459 [07:19<05:18,  0.61it/s, v_num=0w59, train/loss_step=0.0472]Epoch 0:  58%|█████▊    | 267/459 [07:21<05:17,  0.61it/s, v_num=0w59, train/loss_step=0.0472]Epoch 0:  58%|█████▊    | 267/459 [07:21<05:17,  0.61it/s, v_num=0w59, train/loss_step=0.0506]Epoch 0:  58%|█████▊    | 268/459 [07:22<05:15,  0.61it/s, v_num=0w59, train/loss_step=0.0506]Epoch 0:  58%|█████▊    | 268/459 [07:22<05:15,  0.61it/s, v_num=0w59, train/loss_step=0.048] Epoch 0:  59%|█████▊    | 269/459 [07:24<05:13,  0.61it/s, v_num=0w59, train/loss_step=0.048]Epoch 0:  59%|█████▊    | 269/459 [07:24<05:13,  0.61it/s, v_num=0w59, train/loss_step=0.0477]Epoch 0:  59%|█████▉    | 270/459 [07:25<05:12,  0.61it/s, v_num=0w59, train/loss_step=0.0477]Epoch 0:  59%|█████▉    | 270/459 [07:25<05:12,  0.61it/s, v_num=0w59, train/loss_step=0.0525]Epoch 0:  59%|█████▉    | 271/459 [07:27<05:10,  0.61it/s, v_num=0w59, train/loss_step=0.0525]Epoch 0:  59%|█████▉    | 271/459 [07:27<05:10,  0.61it/s, v_num=0w59, train/loss_step=0.0526]Epoch 0:  59%|█████▉    | 272/459 [07:29<05:08,  0.61it/s, v_num=0w59, train/loss_step=0.0526]Epoch 0:  59%|█████▉    | 272/459 [07:29<05:08,  0.61it/s, v_num=0w59, train/loss_step=0.0532]Epoch 0:  59%|█████▉    | 273/459 [07:30<05:07,  0.61it/s, v_num=0w59, train/loss_step=0.0532]Epoch 0:  59%|█████▉    | 273/459 [07:30<05:07,  0.61it/s, v_num=0w59, train/loss_step=0.054] Epoch 0:  60%|█████▉    | 274/459 [07:32<05:05,  0.61it/s, v_num=0w59, train/loss_step=0.054]Epoch 0:  60%|█████▉    | 274/459 [07:32<05:05,  0.61it/s, v_num=0w59, train/loss_step=0.0496]Epoch 0:  60%|█████▉    | 275/459 [07:33<05:03,  0.61it/s, v_num=0w59, train/loss_step=0.0496]Epoch 0:  60%|█████▉    | 275/459 [07:33<05:03,  0.61it/s, v_num=0w59, train/loss_step=0.0518]Epoch 0:  60%|██████    | 276/459 [07:35<05:01,  0.61it/s, v_num=0w59, train/loss_step=0.0518]Epoch 0:  60%|██████    | 276/459 [07:35<05:01,  0.61it/s, v_num=0w59, train/loss_step=0.0499]Epoch 0:  60%|██████    | 277/459 [07:37<05:00,  0.61it/s, v_num=0w59, train/loss_step=0.0499]Epoch 0:  60%|██████    | 277/459 [07:37<05:00,  0.61it/s, v_num=0w59, train/loss_step=0.0536]Epoch 0:  61%|██████    | 278/459 [07:38<04:58,  0.61it/s, v_num=0w59, train/loss_step=0.0536]Epoch 0:  61%|██████    | 278/459 [07:38<04:58,  0.61it/s, v_num=0w59, train/loss_step=0.0509]Epoch 0:  61%|██████    | 279/459 [07:40<04:56,  0.61it/s, v_num=0w59, train/loss_step=0.0509]Epoch 0:  61%|██████    | 279/459 [07:40<04:56,  0.61it/s, v_num=0w59, train/loss_step=0.0502]Epoch 0:  61%|██████    | 280/459 [07:41<04:55,  0.61it/s, v_num=0w59, train/loss_step=0.0502]Epoch 0:  61%|██████    | 280/459 [07:41<04:55,  0.61it/s, v_num=0w59, train/loss_step=0.0499]Epoch 0:  61%|██████    | 281/459 [07:43<04:53,  0.61it/s, v_num=0w59, train/loss_step=0.0499]Epoch 0:  61%|██████    | 281/459 [07:43<04:53,  0.61it/s, v_num=0w59, train/loss_step=0.051] Epoch 0:  61%|██████▏   | 282/459 [07:45<04:51,  0.61it/s, v_num=0w59, train/loss_step=0.051]Epoch 0:  61%|██████▏   | 282/459 [07:45<04:51,  0.61it/s, v_num=0w59, train/loss_step=0.0514]Epoch 0:  62%|██████▏   | 283/459 [07:46<04:50,  0.61it/s, v_num=0w59, train/loss_step=0.0514]Epoch 0:  62%|██████▏   | 283/459 [07:46<04:50,  0.61it/s, v_num=0w59, train/loss_step=0.0479]Epoch 0:  62%|██████▏   | 284/459 [07:48<04:48,  0.61it/s, v_num=0w59, train/loss_step=0.0479]Epoch 0:  62%|██████▏   | 284/459 [07:48<04:48,  0.61it/s, v_num=0w59, train/loss_step=0.052] Epoch 0:  62%|██████▏   | 285/459 [07:49<04:46,  0.61it/s, v_num=0w59, train/loss_step=0.052]Epoch 0:  62%|██████▏   | 285/459 [07:49<04:46,  0.61it/s, v_num=0w59, train/loss_step=0.0507]Epoch 0:  62%|██████▏   | 286/459 [07:51<04:45,  0.61it/s, v_num=0w59, train/loss_step=0.0507]Epoch 0:  62%|██████▏   | 286/459 [07:51<04:45,  0.61it/s, v_num=0w59, train/loss_step=0.0518]Epoch 0:  63%|██████▎   | 287/459 [07:53<04:43,  0.61it/s, v_num=0w59, train/loss_step=0.0518]Epoch 0:  63%|██████▎   | 287/459 [07:53<04:43,  0.61it/s, v_num=0w59, train/loss_step=0.0556]Epoch 0:  63%|██████▎   | 288/459 [07:54<04:41,  0.61it/s, v_num=0w59, train/loss_step=0.0556]Epoch 0:  63%|██████▎   | 288/459 [07:54<04:41,  0.61it/s, v_num=0w59, train/loss_step=0.0495]Epoch 0:  63%|██████▎   | 289/459 [07:56<04:40,  0.61it/s, v_num=0w59, train/loss_step=0.0495]Epoch 0:  63%|██████▎   | 289/459 [07:56<04:40,  0.61it/s, v_num=0w59, train/loss_step=0.0479]Epoch 0:  63%|██████▎   | 290/459 [07:57<04:38,  0.61it/s, v_num=0w59, train/loss_step=0.0479]Epoch 0:  63%|██████▎   | 290/459 [07:57<04:38,  0.61it/s, v_num=0w59, train/loss_step=0.0535]Epoch 0:  63%|██████▎   | 291/459 [07:59<04:36,  0.61it/s, v_num=0w59, train/loss_step=0.0535]Epoch 0:  63%|██████▎   | 291/459 [07:59<04:36,  0.61it/s, v_num=0w59, train/loss_step=0.0496]Epoch 0:  64%|██████▎   | 292/459 [08:01<04:35,  0.61it/s, v_num=0w59, train/loss_step=0.0496]Epoch 0:  64%|██████▎   | 292/459 [08:01<04:35,  0.61it/s, v_num=0w59, train/loss_step=0.0487]Epoch 0:  64%|██████▍   | 293/459 [08:02<04:33,  0.61it/s, v_num=0w59, train/loss_step=0.0487]Epoch 0:  64%|██████▍   | 293/459 [08:02<04:33,  0.61it/s, v_num=0w59, train/loss_step=0.0521]Epoch 0:  64%|██████▍   | 294/459 [08:04<04:31,  0.61it/s, v_num=0w59, train/loss_step=0.0521]Epoch 0:  64%|██████▍   | 294/459 [08:04<04:31,  0.61it/s, v_num=0w59, train/loss_step=0.0508]Epoch 0:  64%|██████▍   | 295/459 [08:05<04:30,  0.61it/s, v_num=0w59, train/loss_step=0.0508]Epoch 0:  64%|██████▍   | 295/459 [08:05<04:30,  0.61it/s, v_num=0w59, train/loss_step=0.0522]Epoch 0:  64%|██████▍   | 296/459 [08:07<04:28,  0.61it/s, v_num=0w59, train/loss_step=0.0522]Epoch 0:  64%|██████▍   | 296/459 [08:07<04:28,  0.61it/s, v_num=0w59, train/loss_step=0.0495]Epoch 0:  65%|██████▍   | 297/459 [08:08<04:26,  0.61it/s, v_num=0w59, train/loss_step=0.0495]Epoch 0:  65%|██████▍   | 297/459 [08:08<04:26,  0.61it/s, v_num=0w59, train/loss_step=0.0472]Epoch 0:  65%|██████▍   | 298/459 [08:10<04:25,  0.61it/s, v_num=0w59, train/loss_step=0.0472]Epoch 0:  65%|██████▍   | 298/459 [08:10<04:25,  0.61it/s, v_num=0w59, train/loss_step=0.0487]Epoch 0:  65%|██████▌   | 299/459 [08:12<04:23,  0.61it/s, v_num=0w59, train/loss_step=0.0487]Epoch 0:  65%|██████▌   | 299/459 [08:12<04:23,  0.61it/s, v_num=0w59, train/loss_step=0.0487]Epoch 0:  65%|██████▌   | 300/459 [08:13<04:21,  0.61it/s, v_num=0w59, train/loss_step=0.0487]Epoch 0:  65%|██████▌   | 300/459 [08:13<04:21,  0.61it/s, v_num=0w59, train/loss_step=0.0517]Epoch 0:  66%|██████▌   | 301/459 [08:15<04:20,  0.61it/s, v_num=0w59, train/loss_step=0.0517]Epoch 0:  66%|██████▌   | 301/459 [08:15<04:20,  0.61it/s, v_num=0w59, train/loss_step=0.0496]Epoch 0:  66%|██████▌   | 302/459 [08:16<04:18,  0.61it/s, v_num=0w59, train/loss_step=0.0496]Epoch 0:  66%|██████▌   | 302/459 [08:16<04:18,  0.61it/s, v_num=0w59, train/loss_step=0.0525]Epoch 0:  66%|██████▌   | 303/459 [08:18<04:16,  0.61it/s, v_num=0w59, train/loss_step=0.0525]Epoch 0:  66%|██████▌   | 303/459 [08:18<04:16,  0.61it/s, v_num=0w59, train/loss_step=0.0493]Epoch 0:  66%|██████▌   | 304/459 [08:20<04:15,  0.61it/s, v_num=0w59, train/loss_step=0.0493]Epoch 0:  66%|██████▌   | 304/459 [08:20<04:15,  0.61it/s, v_num=0w59, train/loss_step=0.0517]Epoch 0:  66%|██████▋   | 305/459 [08:21<04:13,  0.61it/s, v_num=0w59, train/loss_step=0.0517]Epoch 0:  66%|██████▋   | 305/459 [08:21<04:13,  0.61it/s, v_num=0w59, train/loss_step=0.0459]Epoch 0:  67%|██████▋   | 306/459 [08:23<04:11,  0.61it/s, v_num=0w59, train/loss_step=0.0459]Epoch 0:  67%|██████▋   | 306/459 [08:23<04:11,  0.61it/s, v_num=0w59, train/loss_step=0.0504]Epoch 0:  67%|██████▋   | 307/459 [08:24<04:10,  0.61it/s, v_num=0w59, train/loss_step=0.0504]Epoch 0:  67%|██████▋   | 307/459 [08:24<04:10,  0.61it/s, v_num=0w59, train/loss_step=0.0493]Epoch 0:  67%|██████▋   | 308/459 [08:26<04:08,  0.61it/s, v_num=0w59, train/loss_step=0.0493]Epoch 0:  67%|██████▋   | 308/459 [08:26<04:08,  0.61it/s, v_num=0w59, train/loss_step=0.051] Epoch 0:  67%|██████▋   | 309/459 [08:28<04:06,  0.61it/s, v_num=0w59, train/loss_step=0.051]Epoch 0:  67%|██████▋   | 309/459 [08:28<04:06,  0.61it/s, v_num=0w59, train/loss_step=0.0508]Epoch 0:  68%|██████▊   | 310/459 [08:29<04:05,  0.61it/s, v_num=0w59, train/loss_step=0.0508]Epoch 0:  68%|██████▊   | 310/459 [08:29<04:05,  0.61it/s, v_num=0w59, train/loss_step=0.0487]Epoch 0:  68%|██████▊   | 311/459 [08:31<04:03,  0.61it/s, v_num=0w59, train/loss_step=0.0487]Epoch 0:  68%|██████▊   | 311/459 [08:31<04:03,  0.61it/s, v_num=0w59, train/loss_step=0.0455]Epoch 0:  68%|██████▊   | 312/459 [08:32<04:01,  0.61it/s, v_num=0w59, train/loss_step=0.0455]Epoch 0:  68%|██████▊   | 312/459 [08:32<04:01,  0.61it/s, v_num=0w59, train/loss_step=0.046] Epoch 0:  68%|██████▊   | 313/459 [08:34<04:00,  0.61it/s, v_num=0w59, train/loss_step=0.046]Epoch 0:  68%|██████▊   | 313/459 [08:34<04:00,  0.61it/s, v_num=0w59, train/loss_step=0.0491]Epoch 0:  68%|██████▊   | 314/459 [08:36<03:58,  0.61it/s, v_num=0w59, train/loss_step=0.0491]Epoch 0:  68%|██████▊   | 314/459 [08:36<03:58,  0.61it/s, v_num=0w59, train/loss_step=0.0478]Epoch 0:  69%|██████▊   | 315/459 [08:37<03:56,  0.61it/s, v_num=0w59, train/loss_step=0.0478]Epoch 0:  69%|██████▊   | 315/459 [08:37<03:56,  0.61it/s, v_num=0w59, train/loss_step=0.054] Epoch 0:  69%|██████▉   | 316/459 [08:39<03:55,  0.61it/s, v_num=0w59, train/loss_step=0.054]Epoch 0:  69%|██████▉   | 316/459 [08:39<03:55,  0.61it/s, v_num=0w59, train/loss_step=0.0484]Epoch 0:  69%|██████▉   | 317/459 [08:40<03:53,  0.61it/s, v_num=0w59, train/loss_step=0.0484]Epoch 0:  69%|██████▉   | 317/459 [08:40<03:53,  0.61it/s, v_num=0w59, train/loss_step=0.0514]Epoch 0:  69%|██████▉   | 318/459 [08:42<03:51,  0.61it/s, v_num=0w59, train/loss_step=0.0514]Epoch 0:  69%|██████▉   | 318/459 [08:42<03:51,  0.61it/s, v_num=0w59, train/loss_step=0.0459]Epoch 0:  69%|██████▉   | 319/459 [08:44<03:50,  0.61it/s, v_num=0w59, train/loss_step=0.0459]Epoch 0:  69%|██████▉   | 319/459 [08:44<03:50,  0.61it/s, v_num=0w59, train/loss_step=0.0466]Epoch 0:  70%|██████▉   | 320/459 [08:45<03:48,  0.61it/s, v_num=0w59, train/loss_step=0.0466]Epoch 0:  70%|██████▉   | 320/459 [08:45<03:48,  0.61it/s, v_num=0w59, train/loss_step=0.0455]Epoch 0:  70%|██████▉   | 321/459 [08:47<03:46,  0.61it/s, v_num=0w59, train/loss_step=0.0455]Epoch 0:  70%|██████▉   | 321/459 [08:47<03:46,  0.61it/s, v_num=0w59, train/loss_step=0.0422]Epoch 0:  70%|███████   | 322/459 [08:48<03:45,  0.61it/s, v_num=0w59, train/loss_step=0.0422]Epoch 0:  70%|███████   | 322/459 [08:48<03:45,  0.61it/s, v_num=0w59, train/loss_step=0.0479]Epoch 0:  70%|███████   | 323/459 [08:50<03:43,  0.61it/s, v_num=0w59, train/loss_step=0.0479]Epoch 0:  70%|███████   | 323/459 [08:50<03:43,  0.61it/s, v_num=0w59, train/loss_step=0.0451]Epoch 0:  71%|███████   | 324/459 [08:52<03:41,  0.61it/s, v_num=0w59, train/loss_step=0.0451]Epoch 0:  71%|███████   | 324/459 [08:52<03:41,  0.61it/s, v_num=0w59, train/loss_step=0.0452]Epoch 0:  71%|███████   | 325/459 [08:53<03:40,  0.61it/s, v_num=0w59, train/loss_step=0.0452]Epoch 0:  71%|███████   | 325/459 [08:53<03:40,  0.61it/s, v_num=0w59, train/loss_step=0.0442]Epoch 0:  71%|███████   | 326/459 [08:55<03:38,  0.61it/s, v_num=0w59, train/loss_step=0.0442]Epoch 0:  71%|███████   | 326/459 [08:55<03:38,  0.61it/s, v_num=0w59, train/loss_step=0.0475]Epoch 0:  71%|███████   | 327/459 [08:56<03:36,  0.61it/s, v_num=0w59, train/loss_step=0.0475]Epoch 0:  71%|███████   | 327/459 [08:56<03:36,  0.61it/s, v_num=0w59, train/loss_step=0.0474]Epoch 0:  71%|███████▏  | 328/459 [08:58<03:35,  0.61it/s, v_num=0w59, train/loss_step=0.0474]Epoch 0:  71%|███████▏  | 328/459 [08:58<03:35,  0.61it/s, v_num=0w59, train/loss_step=0.0469]Epoch 0:  72%|███████▏  | 329/459 [09:00<03:33,  0.61it/s, v_num=0w59, train/loss_step=0.0469]Epoch 0:  72%|███████▏  | 329/459 [09:00<03:33,  0.61it/s, v_num=0w59, train/loss_step=0.0528]Epoch 0:  72%|███████▏  | 330/459 [09:01<03:31,  0.61it/s, v_num=0w59, train/loss_step=0.0528]Epoch 0:  72%|███████▏  | 330/459 [09:01<03:31,  0.61it/s, v_num=0w59, train/loss_step=0.0494]Epoch 0:  72%|███████▏  | 331/459 [09:03<03:30,  0.61it/s, v_num=0w59, train/loss_step=0.0494]Epoch 0:  72%|███████▏  | 331/459 [09:03<03:30,  0.61it/s, v_num=0w59, train/loss_step=0.0459]Epoch 0:  72%|███████▏  | 332/459 [09:04<03:28,  0.61it/s, v_num=0w59, train/loss_step=0.0459]Epoch 0:  72%|███████▏  | 332/459 [09:04<03:28,  0.61it/s, v_num=0w59, train/loss_step=0.0495]Epoch 0:  73%|███████▎  | 333/459 [09:06<03:26,  0.61it/s, v_num=0w59, train/loss_step=0.0495]Epoch 0:  73%|███████▎  | 333/459 [09:06<03:26,  0.61it/s, v_num=0w59, train/loss_step=0.0444]Epoch 0:  73%|███████▎  | 334/459 [09:08<03:25,  0.61it/s, v_num=0w59, train/loss_step=0.0444]Epoch 0:  73%|███████▎  | 334/459 [09:08<03:25,  0.61it/s, v_num=0w59, train/loss_step=0.0475]Epoch 0:  73%|███████▎  | 335/459 [09:09<03:23,  0.61it/s, v_num=0w59, train/loss_step=0.0475]Epoch 0:  73%|███████▎  | 335/459 [09:09<03:23,  0.61it/s, v_num=0w59, train/loss_step=0.0485]Epoch 0:  73%|███████▎  | 336/459 [09:11<03:21,  0.61it/s, v_num=0w59, train/loss_step=0.0485]Epoch 0:  73%|███████▎  | 336/459 [09:11<03:21,  0.61it/s, v_num=0w59, train/loss_step=0.050] Epoch 0:  73%|███████▎  | 337/459 [09:12<03:20,  0.61it/s, v_num=0w59, train/loss_step=0.050]Epoch 0:  73%|███████▎  | 337/459 [09:12<03:20,  0.61it/s, v_num=0w59, train/loss_step=0.0457]Epoch 0:  74%|███████▎  | 338/459 [09:14<03:18,  0.61it/s, v_num=0w59, train/loss_step=0.0457]Epoch 0:  74%|███████▎  | 338/459 [09:14<03:18,  0.61it/s, v_num=0w59, train/loss_step=0.0488]Epoch 0:  74%|███████▍  | 339/459 [09:16<03:16,  0.61it/s, v_num=0w59, train/loss_step=0.0488]Epoch 0:  74%|███████▍  | 339/459 [09:16<03:16,  0.61it/s, v_num=0w59, train/loss_step=0.0444]Epoch 0:  74%|███████▍  | 340/459 [09:17<03:15,  0.61it/s, v_num=0w59, train/loss_step=0.0444]Epoch 0:  74%|███████▍  | 340/459 [09:17<03:15,  0.61it/s, v_num=0w59, train/loss_step=0.0437]Epoch 0:  74%|███████▍  | 341/459 [09:19<03:13,  0.61it/s, v_num=0w59, train/loss_step=0.0437]Epoch 0:  74%|███████▍  | 341/459 [09:19<03:13,  0.61it/s, v_num=0w59, train/loss_step=0.0452]Epoch 0:  75%|███████▍  | 342/459 [09:20<03:11,  0.61it/s, v_num=0w59, train/loss_step=0.0452]Epoch 0:  75%|███████▍  | 342/459 [09:20<03:11,  0.61it/s, v_num=0w59, train/loss_step=0.0487]Epoch 0:  75%|███████▍  | 343/459 [09:22<03:10,  0.61it/s, v_num=0w59, train/loss_step=0.0487]Epoch 0:  75%|███████▍  | 343/459 [09:22<03:10,  0.61it/s, v_num=0w59, train/loss_step=0.0447]Epoch 0:  75%|███████▍  | 344/459 [09:24<03:08,  0.61it/s, v_num=0w59, train/loss_step=0.0447]Epoch 0:  75%|███████▍  | 344/459 [09:24<03:08,  0.61it/s, v_num=0w59, train/loss_step=0.047] Epoch 0:  75%|███████▌  | 345/459 [09:25<03:06,  0.61it/s, v_num=0w59, train/loss_step=0.047]Epoch 0:  75%|███████▌  | 345/459 [09:25<03:06,  0.61it/s, v_num=0w59, train/loss_step=0.0431]Epoch 0:  75%|███████▌  | 346/459 [09:27<03:05,  0.61it/s, v_num=0w59, train/loss_step=0.0431]Epoch 0:  75%|███████▌  | 346/459 [09:27<03:05,  0.61it/s, v_num=0w59, train/loss_step=0.0449]Epoch 0:  76%|███████▌  | 347/459 [09:28<03:03,  0.61it/s, v_num=0w59, train/loss_step=0.0449]Epoch 0:  76%|███████▌  | 347/459 [09:28<03:03,  0.61it/s, v_num=0w59, train/loss_step=0.0408]Epoch 0:  76%|███████▌  | 348/459 [09:30<03:01,  0.61it/s, v_num=0w59, train/loss_step=0.0408]Epoch 0:  76%|███████▌  | 348/459 [09:30<03:01,  0.61it/s, v_num=0w59, train/loss_step=0.0451]Epoch 0:  76%|███████▌  | 349/459 [09:32<03:00,  0.61it/s, v_num=0w59, train/loss_step=0.0451]Epoch 0:  76%|███████▌  | 349/459 [09:32<03:00,  0.61it/s, v_num=0w59, train/loss_step=0.0448]Epoch 0:  76%|███████▋  | 350/459 [09:33<02:58,  0.61it/s, v_num=0w59, train/loss_step=0.0448]Epoch 0:  76%|███████▋  | 350/459 [09:33<02:58,  0.61it/s, v_num=0w59, train/loss_step=0.0485]Epoch 0:  76%|███████▋  | 351/459 [09:35<02:56,  0.61it/s, v_num=0w59, train/loss_step=0.0485]Epoch 0:  76%|███████▋  | 351/459 [09:35<02:56,  0.61it/s, v_num=0w59, train/loss_step=0.0467]Epoch 0:  77%|███████▋  | 352/459 [09:36<02:55,  0.61it/s, v_num=0w59, train/loss_step=0.0467]Epoch 0:  77%|███████▋  | 352/459 [09:36<02:55,  0.61it/s, v_num=0w59, train/loss_step=0.0448]Epoch 0:  77%|███████▋  | 353/459 [09:38<02:53,  0.61it/s, v_num=0w59, train/loss_step=0.0448]Epoch 0:  77%|███████▋  | 353/459 [09:38<02:53,  0.61it/s, v_num=0w59, train/loss_step=0.0436]Epoch 0:  77%|███████▋  | 354/459 [09:39<02:52,  0.61it/s, v_num=0w59, train/loss_step=0.0436]Epoch 0:  77%|███████▋  | 354/459 [09:40<02:52,  0.61it/s, v_num=0w59, train/loss_step=0.0452]Epoch 0:  77%|███████▋  | 355/459 [09:41<02:50,  0.61it/s, v_num=0w59, train/loss_step=0.0452]Epoch 0:  77%|███████▋  | 355/459 [09:41<02:50,  0.61it/s, v_num=0w59, train/loss_step=0.0458]Epoch 0:  78%|███████▊  | 356/459 [09:43<02:48,  0.61it/s, v_num=0w59, train/loss_step=0.0458]Epoch 0:  78%|███████▊  | 356/459 [09:43<02:48,  0.61it/s, v_num=0w59, train/loss_step=0.045] Epoch 0:  78%|███████▊  | 357/459 [09:44<02:47,  0.61it/s, v_num=0w59, train/loss_step=0.045]Epoch 0:  78%|███████▊  | 357/459 [09:44<02:47,  0.61it/s, v_num=0w59, train/loss_step=0.043]Epoch 0:  78%|███████▊  | 358/459 [09:46<02:45,  0.61it/s, v_num=0w59, train/loss_step=0.043]Epoch 0:  78%|███████▊  | 358/459 [09:46<02:45,  0.61it/s, v_num=0w59, train/loss_step=0.049]Epoch 0:  78%|███████▊  | 359/459 [09:48<02:43,  0.61it/s, v_num=0w59, train/loss_step=0.049]Epoch 0:  78%|███████▊  | 359/459 [09:48<02:43,  0.61it/s, v_num=0w59, train/loss_step=0.0415]Epoch 0:  78%|███████▊  | 360/459 [09:49<02:42,  0.61it/s, v_num=0w59, train/loss_step=0.0415]Epoch 0:  78%|███████▊  | 360/459 [09:49<02:42,  0.61it/s, v_num=0w59, train/loss_step=0.0431]Epoch 0:  79%|███████▊  | 361/459 [09:51<02:40,  0.61it/s, v_num=0w59, train/loss_step=0.0431]Epoch 0:  79%|███████▊  | 361/459 [09:51<02:40,  0.61it/s, v_num=0w59, train/loss_step=0.0451]Epoch 0:  79%|███████▉  | 362/459 [09:52<02:38,  0.61it/s, v_num=0w59, train/loss_step=0.0451]Epoch 0:  79%|███████▉  | 362/459 [09:52<02:38,  0.61it/s, v_num=0w59, train/loss_step=0.0465]Epoch 0:  79%|███████▉  | 363/459 [09:54<02:37,  0.61it/s, v_num=0w59, train/loss_step=0.0465]Epoch 0:  79%|███████▉  | 363/459 [09:54<02:37,  0.61it/s, v_num=0w59, train/loss_step=0.0461]Epoch 0:  79%|███████▉  | 364/459 [09:55<02:35,  0.61it/s, v_num=0w59, train/loss_step=0.0461]Epoch 0:  79%|███████▉  | 364/459 [09:55<02:35,  0.61it/s, v_num=0w59, train/loss_step=0.0453]Epoch 0:  80%|███████▉  | 365/459 [09:57<02:33,  0.61it/s, v_num=0w59, train/loss_step=0.0453]Epoch 0:  80%|███████▉  | 365/459 [09:57<02:33,  0.61it/s, v_num=0w59, train/loss_step=0.0449]Epoch 0:  80%|███████▉  | 366/459 [09:59<02:32,  0.61it/s, v_num=0w59, train/loss_step=0.0449]Epoch 0:  80%|███████▉  | 366/459 [09:59<02:32,  0.61it/s, v_num=0w59, train/loss_step=0.048] Epoch 0:  80%|███████▉  | 367/459 [10:00<02:30,  0.61it/s, v_num=0w59, train/loss_step=0.048]Epoch 0:  80%|███████▉  | 367/459 [10:00<02:30,  0.61it/s, v_num=0w59, train/loss_step=0.049]Epoch 0:  80%|████████  | 368/459 [10:02<02:28,  0.61it/s, v_num=0w59, train/loss_step=0.049]Epoch 0:  80%|████████  | 368/459 [10:02<02:28,  0.61it/s, v_num=0w59, train/loss_step=0.0426]Epoch 0:  80%|████████  | 369/459 [10:03<02:27,  0.61it/s, v_num=0w59, train/loss_step=0.0426]Epoch 0:  80%|████████  | 369/459 [10:03<02:27,  0.61it/s, v_num=0w59, train/loss_step=0.0455]Epoch 0:  81%|████████  | 370/459 [10:05<02:25,  0.61it/s, v_num=0w59, train/loss_step=0.0455]Epoch 0:  81%|████████  | 370/459 [10:05<02:25,  0.61it/s, v_num=0w59, train/loss_step=0.0431]Epoch 0:  81%|████████  | 371/459 [10:06<02:23,  0.61it/s, v_num=0w59, train/loss_step=0.0431]Epoch 0:  81%|████████  | 371/459 [10:06<02:23,  0.61it/s, v_num=0w59, train/loss_step=0.0423]Epoch 0:  81%|████████  | 372/459 [10:08<02:22,  0.61it/s, v_num=0w59, train/loss_step=0.0423]Epoch 0:  81%|████████  | 372/459 [10:08<02:22,  0.61it/s, v_num=0w59, train/loss_step=0.0436]Epoch 0:  81%|████████▏ | 373/459 [10:10<02:20,  0.61it/s, v_num=0w59, train/loss_step=0.0436]Epoch 0:  81%|████████▏ | 373/459 [10:10<02:20,  0.61it/s, v_num=0w59, train/loss_step=0.0427]Epoch 0:  81%|████████▏ | 374/459 [10:11<02:19,  0.61it/s, v_num=0w59, train/loss_step=0.0427]Epoch 0:  81%|████████▏ | 374/459 [10:11<02:19,  0.61it/s, v_num=0w59, train/loss_step=0.0432]Epoch 0:  82%|████████▏ | 375/459 [10:13<02:17,  0.61it/s, v_num=0w59, train/loss_step=0.0432]Epoch 0:  82%|████████▏ | 375/459 [10:13<02:17,  0.61it/s, v_num=0w59, train/loss_step=0.0435]Epoch 0:  82%|████████▏ | 376/459 [10:14<02:15,  0.61it/s, v_num=0w59, train/loss_step=0.0435]Epoch 0:  82%|████████▏ | 376/459 [10:14<02:15,  0.61it/s, v_num=0w59, train/loss_step=0.0448]Epoch 0:  82%|████████▏ | 377/459 [10:16<02:14,  0.61it/s, v_num=0w59, train/loss_step=0.0448]Epoch 0:  82%|████████▏ | 377/459 [10:16<02:14,  0.61it/s, v_num=0w59, train/loss_step=0.0482]Epoch 0:  82%|████████▏ | 378/459 [10:18<02:12,  0.61it/s, v_num=0w59, train/loss_step=0.0482]Epoch 0:  82%|████████▏ | 378/459 [10:18<02:12,  0.61it/s, v_num=0w59, train/loss_step=0.0459]Epoch 0:  83%|████████▎ | 379/459 [10:19<02:10,  0.61it/s, v_num=0w59, train/loss_step=0.0459]Epoch 0:  83%|████████▎ | 379/459 [10:19<02:10,  0.61it/s, v_num=0w59, train/loss_step=0.0447]Epoch 0:  83%|████████▎ | 380/459 [10:21<02:09,  0.61it/s, v_num=0w59, train/loss_step=0.0447]Epoch 0:  83%|████████▎ | 380/459 [10:21<02:09,  0.61it/s, v_num=0w59, train/loss_step=0.0419]Epoch 0:  83%|████████▎ | 381/459 [10:22<02:07,  0.61it/s, v_num=0w59, train/loss_step=0.0419]Epoch 0:  83%|████████▎ | 381/459 [10:22<02:07,  0.61it/s, v_num=0w59, train/loss_step=0.0432]Epoch 0:  83%|████████▎ | 382/459 [10:24<02:05,  0.61it/s, v_num=0w59, train/loss_step=0.0432]Epoch 0:  83%|████████▎ | 382/459 [10:24<02:05,  0.61it/s, v_num=0w59, train/loss_step=0.0416]Epoch 0:  83%|████████▎ | 383/459 [10:26<02:04,  0.61it/s, v_num=0w59, train/loss_step=0.0416]Epoch 0:  83%|████████▎ | 383/459 [10:26<02:04,  0.61it/s, v_num=0w59, train/loss_step=0.0403]Epoch 0:  84%|████████▎ | 384/459 [10:27<02:02,  0.61it/s, v_num=0w59, train/loss_step=0.0403]Epoch 0:  84%|████████▎ | 384/459 [10:27<02:02,  0.61it/s, v_num=0w59, train/loss_step=0.0394]Epoch 0:  84%|████████▍ | 385/459 [10:29<02:00,  0.61it/s, v_num=0w59, train/loss_step=0.0394]Epoch 0:  84%|████████▍ | 385/459 [10:29<02:00,  0.61it/s, v_num=0w59, train/loss_step=0.0445]Epoch 0:  84%|████████▍ | 386/459 [10:30<01:59,  0.61it/s, v_num=0w59, train/loss_step=0.0445]Epoch 0:  84%|████████▍ | 386/459 [10:30<01:59,  0.61it/s, v_num=0w59, train/loss_step=0.0435]Epoch 0:  84%|████████▍ | 387/459 [10:32<01:57,  0.61it/s, v_num=0w59, train/loss_step=0.0435]Epoch 0:  84%|████████▍ | 387/459 [10:32<01:57,  0.61it/s, v_num=0w59, train/loss_step=0.0422]Epoch 0:  85%|████████▍ | 388/459 [10:34<01:56,  0.61it/s, v_num=0w59, train/loss_step=0.0422]Epoch 0:  85%|████████▍ | 388/459 [10:34<01:56,  0.61it/s, v_num=0w59, train/loss_step=0.0446]Epoch 0:  85%|████████▍ | 389/459 [10:35<01:54,  0.61it/s, v_num=0w59, train/loss_step=0.0446]Epoch 0:  85%|████████▍ | 389/459 [10:35<01:54,  0.61it/s, v_num=0w59, train/loss_step=0.0413]Epoch 0:  85%|████████▍ | 390/459 [10:37<01:52,  0.61it/s, v_num=0w59, train/loss_step=0.0413]Epoch 0:  85%|████████▍ | 390/459 [10:37<01:52,  0.61it/s, v_num=0w59, train/loss_step=0.0403]Epoch 0:  85%|████████▌ | 391/459 [10:38<01:51,  0.61it/s, v_num=0w59, train/loss_step=0.0403]Epoch 0:  85%|████████▌ | 391/459 [10:38<01:51,  0.61it/s, v_num=0w59, train/loss_step=0.0413]Epoch 0:  85%|████████▌ | 392/459 [10:40<01:49,  0.61it/s, v_num=0w59, train/loss_step=0.0413]Epoch 0:  85%|████████▌ | 392/459 [10:40<01:49,  0.61it/s, v_num=0w59, train/loss_step=0.0429]Epoch 0:  86%|████████▌ | 393/459 [10:42<01:47,  0.61it/s, v_num=0w59, train/loss_step=0.0429]Epoch 0:  86%|████████▌ | 393/459 [10:42<01:47,  0.61it/s, v_num=0w59, train/loss_step=0.0426]Epoch 0:  86%|████████▌ | 394/459 [10:43<01:46,  0.61it/s, v_num=0w59, train/loss_step=0.0426]Epoch 0:  86%|████████▌ | 394/459 [10:43<01:46,  0.61it/s, v_num=0w59, train/loss_step=0.0455]Epoch 0:  86%|████████▌ | 395/459 [10:45<01:44,  0.61it/s, v_num=0w59, train/loss_step=0.0455]Epoch 0:  86%|████████▌ | 395/459 [10:45<01:44,  0.61it/s, v_num=0w59, train/loss_step=0.0432]Epoch 0:  86%|████████▋ | 396/459 [10:46<01:42,  0.61it/s, v_num=0w59, train/loss_step=0.0432]Epoch 0:  86%|████████▋ | 396/459 [10:46<01:42,  0.61it/s, v_num=0w59, train/loss_step=0.0462]Epoch 0:  86%|████████▋ | 397/459 [10:48<01:41,  0.61it/s, v_num=0w59, train/loss_step=0.0462]Epoch 0:  86%|████████▋ | 397/459 [10:48<01:41,  0.61it/s, v_num=0w59, train/loss_step=0.0431]Epoch 0:  87%|████████▋ | 398/459 [10:50<01:39,  0.61it/s, v_num=0w59, train/loss_step=0.0431]Epoch 0:  87%|████████▋ | 398/459 [10:50<01:39,  0.61it/s, v_num=0w59, train/loss_step=0.0452]Epoch 0:  87%|████████▋ | 399/459 [10:51<01:37,  0.61it/s, v_num=0w59, train/loss_step=0.0452]Epoch 0:  87%|████████▋ | 399/459 [10:51<01:37,  0.61it/s, v_num=0w59, train/loss_step=0.045] Epoch 0:  87%|████████▋ | 400/459 [10:53<01:36,  0.61it/s, v_num=0w59, train/loss_step=0.045]Epoch 0:  87%|████████▋ | 400/459 [10:53<01:36,  0.61it/s, v_num=0w59, train/loss_step=0.0418]Epoch 0:  87%|████████▋ | 401/459 [10:54<01:34,  0.61it/s, v_num=0w59, train/loss_step=0.0418]Epoch 0:  87%|████████▋ | 401/459 [10:54<01:34,  0.61it/s, v_num=0w59, train/loss_step=0.0397]Epoch 0:  88%|████████▊ | 402/459 [10:56<01:33,  0.61it/s, v_num=0w59, train/loss_step=0.0397]Epoch 0:  88%|████████▊ | 402/459 [10:56<01:33,  0.61it/s, v_num=0w59, train/loss_step=0.0421]Epoch 0:  88%|████████▊ | 403/459 [10:58<01:31,  0.61it/s, v_num=0w59, train/loss_step=0.0421]Epoch 0:  88%|████████▊ | 403/459 [10:58<01:31,  0.61it/s, v_num=0w59, train/loss_step=0.0401]Epoch 0:  88%|████████▊ | 404/459 [10:59<01:29,  0.61it/s, v_num=0w59, train/loss_step=0.0401]Epoch 0:  88%|████████▊ | 404/459 [10:59<01:29,  0.61it/s, v_num=0w59, train/loss_step=0.0407]Epoch 0:  88%|████████▊ | 405/459 [11:01<01:28,  0.61it/s, v_num=0w59, train/loss_step=0.0407]Epoch 0:  88%|████████▊ | 405/459 [11:01<01:28,  0.61it/s, v_num=0w59, train/loss_step=0.0443]Epoch 0:  88%|████████▊ | 406/459 [11:02<01:26,  0.61it/s, v_num=0w59, train/loss_step=0.0443]Epoch 0:  88%|████████▊ | 406/459 [11:02<01:26,  0.61it/s, v_num=0w59, train/loss_step=0.0379]Epoch 0:  89%|████████▊ | 407/459 [11:04<01:24,  0.61it/s, v_num=0w59, train/loss_step=0.0379]Epoch 0:  89%|████████▊ | 407/459 [11:04<01:24,  0.61it/s, v_num=0w59, train/loss_step=0.044] Epoch 0:  89%|████████▉ | 408/459 [11:06<01:23,  0.61it/s, v_num=0w59, train/loss_step=0.044]Epoch 0:  89%|████████▉ | 408/459 [11:06<01:23,  0.61it/s, v_num=0w59, train/loss_step=0.0414]Epoch 0:  89%|████████▉ | 409/459 [11:07<01:21,  0.61it/s, v_num=0w59, train/loss_step=0.0414]Epoch 0:  89%|████████▉ | 409/459 [11:07<01:21,  0.61it/s, v_num=0w59, train/loss_step=0.0424]Epoch 0:  89%|████████▉ | 410/459 [11:09<01:19,  0.61it/s, v_num=0w59, train/loss_step=0.0424]Epoch 0:  89%|████████▉ | 410/459 [11:09<01:19,  0.61it/s, v_num=0w59, train/loss_step=0.0404]Epoch 0:  90%|████████▉ | 411/459 [11:10<01:18,  0.61it/s, v_num=0w59, train/loss_step=0.0404]Epoch 0:  90%|████████▉ | 411/459 [11:10<01:18,  0.61it/s, v_num=0w59, train/loss_step=0.0408]Epoch 0:  90%|████████▉ | 412/459 [11:12<01:16,  0.61it/s, v_num=0w59, train/loss_step=0.0408]Epoch 0:  90%|████████▉ | 412/459 [11:12<01:16,  0.61it/s, v_num=0w59, train/loss_step=0.0433]Epoch 0:  90%|████████▉ | 413/459 [11:14<01:15,  0.61it/s, v_num=0w59, train/loss_step=0.0433]Epoch 0:  90%|████████▉ | 413/459 [11:14<01:15,  0.61it/s, v_num=0w59, train/loss_step=0.0427]Epoch 0:  90%|█████████ | 414/459 [11:15<01:13,  0.61it/s, v_num=0w59, train/loss_step=0.0427]Epoch 0:  90%|█████████ | 414/459 [11:15<01:13,  0.61it/s, v_num=0w59, train/loss_step=0.0364]Epoch 0:  90%|█████████ | 415/459 [11:17<01:11,  0.61it/s, v_num=0w59, train/loss_step=0.0364]Epoch 0:  90%|█████████ | 415/459 [11:17<01:11,  0.61it/s, v_num=0w59, train/loss_step=0.0444]Epoch 0:  91%|█████████ | 416/459 [11:18<01:10,  0.61it/s, v_num=0w59, train/loss_step=0.0444]Epoch 0:  91%|█████████ | 416/459 [11:18<01:10,  0.61it/s, v_num=0w59, train/loss_step=0.0382]Epoch 0:  91%|█████████ | 417/459 [11:20<01:08,  0.61it/s, v_num=0w59, train/loss_step=0.0382]Epoch 0:  91%|█████████ | 417/459 [11:20<01:08,  0.61it/s, v_num=0w59, train/loss_step=0.0414]Epoch 0:  91%|█████████ | 418/459 [11:22<01:06,  0.61it/s, v_num=0w59, train/loss_step=0.0414]Epoch 0:  91%|█████████ | 418/459 [11:22<01:06,  0.61it/s, v_num=0w59, train/loss_step=0.0435]Epoch 0:  91%|█████████▏| 419/459 [11:23<01:05,  0.61it/s, v_num=0w59, train/loss_step=0.0435]Epoch 0:  91%|█████████▏| 419/459 [11:23<01:05,  0.61it/s, v_num=0w59, train/loss_step=0.044] Epoch 0:  92%|█████████▏| 420/459 [11:25<01:03,  0.61it/s, v_num=0w59, train/loss_step=0.044]Epoch 0:  92%|█████████▏| 420/459 [11:25<01:03,  0.61it/s, v_num=0w59, train/loss_step=0.0418]Epoch 0:  92%|█████████▏| 421/459 [11:26<01:01,  0.61it/s, v_num=0w59, train/loss_step=0.0418]Epoch 0:  92%|█████████▏| 421/459 [11:26<01:02,  0.61it/s, v_num=0w59, train/loss_step=0.0409]Epoch 0:  92%|█████████▏| 422/459 [11:28<01:00,  0.61it/s, v_num=0w59, train/loss_step=0.0409]Epoch 0:  92%|█████████▏| 422/459 [11:28<01:00,  0.61it/s, v_num=0w59, train/loss_step=0.0438]Epoch 0:  92%|█████████▏| 423/459 [11:30<00:58,  0.61it/s, v_num=0w59, train/loss_step=0.0438]Epoch 0:  92%|█████████▏| 423/459 [11:30<00:58,  0.61it/s, v_num=0w59, train/loss_step=0.042] Epoch 0:  92%|█████████▏| 424/459 [11:31<00:57,  0.61it/s, v_num=0w59, train/loss_step=0.042]Epoch 0:  92%|█████████▏| 424/459 [11:31<00:57,  0.61it/s, v_num=0w59, train/loss_step=0.036]Epoch 0:  93%|█████████▎| 425/459 [11:33<00:55,  0.61it/s, v_num=0w59, train/loss_step=0.036]Epoch 0:  93%|█████████▎| 425/459 [11:33<00:55,  0.61it/s, v_num=0w59, train/loss_step=0.0387]Epoch 0:  93%|█████████▎| 426/459 [11:34<00:53,  0.61it/s, v_num=0w59, train/loss_step=0.0387]Epoch 0:  93%|█████████▎| 426/459 [11:34<00:53,  0.61it/s, v_num=0w59, train/loss_step=0.0407]Epoch 0:  93%|█████████▎| 427/459 [11:36<00:52,  0.61it/s, v_num=0w59, train/loss_step=0.0407]Epoch 0:  93%|█████████▎| 427/459 [11:36<00:52,  0.61it/s, v_num=0w59, train/loss_step=0.0403]Epoch 0:  93%|█████████▎| 428/459 [11:38<00:50,  0.61it/s, v_num=0w59, train/loss_step=0.0403]Epoch 0:  93%|█████████▎| 428/459 [11:38<00:50,  0.61it/s, v_num=0w59, train/loss_step=0.0418]Epoch 0:  93%|█████████▎| 429/459 [11:39<00:48,  0.61it/s, v_num=0w59, train/loss_step=0.0418]Epoch 0:  93%|█████████▎| 429/459 [11:39<00:48,  0.61it/s, v_num=0w59, train/loss_step=0.0416]Epoch 0:  94%|█████████▎| 430/459 [11:41<00:47,  0.61it/s, v_num=0w59, train/loss_step=0.0416]Epoch 0:  94%|█████████▎| 430/459 [11:41<00:47,  0.61it/s, v_num=0w59, train/loss_step=0.0396]Epoch 0:  94%|█████████▍| 431/459 [11:42<00:45,  0.61it/s, v_num=0w59, train/loss_step=0.0396]Epoch 0:  94%|█████████▍| 431/459 [11:42<00:45,  0.61it/s, v_num=0w59, train/loss_step=0.0416]Epoch 0:  94%|█████████▍| 432/459 [11:44<00:44,  0.61it/s, v_num=0w59, train/loss_step=0.0416]Epoch 0:  94%|█████████▍| 432/459 [11:44<00:44,  0.61it/s, v_num=0w59, train/loss_step=0.0395]Epoch 0:  94%|█████████▍| 433/459 [11:46<00:42,  0.61it/s, v_num=0w59, train/loss_step=0.0395]Epoch 0:  94%|█████████▍| 433/459 [11:46<00:42,  0.61it/s, v_num=0w59, train/loss_step=0.0394]Epoch 0:  95%|█████████▍| 434/459 [11:47<00:40,  0.61it/s, v_num=0w59, train/loss_step=0.0394]Epoch 0:  95%|█████████▍| 434/459 [11:47<00:40,  0.61it/s, v_num=0w59, train/loss_step=0.0422]Epoch 0:  95%|█████████▍| 435/459 [11:49<00:39,  0.61it/s, v_num=0w59, train/loss_step=0.0422]Epoch 0:  95%|█████████▍| 435/459 [11:49<00:39,  0.61it/s, v_num=0w59, train/loss_step=0.0386]Epoch 0:  95%|█████████▍| 436/459 [11:50<00:37,  0.61it/s, v_num=0w59, train/loss_step=0.0386]Epoch 0:  95%|█████████▍| 436/459 [11:50<00:37,  0.61it/s, v_num=0w59, train/loss_step=0.0416]Epoch 0:  95%|█████████▌| 437/459 [11:52<00:35,  0.61it/s, v_num=0w59, train/loss_step=0.0416]Epoch 0:  95%|█████████▌| 437/459 [11:52<00:35,  0.61it/s, v_num=0w59, train/loss_step=0.0417]Epoch 0:  95%|█████████▌| 438/459 [11:54<00:34,  0.61it/s, v_num=0w59, train/loss_step=0.0417]Epoch 0:  95%|█████████▌| 438/459 [11:54<00:34,  0.61it/s, v_num=0w59, train/loss_step=0.0389]Epoch 0:  96%|█████████▌| 439/459 [11:55<00:32,  0.61it/s, v_num=0w59, train/loss_step=0.0389]Epoch 0:  96%|█████████▌| 439/459 [11:55<00:32,  0.61it/s, v_num=0w59, train/loss_step=0.0365]Epoch 0:  96%|█████████▌| 440/459 [11:57<00:30,  0.61it/s, v_num=0w59, train/loss_step=0.0365]Epoch 0:  96%|█████████▌| 440/459 [11:57<00:30,  0.61it/s, v_num=0w59, train/loss_step=0.0362]Epoch 0:  96%|█████████▌| 441/459 [11:58<00:29,  0.61it/s, v_num=0w59, train/loss_step=0.0362]Epoch 0:  96%|█████████▌| 441/459 [11:58<00:29,  0.61it/s, v_num=0w59, train/loss_step=0.0409]Epoch 0:  96%|█████████▋| 442/459 [12:00<00:27,  0.61it/s, v_num=0w59, train/loss_step=0.0409]Epoch 0:  96%|█████████▋| 442/459 [12:00<00:27,  0.61it/s, v_num=0w59, train/loss_step=0.0385]Epoch 0:  97%|█████████▋| 443/459 [12:02<00:26,  0.61it/s, v_num=0w59, train/loss_step=0.0385]Epoch 0:  97%|█████████▋| 443/459 [12:02<00:26,  0.61it/s, v_num=0w59, train/loss_step=0.0396]Epoch 0:  97%|█████████▋| 444/459 [12:03<00:24,  0.61it/s, v_num=0w59, train/loss_step=0.0396]Epoch 0:  97%|█████████▋| 444/459 [12:03<00:24,  0.61it/s, v_num=0w59, train/loss_step=0.0402]Epoch 0:  97%|█████████▋| 445/459 [12:05<00:22,  0.61it/s, v_num=0w59, train/loss_step=0.0402]Epoch 0:  97%|█████████▋| 445/459 [12:05<00:22,  0.61it/s, v_num=0w59, train/loss_step=0.044] Epoch 0:  97%|█████████▋| 446/459 [12:06<00:21,  0.61it/s, v_num=0w59, train/loss_step=0.044]Epoch 0:  97%|█████████▋| 446/459 [12:06<00:21,  0.61it/s, v_num=0w59, train/loss_step=0.0385]Epoch 0:  97%|█████████▋| 447/459 [12:08<00:19,  0.61it/s, v_num=0w59, train/loss_step=0.0385]Epoch 0:  97%|█████████▋| 447/459 [12:08<00:19,  0.61it/s, v_num=0w59, train/loss_step=0.043] Epoch 0:  98%|█████████▊| 448/459 [12:09<00:17,  0.61it/s, v_num=0w59, train/loss_step=0.043]Epoch 0:  98%|█████████▊| 448/459 [12:09<00:17,  0.61it/s, v_num=0w59, train/loss_step=0.0391]Epoch 0:  98%|█████████▊| 449/459 [12:11<00:16,  0.61it/s, v_num=0w59, train/loss_step=0.0391]Epoch 0:  98%|█████████▊| 449/459 [12:11<00:16,  0.61it/s, v_num=0w59, train/loss_step=0.0379]Epoch 0:  98%|█████████▊| 450/459 [12:13<00:14,  0.61it/s, v_num=0w59, train/loss_step=0.0379]Epoch 0:  98%|█████████▊| 450/459 [12:13<00:14,  0.61it/s, v_num=0w59, train/loss_step=0.0394]Epoch 0:  98%|█████████▊| 451/459 [12:14<00:13,  0.61it/s, v_num=0w59, train/loss_step=0.0394]Epoch 0:  98%|█████████▊| 451/459 [12:14<00:13,  0.61it/s, v_num=0w59, train/loss_step=0.038] Epoch 0:  98%|█████████▊| 452/459 [12:16<00:11,  0.61it/s, v_num=0w59, train/loss_step=0.038]Epoch 0:  98%|█████████▊| 452/459 [12:16<00:11,  0.61it/s, v_num=0w59, train/loss_step=0.041]Epoch 0:  99%|█████████▊| 453/459 [12:17<00:09,  0.61it/s, v_num=0w59, train/loss_step=0.041]Epoch 0:  99%|█████████▊| 453/459 [12:17<00:09,  0.61it/s, v_num=0w59, train/loss_step=0.0418]Epoch 0:  99%|█████████▉| 454/459 [12:19<00:08,  0.61it/s, v_num=0w59, train/loss_step=0.0418]Epoch 0:  99%|█████████▉| 454/459 [12:19<00:08,  0.61it/s, v_num=0w59, train/loss_step=0.044] Epoch 0:  99%|█████████▉| 455/459 [12:20<00:06,  0.61it/s, v_num=0w59, train/loss_step=0.044]Epoch 0:  99%|█████████▉| 455/459 [12:20<00:06,  0.61it/s, v_num=0w59, train/loss_step=0.0441]Epoch 0:  99%|█████████▉| 456/459 [12:22<00:04,  0.61it/s, v_num=0w59, train/loss_step=0.0441]Epoch 0:  99%|█████████▉| 456/459 [12:22<00:04,  0.61it/s, v_num=0w59, train/loss_step=0.0386]Epoch 0: 100%|█████████▉| 457/459 [12:23<00:03,  0.61it/s, v_num=0w59, train/loss_step=0.0386]Epoch 0: 100%|█████████▉| 457/459 [12:23<00:03,  0.61it/s, v_num=0w59, train/loss_step=0.0387]Epoch 0: 100%|█████████▉| 458/459 [12:25<00:01,  0.61it/s, v_num=0w59, train/loss_step=0.0387]Epoch 0: 100%|█████████▉| 458/459 [12:25<00:01,  0.61it/s, v_num=0w59, train/loss_step=0.0414]Epoch 0: 100%|██████████| 459/459 [12:27<00:00,  0.61it/s, v_num=0w59, train/loss_step=0.0414]Epoch 0: 100%|██████████| 459/459 [12:27<00:00,  0.61it/s, v_num=0w59, train/loss_step=0.0416]hyperparameters: "compile":            False
"learning_rate":      0.0005
"loss":               bce
"lr_rate":            [0.05, 0.02, 0.01, 0.005, 0.002, 0.001, 0.0005, 0.0002]
"lr_scheduler_epoch": [10, 15, 20, 25, 30, 35, 50, 45]
"net":                HGCN(
  (stem): Stem_conv(
    (convs): Sequential(
      (0): Conv2d(1, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): GELU(approximate='none')
      (3): Conv2d(40, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (4): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): GELU(approximate='none')
      (6): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (backbone): Sequential(
    (0): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): Identity()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
        )
        (drop_path): Identity()
      )
    )
    (1): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
        )
        (drop_path): DropPath()
      )
    )
    (2): DownSample(
      (conv): Sequential(
        (0): Conv2d(80, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(480, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)
        )
        (drop_path): DropPath()
      )
    )
    (4): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(480, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)
        )
        (drop_path): DropPath()
      )
    )
    (5): DownSample(
      (conv): Sequential(
        (0): Conv2d(160, 400, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (7): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (8): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (9): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (10): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (11): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (12): DownSample(
      (conv): Sequential(
        (0): Conv2d(400, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (13): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1920, 1920, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(640, 2560, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(2560, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(2560, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(2560, 2560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2560)
        )
        (drop_path): DropPath()
      )
    )
    (14): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1920, 1920, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(640, 2560, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(2560, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(2560, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(2560, 2560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2560)
        )
        (drop_path): DropPath()
      )
    )
  )
  (prediction): Sequential(
    (0): Conv2d(640, 1024, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): GELU(approximate='none')
    (3): Dropout(p=0.0, inplace=False)
    (4): Conv2d(1024, 200, kernel_size=(1, 1), stride=(1, 1))
  )
)
"opt_warmup":         True
"optimizer":          functools.partial(<class 'torch.optim.adam.Adam'>, lr=0.0005, weight_decay=5e-07, eps=1e-08, betas=[0.95, 0.999])
"scheduler":          functools.partial(<class 'torch.optim.lr_scheduler.MultiStepLR'>, milestones=[10, 15, 20, 25, 30, 35, 40], gamma=0.5)

Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/52 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/52 [00:00<?, ?it/s][A
Validation DataLoader 0:   2%|▏         | 1/52 [00:01<00:52,  0.97it/s][A
Validation DataLoader 0:   4%|▍         | 2/52 [00:01<00:47,  1.06it/s][A
Validation DataLoader 0:   6%|▌         | 3/52 [00:02<00:44,  1.09it/s][A
Validation DataLoader 0:   8%|▊         | 4/52 [00:03<00:43,  1.11it/s][A
Validation DataLoader 0:  10%|▉         | 5/52 [00:04<00:42,  1.12it/s][A
Validation DataLoader 0:  12%|█▏        | 6/52 [00:05<00:40,  1.13it/s][A
Validation DataLoader 0:  13%|█▎        | 7/52 [00:06<00:39,  1.13it/s][A
Validation DataLoader 0:  15%|█▌        | 8/52 [00:07<00:38,  1.14it/s][A
Validation DataLoader 0:  17%|█▋        | 9/52 [00:07<00:37,  1.14it/s][A
Validation DataLoader 0:  19%|█▉        | 10/52 [00:08<00:36,  1.14it/s][A
Validation DataLoader 0:  21%|██        | 11/52 [00:09<00:35,  1.14it/s][A
Validation DataLoader 0:  23%|██▎       | 12/52 [00:10<00:34,  1.15it/s][A
Validation DataLoader 0:  25%|██▌       | 13/52 [00:11<00:33,  1.15it/s][A
Validation DataLoader 0:  27%|██▋       | 14/52 [00:12<00:33,  1.15it/s][A
Validation DataLoader 0:  29%|██▉       | 15/52 [00:13<00:32,  1.15it/s][A
Validation DataLoader 0:  31%|███       | 16/52 [00:13<00:31,  1.15it/s][A
Validation DataLoader 0:  33%|███▎      | 17/52 [00:14<00:30,  1.15it/s][A
Validation DataLoader 0:  35%|███▍      | 18/52 [00:15<00:29,  1.15it/s][A
Validation DataLoader 0:  37%|███▋      | 19/52 [00:16<00:28,  1.16it/s][A
Validation DataLoader 0:  38%|███▊      | 20/52 [00:17<00:27,  1.16it/s][A
Validation DataLoader 0:  40%|████      | 21/52 [00:18<00:26,  1.16it/s][A
Validation DataLoader 0:  42%|████▏     | 22/52 [00:19<00:25,  1.16it/s][A
Validation DataLoader 0:  44%|████▍     | 23/52 [00:19<00:25,  1.16it/s][A
Validation DataLoader 0:  46%|████▌     | 24/52 [00:20<00:24,  1.16it/s][A
Validation DataLoader 0:  48%|████▊     | 25/52 [00:21<00:23,  1.16it/s][A
Validation DataLoader 0:  50%|█████     | 26/52 [00:22<00:22,  1.16it/s][A
Validation DataLoader 0:  52%|█████▏    | 27/52 [00:23<00:21,  1.16it/s][A
Validation DataLoader 0:  54%|█████▍    | 28/52 [00:24<00:20,  1.16it/s][A
Validation DataLoader 0:  56%|█████▌    | 29/52 [00:25<00:19,  1.16it/s][A
Validation DataLoader 0:  58%|█████▊    | 30/52 [00:25<00:18,  1.16it/s][A
Validation DataLoader 0:  60%|█████▉    | 31/52 [00:26<00:18,  1.16it/s][A
Validation DataLoader 0:  62%|██████▏   | 32/52 [00:27<00:17,  1.16it/s][A
Validation DataLoader 0:  63%|██████▎   | 33/52 [00:28<00:16,  1.16it/s][A
Validation DataLoader 0:  65%|██████▌   | 34/52 [00:29<00:15,  1.16it/s][A
Validation DataLoader 0:  67%|██████▋   | 35/52 [00:30<00:14,  1.16it/s][A
Validation DataLoader 0:  69%|██████▉   | 36/52 [00:31<00:13,  1.16it/s][A
Validation DataLoader 0:  71%|███████   | 37/52 [00:31<00:12,  1.16it/s][A
Validation DataLoader 0:  73%|███████▎  | 38/52 [00:32<00:12,  1.16it/s][A
Validation DataLoader 0:  75%|███████▌  | 39/52 [00:33<00:11,  1.16it/s][A
Validation DataLoader 0:  77%|███████▋  | 40/52 [00:34<00:10,  1.16it/s][A
Validation DataLoader 0:  79%|███████▉  | 41/52 [00:35<00:09,  1.16it/s][A
Validation DataLoader 0:  81%|████████  | 42/52 [00:36<00:08,  1.16it/s][A
Validation DataLoader 0:  83%|████████▎ | 43/52 [00:36<00:07,  1.16it/s][A
Validation DataLoader 0:  85%|████████▍ | 44/52 [00:37<00:06,  1.16it/s][A
Validation DataLoader 0:  87%|████████▋ | 45/52 [00:38<00:06,  1.16it/s][A
Validation DataLoader 0:  88%|████████▊ | 46/52 [00:39<00:05,  1.16it/s][A
Validation DataLoader 0:  90%|█████████ | 47/52 [00:40<00:04,  1.16it/s][A
Validation DataLoader 0:  92%|█████████▏| 48/52 [00:41<00:03,  1.16it/s][A
Validation DataLoader 0:  94%|█████████▍| 49/52 [00:42<00:02,  1.16it/s][A
Validation DataLoader 0:  96%|█████████▌| 50/52 [00:42<00:01,  1.16it/s][A
Validation DataLoader 0:  98%|█████████▊| 51/52 [00:43<00:00,  1.16it/s][A
Validation DataLoader 0: 100%|██████████| 52/52 [00:44<00:00,  1.16it/s][A
                                                                        [AEpoch 0: 100%|██████████| 459/459 [13:16<00:00,  0.58it/s, v_num=0w59, train/loss_step=0.0416, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080]Epoch 0: 100%|██████████| 459/459 [13:16<00:00,  0.58it/s, v_num=0w59, train/loss_step=0.0416, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 0:   0%|          | 0/459 [00:00<?, ?it/s, v_num=0w59, train/loss_step=0.0416, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]          Epoch 1:   0%|          | 0/459 [00:00<?, ?it/s, v_num=0w59, train/loss_step=0.0416, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]hyperparameters: "compile":            False
"learning_rate":      0.0005
"loss":               bce
"lr_rate":            [0.05, 0.02, 0.01, 0.005, 0.002, 0.001, 0.0005, 0.0002]
"lr_scheduler_epoch": [10, 15, 20, 25, 30, 35, 50, 45]
"net":                HGCN(
  (stem): Stem_conv(
    (convs): Sequential(
      (0): Conv2d(1, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): GELU(approximate='none')
      (3): Conv2d(40, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (4): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): GELU(approximate='none')
      (6): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (backbone): Sequential(
    (0): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): Identity()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
        )
        (drop_path): Identity()
      )
    )
    (1): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
        )
        (drop_path): DropPath()
      )
    )
    (2): DownSample(
      (conv): Sequential(
        (0): Conv2d(80, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(480, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)
        )
        (drop_path): DropPath()
      )
    )
    (4): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(480, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)
        )
        (drop_path): DropPath()
      )
    )
    (5): DownSample(
      (conv): Sequential(
        (0): Conv2d(160, 400, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (7): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (8): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (9): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (10): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (11): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (12): DownSample(
      (conv): Sequential(
        (0): Conv2d(400, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (13): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1920, 1920, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(640, 2560, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(2560, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(2560, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(2560, 2560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2560)
        )
        (drop_path): DropPath()
      )
    )
    (14): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1920, 1920, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(640, 2560, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(2560, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(2560, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(2560, 2560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2560)
        )
        (drop_path): DropPath()
      )
    )
  )
  (prediction): Sequential(
    (0): Conv2d(640, 1024, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): GELU(approximate='none')
    (3): Dropout(p=0.0, inplace=False)
    (4): Conv2d(1024, 200, kernel_size=(1, 1), stride=(1, 1))
  )
)
"opt_warmup":         True
"optimizer":          functools.partial(<class 'torch.optim.adam.Adam'>, lr=0.0005, weight_decay=5e-07, eps=1e-08, betas=[0.95, 0.999])
"scheduler":          functools.partial(<class 'torch.optim.lr_scheduler.MultiStepLR'>, milestones=[10, 15, 20, 25, 30, 35, 40], gamma=0.5)
Epoch 1:   0%|          | 1/459 [00:04<35:54,  0.21it/s, v_num=0w59, train/loss_step=0.0416, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   0%|          | 1/459 [00:04<35:54,  0.21it/s, v_num=0w59, train/loss_step=0.0367, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   0%|          | 2/459 [00:06<23:57,  0.32it/s, v_num=0w59, train/loss_step=0.0367, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   0%|          | 2/459 [00:06<23:57,  0.32it/s, v_num=0w59, train/loss_step=0.0393, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   1%|          | 3/459 [00:08<20:39,  0.37it/s, v_num=0w59, train/loss_step=0.0393, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   1%|          | 3/459 [00:08<20:39,  0.37it/s, v_num=0w59, train/loss_step=0.038, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:   1%|          | 4/459 [00:09<18:28,  0.41it/s, v_num=0w59, train/loss_step=0.038, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   1%|          | 4/459 [00:09<18:28,  0.41it/s, v_num=0w59, train/loss_step=0.0394, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   1%|          | 5/459 [00:11<17:09,  0.44it/s, v_num=0w59, train/loss_step=0.0394, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   1%|          | 5/459 [00:11<17:09,  0.44it/s, v_num=0w59, train/loss_step=0.0413, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   1%|▏         | 6/459 [00:12<16:15,  0.46it/s, v_num=0w59, train/loss_step=0.0413, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   1%|▏         | 6/459 [00:12<16:15,  0.46it/s, v_num=0w59, train/loss_step=0.0378, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   2%|▏         | 7/459 [00:14<15:37,  0.48it/s, v_num=0w59, train/loss_step=0.0378, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   2%|▏         | 7/459 [00:14<15:37,  0.48it/s, v_num=0w59, train/loss_step=0.0403, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   2%|▏         | 8/459 [00:16<15:08,  0.50it/s, v_num=0w59, train/loss_step=0.0403, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   2%|▏         | 8/459 [00:16<15:08,  0.50it/s, v_num=0w59, train/loss_step=0.041, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:   2%|▏         | 9/459 [00:17<14:46,  0.51it/s, v_num=0w59, train/loss_step=0.041, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   2%|▏         | 9/459 [00:17<14:46,  0.51it/s, v_num=0w59, train/loss_step=0.0421, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   2%|▏         | 10/459 [00:19<14:27,  0.52it/s, v_num=0w59, train/loss_step=0.0421, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   2%|▏         | 10/459 [00:19<14:27,  0.52it/s, v_num=0w59, train/loss_step=0.0386, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   2%|▏         | 11/459 [00:20<14:12,  0.53it/s, v_num=0w59, train/loss_step=0.0386, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   2%|▏         | 11/459 [00:20<14:12,  0.53it/s, v_num=0w59, train/loss_step=0.0434, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   3%|▎         | 12/459 [00:22<13:58,  0.53it/s, v_num=0w59, train/loss_step=0.0434, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   3%|▎         | 12/459 [00:22<13:58,  0.53it/s, v_num=0w59, train/loss_step=0.0412, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   3%|▎         | 13/459 [00:24<13:46,  0.54it/s, v_num=0w59, train/loss_step=0.0412, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   3%|▎         | 13/459 [00:24<13:46,  0.54it/s, v_num=0w59, train/loss_step=0.0357, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   3%|▎         | 14/459 [00:25<13:36,  0.54it/s, v_num=0w59, train/loss_step=0.0357, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   3%|▎         | 14/459 [00:25<13:36,  0.54it/s, v_num=0w59, train/loss_step=0.0378, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   3%|▎         | 15/459 [00:27<13:27,  0.55it/s, v_num=0w59, train/loss_step=0.0378, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   3%|▎         | 15/459 [00:27<13:27,  0.55it/s, v_num=0w59, train/loss_step=0.0399, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   3%|▎         | 16/459 [00:28<13:19,  0.55it/s, v_num=0w59, train/loss_step=0.0399, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   3%|▎         | 16/459 [00:28<13:19,  0.55it/s, v_num=0w59, train/loss_step=0.0384, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   4%|▎         | 17/459 [00:30<13:12,  0.56it/s, v_num=0w59, train/loss_step=0.0384, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   4%|▎         | 17/459 [00:30<13:12,  0.56it/s, v_num=0w59, train/loss_step=0.0396, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   4%|▍         | 18/459 [00:32<13:05,  0.56it/s, v_num=0w59, train/loss_step=0.0396, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   4%|▍         | 18/459 [00:32<13:05,  0.56it/s, v_num=0w59, train/loss_step=0.0393, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   4%|▍         | 19/459 [00:33<12:59,  0.56it/s, v_num=0w59, train/loss_step=0.0393, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   4%|▍         | 19/459 [00:33<12:59,  0.56it/s, v_num=0w59, train/loss_step=0.038, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:   4%|▍         | 20/459 [00:35<12:53,  0.57it/s, v_num=0w59, train/loss_step=0.038, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   4%|▍         | 20/459 [00:35<12:53,  0.57it/s, v_num=0w59, train/loss_step=0.0357, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   5%|▍         | 21/459 [00:36<12:48,  0.57it/s, v_num=0w59, train/loss_step=0.0357, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   5%|▍         | 21/459 [00:36<12:48,  0.57it/s, v_num=0w59, train/loss_step=0.0396, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   5%|▍         | 22/459 [00:38<12:43,  0.57it/s, v_num=0w59, train/loss_step=0.0396, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   5%|▍         | 22/459 [00:38<12:43,  0.57it/s, v_num=0w59, train/loss_step=0.0403, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   5%|▌         | 23/459 [00:40<12:38,  0.57it/s, v_num=0w59, train/loss_step=0.0403, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   5%|▌         | 23/459 [00:40<12:38,  0.57it/s, v_num=0w59, train/loss_step=0.0397, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   5%|▌         | 24/459 [00:41<12:34,  0.58it/s, v_num=0w59, train/loss_step=0.0397, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   5%|▌         | 24/459 [00:41<12:34,  0.58it/s, v_num=0w59, train/loss_step=0.0392, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   5%|▌         | 25/459 [00:43<12:29,  0.58it/s, v_num=0w59, train/loss_step=0.0392, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   5%|▌         | 25/459 [00:43<12:29,  0.58it/s, v_num=0w59, train/loss_step=0.0391, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   6%|▌         | 26/459 [00:44<12:25,  0.58it/s, v_num=0w59, train/loss_step=0.0391, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   6%|▌         | 26/459 [00:44<12:25,  0.58it/s, v_num=0w59, train/loss_step=0.0368, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   6%|▌         | 27/459 [00:46<12:22,  0.58it/s, v_num=0w59, train/loss_step=0.0368, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   6%|▌         | 27/459 [00:46<12:22,  0.58it/s, v_num=0w59, train/loss_step=0.0374, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   6%|▌         | 28/459 [00:47<12:18,  0.58it/s, v_num=0w59, train/loss_step=0.0374, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   6%|▌         | 28/459 [00:47<12:18,  0.58it/s, v_num=0w59, train/loss_step=0.0398, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   6%|▋         | 29/459 [00:49<12:14,  0.59it/s, v_num=0w59, train/loss_step=0.0398, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   6%|▋         | 29/459 [00:49<12:14,  0.59it/s, v_num=0w59, train/loss_step=0.0414, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   7%|▋         | 30/459 [00:51<12:11,  0.59it/s, v_num=0w59, train/loss_step=0.0414, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   7%|▋         | 30/459 [00:51<12:11,  0.59it/s, v_num=0w59, train/loss_step=0.0398, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   7%|▋         | 31/459 [00:52<12:08,  0.59it/s, v_num=0w59, train/loss_step=0.0398, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   7%|▋         | 31/459 [00:52<12:08,  0.59it/s, v_num=0w59, train/loss_step=0.0407, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   7%|▋         | 32/459 [00:54<12:05,  0.59it/s, v_num=0w59, train/loss_step=0.0407, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   7%|▋         | 32/459 [00:54<12:05,  0.59it/s, v_num=0w59, train/loss_step=0.0361, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   7%|▋         | 33/459 [00:55<12:02,  0.59it/s, v_num=0w59, train/loss_step=0.0361, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   7%|▋         | 33/459 [00:55<12:02,  0.59it/s, v_num=0w59, train/loss_step=0.0351, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   7%|▋         | 34/459 [00:57<11:59,  0.59it/s, v_num=0w59, train/loss_step=0.0351, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   7%|▋         | 34/459 [00:57<11:59,  0.59it/s, v_num=0w59, train/loss_step=0.0389, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   8%|▊         | 35/459 [00:59<11:56,  0.59it/s, v_num=0w59, train/loss_step=0.0389, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   8%|▊         | 35/459 [00:59<11:56,  0.59it/s, v_num=0w59, train/loss_step=0.0406, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   8%|▊         | 36/459 [01:00<11:53,  0.59it/s, v_num=0w59, train/loss_step=0.0406, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   8%|▊         | 36/459 [01:00<11:53,  0.59it/s, v_num=0w59, train/loss_step=0.0397, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   8%|▊         | 37/459 [01:02<11:50,  0.59it/s, v_num=0w59, train/loss_step=0.0397, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   8%|▊         | 37/459 [01:02<11:50,  0.59it/s, v_num=0w59, train/loss_step=0.0466, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   8%|▊         | 38/459 [01:03<11:48,  0.59it/s, v_num=0w59, train/loss_step=0.0466, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   8%|▊         | 38/459 [01:03<11:48,  0.59it/s, v_num=0w59, train/loss_step=0.0386, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   8%|▊         | 39/459 [01:05<11:45,  0.60it/s, v_num=0w59, train/loss_step=0.0386, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   8%|▊         | 39/459 [01:05<11:45,  0.60it/s, v_num=0w59, train/loss_step=0.0378, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   9%|▊         | 40/459 [01:07<11:43,  0.60it/s, v_num=0w59, train/loss_step=0.0378, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   9%|▊         | 40/459 [01:07<11:43,  0.60it/s, v_num=0w59, train/loss_step=0.0378, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   9%|▉         | 41/459 [01:08<11:40,  0.60it/s, v_num=0w59, train/loss_step=0.0378, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   9%|▉         | 41/459 [01:08<11:40,  0.60it/s, v_num=0w59, train/loss_step=0.0421, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   9%|▉         | 42/459 [01:10<11:38,  0.60it/s, v_num=0w59, train/loss_step=0.0421, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   9%|▉         | 42/459 [01:10<11:38,  0.60it/s, v_num=0w59, train/loss_step=0.0383, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   9%|▉         | 43/459 [01:11<11:35,  0.60it/s, v_num=0w59, train/loss_step=0.0383, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:   9%|▉         | 43/459 [01:11<11:35,  0.60it/s, v_num=0w59, train/loss_step=0.0392, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  10%|▉         | 44/459 [01:13<11:33,  0.60it/s, v_num=0w59, train/loss_step=0.0392, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  10%|▉         | 44/459 [01:13<11:33,  0.60it/s, v_num=0w59, train/loss_step=0.0378, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  10%|▉         | 45/459 [01:15<11:30,  0.60it/s, v_num=0w59, train/loss_step=0.0378, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  10%|▉         | 45/459 [01:15<11:30,  0.60it/s, v_num=0w59, train/loss_step=0.0394, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  10%|█         | 46/459 [01:16<11:28,  0.60it/s, v_num=0w59, train/loss_step=0.0394, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  10%|█         | 46/459 [01:16<11:28,  0.60it/s, v_num=0w59, train/loss_step=0.0374, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  10%|█         | 47/459 [01:18<11:26,  0.60it/s, v_num=0w59, train/loss_step=0.0374, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  10%|█         | 47/459 [01:18<11:26,  0.60it/s, v_num=0w59, train/loss_step=0.0391, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  10%|█         | 48/459 [01:19<11:24,  0.60it/s, v_num=0w59, train/loss_step=0.0391, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  10%|█         | 48/459 [01:19<11:24,  0.60it/s, v_num=0w59, train/loss_step=0.0362, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  11%|█         | 49/459 [01:21<11:21,  0.60it/s, v_num=0w59, train/loss_step=0.0362, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  11%|█         | 49/459 [01:21<11:21,  0.60it/s, v_num=0w59, train/loss_step=0.0397, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  11%|█         | 50/459 [01:23<11:19,  0.60it/s, v_num=0w59, train/loss_step=0.0397, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  11%|█         | 50/459 [01:23<11:19,  0.60it/s, v_num=0w59, train/loss_step=0.0356, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  11%|█         | 51/459 [01:24<11:17,  0.60it/s, v_num=0w59, train/loss_step=0.0356, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  11%|█         | 51/459 [01:24<11:17,  0.60it/s, v_num=0w59, train/loss_step=0.0343, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  11%|█▏        | 52/459 [01:26<11:15,  0.60it/s, v_num=0w59, train/loss_step=0.0343, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  11%|█▏        | 52/459 [01:26<11:15,  0.60it/s, v_num=0w59, train/loss_step=0.0394, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  12%|█▏        | 53/459 [01:27<11:12,  0.60it/s, v_num=0w59, train/loss_step=0.0394, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  12%|█▏        | 53/459 [01:27<11:12,  0.60it/s, v_num=0w59, train/loss_step=0.0373, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  12%|█▏        | 54/459 [01:29<11:10,  0.60it/s, v_num=0w59, train/loss_step=0.0373, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  12%|█▏        | 54/459 [01:29<11:10,  0.60it/s, v_num=0w59, train/loss_step=0.0385, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  12%|█▏        | 55/459 [01:30<11:08,  0.60it/s, v_num=0w59, train/loss_step=0.0385, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  12%|█▏        | 55/459 [01:30<11:08,  0.60it/s, v_num=0w59, train/loss_step=0.038, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:  12%|█▏        | 56/459 [01:32<11:06,  0.60it/s, v_num=0w59, train/loss_step=0.038, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  12%|█▏        | 56/459 [01:32<11:06,  0.60it/s, v_num=0w59, train/loss_step=0.0366, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  12%|█▏        | 57/459 [01:34<11:04,  0.61it/s, v_num=0w59, train/loss_step=0.0366, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  12%|█▏        | 57/459 [01:34<11:04,  0.61it/s, v_num=0w59, train/loss_step=0.0388, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  13%|█▎        | 58/459 [01:35<11:01,  0.61it/s, v_num=0w59, train/loss_step=0.0388, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  13%|█▎        | 58/459 [01:35<11:01,  0.61it/s, v_num=0w59, train/loss_step=0.0348, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  13%|█▎        | 59/459 [01:37<10:59,  0.61it/s, v_num=0w59, train/loss_step=0.0348, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  13%|█▎        | 59/459 [01:37<10:59,  0.61it/s, v_num=0w59, train/loss_step=0.0384, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  13%|█▎        | 60/459 [01:38<10:57,  0.61it/s, v_num=0w59, train/loss_step=0.0384, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  13%|█▎        | 60/459 [01:38<10:57,  0.61it/s, v_num=0w59, train/loss_step=0.0399, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  13%|█▎        | 61/459 [01:40<10:55,  0.61it/s, v_num=0w59, train/loss_step=0.0399, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  13%|█▎        | 61/459 [01:40<10:55,  0.61it/s, v_num=0w59, train/loss_step=0.0359, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  14%|█▎        | 62/459 [01:42<10:53,  0.61it/s, v_num=0w59, train/loss_step=0.0359, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  14%|█▎        | 62/459 [01:42<10:53,  0.61it/s, v_num=0w59, train/loss_step=0.0389, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  14%|█▎        | 63/459 [01:43<10:51,  0.61it/s, v_num=0w59, train/loss_step=0.0389, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  14%|█▎        | 63/459 [01:43<10:51,  0.61it/s, v_num=0w59, train/loss_step=0.0353, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  14%|█▍        | 64/459 [01:45<10:49,  0.61it/s, v_num=0w59, train/loss_step=0.0353, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  14%|█▍        | 64/459 [01:45<10:49,  0.61it/s, v_num=0w59, train/loss_step=0.0412, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  14%|█▍        | 65/459 [01:46<10:47,  0.61it/s, v_num=0w59, train/loss_step=0.0412, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  14%|█▍        | 65/459 [01:46<10:47,  0.61it/s, v_num=0w59, train/loss_step=0.0379, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  14%|█▍        | 66/459 [01:48<10:45,  0.61it/s, v_num=0w59, train/loss_step=0.0379, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  14%|█▍        | 66/459 [01:48<10:45,  0.61it/s, v_num=0w59, train/loss_step=0.0354, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  15%|█▍        | 67/459 [01:49<10:43,  0.61it/s, v_num=0w59, train/loss_step=0.0354, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  15%|█▍        | 67/459 [01:49<10:43,  0.61it/s, v_num=0w59, train/loss_step=0.0383, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  15%|█▍        | 68/459 [01:51<10:41,  0.61it/s, v_num=0w59, train/loss_step=0.0383, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  15%|█▍        | 68/459 [01:51<10:41,  0.61it/s, v_num=0w59, train/loss_step=0.0406, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  15%|█▌        | 69/459 [01:53<10:39,  0.61it/s, v_num=0w59, train/loss_step=0.0406, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  15%|█▌        | 69/459 [01:53<10:39,  0.61it/s, v_num=0w59, train/loss_step=0.0382, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  15%|█▌        | 70/459 [01:54<10:37,  0.61it/s, v_num=0w59, train/loss_step=0.0382, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  15%|█▌        | 70/459 [01:54<10:37,  0.61it/s, v_num=0w59, train/loss_step=0.0315, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  15%|█▌        | 71/459 [01:56<10:35,  0.61it/s, v_num=0w59, train/loss_step=0.0315, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  15%|█▌        | 71/459 [01:56<10:35,  0.61it/s, v_num=0w59, train/loss_step=0.0367, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  16%|█▌        | 72/459 [01:57<10:33,  0.61it/s, v_num=0w59, train/loss_step=0.0367, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  16%|█▌        | 72/459 [01:57<10:33,  0.61it/s, v_num=0w59, train/loss_step=0.038, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:  16%|█▌        | 73/459 [01:59<10:31,  0.61it/s, v_num=0w59, train/loss_step=0.038, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  16%|█▌        | 73/459 [01:59<10:31,  0.61it/s, v_num=0w59, train/loss_step=0.0359, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  16%|█▌        | 74/459 [02:01<10:29,  0.61it/s, v_num=0w59, train/loss_step=0.0359, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  16%|█▌        | 74/459 [02:01<10:29,  0.61it/s, v_num=0w59, train/loss_step=0.0397, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  16%|█▋        | 75/459 [02:02<10:27,  0.61it/s, v_num=0w59, train/loss_step=0.0397, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  16%|█▋        | 75/459 [02:02<10:27,  0.61it/s, v_num=0w59, train/loss_step=0.0401, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  17%|█▋        | 76/459 [02:04<10:26,  0.61it/s, v_num=0w59, train/loss_step=0.0401, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  17%|█▋        | 76/459 [02:04<10:26,  0.61it/s, v_num=0w59, train/loss_step=0.0386, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  17%|█▋        | 77/459 [02:05<10:24,  0.61it/s, v_num=0w59, train/loss_step=0.0386, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  17%|█▋        | 77/459 [02:05<10:24,  0.61it/s, v_num=0w59, train/loss_step=0.0377, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  17%|█▋        | 78/459 [02:07<10:22,  0.61it/s, v_num=0w59, train/loss_step=0.0377, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  17%|█▋        | 78/459 [02:07<10:22,  0.61it/s, v_num=0w59, train/loss_step=0.0336, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  17%|█▋        | 79/459 [02:09<10:20,  0.61it/s, v_num=0w59, train/loss_step=0.0336, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  17%|█▋        | 79/459 [02:09<10:20,  0.61it/s, v_num=0w59, train/loss_step=0.0438, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  17%|█▋        | 80/459 [02:10<10:18,  0.61it/s, v_num=0w59, train/loss_step=0.0438, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  17%|█▋        | 80/459 [02:10<10:18,  0.61it/s, v_num=0w59, train/loss_step=0.0376, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  18%|█▊        | 81/459 [02:12<10:16,  0.61it/s, v_num=0w59, train/loss_step=0.0376, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  18%|█▊        | 81/459 [02:12<10:17,  0.61it/s, v_num=0w59, train/loss_step=0.0361, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  18%|█▊        | 82/459 [02:13<10:15,  0.61it/s, v_num=0w59, train/loss_step=0.0361, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  18%|█▊        | 82/459 [02:13<10:15,  0.61it/s, v_num=0w59, train/loss_step=0.0346, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  18%|█▊        | 83/459 [02:15<10:13,  0.61it/s, v_num=0w59, train/loss_step=0.0346, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  18%|█▊        | 83/459 [02:15<10:13,  0.61it/s, v_num=0w59, train/loss_step=0.0338, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  18%|█▊        | 84/459 [02:16<10:11,  0.61it/s, v_num=0w59, train/loss_step=0.0338, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  18%|█▊        | 84/459 [02:16<10:11,  0.61it/s, v_num=0w59, train/loss_step=0.0392, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  19%|█▊        | 85/459 [02:18<10:09,  0.61it/s, v_num=0w59, train/loss_step=0.0392, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  19%|█▊        | 85/459 [02:18<10:09,  0.61it/s, v_num=0w59, train/loss_step=0.0354, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  19%|█▊        | 86/459 [02:20<10:08,  0.61it/s, v_num=0w59, train/loss_step=0.0354, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  19%|█▊        | 86/459 [02:20<10:08,  0.61it/s, v_num=0w59, train/loss_step=0.0354, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  19%|█▉        | 87/459 [02:21<10:06,  0.61it/s, v_num=0w59, train/loss_step=0.0354, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  19%|█▉        | 87/459 [02:21<10:06,  0.61it/s, v_num=0w59, train/loss_step=0.0344, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  19%|█▉        | 88/459 [02:23<10:04,  0.61it/s, v_num=0w59, train/loss_step=0.0344, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  19%|█▉        | 88/459 [02:23<10:04,  0.61it/s, v_num=0w59, train/loss_step=0.0374, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  19%|█▉        | 89/459 [02:24<10:02,  0.61it/s, v_num=0w59, train/loss_step=0.0374, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  19%|█▉        | 89/459 [02:24<10:02,  0.61it/s, v_num=0w59, train/loss_step=0.0349, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  20%|█▉        | 90/459 [02:26<10:00,  0.61it/s, v_num=0w59, train/loss_step=0.0349, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  20%|█▉        | 90/459 [02:26<10:00,  0.61it/s, v_num=0w59, train/loss_step=0.033, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:  20%|█▉        | 91/459 [02:28<09:59,  0.61it/s, v_num=0w59, train/loss_step=0.033, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  20%|█▉        | 91/459 [02:28<09:59,  0.61it/s, v_num=0w59, train/loss_step=0.0399, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  20%|██        | 92/459 [02:29<09:57,  0.61it/s, v_num=0w59, train/loss_step=0.0399, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  20%|██        | 92/459 [02:29<09:57,  0.61it/s, v_num=0w59, train/loss_step=0.036, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:  20%|██        | 93/459 [02:31<09:55,  0.61it/s, v_num=0w59, train/loss_step=0.036, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  20%|██        | 93/459 [02:31<09:55,  0.61it/s, v_num=0w59, train/loss_step=0.0344, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  20%|██        | 94/459 [02:32<09:53,  0.61it/s, v_num=0w59, train/loss_step=0.0344, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  20%|██        | 94/459 [02:32<09:53,  0.61it/s, v_num=0w59, train/loss_step=0.0358, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  21%|██        | 95/459 [02:34<09:52,  0.61it/s, v_num=0w59, train/loss_step=0.0358, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  21%|██        | 95/459 [02:34<09:52,  0.61it/s, v_num=0w59, train/loss_step=0.0364, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  21%|██        | 96/459 [02:36<09:50,  0.61it/s, v_num=0w59, train/loss_step=0.0364, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  21%|██        | 96/459 [02:36<09:50,  0.61it/s, v_num=0w59, train/loss_step=0.0375, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  21%|██        | 97/459 [02:37<09:48,  0.61it/s, v_num=0w59, train/loss_step=0.0375, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  21%|██        | 97/459 [02:37<09:48,  0.61it/s, v_num=0w59, train/loss_step=0.0426, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  21%|██▏       | 98/459 [02:39<09:47,  0.61it/s, v_num=0w59, train/loss_step=0.0426, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  21%|██▏       | 98/459 [02:39<09:47,  0.61it/s, v_num=0w59, train/loss_step=0.038, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:  22%|██▏       | 99/459 [02:40<09:45,  0.61it/s, v_num=0w59, train/loss_step=0.038, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  22%|██▏       | 99/459 [02:40<09:45,  0.61it/s, v_num=0w59, train/loss_step=0.0425, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  22%|██▏       | 100/459 [02:42<09:43,  0.62it/s, v_num=0w59, train/loss_step=0.0425, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  22%|██▏       | 100/459 [02:42<09:43,  0.62it/s, v_num=0w59, train/loss_step=0.038, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:  22%|██▏       | 101/459 [02:44<09:41,  0.62it/s, v_num=0w59, train/loss_step=0.038, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  22%|██▏       | 101/459 [02:44<09:41,  0.62it/s, v_num=0w59, train/loss_step=0.0381, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  22%|██▏       | 102/459 [02:45<09:40,  0.62it/s, v_num=0w59, train/loss_step=0.0381, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  22%|██▏       | 102/459 [02:45<09:40,  0.62it/s, v_num=0w59, train/loss_step=0.0359, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  22%|██▏       | 103/459 [02:47<09:38,  0.62it/s, v_num=0w59, train/loss_step=0.0359, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  22%|██▏       | 103/459 [02:47<09:38,  0.62it/s, v_num=0w59, train/loss_step=0.0362, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  23%|██▎       | 104/459 [02:48<09:36,  0.62it/s, v_num=0w59, train/loss_step=0.0362, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  23%|██▎       | 104/459 [02:48<09:36,  0.62it/s, v_num=0w59, train/loss_step=0.0392, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  23%|██▎       | 105/459 [02:50<09:35,  0.62it/s, v_num=0w59, train/loss_step=0.0392, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  23%|██▎       | 105/459 [02:50<09:35,  0.62it/s, v_num=0w59, train/loss_step=0.0343, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  23%|██▎       | 106/459 [02:52<09:33,  0.62it/s, v_num=0w59, train/loss_step=0.0343, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  23%|██▎       | 106/459 [02:52<09:33,  0.62it/s, v_num=0w59, train/loss_step=0.0382, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  23%|██▎       | 107/459 [02:53<09:31,  0.62it/s, v_num=0w59, train/loss_step=0.0382, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  23%|██▎       | 107/459 [02:53<09:31,  0.62it/s, v_num=0w59, train/loss_step=0.0343, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  24%|██▎       | 108/459 [02:55<09:30,  0.62it/s, v_num=0w59, train/loss_step=0.0343, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  24%|██▎       | 108/459 [02:55<09:30,  0.62it/s, v_num=0w59, train/loss_step=0.0368, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  24%|██▎       | 109/459 [02:56<09:28,  0.62it/s, v_num=0w59, train/loss_step=0.0368, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  24%|██▎       | 109/459 [02:56<09:28,  0.62it/s, v_num=0w59, train/loss_step=0.0372, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  24%|██▍       | 110/459 [02:58<09:26,  0.62it/s, v_num=0w59, train/loss_step=0.0372, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  24%|██▍       | 110/459 [02:58<09:26,  0.62it/s, v_num=0w59, train/loss_step=0.0351, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  24%|██▍       | 111/459 [03:00<09:24,  0.62it/s, v_num=0w59, train/loss_step=0.0351, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  24%|██▍       | 111/459 [03:00<09:24,  0.62it/s, v_num=0w59, train/loss_step=0.0374, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  24%|██▍       | 112/459 [03:01<09:23,  0.62it/s, v_num=0w59, train/loss_step=0.0374, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  24%|██▍       | 112/459 [03:01<09:23,  0.62it/s, v_num=0w59, train/loss_step=0.0364, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  25%|██▍       | 113/459 [03:03<09:21,  0.62it/s, v_num=0w59, train/loss_step=0.0364, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  25%|██▍       | 113/459 [03:03<09:21,  0.62it/s, v_num=0w59, train/loss_step=0.0365, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  25%|██▍       | 114/459 [03:04<09:19,  0.62it/s, v_num=0w59, train/loss_step=0.0365, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  25%|██▍       | 114/459 [03:04<09:19,  0.62it/s, v_num=0w59, train/loss_step=0.0328, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  25%|██▌       | 115/459 [03:06<09:17,  0.62it/s, v_num=0w59, train/loss_step=0.0328, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  25%|██▌       | 115/459 [03:06<09:17,  0.62it/s, v_num=0w59, train/loss_step=0.0369, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  25%|██▌       | 116/459 [03:08<09:16,  0.62it/s, v_num=0w59, train/loss_step=0.0369, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  25%|██▌       | 116/459 [03:08<09:16,  0.62it/s, v_num=0w59, train/loss_step=0.038, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:  25%|██▌       | 117/459 [03:09<09:14,  0.62it/s, v_num=0w59, train/loss_step=0.038, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  25%|██▌       | 117/459 [03:09<09:14,  0.62it/s, v_num=0w59, train/loss_step=0.0308, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  26%|██▌       | 118/459 [03:11<09:12,  0.62it/s, v_num=0w59, train/loss_step=0.0308, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  26%|██▌       | 118/459 [03:11<09:12,  0.62it/s, v_num=0w59, train/loss_step=0.034, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:  26%|██▌       | 119/459 [03:12<09:10,  0.62it/s, v_num=0w59, train/loss_step=0.034, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  26%|██▌       | 119/459 [03:12<09:10,  0.62it/s, v_num=0w59, train/loss_step=0.0369, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  26%|██▌       | 120/459 [03:14<09:09,  0.62it/s, v_num=0w59, train/loss_step=0.0369, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  26%|██▌       | 120/459 [03:14<09:09,  0.62it/s, v_num=0w59, train/loss_step=0.036, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:  26%|██▋       | 121/459 [03:15<09:07,  0.62it/s, v_num=0w59, train/loss_step=0.036, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  26%|██▋       | 121/459 [03:15<09:07,  0.62it/s, v_num=0w59, train/loss_step=0.0382, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  27%|██▋       | 122/459 [03:17<09:05,  0.62it/s, v_num=0w59, train/loss_step=0.0382, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  27%|██▋       | 122/459 [03:17<09:05,  0.62it/s, v_num=0w59, train/loss_step=0.033, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:  27%|██▋       | 123/459 [03:19<09:03,  0.62it/s, v_num=0w59, train/loss_step=0.033, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  27%|██▋       | 123/459 [03:19<09:03,  0.62it/s, v_num=0w59, train/loss_step=0.0349, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  27%|██▋       | 124/459 [03:20<09:02,  0.62it/s, v_num=0w59, train/loss_step=0.0349, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  27%|██▋       | 124/459 [03:20<09:02,  0.62it/s, v_num=0w59, train/loss_step=0.0345, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  27%|██▋       | 125/459 [03:22<09:00,  0.62it/s, v_num=0w59, train/loss_step=0.0345, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  27%|██▋       | 125/459 [03:22<09:00,  0.62it/s, v_num=0w59, train/loss_step=0.0369, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  27%|██▋       | 126/459 [03:23<08:58,  0.62it/s, v_num=0w59, train/loss_step=0.0369, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  27%|██▋       | 126/459 [03:23<08:58,  0.62it/s, v_num=0w59, train/loss_step=0.0395, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  28%|██▊       | 127/459 [03:25<08:56,  0.62it/s, v_num=0w59, train/loss_step=0.0395, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  28%|██▊       | 127/459 [03:25<08:56,  0.62it/s, v_num=0w59, train/loss_step=0.039, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:  28%|██▊       | 128/459 [03:26<08:55,  0.62it/s, v_num=0w59, train/loss_step=0.039, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  28%|██▊       | 128/459 [03:26<08:55,  0.62it/s, v_num=0w59, train/loss_step=0.0401, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  28%|██▊       | 129/459 [03:28<08:53,  0.62it/s, v_num=0w59, train/loss_step=0.0401, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  28%|██▊       | 129/459 [03:28<08:53,  0.62it/s, v_num=0w59, train/loss_step=0.0347, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  28%|██▊       | 130/459 [03:30<08:51,  0.62it/s, v_num=0w59, train/loss_step=0.0347, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  28%|██▊       | 130/459 [03:30<08:51,  0.62it/s, v_num=0w59, train/loss_step=0.0357, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  29%|██▊       | 131/459 [03:31<08:50,  0.62it/s, v_num=0w59, train/loss_step=0.0357, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  29%|██▊       | 131/459 [03:31<08:50,  0.62it/s, v_num=0w59, train/loss_step=0.0363, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  29%|██▉       | 132/459 [03:33<08:48,  0.62it/s, v_num=0w59, train/loss_step=0.0363, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  29%|██▉       | 132/459 [03:33<08:48,  0.62it/s, v_num=0w59, train/loss_step=0.0354, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  29%|██▉       | 133/459 [03:34<08:46,  0.62it/s, v_num=0w59, train/loss_step=0.0354, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  29%|██▉       | 133/459 [03:34<08:46,  0.62it/s, v_num=0w59, train/loss_step=0.0352, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  29%|██▉       | 134/459 [03:36<08:44,  0.62it/s, v_num=0w59, train/loss_step=0.0352, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  29%|██▉       | 134/459 [03:36<08:44,  0.62it/s, v_num=0w59, train/loss_step=0.0395, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  29%|██▉       | 135/459 [03:37<08:43,  0.62it/s, v_num=0w59, train/loss_step=0.0395, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  29%|██▉       | 135/459 [03:37<08:43,  0.62it/s, v_num=0w59, train/loss_step=0.0378, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  30%|██▉       | 136/459 [03:39<08:41,  0.62it/s, v_num=0w59, train/loss_step=0.0378, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  30%|██▉       | 136/459 [03:39<08:41,  0.62it/s, v_num=0w59, train/loss_step=0.0318, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  30%|██▉       | 137/459 [03:41<08:39,  0.62it/s, v_num=0w59, train/loss_step=0.0318, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  30%|██▉       | 137/459 [03:41<08:39,  0.62it/s, v_num=0w59, train/loss_step=0.0375, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  30%|███       | 138/459 [03:42<08:37,  0.62it/s, v_num=0w59, train/loss_step=0.0375, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  30%|███       | 138/459 [03:42<08:37,  0.62it/s, v_num=0w59, train/loss_step=0.0398, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  30%|███       | 139/459 [03:44<08:36,  0.62it/s, v_num=0w59, train/loss_step=0.0398, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  30%|███       | 139/459 [03:44<08:36,  0.62it/s, v_num=0w59, train/loss_step=0.0341, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  31%|███       | 140/459 [03:45<08:34,  0.62it/s, v_num=0w59, train/loss_step=0.0341, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  31%|███       | 140/459 [03:45<08:34,  0.62it/s, v_num=0w59, train/loss_step=0.0401, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  31%|███       | 141/459 [03:47<08:32,  0.62it/s, v_num=0w59, train/loss_step=0.0401, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  31%|███       | 141/459 [03:47<08:32,  0.62it/s, v_num=0w59, train/loss_step=0.0364, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  31%|███       | 142/459 [03:48<08:31,  0.62it/s, v_num=0w59, train/loss_step=0.0364, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  31%|███       | 142/459 [03:48<08:31,  0.62it/s, v_num=0w59, train/loss_step=0.0398, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  31%|███       | 143/459 [03:50<08:29,  0.62it/s, v_num=0w59, train/loss_step=0.0398, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  31%|███       | 143/459 [03:50<08:29,  0.62it/s, v_num=0w59, train/loss_step=0.0367, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  31%|███▏      | 144/459 [03:52<08:27,  0.62it/s, v_num=0w59, train/loss_step=0.0367, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  31%|███▏      | 144/459 [03:52<08:27,  0.62it/s, v_num=0w59, train/loss_step=0.0364, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  32%|███▏      | 145/459 [03:53<08:26,  0.62it/s, v_num=0w59, train/loss_step=0.0364, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  32%|███▏      | 145/459 [03:53<08:26,  0.62it/s, v_num=0w59, train/loss_step=0.0331, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  32%|███▏      | 146/459 [03:55<08:24,  0.62it/s, v_num=0w59, train/loss_step=0.0331, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  32%|███▏      | 146/459 [03:55<08:24,  0.62it/s, v_num=0w59, train/loss_step=0.0364, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  32%|███▏      | 147/459 [03:56<08:22,  0.62it/s, v_num=0w59, train/loss_step=0.0364, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  32%|███▏      | 147/459 [03:56<08:22,  0.62it/s, v_num=0w59, train/loss_step=0.0373, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  32%|███▏      | 148/459 [03:58<08:20,  0.62it/s, v_num=0w59, train/loss_step=0.0373, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  32%|███▏      | 148/459 [03:58<08:21,  0.62it/s, v_num=0w59, train/loss_step=0.0382, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  32%|███▏      | 149/459 [03:59<08:19,  0.62it/s, v_num=0w59, train/loss_step=0.0382, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  32%|███▏      | 149/459 [03:59<08:19,  0.62it/s, v_num=0w59, train/loss_step=0.0369, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  33%|███▎      | 150/459 [04:01<08:17,  0.62it/s, v_num=0w59, train/loss_step=0.0369, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  33%|███▎      | 150/459 [04:01<08:17,  0.62it/s, v_num=0w59, train/loss_step=0.0325, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  33%|███▎      | 151/459 [04:03<08:15,  0.62it/s, v_num=0w59, train/loss_step=0.0325, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  33%|███▎      | 151/459 [04:03<08:15,  0.62it/s, v_num=0w59, train/loss_step=0.0352, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  33%|███▎      | 152/459 [04:04<08:14,  0.62it/s, v_num=0w59, train/loss_step=0.0352, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  33%|███▎      | 152/459 [04:04<08:14,  0.62it/s, v_num=0w59, train/loss_step=0.0313, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  33%|███▎      | 153/459 [04:06<08:12,  0.62it/s, v_num=0w59, train/loss_step=0.0313, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  33%|███▎      | 153/459 [04:06<08:12,  0.62it/s, v_num=0w59, train/loss_step=0.0347, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  34%|███▎      | 154/459 [04:07<08:10,  0.62it/s, v_num=0w59, train/loss_step=0.0347, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  34%|███▎      | 154/459 [04:07<08:10,  0.62it/s, v_num=0w59, train/loss_step=0.0378, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  34%|███▍      | 155/459 [04:09<08:09,  0.62it/s, v_num=0w59, train/loss_step=0.0378, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  34%|███▍      | 155/459 [04:09<08:09,  0.62it/s, v_num=0w59, train/loss_step=0.0367, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  34%|███▍      | 156/459 [04:10<08:07,  0.62it/s, v_num=0w59, train/loss_step=0.0367, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  34%|███▍      | 156/459 [04:10<08:07,  0.62it/s, v_num=0w59, train/loss_step=0.0385, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  34%|███▍      | 157/459 [04:12<08:05,  0.62it/s, v_num=0w59, train/loss_step=0.0385, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  34%|███▍      | 157/459 [04:12<08:05,  0.62it/s, v_num=0w59, train/loss_step=0.0316, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  34%|███▍      | 158/459 [04:14<08:04,  0.62it/s, v_num=0w59, train/loss_step=0.0316, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  34%|███▍      | 158/459 [04:14<08:04,  0.62it/s, v_num=0w59, train/loss_step=0.0363, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  35%|███▍      | 159/459 [04:15<08:02,  0.62it/s, v_num=0w59, train/loss_step=0.0363, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  35%|███▍      | 159/459 [04:15<08:02,  0.62it/s, v_num=0w59, train/loss_step=0.0317, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  35%|███▍      | 160/459 [04:17<08:00,  0.62it/s, v_num=0w59, train/loss_step=0.0317, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  35%|███▍      | 160/459 [04:17<08:00,  0.62it/s, v_num=0w59, train/loss_step=0.0377, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  35%|███▌      | 161/459 [04:18<07:59,  0.62it/s, v_num=0w59, train/loss_step=0.0377, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  35%|███▌      | 161/459 [04:18<07:59,  0.62it/s, v_num=0w59, train/loss_step=0.0339, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  35%|███▌      | 162/459 [04:20<07:57,  0.62it/s, v_num=0w59, train/loss_step=0.0339, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  35%|███▌      | 162/459 [04:20<07:57,  0.62it/s, v_num=0w59, train/loss_step=0.0368, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  36%|███▌      | 163/459 [04:21<07:55,  0.62it/s, v_num=0w59, train/loss_step=0.0368, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  36%|███▌      | 163/459 [04:21<07:55,  0.62it/s, v_num=0w59, train/loss_step=0.0364, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  36%|███▌      | 164/459 [04:23<07:54,  0.62it/s, v_num=0w59, train/loss_step=0.0364, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  36%|███▌      | 164/459 [04:23<07:54,  0.62it/s, v_num=0w59, train/loss_step=0.0379, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  36%|███▌      | 165/459 [04:25<07:52,  0.62it/s, v_num=0w59, train/loss_step=0.0379, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  36%|███▌      | 165/459 [04:25<07:52,  0.62it/s, v_num=0w59, train/loss_step=0.0395, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  36%|███▌      | 166/459 [04:26<07:50,  0.62it/s, v_num=0w59, train/loss_step=0.0395, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  36%|███▌      | 166/459 [04:26<07:50,  0.62it/s, v_num=0w59, train/loss_step=0.0313, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  36%|███▋      | 167/459 [04:28<07:49,  0.62it/s, v_num=0w59, train/loss_step=0.0313, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  36%|███▋      | 167/459 [04:28<07:49,  0.62it/s, v_num=0w59, train/loss_step=0.0362, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  37%|███▋      | 168/459 [04:29<07:47,  0.62it/s, v_num=0w59, train/loss_step=0.0362, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  37%|███▋      | 168/459 [04:29<07:47,  0.62it/s, v_num=0w59, train/loss_step=0.0367, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  37%|███▋      | 169/459 [04:31<07:45,  0.62it/s, v_num=0w59, train/loss_step=0.0367, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  37%|███▋      | 169/459 [04:31<07:45,  0.62it/s, v_num=0w59, train/loss_step=0.0346, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  37%|███▋      | 170/459 [04:32<07:44,  0.62it/s, v_num=0w59, train/loss_step=0.0346, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  37%|███▋      | 170/459 [04:32<07:44,  0.62it/s, v_num=0w59, train/loss_step=0.0364, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  37%|███▋      | 171/459 [04:34<07:42,  0.62it/s, v_num=0w59, train/loss_step=0.0364, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  37%|███▋      | 171/459 [04:34<07:42,  0.62it/s, v_num=0w59, train/loss_step=0.0365, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  37%|███▋      | 172/459 [04:36<07:40,  0.62it/s, v_num=0w59, train/loss_step=0.0365, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  37%|███▋      | 172/459 [04:36<07:40,  0.62it/s, v_num=0w59, train/loss_step=0.0364, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  38%|███▊      | 173/459 [04:37<07:39,  0.62it/s, v_num=0w59, train/loss_step=0.0364, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  38%|███▊      | 173/459 [04:37<07:39,  0.62it/s, v_num=0w59, train/loss_step=0.0362, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  38%|███▊      | 174/459 [04:39<07:37,  0.62it/s, v_num=0w59, train/loss_step=0.0362, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  38%|███▊      | 174/459 [04:39<07:37,  0.62it/s, v_num=0w59, train/loss_step=0.0348, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  38%|███▊      | 175/459 [04:40<07:35,  0.62it/s, v_num=0w59, train/loss_step=0.0348, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  38%|███▊      | 175/459 [04:40<07:35,  0.62it/s, v_num=0w59, train/loss_step=0.0323, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  38%|███▊      | 176/459 [04:42<07:34,  0.62it/s, v_num=0w59, train/loss_step=0.0323, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  38%|███▊      | 176/459 [04:42<07:34,  0.62it/s, v_num=0w59, train/loss_step=0.0355, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  39%|███▊      | 177/459 [04:43<07:32,  0.62it/s, v_num=0w59, train/loss_step=0.0355, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  39%|███▊      | 177/459 [04:43<07:32,  0.62it/s, v_num=0w59, train/loss_step=0.034, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:  39%|███▉      | 178/459 [04:45<07:30,  0.62it/s, v_num=0w59, train/loss_step=0.034, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  39%|███▉      | 178/459 [04:45<07:30,  0.62it/s, v_num=0w59, train/loss_step=0.0366, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  39%|███▉      | 179/459 [04:47<07:29,  0.62it/s, v_num=0w59, train/loss_step=0.0366, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  39%|███▉      | 179/459 [04:47<07:29,  0.62it/s, v_num=0w59, train/loss_step=0.0368, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  39%|███▉      | 180/459 [04:48<07:27,  0.62it/s, v_num=0w59, train/loss_step=0.0368, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  39%|███▉      | 180/459 [04:48<07:27,  0.62it/s, v_num=0w59, train/loss_step=0.0372, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  39%|███▉      | 181/459 [04:50<07:25,  0.62it/s, v_num=0w59, train/loss_step=0.0372, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  39%|███▉      | 181/459 [04:50<07:25,  0.62it/s, v_num=0w59, train/loss_step=0.034, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:  40%|███▉      | 182/459 [04:51<07:24,  0.62it/s, v_num=0w59, train/loss_step=0.034, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  40%|███▉      | 182/459 [04:51<07:24,  0.62it/s, v_num=0w59, train/loss_step=0.0354, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  40%|███▉      | 183/459 [04:53<07:22,  0.62it/s, v_num=0w59, train/loss_step=0.0354, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  40%|███▉      | 183/459 [04:53<07:22,  0.62it/s, v_num=0w59, train/loss_step=0.0393, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  40%|████      | 184/459 [04:55<07:20,  0.62it/s, v_num=0w59, train/loss_step=0.0393, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  40%|████      | 184/459 [04:55<07:20,  0.62it/s, v_num=0w59, train/loss_step=0.0327, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  40%|████      | 185/459 [04:56<07:19,  0.62it/s, v_num=0w59, train/loss_step=0.0327, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  40%|████      | 185/459 [04:56<07:19,  0.62it/s, v_num=0w59, train/loss_step=0.0354, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  41%|████      | 186/459 [04:58<07:17,  0.62it/s, v_num=0w59, train/loss_step=0.0354, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  41%|████      | 186/459 [04:58<07:17,  0.62it/s, v_num=0w59, train/loss_step=0.0368, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  41%|████      | 187/459 [04:59<07:15,  0.62it/s, v_num=0w59, train/loss_step=0.0368, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  41%|████      | 187/459 [04:59<07:15,  0.62it/s, v_num=0w59, train/loss_step=0.0324, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  41%|████      | 188/459 [05:01<07:14,  0.62it/s, v_num=0w59, train/loss_step=0.0324, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  41%|████      | 188/459 [05:01<07:14,  0.62it/s, v_num=0w59, train/loss_step=0.0364, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  41%|████      | 189/459 [05:02<07:12,  0.62it/s, v_num=0w59, train/loss_step=0.0364, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  41%|████      | 189/459 [05:02<07:12,  0.62it/s, v_num=0w59, train/loss_step=0.0331, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  41%|████▏     | 190/459 [05:04<07:11,  0.62it/s, v_num=0w59, train/loss_step=0.0331, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  41%|████▏     | 190/459 [05:04<07:11,  0.62it/s, v_num=0w59, train/loss_step=0.0336, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  42%|████▏     | 191/459 [05:06<07:09,  0.62it/s, v_num=0w59, train/loss_step=0.0336, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  42%|████▏     | 191/459 [05:06<07:09,  0.62it/s, v_num=0w59, train/loss_step=0.033, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:  42%|████▏     | 192/459 [05:07<07:07,  0.62it/s, v_num=0w59, train/loss_step=0.033, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  42%|████▏     | 192/459 [05:07<07:07,  0.62it/s, v_num=0w59, train/loss_step=0.0358, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  42%|████▏     | 193/459 [05:09<07:06,  0.62it/s, v_num=0w59, train/loss_step=0.0358, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  42%|████▏     | 193/459 [05:09<07:06,  0.62it/s, v_num=0w59, train/loss_step=0.0396, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  42%|████▏     | 194/459 [05:10<07:04,  0.62it/s, v_num=0w59, train/loss_step=0.0396, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  42%|████▏     | 194/459 [05:10<07:04,  0.62it/s, v_num=0w59, train/loss_step=0.0351, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  42%|████▏     | 195/459 [05:12<07:02,  0.62it/s, v_num=0w59, train/loss_step=0.0351, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  42%|████▏     | 195/459 [05:12<07:02,  0.62it/s, v_num=0w59, train/loss_step=0.0367, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  43%|████▎     | 196/459 [05:14<07:01,  0.62it/s, v_num=0w59, train/loss_step=0.0367, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  43%|████▎     | 196/459 [05:14<07:01,  0.62it/s, v_num=0w59, train/loss_step=0.0358, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  43%|████▎     | 197/459 [05:15<06:59,  0.62it/s, v_num=0w59, train/loss_step=0.0358, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  43%|████▎     | 197/459 [05:15<06:59,  0.62it/s, v_num=0w59, train/loss_step=0.0322, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  43%|████▎     | 198/459 [05:17<06:58,  0.62it/s, v_num=0w59, train/loss_step=0.0322, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  43%|████▎     | 198/459 [05:17<06:58,  0.62it/s, v_num=0w59, train/loss_step=0.0342, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  43%|████▎     | 199/459 [05:18<06:56,  0.62it/s, v_num=0w59, train/loss_step=0.0342, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  43%|████▎     | 199/459 [05:18<06:56,  0.62it/s, v_num=0w59, train/loss_step=0.032, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:  44%|████▎     | 200/459 [05:20<06:54,  0.62it/s, v_num=0w59, train/loss_step=0.032, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  44%|████▎     | 200/459 [05:20<06:54,  0.62it/s, v_num=0w59, train/loss_step=0.0331, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  44%|████▍     | 201/459 [05:21<06:53,  0.62it/s, v_num=0w59, train/loss_step=0.0331, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  44%|████▍     | 201/459 [05:21<06:53,  0.62it/s, v_num=0w59, train/loss_step=0.0383, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  44%|████▍     | 202/459 [05:23<06:51,  0.62it/s, v_num=0w59, train/loss_step=0.0383, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  44%|████▍     | 202/459 [05:23<06:51,  0.62it/s, v_num=0w59, train/loss_step=0.0368, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  44%|████▍     | 203/459 [05:25<06:50,  0.62it/s, v_num=0w59, train/loss_step=0.0368, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  44%|████▍     | 203/459 [05:25<06:50,  0.62it/s, v_num=0w59, train/loss_step=0.0373, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  44%|████▍     | 204/459 [05:26<06:48,  0.62it/s, v_num=0w59, train/loss_step=0.0373, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  44%|████▍     | 204/459 [05:26<06:48,  0.62it/s, v_num=0w59, train/loss_step=0.0378, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  45%|████▍     | 205/459 [05:28<06:46,  0.62it/s, v_num=0w59, train/loss_step=0.0378, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  45%|████▍     | 205/459 [05:28<06:46,  0.62it/s, v_num=0w59, train/loss_step=0.0371, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  45%|████▍     | 206/459 [05:29<06:45,  0.62it/s, v_num=0w59, train/loss_step=0.0371, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  45%|████▍     | 206/459 [05:29<06:45,  0.62it/s, v_num=0w59, train/loss_step=0.036, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:  45%|████▌     | 207/459 [05:31<06:43,  0.62it/s, v_num=0w59, train/loss_step=0.036, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  45%|████▌     | 207/459 [05:31<06:43,  0.62it/s, v_num=0w59, train/loss_step=0.0328, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  45%|████▌     | 208/459 [05:33<06:41,  0.62it/s, v_num=0w59, train/loss_step=0.0328, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  45%|████▌     | 208/459 [05:33<06:41,  0.62it/s, v_num=0w59, train/loss_step=0.0366, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  46%|████▌     | 209/459 [05:34<06:40,  0.62it/s, v_num=0w59, train/loss_step=0.0366, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  46%|████▌     | 209/459 [05:34<06:40,  0.62it/s, v_num=0w59, train/loss_step=0.0401, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  46%|████▌     | 210/459 [05:36<06:38,  0.62it/s, v_num=0w59, train/loss_step=0.0401, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  46%|████▌     | 210/459 [05:36<06:38,  0.62it/s, v_num=0w59, train/loss_step=0.0354, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  46%|████▌     | 211/459 [05:37<06:37,  0.62it/s, v_num=0w59, train/loss_step=0.0354, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  46%|████▌     | 211/459 [05:37<06:37,  0.62it/s, v_num=0w59, train/loss_step=0.0324, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  46%|████▌     | 212/459 [05:39<06:35,  0.62it/s, v_num=0w59, train/loss_step=0.0324, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  46%|████▌     | 212/459 [05:39<06:35,  0.62it/s, v_num=0w59, train/loss_step=0.0377, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  46%|████▋     | 213/459 [05:41<06:33,  0.62it/s, v_num=0w59, train/loss_step=0.0377, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  46%|████▋     | 213/459 [05:41<06:33,  0.62it/s, v_num=0w59, train/loss_step=0.0383, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  47%|████▋     | 214/459 [05:42<06:32,  0.62it/s, v_num=0w59, train/loss_step=0.0383, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  47%|████▋     | 214/459 [05:42<06:32,  0.62it/s, v_num=0w59, train/loss_step=0.0296, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  47%|████▋     | 215/459 [05:44<06:30,  0.62it/s, v_num=0w59, train/loss_step=0.0296, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  47%|████▋     | 215/459 [05:44<06:30,  0.62it/s, v_num=0w59, train/loss_step=0.0349, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  47%|████▋     | 216/459 [05:45<06:29,  0.62it/s, v_num=0w59, train/loss_step=0.0349, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  47%|████▋     | 216/459 [05:45<06:29,  0.62it/s, v_num=0w59, train/loss_step=0.0363, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  47%|████▋     | 217/459 [05:47<06:27,  0.62it/s, v_num=0w59, train/loss_step=0.0363, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  47%|████▋     | 217/459 [05:47<06:27,  0.62it/s, v_num=0w59, train/loss_step=0.0389, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  47%|████▋     | 218/459 [05:49<06:25,  0.62it/s, v_num=0w59, train/loss_step=0.0389, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  47%|████▋     | 218/459 [05:49<06:25,  0.62it/s, v_num=0w59, train/loss_step=0.0296, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  48%|████▊     | 219/459 [05:50<06:24,  0.62it/s, v_num=0w59, train/loss_step=0.0296, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  48%|████▊     | 219/459 [05:50<06:24,  0.62it/s, v_num=0w59, train/loss_step=0.0361, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  48%|████▊     | 220/459 [05:52<06:22,  0.62it/s, v_num=0w59, train/loss_step=0.0361, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  48%|████▊     | 220/459 [05:52<06:22,  0.62it/s, v_num=0w59, train/loss_step=0.0314, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  48%|████▊     | 221/459 [05:53<06:21,  0.62it/s, v_num=0w59, train/loss_step=0.0314, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  48%|████▊     | 221/459 [05:53<06:21,  0.62it/s, v_num=0w59, train/loss_step=0.033, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:  48%|████▊     | 222/459 [05:55<06:19,  0.62it/s, v_num=0w59, train/loss_step=0.033, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  48%|████▊     | 222/459 [05:55<06:19,  0.62it/s, v_num=0w59, train/loss_step=0.0349, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  49%|████▊     | 223/459 [05:57<06:17,  0.62it/s, v_num=0w59, train/loss_step=0.0349, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  49%|████▊     | 223/459 [05:57<06:17,  0.62it/s, v_num=0w59, train/loss_step=0.0367, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  49%|████▉     | 224/459 [05:58<06:16,  0.62it/s, v_num=0w59, train/loss_step=0.0367, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  49%|████▉     | 224/459 [05:58<06:16,  0.62it/s, v_num=0w59, train/loss_step=0.0356, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  49%|████▉     | 225/459 [06:00<06:14,  0.62it/s, v_num=0w59, train/loss_step=0.0356, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  49%|████▉     | 225/459 [06:00<06:14,  0.62it/s, v_num=0w59, train/loss_step=0.0332, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  49%|████▉     | 226/459 [06:01<06:13,  0.62it/s, v_num=0w59, train/loss_step=0.0332, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  49%|████▉     | 226/459 [06:01<06:13,  0.62it/s, v_num=0w59, train/loss_step=0.0327, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  49%|████▉     | 227/459 [06:03<06:11,  0.62it/s, v_num=0w59, train/loss_step=0.0327, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  49%|████▉     | 227/459 [06:03<06:11,  0.62it/s, v_num=0w59, train/loss_step=0.0372, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  50%|████▉     | 228/459 [06:05<06:09,  0.62it/s, v_num=0w59, train/loss_step=0.0372, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  50%|████▉     | 228/459 [06:05<06:09,  0.62it/s, v_num=0w59, train/loss_step=0.0366, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  50%|████▉     | 229/459 [06:06<06:08,  0.62it/s, v_num=0w59, train/loss_step=0.0366, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  50%|████▉     | 229/459 [06:06<06:08,  0.62it/s, v_num=0w59, train/loss_step=0.033, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:  50%|█████     | 230/459 [06:08<06:06,  0.62it/s, v_num=0w59, train/loss_step=0.033, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  50%|█████     | 230/459 [06:08<06:06,  0.62it/s, v_num=0w59, train/loss_step=0.0385, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  50%|█████     | 231/459 [06:09<06:05,  0.62it/s, v_num=0w59, train/loss_step=0.0385, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  50%|█████     | 231/459 [06:09<06:05,  0.62it/s, v_num=0w59, train/loss_step=0.0338, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  51%|█████     | 232/459 [06:11<06:03,  0.62it/s, v_num=0w59, train/loss_step=0.0338, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  51%|█████     | 232/459 [06:11<06:03,  0.62it/s, v_num=0w59, train/loss_step=0.0351, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  51%|█████     | 233/459 [06:13<06:01,  0.62it/s, v_num=0w59, train/loss_step=0.0351, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  51%|█████     | 233/459 [06:13<06:01,  0.62it/s, v_num=0w59, train/loss_step=0.0318, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  51%|█████     | 234/459 [06:14<06:00,  0.62it/s, v_num=0w59, train/loss_step=0.0318, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  51%|█████     | 234/459 [06:14<06:00,  0.62it/s, v_num=0w59, train/loss_step=0.0374, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  51%|█████     | 235/459 [06:16<05:58,  0.62it/s, v_num=0w59, train/loss_step=0.0374, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  51%|█████     | 235/459 [06:16<05:58,  0.62it/s, v_num=0w59, train/loss_step=0.0348, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  51%|█████▏    | 236/459 [06:17<05:57,  0.62it/s, v_num=0w59, train/loss_step=0.0348, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  51%|█████▏    | 236/459 [06:17<05:57,  0.62it/s, v_num=0w59, train/loss_step=0.0363, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  52%|█████▏    | 237/459 [06:19<05:55,  0.62it/s, v_num=0w59, train/loss_step=0.0363, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  52%|█████▏    | 237/459 [06:19<05:55,  0.62it/s, v_num=0w59, train/loss_step=0.0349, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  52%|█████▏    | 238/459 [06:21<05:53,  0.62it/s, v_num=0w59, train/loss_step=0.0349, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  52%|█████▏    | 238/459 [06:21<05:53,  0.62it/s, v_num=0w59, train/loss_step=0.0345, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  52%|█████▏    | 239/459 [06:22<05:52,  0.62it/s, v_num=0w59, train/loss_step=0.0345, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  52%|█████▏    | 239/459 [06:22<05:52,  0.62it/s, v_num=0w59, train/loss_step=0.0345, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  52%|█████▏    | 240/459 [06:24<05:50,  0.62it/s, v_num=0w59, train/loss_step=0.0345, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  52%|█████▏    | 240/459 [06:24<05:50,  0.62it/s, v_num=0w59, train/loss_step=0.0328, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  53%|█████▎    | 241/459 [06:25<05:49,  0.62it/s, v_num=0w59, train/loss_step=0.0328, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  53%|█████▎    | 241/459 [06:25<05:49,  0.62it/s, v_num=0w59, train/loss_step=0.033, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:  53%|█████▎    | 242/459 [06:27<05:47,  0.62it/s, v_num=0w59, train/loss_step=0.033, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  53%|█████▎    | 242/459 [06:27<05:47,  0.62it/s, v_num=0w59, train/loss_step=0.0345, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  53%|█████▎    | 243/459 [06:29<05:45,  0.62it/s, v_num=0w59, train/loss_step=0.0345, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  53%|█████▎    | 243/459 [06:29<05:45,  0.62it/s, v_num=0w59, train/loss_step=0.0373, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  53%|█████▎    | 244/459 [06:30<05:44,  0.62it/s, v_num=0w59, train/loss_step=0.0373, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  53%|█████▎    | 244/459 [06:30<05:44,  0.62it/s, v_num=0w59, train/loss_step=0.0344, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  53%|█████▎    | 245/459 [06:32<05:42,  0.62it/s, v_num=0w59, train/loss_step=0.0344, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  53%|█████▎    | 245/459 [06:32<05:42,  0.62it/s, v_num=0w59, train/loss_step=0.0325, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  54%|█████▎    | 246/459 [06:33<05:41,  0.62it/s, v_num=0w59, train/loss_step=0.0325, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  54%|█████▎    | 246/459 [06:33<05:41,  0.62it/s, v_num=0w59, train/loss_step=0.0393, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  54%|█████▍    | 247/459 [06:35<05:39,  0.62it/s, v_num=0w59, train/loss_step=0.0393, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  54%|█████▍    | 247/459 [06:35<05:39,  0.62it/s, v_num=0w59, train/loss_step=0.0333, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  54%|█████▍    | 248/459 [06:37<05:37,  0.62it/s, v_num=0w59, train/loss_step=0.0333, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  54%|█████▍    | 248/459 [06:37<05:37,  0.62it/s, v_num=0w59, train/loss_step=0.0337, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  54%|█████▍    | 249/459 [06:38<05:36,  0.62it/s, v_num=0w59, train/loss_step=0.0337, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  54%|█████▍    | 249/459 [06:38<05:36,  0.62it/s, v_num=0w59, train/loss_step=0.0351, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  54%|█████▍    | 250/459 [06:40<05:34,  0.62it/s, v_num=0w59, train/loss_step=0.0351, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  54%|█████▍    | 250/459 [06:40<05:34,  0.62it/s, v_num=0w59, train/loss_step=0.0332, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  55%|█████▍    | 251/459 [06:42<05:33,  0.62it/s, v_num=0w59, train/loss_step=0.0332, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  55%|█████▍    | 251/459 [06:42<05:33,  0.62it/s, v_num=0w59, train/loss_step=0.0314, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  55%|█████▍    | 252/459 [06:43<05:31,  0.62it/s, v_num=0w59, train/loss_step=0.0314, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  55%|█████▍    | 252/459 [06:43<05:31,  0.62it/s, v_num=0w59, train/loss_step=0.0359, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  55%|█████▌    | 253/459 [06:45<05:29,  0.62it/s, v_num=0w59, train/loss_step=0.0359, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  55%|█████▌    | 253/459 [06:45<05:29,  0.62it/s, v_num=0w59, train/loss_step=0.0337, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  55%|█████▌    | 254/459 [06:46<05:28,  0.62it/s, v_num=0w59, train/loss_step=0.0337, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  55%|█████▌    | 254/459 [06:46<05:28,  0.62it/s, v_num=0w59, train/loss_step=0.0335, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  56%|█████▌    | 255/459 [06:48<05:26,  0.62it/s, v_num=0w59, train/loss_step=0.0335, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  56%|█████▌    | 255/459 [06:48<05:26,  0.62it/s, v_num=0w59, train/loss_step=0.0359, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  56%|█████▌    | 256/459 [06:49<05:25,  0.62it/s, v_num=0w59, train/loss_step=0.0359, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  56%|█████▌    | 256/459 [06:49<05:25,  0.62it/s, v_num=0w59, train/loss_step=0.0364, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  56%|█████▌    | 257/459 [06:51<05:23,  0.62it/s, v_num=0w59, train/loss_step=0.0364, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  56%|█████▌    | 257/459 [06:51<05:23,  0.62it/s, v_num=0w59, train/loss_step=0.0326, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  56%|█████▌    | 258/459 [06:53<05:21,  0.62it/s, v_num=0w59, train/loss_step=0.0326, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  56%|█████▌    | 258/459 [06:53<05:21,  0.62it/s, v_num=0w59, train/loss_step=0.0341, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  56%|█████▋    | 259/459 [06:54<05:20,  0.62it/s, v_num=0w59, train/loss_step=0.0341, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  56%|█████▋    | 259/459 [06:54<05:20,  0.62it/s, v_num=0w59, train/loss_step=0.0322, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  57%|█████▋    | 260/459 [06:56<05:18,  0.62it/s, v_num=0w59, train/loss_step=0.0322, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  57%|█████▋    | 260/459 [06:56<05:18,  0.62it/s, v_num=0w59, train/loss_step=0.032, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:  57%|█████▋    | 261/459 [06:57<05:17,  0.62it/s, v_num=0w59, train/loss_step=0.032, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  57%|█████▋    | 261/459 [06:57<05:17,  0.62it/s, v_num=0w59, train/loss_step=0.0406, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  57%|█████▋    | 262/459 [06:59<05:15,  0.62it/s, v_num=0w59, train/loss_step=0.0406, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  57%|█████▋    | 262/459 [06:59<05:15,  0.62it/s, v_num=0w59, train/loss_step=0.0411, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  57%|█████▋    | 263/459 [07:01<05:13,  0.62it/s, v_num=0w59, train/loss_step=0.0411, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  57%|█████▋    | 263/459 [07:01<05:13,  0.62it/s, v_num=0w59, train/loss_step=0.0317, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  58%|█████▊    | 264/459 [07:02<05:12,  0.62it/s, v_num=0w59, train/loss_step=0.0317, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  58%|█████▊    | 264/459 [07:02<05:12,  0.62it/s, v_num=0w59, train/loss_step=0.0355, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  58%|█████▊    | 265/459 [07:04<05:10,  0.62it/s, v_num=0w59, train/loss_step=0.0355, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  58%|█████▊    | 265/459 [07:04<05:10,  0.62it/s, v_num=0w59, train/loss_step=0.0346, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  58%|█████▊    | 266/459 [07:05<05:08,  0.62it/s, v_num=0w59, train/loss_step=0.0346, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  58%|█████▊    | 266/459 [07:05<05:08,  0.62it/s, v_num=0w59, train/loss_step=0.0322, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  58%|█████▊    | 267/459 [07:07<05:07,  0.62it/s, v_num=0w59, train/loss_step=0.0322, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  58%|█████▊    | 267/459 [07:07<05:07,  0.62it/s, v_num=0w59, train/loss_step=0.0316, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  58%|█████▊    | 268/459 [07:08<05:05,  0.62it/s, v_num=0w59, train/loss_step=0.0316, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  58%|█████▊    | 268/459 [07:08<05:05,  0.62it/s, v_num=0w59, train/loss_step=0.0321, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  59%|█████▊    | 269/459 [07:10<05:04,  0.62it/s, v_num=0w59, train/loss_step=0.0321, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  59%|█████▊    | 269/459 [07:10<05:04,  0.62it/s, v_num=0w59, train/loss_step=0.0303, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  59%|█████▉    | 270/459 [07:12<05:02,  0.62it/s, v_num=0w59, train/loss_step=0.0303, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  59%|█████▉    | 270/459 [07:12<05:02,  0.62it/s, v_num=0w59, train/loss_step=0.0308, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  59%|█████▉    | 271/459 [07:13<05:00,  0.62it/s, v_num=0w59, train/loss_step=0.0308, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  59%|█████▉    | 271/459 [07:13<05:00,  0.62it/s, v_num=0w59, train/loss_step=0.0343, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  59%|█████▉    | 272/459 [07:15<04:59,  0.62it/s, v_num=0w59, train/loss_step=0.0343, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  59%|█████▉    | 272/459 [07:15<04:59,  0.62it/s, v_num=0w59, train/loss_step=0.0355, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  59%|█████▉    | 273/459 [07:16<04:57,  0.62it/s, v_num=0w59, train/loss_step=0.0355, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  59%|█████▉    | 273/459 [07:16<04:57,  0.62it/s, v_num=0w59, train/loss_step=0.0365, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  60%|█████▉    | 274/459 [07:18<04:56,  0.62it/s, v_num=0w59, train/loss_step=0.0365, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  60%|█████▉    | 274/459 [07:18<04:56,  0.62it/s, v_num=0w59, train/loss_step=0.0334, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  60%|█████▉    | 275/459 [07:20<04:54,  0.62it/s, v_num=0w59, train/loss_step=0.0334, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  60%|█████▉    | 275/459 [07:20<04:54,  0.62it/s, v_num=0w59, train/loss_step=0.0363, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  60%|██████    | 276/459 [07:21<04:52,  0.62it/s, v_num=0w59, train/loss_step=0.0363, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  60%|██████    | 276/459 [07:21<04:52,  0.62it/s, v_num=0w59, train/loss_step=0.0333, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  60%|██████    | 277/459 [07:23<04:51,  0.63it/s, v_num=0w59, train/loss_step=0.0333, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  60%|██████    | 277/459 [07:23<04:51,  0.63it/s, v_num=0w59, train/loss_step=0.0333, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  61%|██████    | 278/459 [07:24<04:49,  0.63it/s, v_num=0w59, train/loss_step=0.0333, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  61%|██████    | 278/459 [07:24<04:49,  0.63it/s, v_num=0w59, train/loss_step=0.0385, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  61%|██████    | 279/459 [07:26<04:47,  0.63it/s, v_num=0w59, train/loss_step=0.0385, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  61%|██████    | 279/459 [07:26<04:47,  0.63it/s, v_num=0w59, train/loss_step=0.0309, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  61%|██████    | 280/459 [07:27<04:46,  0.63it/s, v_num=0w59, train/loss_step=0.0309, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  61%|██████    | 280/459 [07:27<04:46,  0.63it/s, v_num=0w59, train/loss_step=0.0311, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  61%|██████    | 281/459 [07:29<04:44,  0.63it/s, v_num=0w59, train/loss_step=0.0311, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  61%|██████    | 281/459 [07:29<04:44,  0.63it/s, v_num=0w59, train/loss_step=0.0324, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  61%|██████▏   | 282/459 [07:31<04:43,  0.63it/s, v_num=0w59, train/loss_step=0.0324, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  61%|██████▏   | 282/459 [07:31<04:43,  0.63it/s, v_num=0w59, train/loss_step=0.0335, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  62%|██████▏   | 283/459 [07:32<04:41,  0.63it/s, v_num=0w59, train/loss_step=0.0335, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  62%|██████▏   | 283/459 [07:32<04:41,  0.63it/s, v_num=0w59, train/loss_step=0.0329, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  62%|██████▏   | 284/459 [07:34<04:39,  0.63it/s, v_num=0w59, train/loss_step=0.0329, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  62%|██████▏   | 284/459 [07:34<04:39,  0.63it/s, v_num=0w59, train/loss_step=0.0348, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  62%|██████▏   | 285/459 [07:35<04:38,  0.63it/s, v_num=0w59, train/loss_step=0.0348, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  62%|██████▏   | 285/459 [07:35<04:38,  0.63it/s, v_num=0w59, train/loss_step=0.0355, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  62%|██████▏   | 286/459 [07:37<04:36,  0.63it/s, v_num=0w59, train/loss_step=0.0355, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  62%|██████▏   | 286/459 [07:37<04:36,  0.63it/s, v_num=0w59, train/loss_step=0.0329, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  63%|██████▎   | 287/459 [07:38<04:35,  0.63it/s, v_num=0w59, train/loss_step=0.0329, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  63%|██████▎   | 287/459 [07:38<04:35,  0.63it/s, v_num=0w59, train/loss_step=0.0305, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  63%|██████▎   | 288/459 [07:40<04:33,  0.63it/s, v_num=0w59, train/loss_step=0.0305, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  63%|██████▎   | 288/459 [07:40<04:33,  0.63it/s, v_num=0w59, train/loss_step=0.0322, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  63%|██████▎   | 289/459 [07:42<04:31,  0.63it/s, v_num=0w59, train/loss_step=0.0322, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  63%|██████▎   | 289/459 [07:42<04:31,  0.63it/s, v_num=0w59, train/loss_step=0.0353, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  63%|██████▎   | 290/459 [07:43<04:30,  0.63it/s, v_num=0w59, train/loss_step=0.0353, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  63%|██████▎   | 290/459 [07:43<04:30,  0.63it/s, v_num=0w59, train/loss_step=0.0319, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  63%|██████▎   | 291/459 [07:45<04:28,  0.63it/s, v_num=0w59, train/loss_step=0.0319, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  63%|██████▎   | 291/459 [07:45<04:28,  0.63it/s, v_num=0w59, train/loss_step=0.0349, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  64%|██████▎   | 292/459 [07:46<04:26,  0.63it/s, v_num=0w59, train/loss_step=0.0349, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  64%|██████▎   | 292/459 [07:46<04:26,  0.63it/s, v_num=0w59, train/loss_step=0.0349, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  64%|██████▍   | 293/459 [07:48<04:25,  0.63it/s, v_num=0w59, train/loss_step=0.0349, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  64%|██████▍   | 293/459 [07:48<04:25,  0.63it/s, v_num=0w59, train/loss_step=0.0343, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  64%|██████▍   | 294/459 [07:49<04:23,  0.63it/s, v_num=0w59, train/loss_step=0.0343, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  64%|██████▍   | 294/459 [07:49<04:23,  0.63it/s, v_num=0w59, train/loss_step=0.0348, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  64%|██████▍   | 295/459 [07:51<04:22,  0.63it/s, v_num=0w59, train/loss_step=0.0348, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  64%|██████▍   | 295/459 [07:51<04:22,  0.63it/s, v_num=0w59, train/loss_step=0.0334, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  64%|██████▍   | 296/459 [07:53<04:20,  0.63it/s, v_num=0w59, train/loss_step=0.0334, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  64%|██████▍   | 296/459 [07:53<04:20,  0.63it/s, v_num=0w59, train/loss_step=0.0379, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  65%|██████▍   | 297/459 [07:54<04:18,  0.63it/s, v_num=0w59, train/loss_step=0.0379, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  65%|██████▍   | 297/459 [07:54<04:18,  0.63it/s, v_num=0w59, train/loss_step=0.0382, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  65%|██████▍   | 298/459 [07:56<04:17,  0.63it/s, v_num=0w59, train/loss_step=0.0382, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  65%|██████▍   | 298/459 [07:56<04:17,  0.63it/s, v_num=0w59, train/loss_step=0.0389, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  65%|██████▌   | 299/459 [07:57<04:15,  0.63it/s, v_num=0w59, train/loss_step=0.0389, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  65%|██████▌   | 299/459 [07:57<04:15,  0.63it/s, v_num=0w59, train/loss_step=0.0365, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  65%|██████▌   | 300/459 [07:59<04:14,  0.63it/s, v_num=0w59, train/loss_step=0.0365, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  65%|██████▌   | 300/459 [07:59<04:14,  0.63it/s, v_num=0w59, train/loss_step=0.033, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:  66%|██████▌   | 301/459 [08:00<04:12,  0.63it/s, v_num=0w59, train/loss_step=0.033, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  66%|██████▌   | 301/459 [08:00<04:12,  0.63it/s, v_num=0w59, train/loss_step=0.0278, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  66%|██████▌   | 302/459 [08:02<04:10,  0.63it/s, v_num=0w59, train/loss_step=0.0278, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  66%|██████▌   | 302/459 [08:02<04:10,  0.63it/s, v_num=0w59, train/loss_step=0.0342, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  66%|██████▌   | 303/459 [08:04<04:09,  0.63it/s, v_num=0w59, train/loss_step=0.0342, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  66%|██████▌   | 303/459 [08:04<04:09,  0.63it/s, v_num=0w59, train/loss_step=0.0367, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  66%|██████▌   | 304/459 [08:05<04:07,  0.63it/s, v_num=0w59, train/loss_step=0.0367, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  66%|██████▌   | 304/459 [08:05<04:07,  0.63it/s, v_num=0w59, train/loss_step=0.0311, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  66%|██████▋   | 305/459 [08:07<04:06,  0.63it/s, v_num=0w59, train/loss_step=0.0311, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  66%|██████▋   | 305/459 [08:07<04:06,  0.63it/s, v_num=0w59, train/loss_step=0.0342, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  67%|██████▋   | 306/459 [08:08<04:04,  0.63it/s, v_num=0w59, train/loss_step=0.0342, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  67%|██████▋   | 306/459 [08:08<04:04,  0.63it/s, v_num=0w59, train/loss_step=0.0355, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  67%|██████▋   | 307/459 [08:10<04:02,  0.63it/s, v_num=0w59, train/loss_step=0.0355, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  67%|██████▋   | 307/459 [08:10<04:02,  0.63it/s, v_num=0w59, train/loss_step=0.0326, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  67%|██████▋   | 308/459 [08:11<04:01,  0.63it/s, v_num=0w59, train/loss_step=0.0326, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  67%|██████▋   | 308/459 [08:11<04:01,  0.63it/s, v_num=0w59, train/loss_step=0.034, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:  67%|██████▋   | 309/459 [08:13<03:59,  0.63it/s, v_num=0w59, train/loss_step=0.034, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  67%|██████▋   | 309/459 [08:13<03:59,  0.63it/s, v_num=0w59, train/loss_step=0.0333, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  68%|██████▊   | 310/459 [08:15<03:57,  0.63it/s, v_num=0w59, train/loss_step=0.0333, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  68%|██████▊   | 310/459 [08:15<03:57,  0.63it/s, v_num=0w59, train/loss_step=0.0337, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  68%|██████▊   | 311/459 [08:16<03:56,  0.63it/s, v_num=0w59, train/loss_step=0.0337, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  68%|██████▊   | 311/459 [08:16<03:56,  0.63it/s, v_num=0w59, train/loss_step=0.0322, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  68%|██████▊   | 312/459 [08:18<03:54,  0.63it/s, v_num=0w59, train/loss_step=0.0322, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  68%|██████▊   | 312/459 [08:18<03:54,  0.63it/s, v_num=0w59, train/loss_step=0.0329, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  68%|██████▊   | 313/459 [08:19<03:53,  0.63it/s, v_num=0w59, train/loss_step=0.0329, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  68%|██████▊   | 313/459 [08:19<03:53,  0.63it/s, v_num=0w59, train/loss_step=0.030, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:  68%|██████▊   | 314/459 [08:21<03:51,  0.63it/s, v_num=0w59, train/loss_step=0.030, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  68%|██████▊   | 314/459 [08:21<03:51,  0.63it/s, v_num=0w59, train/loss_step=0.0347, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  69%|██████▊   | 315/459 [08:23<03:49,  0.63it/s, v_num=0w59, train/loss_step=0.0347, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  69%|██████▊   | 315/459 [08:23<03:49,  0.63it/s, v_num=0w59, train/loss_step=0.0306, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  69%|██████▉   | 316/459 [08:24<03:48,  0.63it/s, v_num=0w59, train/loss_step=0.0306, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  69%|██████▉   | 316/459 [08:24<03:48,  0.63it/s, v_num=0w59, train/loss_step=0.0343, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  69%|██████▉   | 317/459 [08:26<03:46,  0.63it/s, v_num=0w59, train/loss_step=0.0343, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  69%|██████▉   | 317/459 [08:26<03:46,  0.63it/s, v_num=0w59, train/loss_step=0.0348, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  69%|██████▉   | 318/459 [08:27<03:45,  0.63it/s, v_num=0w59, train/loss_step=0.0348, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  69%|██████▉   | 318/459 [08:27<03:45,  0.63it/s, v_num=0w59, train/loss_step=0.034, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:  69%|██████▉   | 319/459 [08:29<03:43,  0.63it/s, v_num=0w59, train/loss_step=0.034, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  69%|██████▉   | 319/459 [08:29<03:43,  0.63it/s, v_num=0w59, train/loss_step=0.0352, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  70%|██████▉   | 320/459 [08:30<03:41,  0.63it/s, v_num=0w59, train/loss_step=0.0352, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  70%|██████▉   | 320/459 [08:30<03:41,  0.63it/s, v_num=0w59, train/loss_step=0.0348, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  70%|██████▉   | 321/459 [08:32<03:40,  0.63it/s, v_num=0w59, train/loss_step=0.0348, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  70%|██████▉   | 321/459 [08:32<03:40,  0.63it/s, v_num=0w59, train/loss_step=0.0368, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  70%|███████   | 322/459 [08:34<03:38,  0.63it/s, v_num=0w59, train/loss_step=0.0368, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  70%|███████   | 322/459 [08:34<03:38,  0.63it/s, v_num=0w59, train/loss_step=0.0354, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  70%|███████   | 323/459 [08:35<03:37,  0.63it/s, v_num=0w59, train/loss_step=0.0354, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  70%|███████   | 323/459 [08:35<03:37,  0.63it/s, v_num=0w59, train/loss_step=0.0292, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  71%|███████   | 324/459 [08:37<03:35,  0.63it/s, v_num=0w59, train/loss_step=0.0292, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  71%|███████   | 324/459 [08:37<03:35,  0.63it/s, v_num=0w59, train/loss_step=0.0339, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  71%|███████   | 325/459 [08:38<03:33,  0.63it/s, v_num=0w59, train/loss_step=0.0339, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  71%|███████   | 325/459 [08:38<03:33,  0.63it/s, v_num=0w59, train/loss_step=0.0374, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  71%|███████   | 326/459 [08:40<03:32,  0.63it/s, v_num=0w59, train/loss_step=0.0374, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  71%|███████   | 326/459 [08:40<03:32,  0.63it/s, v_num=0w59, train/loss_step=0.0385, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  71%|███████   | 327/459 [08:41<03:30,  0.63it/s, v_num=0w59, train/loss_step=0.0385, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  71%|███████   | 327/459 [08:41<03:30,  0.63it/s, v_num=0w59, train/loss_step=0.0329, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  71%|███████▏  | 328/459 [08:43<03:29,  0.63it/s, v_num=0w59, train/loss_step=0.0329, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  71%|███████▏  | 328/459 [08:43<03:29,  0.63it/s, v_num=0w59, train/loss_step=0.0361, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  72%|███████▏  | 329/459 [08:45<03:27,  0.63it/s, v_num=0w59, train/loss_step=0.0361, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  72%|███████▏  | 329/459 [08:45<03:27,  0.63it/s, v_num=0w59, train/loss_step=0.0323, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  72%|███████▏  | 330/459 [08:46<03:25,  0.63it/s, v_num=0w59, train/loss_step=0.0323, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  72%|███████▏  | 330/459 [08:46<03:25,  0.63it/s, v_num=0w59, train/loss_step=0.0339, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  72%|███████▏  | 331/459 [08:48<03:24,  0.63it/s, v_num=0w59, train/loss_step=0.0339, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  72%|███████▏  | 331/459 [08:48<03:24,  0.63it/s, v_num=0w59, train/loss_step=0.0354, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  72%|███████▏  | 332/459 [08:49<03:22,  0.63it/s, v_num=0w59, train/loss_step=0.0354, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  72%|███████▏  | 332/459 [08:49<03:22,  0.63it/s, v_num=0w59, train/loss_step=0.035, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:  73%|███████▎  | 333/459 [08:51<03:21,  0.63it/s, v_num=0w59, train/loss_step=0.035, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  73%|███████▎  | 333/459 [08:51<03:21,  0.63it/s, v_num=0w59, train/loss_step=0.0334, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  73%|███████▎  | 334/459 [08:52<03:19,  0.63it/s, v_num=0w59, train/loss_step=0.0334, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  73%|███████▎  | 334/459 [08:52<03:19,  0.63it/s, v_num=0w59, train/loss_step=0.0348, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  73%|███████▎  | 335/459 [08:54<03:17,  0.63it/s, v_num=0w59, train/loss_step=0.0348, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  73%|███████▎  | 335/459 [08:54<03:17,  0.63it/s, v_num=0w59, train/loss_step=0.0372, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  73%|███████▎  | 336/459 [08:56<03:16,  0.63it/s, v_num=0w59, train/loss_step=0.0372, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  73%|███████▎  | 336/459 [08:56<03:16,  0.63it/s, v_num=0w59, train/loss_step=0.0333, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  73%|███████▎  | 337/459 [08:57<03:14,  0.63it/s, v_num=0w59, train/loss_step=0.0333, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  73%|███████▎  | 337/459 [08:57<03:14,  0.63it/s, v_num=0w59, train/loss_step=0.0351, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  74%|███████▎  | 338/459 [08:59<03:13,  0.63it/s, v_num=0w59, train/loss_step=0.0351, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  74%|███████▎  | 338/459 [08:59<03:13,  0.63it/s, v_num=0w59, train/loss_step=0.0352, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  74%|███████▍  | 339/459 [09:00<03:11,  0.63it/s, v_num=0w59, train/loss_step=0.0352, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  74%|███████▍  | 339/459 [09:00<03:11,  0.63it/s, v_num=0w59, train/loss_step=0.0358, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  74%|███████▍  | 340/459 [09:02<03:09,  0.63it/s, v_num=0w59, train/loss_step=0.0358, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  74%|███████▍  | 340/459 [09:02<03:09,  0.63it/s, v_num=0w59, train/loss_step=0.0346, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  74%|███████▍  | 341/459 [09:03<03:08,  0.63it/s, v_num=0w59, train/loss_step=0.0346, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  74%|███████▍  | 341/459 [09:03<03:08,  0.63it/s, v_num=0w59, train/loss_step=0.0372, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  75%|███████▍  | 342/459 [09:05<03:06,  0.63it/s, v_num=0w59, train/loss_step=0.0372, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  75%|███████▍  | 342/459 [09:05<03:06,  0.63it/s, v_num=0w59, train/loss_step=0.0305, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  75%|███████▍  | 343/459 [09:07<03:05,  0.63it/s, v_num=0w59, train/loss_step=0.0305, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  75%|███████▍  | 343/459 [09:07<03:05,  0.63it/s, v_num=0w59, train/loss_step=0.0318, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  75%|███████▍  | 344/459 [09:08<03:03,  0.63it/s, v_num=0w59, train/loss_step=0.0318, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  75%|███████▍  | 344/459 [09:08<03:03,  0.63it/s, v_num=0w59, train/loss_step=0.0368, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  75%|███████▌  | 345/459 [09:10<03:01,  0.63it/s, v_num=0w59, train/loss_step=0.0368, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  75%|███████▌  | 345/459 [09:10<03:01,  0.63it/s, v_num=0w59, train/loss_step=0.0319, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  75%|███████▌  | 346/459 [09:11<03:00,  0.63it/s, v_num=0w59, train/loss_step=0.0319, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  75%|███████▌  | 346/459 [09:11<03:00,  0.63it/s, v_num=0w59, train/loss_step=0.0334, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  76%|███████▌  | 347/459 [09:13<02:58,  0.63it/s, v_num=0w59, train/loss_step=0.0334, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  76%|███████▌  | 347/459 [09:13<02:58,  0.63it/s, v_num=0w59, train/loss_step=0.0335, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  76%|███████▌  | 348/459 [09:15<02:57,  0.63it/s, v_num=0w59, train/loss_step=0.0335, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  76%|███████▌  | 348/459 [09:15<02:57,  0.63it/s, v_num=0w59, train/loss_step=0.0339, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  76%|███████▌  | 349/459 [09:16<02:55,  0.63it/s, v_num=0w59, train/loss_step=0.0339, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  76%|███████▌  | 349/459 [09:16<02:55,  0.63it/s, v_num=0w59, train/loss_step=0.0361, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  76%|███████▋  | 350/459 [09:18<02:53,  0.63it/s, v_num=0w59, train/loss_step=0.0361, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  76%|███████▋  | 350/459 [09:18<02:53,  0.63it/s, v_num=0w59, train/loss_step=0.0319, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  76%|███████▋  | 351/459 [09:19<02:52,  0.63it/s, v_num=0w59, train/loss_step=0.0319, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  76%|███████▋  | 351/459 [09:19<02:52,  0.63it/s, v_num=0w59, train/loss_step=0.0354, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  77%|███████▋  | 352/459 [09:21<02:50,  0.63it/s, v_num=0w59, train/loss_step=0.0354, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  77%|███████▋  | 352/459 [09:21<02:50,  0.63it/s, v_num=0w59, train/loss_step=0.0308, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  77%|███████▋  | 353/459 [09:22<02:49,  0.63it/s, v_num=0w59, train/loss_step=0.0308, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  77%|███████▋  | 353/459 [09:22<02:49,  0.63it/s, v_num=0w59, train/loss_step=0.0308, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  77%|███████▋  | 354/459 [09:24<02:47,  0.63it/s, v_num=0w59, train/loss_step=0.0308, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  77%|███████▋  | 354/459 [09:24<02:47,  0.63it/s, v_num=0w59, train/loss_step=0.0321, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  77%|███████▋  | 355/459 [09:26<02:45,  0.63it/s, v_num=0w59, train/loss_step=0.0321, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  77%|███████▋  | 355/459 [09:26<02:45,  0.63it/s, v_num=0w59, train/loss_step=0.0354, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  78%|███████▊  | 356/459 [09:27<02:44,  0.63it/s, v_num=0w59, train/loss_step=0.0354, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  78%|███████▊  | 356/459 [09:27<02:44,  0.63it/s, v_num=0w59, train/loss_step=0.0305, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  78%|███████▊  | 357/459 [09:29<02:42,  0.63it/s, v_num=0w59, train/loss_step=0.0305, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  78%|███████▊  | 357/459 [09:29<02:42,  0.63it/s, v_num=0w59, train/loss_step=0.0302, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  78%|███████▊  | 358/459 [09:31<02:41,  0.63it/s, v_num=0w59, train/loss_step=0.0302, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  78%|███████▊  | 358/459 [09:31<02:41,  0.63it/s, v_num=0w59, train/loss_step=0.0341, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  78%|███████▊  | 359/459 [09:33<02:39,  0.63it/s, v_num=0w59, train/loss_step=0.0341, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  78%|███████▊  | 359/459 [09:33<02:39,  0.63it/s, v_num=0w59, train/loss_step=0.0331, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  78%|███████▊  | 360/459 [09:35<02:38,  0.63it/s, v_num=0w59, train/loss_step=0.0331, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  78%|███████▊  | 360/459 [09:35<02:38,  0.63it/s, v_num=0w59, train/loss_step=0.0306, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  79%|███████▊  | 361/459 [09:37<02:36,  0.63it/s, v_num=0w59, train/loss_step=0.0306, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  79%|███████▊  | 361/459 [09:37<02:36,  0.63it/s, v_num=0w59, train/loss_step=0.0325, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  79%|███████▉  | 362/459 [09:38<02:35,  0.63it/s, v_num=0w59, train/loss_step=0.0325, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  79%|███████▉  | 362/459 [09:38<02:35,  0.63it/s, v_num=0w59, train/loss_step=0.039, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:  79%|███████▉  | 363/459 [09:40<02:33,  0.63it/s, v_num=0w59, train/loss_step=0.039, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  79%|███████▉  | 363/459 [09:40<02:33,  0.63it/s, v_num=0w59, train/loss_step=0.0348, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  79%|███████▉  | 364/459 [09:42<02:31,  0.63it/s, v_num=0w59, train/loss_step=0.0348, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  79%|███████▉  | 364/459 [09:42<02:31,  0.63it/s, v_num=0w59, train/loss_step=0.0362, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  80%|███████▉  | 365/459 [09:43<02:30,  0.63it/s, v_num=0w59, train/loss_step=0.0362, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  80%|███████▉  | 365/459 [09:43<02:30,  0.63it/s, v_num=0w59, train/loss_step=0.033, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:  80%|███████▉  | 366/459 [09:45<02:28,  0.63it/s, v_num=0w59, train/loss_step=0.033, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  80%|███████▉  | 366/459 [09:45<02:28,  0.63it/s, v_num=0w59, train/loss_step=0.0341, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  80%|███████▉  | 367/459 [09:47<02:27,  0.63it/s, v_num=0w59, train/loss_step=0.0341, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  80%|███████▉  | 367/459 [09:47<02:27,  0.63it/s, v_num=0w59, train/loss_step=0.0342, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  80%|████████  | 368/459 [09:48<02:25,  0.63it/s, v_num=0w59, train/loss_step=0.0342, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  80%|████████  | 368/459 [09:48<02:25,  0.63it/s, v_num=0w59, train/loss_step=0.0387, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  80%|████████  | 369/459 [09:50<02:23,  0.63it/s, v_num=0w59, train/loss_step=0.0387, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  80%|████████  | 369/459 [09:50<02:23,  0.63it/s, v_num=0w59, train/loss_step=0.0336, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  81%|████████  | 370/459 [09:51<02:22,  0.63it/s, v_num=0w59, train/loss_step=0.0336, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  81%|████████  | 370/459 [09:51<02:22,  0.63it/s, v_num=0w59, train/loss_step=0.037, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:  81%|████████  | 371/459 [09:53<02:20,  0.63it/s, v_num=0w59, train/loss_step=0.037, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  81%|████████  | 371/459 [09:53<02:20,  0.63it/s, v_num=0w59, train/loss_step=0.0313, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  81%|████████  | 372/459 [09:54<02:19,  0.63it/s, v_num=0w59, train/loss_step=0.0313, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  81%|████████  | 372/459 [09:54<02:19,  0.63it/s, v_num=0w59, train/loss_step=0.0328, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  81%|████████▏ | 373/459 [09:56<02:17,  0.63it/s, v_num=0w59, train/loss_step=0.0328, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  81%|████████▏ | 373/459 [09:56<02:17,  0.63it/s, v_num=0w59, train/loss_step=0.0317, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  81%|████████▏ | 374/459 [09:57<02:15,  0.63it/s, v_num=0w59, train/loss_step=0.0317, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  81%|████████▏ | 374/459 [09:57<02:15,  0.63it/s, v_num=0w59, train/loss_step=0.0289, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  82%|████████▏ | 375/459 [09:59<02:14,  0.63it/s, v_num=0w59, train/loss_step=0.0289, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  82%|████████▏ | 375/459 [09:59<02:14,  0.63it/s, v_num=0w59, train/loss_step=0.0312, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  82%|████████▏ | 376/459 [10:01<02:12,  0.63it/s, v_num=0w59, train/loss_step=0.0312, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  82%|████████▏ | 376/459 [10:01<02:12,  0.63it/s, v_num=0w59, train/loss_step=0.0317, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  82%|████████▏ | 377/459 [10:02<02:11,  0.63it/s, v_num=0w59, train/loss_step=0.0317, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  82%|████████▏ | 377/459 [10:02<02:11,  0.63it/s, v_num=0w59, train/loss_step=0.0334, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  82%|████████▏ | 378/459 [10:04<02:09,  0.63it/s, v_num=0w59, train/loss_step=0.0334, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  82%|████████▏ | 378/459 [10:04<02:09,  0.63it/s, v_num=0w59, train/loss_step=0.0325, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  83%|████████▎ | 379/459 [10:05<02:07,  0.63it/s, v_num=0w59, train/loss_step=0.0325, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  83%|████████▎ | 379/459 [10:05<02:07,  0.63it/s, v_num=0w59, train/loss_step=0.0336, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  83%|████████▎ | 380/459 [10:07<02:06,  0.63it/s, v_num=0w59, train/loss_step=0.0336, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  83%|████████▎ | 380/459 [10:07<02:06,  0.63it/s, v_num=0w59, train/loss_step=0.031, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:  83%|████████▎ | 381/459 [10:09<02:04,  0.63it/s, v_num=0w59, train/loss_step=0.031, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  83%|████████▎ | 381/459 [10:09<02:04,  0.63it/s, v_num=0w59, train/loss_step=0.0321, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  83%|████████▎ | 382/459 [10:10<02:03,  0.63it/s, v_num=0w59, train/loss_step=0.0321, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  83%|████████▎ | 382/459 [10:10<02:03,  0.63it/s, v_num=0w59, train/loss_step=0.0371, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  83%|████████▎ | 383/459 [10:12<02:01,  0.63it/s, v_num=0w59, train/loss_step=0.0371, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  83%|████████▎ | 383/459 [10:12<02:01,  0.63it/s, v_num=0w59, train/loss_step=0.0341, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  84%|████████▎ | 384/459 [10:13<01:59,  0.63it/s, v_num=0w59, train/loss_step=0.0341, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  84%|████████▎ | 384/459 [10:13<01:59,  0.63it/s, v_num=0w59, train/loss_step=0.030, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:  84%|████████▍ | 385/459 [10:15<01:58,  0.63it/s, v_num=0w59, train/loss_step=0.030, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  84%|████████▍ | 385/459 [10:15<01:58,  0.63it/s, v_num=0w59, train/loss_step=0.0293, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  84%|████████▍ | 386/459 [10:16<01:56,  0.63it/s, v_num=0w59, train/loss_step=0.0293, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  84%|████████▍ | 386/459 [10:16<01:56,  0.63it/s, v_num=0w59, train/loss_step=0.0348, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  84%|████████▍ | 387/459 [10:18<01:55,  0.63it/s, v_num=0w59, train/loss_step=0.0348, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  84%|████████▍ | 387/459 [10:18<01:55,  0.63it/s, v_num=0w59, train/loss_step=0.0311, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  85%|████████▍ | 388/459 [10:20<01:53,  0.63it/s, v_num=0w59, train/loss_step=0.0311, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  85%|████████▍ | 388/459 [10:20<01:53,  0.63it/s, v_num=0w59, train/loss_step=0.0363, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  85%|████████▍ | 389/459 [10:21<01:51,  0.63it/s, v_num=0w59, train/loss_step=0.0363, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  85%|████████▍ | 389/459 [10:21<01:51,  0.63it/s, v_num=0w59, train/loss_step=0.0332, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  85%|████████▍ | 390/459 [10:23<01:50,  0.63it/s, v_num=0w59, train/loss_step=0.0332, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  85%|████████▍ | 390/459 [10:23<01:50,  0.63it/s, v_num=0w59, train/loss_step=0.0345, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  85%|████████▌ | 391/459 [10:24<01:48,  0.63it/s, v_num=0w59, train/loss_step=0.0345, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  85%|████████▌ | 391/459 [10:24<01:48,  0.63it/s, v_num=0w59, train/loss_step=0.0319, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  85%|████████▌ | 392/459 [10:26<01:47,  0.63it/s, v_num=0w59, train/loss_step=0.0319, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  85%|████████▌ | 392/459 [10:26<01:47,  0.63it/s, v_num=0w59, train/loss_step=0.0308, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  86%|████████▌ | 393/459 [10:28<01:45,  0.63it/s, v_num=0w59, train/loss_step=0.0308, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  86%|████████▌ | 393/459 [10:28<01:45,  0.63it/s, v_num=0w59, train/loss_step=0.0355, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  86%|████████▌ | 394/459 [10:29<01:43,  0.63it/s, v_num=0w59, train/loss_step=0.0355, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  86%|████████▌ | 394/459 [10:29<01:43,  0.63it/s, v_num=0w59, train/loss_step=0.0314, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  86%|████████▌ | 395/459 [10:31<01:42,  0.63it/s, v_num=0w59, train/loss_step=0.0314, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  86%|████████▌ | 395/459 [10:31<01:42,  0.63it/s, v_num=0w59, train/loss_step=0.0364, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  86%|████████▋ | 396/459 [10:32<01:40,  0.63it/s, v_num=0w59, train/loss_step=0.0364, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  86%|████████▋ | 396/459 [10:32<01:40,  0.63it/s, v_num=0w59, train/loss_step=0.033, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:  86%|████████▋ | 397/459 [10:34<01:39,  0.63it/s, v_num=0w59, train/loss_step=0.033, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  86%|████████▋ | 397/459 [10:34<01:39,  0.63it/s, v_num=0w59, train/loss_step=0.0315, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  87%|████████▋ | 398/459 [10:36<01:37,  0.63it/s, v_num=0w59, train/loss_step=0.0315, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  87%|████████▋ | 398/459 [10:36<01:37,  0.63it/s, v_num=0w59, train/loss_step=0.0346, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  87%|████████▋ | 399/459 [10:37<01:35,  0.63it/s, v_num=0w59, train/loss_step=0.0346, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  87%|████████▋ | 399/459 [10:37<01:35,  0.63it/s, v_num=0w59, train/loss_step=0.0317, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  87%|████████▋ | 400/459 [10:39<01:34,  0.63it/s, v_num=0w59, train/loss_step=0.0317, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  87%|████████▋ | 400/459 [10:39<01:34,  0.63it/s, v_num=0w59, train/loss_step=0.0299, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  87%|████████▋ | 401/459 [10:40<01:32,  0.63it/s, v_num=0w59, train/loss_step=0.0299, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  87%|████████▋ | 401/459 [10:40<01:32,  0.63it/s, v_num=0w59, train/loss_step=0.0318, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  88%|████████▊ | 402/459 [10:42<01:31,  0.63it/s, v_num=0w59, train/loss_step=0.0318, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  88%|████████▊ | 402/459 [10:42<01:31,  0.63it/s, v_num=0w59, train/loss_step=0.033, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:  88%|████████▊ | 403/459 [10:44<01:29,  0.63it/s, v_num=0w59, train/loss_step=0.033, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  88%|████████▊ | 403/459 [10:44<01:29,  0.63it/s, v_num=0w59, train/loss_step=0.0301, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  88%|████████▊ | 404/459 [10:45<01:27,  0.63it/s, v_num=0w59, train/loss_step=0.0301, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  88%|████████▊ | 404/459 [10:45<01:27,  0.63it/s, v_num=0w59, train/loss_step=0.0333, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  88%|████████▊ | 405/459 [10:47<01:26,  0.63it/s, v_num=0w59, train/loss_step=0.0333, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  88%|████████▊ | 405/459 [10:47<01:26,  0.63it/s, v_num=0w59, train/loss_step=0.0326, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  88%|████████▊ | 406/459 [10:49<01:24,  0.63it/s, v_num=0w59, train/loss_step=0.0326, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  88%|████████▊ | 406/459 [10:49<01:24,  0.63it/s, v_num=0w59, train/loss_step=0.0343, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  89%|████████▊ | 407/459 [10:51<01:23,  0.63it/s, v_num=0w59, train/loss_step=0.0343, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  89%|████████▊ | 407/459 [10:51<01:23,  0.63it/s, v_num=0w59, train/loss_step=0.0364, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  89%|████████▉ | 408/459 [10:53<01:21,  0.62it/s, v_num=0w59, train/loss_step=0.0364, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  89%|████████▉ | 408/459 [10:53<01:21,  0.62it/s, v_num=0w59, train/loss_step=0.0312, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  89%|████████▉ | 409/459 [10:55<01:20,  0.62it/s, v_num=0w59, train/loss_step=0.0312, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  89%|████████▉ | 409/459 [10:55<01:20,  0.62it/s, v_num=0w59, train/loss_step=0.0327, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  89%|████████▉ | 410/459 [10:56<01:18,  0.62it/s, v_num=0w59, train/loss_step=0.0327, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  89%|████████▉ | 410/459 [10:56<01:18,  0.62it/s, v_num=0w59, train/loss_step=0.0321, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  90%|████████▉ | 411/459 [10:58<01:16,  0.62it/s, v_num=0w59, train/loss_step=0.0321, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  90%|████████▉ | 411/459 [10:58<01:16,  0.62it/s, v_num=0w59, train/loss_step=0.0322, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  90%|████████▉ | 412/459 [11:00<01:15,  0.62it/s, v_num=0w59, train/loss_step=0.0322, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  90%|████████▉ | 412/459 [11:00<01:15,  0.62it/s, v_num=0w59, train/loss_step=0.0309, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  90%|████████▉ | 413/459 [11:02<01:13,  0.62it/s, v_num=0w59, train/loss_step=0.0309, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  90%|████████▉ | 413/459 [11:02<01:13,  0.62it/s, v_num=0w59, train/loss_step=0.0338, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  90%|█████████ | 414/459 [11:04<01:12,  0.62it/s, v_num=0w59, train/loss_step=0.0338, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  90%|█████████ | 414/459 [11:04<01:12,  0.62it/s, v_num=0w59, train/loss_step=0.033, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:  90%|█████████ | 415/459 [11:05<01:10,  0.62it/s, v_num=0w59, train/loss_step=0.033, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  90%|█████████ | 415/459 [11:05<01:10,  0.62it/s, v_num=0w59, train/loss_step=0.0375, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  91%|█████████ | 416/459 [11:07<01:09,  0.62it/s, v_num=0w59, train/loss_step=0.0375, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  91%|█████████ | 416/459 [11:07<01:09,  0.62it/s, v_num=0w59, train/loss_step=0.0301, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  91%|█████████ | 417/459 [11:09<01:07,  0.62it/s, v_num=0w59, train/loss_step=0.0301, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  91%|█████████ | 417/459 [11:09<01:07,  0.62it/s, v_num=0w59, train/loss_step=0.0297, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  91%|█████████ | 418/459 [11:10<01:05,  0.62it/s, v_num=0w59, train/loss_step=0.0297, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  91%|█████████ | 418/459 [11:10<01:05,  0.62it/s, v_num=0w59, train/loss_step=0.0274, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  91%|█████████▏| 419/459 [11:12<01:04,  0.62it/s, v_num=0w59, train/loss_step=0.0274, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  91%|█████████▏| 419/459 [11:12<01:04,  0.62it/s, v_num=0w59, train/loss_step=0.0344, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  92%|█████████▏| 420/459 [11:13<01:02,  0.62it/s, v_num=0w59, train/loss_step=0.0344, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  92%|█████████▏| 420/459 [11:13<01:02,  0.62it/s, v_num=0w59, train/loss_step=0.0354, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  92%|█████████▏| 421/459 [11:15<01:00,  0.62it/s, v_num=0w59, train/loss_step=0.0354, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  92%|█████████▏| 421/459 [11:15<01:00,  0.62it/s, v_num=0w59, train/loss_step=0.0314, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  92%|█████████▏| 422/459 [11:17<00:59,  0.62it/s, v_num=0w59, train/loss_step=0.0314, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  92%|█████████▏| 422/459 [11:17<00:59,  0.62it/s, v_num=0w59, train/loss_step=0.0328, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  92%|█████████▏| 423/459 [11:18<00:57,  0.62it/s, v_num=0w59, train/loss_step=0.0328, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  92%|█████████▏| 423/459 [11:18<00:57,  0.62it/s, v_num=0w59, train/loss_step=0.0311, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  92%|█████████▏| 424/459 [11:20<00:56,  0.62it/s, v_num=0w59, train/loss_step=0.0311, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  92%|█████████▏| 424/459 [11:20<00:56,  0.62it/s, v_num=0w59, train/loss_step=0.0317, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  93%|█████████▎| 425/459 [11:21<00:54,  0.62it/s, v_num=0w59, train/loss_step=0.0317, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  93%|█████████▎| 425/459 [11:21<00:54,  0.62it/s, v_num=0w59, train/loss_step=0.0338, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  93%|█████████▎| 426/459 [11:23<00:52,  0.62it/s, v_num=0w59, train/loss_step=0.0338, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  93%|█████████▎| 426/459 [11:23<00:52,  0.62it/s, v_num=0w59, train/loss_step=0.0306, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  93%|█████████▎| 427/459 [11:24<00:51,  0.62it/s, v_num=0w59, train/loss_step=0.0306, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  93%|█████████▎| 427/459 [11:24<00:51,  0.62it/s, v_num=0w59, train/loss_step=0.0364, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  93%|█████████▎| 428/459 [11:26<00:49,  0.62it/s, v_num=0w59, train/loss_step=0.0364, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  93%|█████████▎| 428/459 [11:26<00:49,  0.62it/s, v_num=0w59, train/loss_step=0.0338, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  93%|█████████▎| 429/459 [11:28<00:48,  0.62it/s, v_num=0w59, train/loss_step=0.0338, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  93%|█████████▎| 429/459 [11:28<00:48,  0.62it/s, v_num=0w59, train/loss_step=0.0311, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  94%|█████████▎| 430/459 [11:29<00:46,  0.62it/s, v_num=0w59, train/loss_step=0.0311, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  94%|█████████▎| 430/459 [11:29<00:46,  0.62it/s, v_num=0w59, train/loss_step=0.032, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:  94%|█████████▍| 431/459 [11:31<00:44,  0.62it/s, v_num=0w59, train/loss_step=0.032, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  94%|█████████▍| 431/459 [11:31<00:44,  0.62it/s, v_num=0w59, train/loss_step=0.0337, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  94%|█████████▍| 432/459 [11:32<00:43,  0.62it/s, v_num=0w59, train/loss_step=0.0337, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  94%|█████████▍| 432/459 [11:32<00:43,  0.62it/s, v_num=0w59, train/loss_step=0.0361, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  94%|█████████▍| 433/459 [11:34<00:41,  0.62it/s, v_num=0w59, train/loss_step=0.0361, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  94%|█████████▍| 433/459 [11:34<00:41,  0.62it/s, v_num=0w59, train/loss_step=0.0332, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  95%|█████████▍| 434/459 [11:35<00:40,  0.62it/s, v_num=0w59, train/loss_step=0.0332, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  95%|█████████▍| 434/459 [11:35<00:40,  0.62it/s, v_num=0w59, train/loss_step=0.0373, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  95%|█████████▍| 435/459 [11:37<00:38,  0.62it/s, v_num=0w59, train/loss_step=0.0373, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  95%|█████████▍| 435/459 [11:37<00:38,  0.62it/s, v_num=0w59, train/loss_step=0.0328, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  95%|█████████▍| 436/459 [11:39<00:36,  0.62it/s, v_num=0w59, train/loss_step=0.0328, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  95%|█████████▍| 436/459 [11:39<00:36,  0.62it/s, v_num=0w59, train/loss_step=0.0351, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  95%|█████████▌| 437/459 [11:40<00:35,  0.62it/s, v_num=0w59, train/loss_step=0.0351, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  95%|█████████▌| 437/459 [11:40<00:35,  0.62it/s, v_num=0w59, train/loss_step=0.0262, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  95%|█████████▌| 438/459 [11:42<00:33,  0.62it/s, v_num=0w59, train/loss_step=0.0262, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  95%|█████████▌| 438/459 [11:42<00:33,  0.62it/s, v_num=0w59, train/loss_step=0.029, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:  96%|█████████▌| 439/459 [11:43<00:32,  0.62it/s, v_num=0w59, train/loss_step=0.029, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  96%|█████████▌| 439/459 [11:43<00:32,  0.62it/s, v_num=0w59, train/loss_step=0.0306, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  96%|█████████▌| 440/459 [11:45<00:30,  0.62it/s, v_num=0w59, train/loss_step=0.0306, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  96%|█████████▌| 440/459 [11:45<00:30,  0.62it/s, v_num=0w59, train/loss_step=0.0354, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  96%|█████████▌| 441/459 [11:46<00:28,  0.62it/s, v_num=0w59, train/loss_step=0.0354, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  96%|█████████▌| 441/459 [11:46<00:28,  0.62it/s, v_num=0w59, train/loss_step=0.0328, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  96%|█████████▋| 442/459 [11:48<00:27,  0.62it/s, v_num=0w59, train/loss_step=0.0328, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  96%|█████████▋| 442/459 [11:48<00:27,  0.62it/s, v_num=0w59, train/loss_step=0.0311, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  97%|█████████▋| 443/459 [11:50<00:25,  0.62it/s, v_num=0w59, train/loss_step=0.0311, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  97%|█████████▋| 443/459 [11:50<00:25,  0.62it/s, v_num=0w59, train/loss_step=0.0388, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  97%|█████████▋| 444/459 [11:51<00:24,  0.62it/s, v_num=0w59, train/loss_step=0.0388, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  97%|█████████▋| 444/459 [11:51<00:24,  0.62it/s, v_num=0w59, train/loss_step=0.0306, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  97%|█████████▋| 445/459 [11:53<00:22,  0.62it/s, v_num=0w59, train/loss_step=0.0306, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  97%|█████████▋| 445/459 [11:53<00:22,  0.62it/s, v_num=0w59, train/loss_step=0.028, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:  97%|█████████▋| 446/459 [11:54<00:20,  0.62it/s, v_num=0w59, train/loss_step=0.028, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  97%|█████████▋| 446/459 [11:54<00:20,  0.62it/s, v_num=0w59, train/loss_step=0.0316, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  97%|█████████▋| 447/459 [11:56<00:19,  0.62it/s, v_num=0w59, train/loss_step=0.0316, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  97%|█████████▋| 447/459 [11:56<00:19,  0.62it/s, v_num=0w59, train/loss_step=0.0299, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  98%|█████████▊| 448/459 [11:57<00:17,  0.62it/s, v_num=0w59, train/loss_step=0.0299, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  98%|█████████▊| 448/459 [11:57<00:17,  0.62it/s, v_num=0w59, train/loss_step=0.0309, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  98%|█████████▊| 449/459 [11:59<00:16,  0.62it/s, v_num=0w59, train/loss_step=0.0309, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  98%|█████████▊| 449/459 [11:59<00:16,  0.62it/s, v_num=0w59, train/loss_step=0.0321, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  98%|█████████▊| 450/459 [12:01<00:14,  0.62it/s, v_num=0w59, train/loss_step=0.0321, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  98%|█████████▊| 450/459 [12:01<00:14,  0.62it/s, v_num=0w59, train/loss_step=0.0325, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  98%|█████████▊| 451/459 [12:02<00:12,  0.62it/s, v_num=0w59, train/loss_step=0.0325, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  98%|█████████▊| 451/459 [12:02<00:12,  0.62it/s, v_num=0w59, train/loss_step=0.0321, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  98%|█████████▊| 452/459 [12:05<00:11,  0.62it/s, v_num=0w59, train/loss_step=0.0321, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  98%|█████████▊| 452/459 [12:05<00:11,  0.62it/s, v_num=0w59, train/loss_step=0.0294, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  99%|█████████▊| 453/459 [12:06<00:09,  0.62it/s, v_num=0w59, train/loss_step=0.0294, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  99%|█████████▊| 453/459 [12:06<00:09,  0.62it/s, v_num=0w59, train/loss_step=0.0289, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  99%|█████████▉| 454/459 [12:08<00:08,  0.62it/s, v_num=0w59, train/loss_step=0.0289, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  99%|█████████▉| 454/459 [12:08<00:08,  0.62it/s, v_num=0w59, train/loss_step=0.033, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1:  99%|█████████▉| 455/459 [12:10<00:06,  0.62it/s, v_num=0w59, train/loss_step=0.033, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  99%|█████████▉| 455/459 [12:10<00:06,  0.62it/s, v_num=0w59, train/loss_step=0.0322, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  99%|█████████▉| 456/459 [12:12<00:04,  0.62it/s, v_num=0w59, train/loss_step=0.0322, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1:  99%|█████████▉| 456/459 [12:12<00:04,  0.62it/s, v_num=0w59, train/loss_step=0.0304, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1: 100%|█████████▉| 457/459 [12:13<00:03,  0.62it/s, v_num=0w59, train/loss_step=0.0304, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1: 100%|█████████▉| 457/459 [12:13<00:03,  0.62it/s, v_num=0w59, train/loss_step=0.0342, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1: 100%|█████████▉| 458/459 [12:15<00:01,  0.62it/s, v_num=0w59, train/loss_step=0.0342, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1: 100%|█████████▉| 458/459 [12:15<00:01,  0.62it/s, v_num=0w59, train/loss_step=0.036, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203] Epoch 1: 100%|██████████| 459/459 [12:16<00:00,  0.62it/s, v_num=0w59, train/loss_step=0.036, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]Epoch 1: 100%|██████████| 459/459 [12:16<00:00,  0.62it/s, v_num=0w59, train/loss_step=0.0323, val/loss=1.070, val/mAP=0.080, val/mAP_best=0.080, train/loss_epoch=0.203]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/52 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/52 [00:00<?, ?it/s][A
Validation DataLoader 0:   2%|▏         | 1/52 [00:00<00:43,  1.17it/s][A
Validation DataLoader 0:   4%|▍         | 2/52 [00:01<00:44,  1.14it/s][A
Validation DataLoader 0:   6%|▌         | 3/52 [00:02<00:42,  1.15it/s][A
Validation DataLoader 0:   8%|▊         | 4/52 [00:03<00:41,  1.15it/s][A
Validation DataLoader 0:  10%|▉         | 5/52 [00:04<00:40,  1.15it/s][A
Validation DataLoader 0:  12%|█▏        | 6/52 [00:05<00:39,  1.16it/s][A
Validation DataLoader 0:  13%|█▎        | 7/52 [00:06<00:38,  1.16it/s][A
Validation DataLoader 0:  15%|█▌        | 8/52 [00:06<00:37,  1.16it/s][A
Validation DataLoader 0:  17%|█▋        | 9/52 [00:07<00:37,  1.16it/s][A
Validation DataLoader 0:  19%|█▉        | 10/52 [00:08<00:36,  1.16it/s][A
Validation DataLoader 0:  21%|██        | 11/52 [00:09<00:35,  1.16it/s][A
Validation DataLoader 0:  23%|██▎       | 12/52 [00:10<00:34,  1.16it/s][A
Validation DataLoader 0:  25%|██▌       | 13/52 [00:11<00:33,  1.16it/s][A
Validation DataLoader 0:  27%|██▋       | 14/52 [00:12<00:32,  1.16it/s][A
Validation DataLoader 0:  29%|██▉       | 15/52 [00:12<00:31,  1.16it/s][A
Validation DataLoader 0:  31%|███       | 16/52 [00:13<00:30,  1.16it/s][A
Validation DataLoader 0:  33%|███▎      | 17/52 [00:14<00:30,  1.16it/s][A
Validation DataLoader 0:  35%|███▍      | 18/52 [00:15<00:29,  1.16it/s][A
Validation DataLoader 0:  37%|███▋      | 19/52 [00:16<00:28,  1.16it/s][A
Validation DataLoader 0:  38%|███▊      | 20/52 [00:17<00:27,  1.16it/s][A
Validation DataLoader 0:  40%|████      | 21/52 [00:18<00:26,  1.17it/s][A
Validation DataLoader 0:  42%|████▏     | 22/52 [00:18<00:25,  1.17it/s][A
Validation DataLoader 0:  44%|████▍     | 23/52 [00:19<00:24,  1.17it/s][A
Validation DataLoader 0:  46%|████▌     | 24/52 [00:20<00:24,  1.17it/s][A
Validation DataLoader 0:  48%|████▊     | 25/52 [00:21<00:23,  1.17it/s][A
Validation DataLoader 0:  50%|█████     | 26/52 [00:22<00:22,  1.17it/s][A
Validation DataLoader 0:  52%|█████▏    | 27/52 [00:23<00:21,  1.17it/s][A
Validation DataLoader 0:  54%|█████▍    | 28/52 [00:24<00:20,  1.17it/s][A
Validation DataLoader 0:  56%|█████▌    | 29/52 [00:24<00:19,  1.17it/s][A
Validation DataLoader 0:  58%|█████▊    | 30/52 [00:25<00:18,  1.17it/s][A
Validation DataLoader 0:  60%|█████▉    | 31/52 [00:26<00:18,  1.17it/s][A
Validation DataLoader 0:  62%|██████▏   | 32/52 [00:27<00:17,  1.17it/s][A
Validation DataLoader 0:  63%|██████▎   | 33/52 [00:28<00:16,  1.17it/s][A
Validation DataLoader 0:  65%|██████▌   | 34/52 [00:29<00:15,  1.17it/s][A
Validation DataLoader 0:  67%|██████▋   | 35/52 [00:30<00:14,  1.17it/s][A
Validation DataLoader 0:  69%|██████▉   | 36/52 [00:30<00:13,  1.17it/s][A
Validation DataLoader 0:  71%|███████   | 37/52 [00:31<00:12,  1.17it/s][A
Validation DataLoader 0:  73%|███████▎  | 38/52 [00:32<00:12,  1.17it/s][A
Validation DataLoader 0:  75%|███████▌  | 39/52 [00:33<00:11,  1.17it/s][A
Validation DataLoader 0:  77%|███████▋  | 40/52 [00:34<00:10,  1.17it/s][A
Validation DataLoader 0:  79%|███████▉  | 41/52 [00:35<00:09,  1.17it/s][A
Validation DataLoader 0:  81%|████████  | 42/52 [00:35<00:08,  1.17it/s][A
Validation DataLoader 0:  83%|████████▎ | 43/52 [00:36<00:07,  1.17it/s][A
Validation DataLoader 0:  85%|████████▍ | 44/52 [00:37<00:06,  1.17it/s][A
Validation DataLoader 0:  87%|████████▋ | 45/52 [00:38<00:05,  1.17it/s][A
Validation DataLoader 0:  88%|████████▊ | 46/52 [00:39<00:05,  1.17it/s][A
Validation DataLoader 0:  90%|█████████ | 47/52 [00:40<00:04,  1.17it/s][A
Validation DataLoader 0:  92%|█████████▏| 48/52 [00:41<00:03,  1.17it/s][A
Validation DataLoader 0:  94%|█████████▍| 49/52 [00:41<00:02,  1.17it/s][A
Validation DataLoader 0:  96%|█████████▌| 50/52 [00:42<00:01,  1.17it/s][A
Validation DataLoader 0:  98%|█████████▊| 51/52 [00:43<00:00,  1.17it/s][A
Validation DataLoader 0: 100%|██████████| 52/52 [00:44<00:00,  1.17it/s][A