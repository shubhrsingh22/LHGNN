Variable OMP_NUM_THREADS has been set to 24
--------------------
Hostname: sbg14
Sun Sep  8 10:02:16 BST 2024
Free GPU: 0 of 3
--------------------
GPU0: [92mNot in use.[39m
GPU1: [92mNot in use.[39m
GPU2: [92mNot in use.[39m

User: [91macw572[39m JobID: [91m3835435[39m GPU Allocation: [91m2[39m Queue: [91mall.q[39m
User: [91meey042[39m JobID: [91m3832623[39m GPU Allocation: [91m1[39m Queue: [91mall.q[39m
[91mWarning! GPUs requested but not used![39m
In main
[[36m2024-09-08 10:02:26,623[0m][[34mutils.utils[0m][[32mINFO[0m] - [rank: 0] Enforcing tags! <cfg.extras.enforce_tags=True>[0m
[[36m2024-09-08 10:02:26,627[0m][[34mutils.utils[0m][[32mINFO[0m] - [rank: 0] Printing config tree with Rich! <cfg.extras.print_config=True>[0m
CONFIG
â”œâ”€â”€ data
â”‚   â””â”€â”€ _target_: src.data.audioset_datamodule.AudioSetModule                   
â”‚       json_path: /data/scratch/acw572/AudioSet/datafiles/                     
â”‚       data_dir: /data/EECS-MachineListeningLab/datasets/AudioSet              
â”‚       meta_path: /data/EECS-MachineListeningLab/datasets/AudioSet/ground_truth
â”‚       label_csv_pth: /data/scratch/acw572/AudioSet/datafiles/class_labels_indi
â”‚       samplr_csv_pth: null                                                    
â”‚       balance_samplr: false                                                   
â”‚       batch_size: 32                                                          
â”‚       num_workers: 4                                                          
â”‚       pin_memory: true                                                        
â”‚       persistent_workers: true                                                
â”‚       sr: 16000                                                               
â”‚       fmin: 20                                                                
â”‚       fmax: 8000                                                              
â”‚       num_mels: 128                                                           
â”‚       window_type: hanning                                                    
â”‚       target_len: 1024                                                        
â”‚       freqm: 48                                                               
â”‚       timem: 192                                                              
â”‚       mixup: 0.5                                                              
â”‚       norm_mean: -4.6476                                                      
â”‚       norm_std: 4.5699                                                        
â”‚       subset: full                                                            
â”‚       num_devices: 3                                                          
â”‚                                                                               
â”œâ”€â”€ model
â”‚   â””â”€â”€ _target_: src.models.tagging_module.TaggingModule                       
â”‚       optimizer:                                                              
â”‚         _target_: torch.optim.Adam                                            
â”‚         _partial_: true                                                       
â”‚         lr: 0.001                                                             
â”‚         weight_decay: 5.0e-07                                                 
â”‚         eps: 1.0e-08                                                          
â”‚         betas:                                                                
â”‚         - 0.95                                                                
â”‚         - 0.999                                                               
â”‚       scheduler:                                                              
â”‚         _target_: torch.optim.lr_scheduler.MultiStepLR                        
â”‚         _partial_: true                                                       
â”‚         milestones:                                                           
â”‚         - 10                                                                  
â”‚         - 15                                                                  
â”‚         - 20                                                                  
â”‚         - 25                                                                  
â”‚         - 30                                                                  
â”‚         - 35                                                                  
â”‚         - 40                                                                  
â”‚         gamma: 0.5                                                            
â”‚       net:                                                                    
â”‚         _target_: src.models.components.LHGNN.LHGNN                           
â”‚         k: 25                                                                 
â”‚         act: gelu                                                             
â”‚         norm: batch                                                           
â”‚         bias: true                                                            
â”‚         dropout: 0.0                                                          
â”‚         dilation: true                                                        
â”‚         epsilon: 0.2                                                          
â”‚         drop_path: 0.1                                                        
â”‚         size: s                                                               
â”‚         num_class: 200                                                        
â”‚         emb_dims: 1024                                                        
â”‚         freq_num: 128                                                         
â”‚         time_num: 1024                                                        
â”‚         clusters: 50                                                          
â”‚         cluster_ratio: 0.4                                                    
â”‚         conv: lhg                                                             
â”‚       compile: false                                                          
â”‚       loss: bcelogit                                                          
â”‚       opt_warmup: true                                                        
â”‚       learning_rate: 0.001                                                    
â”‚       lr_rate:                                                                
â”‚       - 0.05                                                                  
â”‚       - 0.02                                                                  
â”‚       - 0.01                                                                  
â”‚       - 0.005                                                                 
â”‚       - 0.002                                                                 
â”‚       - 0.001                                                                 
â”‚       - 0.0005                                                                
â”‚       - 0.0002                                                                
â”‚       lr_scheduler_epoch:                                                     
â”‚       - 10                                                                    
â”‚       - 15                                                                    
â”‚       - 20                                                                    
â”‚       - 25                                                                    
â”‚       - 30                                                                    
â”‚       - 35                                                                    
â”‚       - 50                                                                    
â”‚       - 45                                                                    
â”‚                                                                               
â”œâ”€â”€ callbacks
â”‚   â””â”€â”€ model_checkpoint:                                                       
â”‚         _target_: pytorch_lightning.callbacks.ModelCheckpoint                 
â”‚         dirpath: /data/scratch/acw572/LHGNN/logs/train-audioset-new/runs/2024-
â”‚         filename: epoch_{epoch:03d}                                           
â”‚         monitor: val/mAP                                                      
â”‚         verbose: false                                                        
â”‚         save_last: true                                                       
â”‚         save_top_k: 20                                                        
â”‚         mode: max                                                             
â”‚         auto_insert_metric_name: false                                        
â”‚         save_weights_only: false                                              
â”‚         every_n_train_steps: null                                             
â”‚         train_time_interval: null                                             
â”‚         every_n_epochs: null                                                  
â”‚         save_on_train_epoch_end: null                                         
â”‚       early_stopping:                                                         
â”‚         _target_: pytorch_lightning.callbacks.EarlyStopping                   
â”‚         monitor: val/loss                                                     
â”‚         min_delta: 0.0                                                        
â”‚         patience: 5                                                           
â”‚         verbose: false                                                        
â”‚         mode: min                                                             
â”‚         strict: true                                                          
â”‚         check_finite: true                                                    
â”‚         stopping_threshold: null                                              
â”‚         divergence_threshold: null                                            
â”‚         check_on_train_epoch_end: null                                        
â”‚       model_summary:                                                          
â”‚         _target_: pytorch_lightning.callbacks.RichModelSummary                
â”‚         max_depth: -1                                                         
â”‚       tqdm_progress_bar:                                                      
â”‚         _target_: pytorch_lightning.callbacks.TQDMProgressBar                 
â”‚                                                                               
â”œâ”€â”€ logger
â”‚   â””â”€â”€ wandb:                                                                  
â”‚         _target_: pytorch_lightning.loggers.WandbLogger                       
â”‚         save_dir: /data/scratch/acw572/LHGNN/logs/train-audioset-new/runs/2024
â”‚         offline: false                                                        
â”‚         id: null                                                              
â”‚         anonymous: null                                                       
â”‚         project: audioset-bal                                                 
â”‚         log_model: false                                                      
â”‚         prefix: ''                                                            
â”‚         group: Tagging                                                        
â”‚         tags:                                                                 
â”‚         - fsd                                                                 
â”‚         - hgcn                                                                
â”‚         job_type: ''                                                          
â”‚                                                                               
â”œâ”€â”€ trainer
â”‚   â””â”€â”€ _target_: pytorch_lightning.trainer.Trainer                             
â”‚       default_root_dir: /data/scratch/acw572/LHGNN/logs/train-audioset-new/run
â”‚       num_sanity_val_steps: 0                                                 
â”‚       min_epochs: 50                                                          
â”‚       max_epochs: 50                                                          
â”‚       accelerator: gpu                                                        
â”‚       devices: 3                                                              
â”‚       gradient_clip_val: 0.5                                                  
â”‚       precision: 16                                                           
â”‚       detect_anomaly: false                                                   
â”‚       check_val_every_n_epoch: 1                                              
â”‚       deterministic: false                                                    
â”‚       strategy: ddp                                                           
â”‚       num_nodes: 1                                                            
â”‚       sync_batchnorm: true                                                    
â”‚       use_distributed_sampler: true                                           
â”‚                                                                               
â”œâ”€â”€ paths
â”‚   â””â”€â”€ root_dir: /data/home/acw572/hgann/HGANN                                 
â”‚       exp_dir: /data/scratch/acw572                                           
â”‚       data_dir: /data/EECS-MachineListeningLab/datasets/AudioSet              
â”‚       meta_dir: /data/EECS-MachineListeningLab/shubhr/hgann                   
â”‚       log_dir: /data/scratch/acw572/LHGNN/logs/                               
â”‚       output_dir: /data/scratch/acw572/LHGNN/logs/train-audioset-new/runs/2024
â”‚       work_dir: /data/home/acw572/hgann/HGANN                                 
â”‚                                                                               
â”œâ”€â”€ extras
â”‚   â””â”€â”€ ignore_warnings: false                                                  
â”‚       enforce_tags: true                                                      
â”‚       print_config: true                                                      
â”‚                                                                               
â”œâ”€â”€ task_name
â”‚   â””â”€â”€ train-audioset-new                                                      
â”œâ”€â”€ pretrained
â”‚   â””â”€â”€ None                                                                    
â”œâ”€â”€ tags
â”‚   â””â”€â”€ ['dev']                                                                 
â”œâ”€â”€ train
â”‚   â””â”€â”€ True                                                                    
â”œâ”€â”€ eval
â”‚   â””â”€â”€ False                                                                   
â”œâ”€â”€ wa
â”‚   â””â”€â”€ False                                                                   
â”œâ”€â”€ pretrain_path
â”‚   â””â”€â”€ /data/scratch/acw572/model_out/train/20240424-063514-pvig_s_224_gelu-224
â”œâ”€â”€ ckpt_path
â”‚   â””â”€â”€ /data/scratch/acw572/LHGNN/logs/train/runs/2024-08-22_21-04-17/checkpoin
â””â”€â”€ seed
    â””â”€â”€ None                                                                    
[[36m2024-09-08 10:02:26,685[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] In train[0m
[[36m2024-09-08 10:02:26,685[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating datamodule <src.data.audioset_datamodule.AudioSetModule>[0m
[[36m2024-09-08 10:02:26,889[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating model <src.models.tagging_module.TaggingModule>[0m
/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/utilities/parsing.py:198: Attribute 'net' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['net'])`.
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
[[36m2024-09-08 10:02:33,790[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Training from scratch[0m
[[36m2024-09-08 10:02:33,790[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating callbacks...[0m
[[36m2024-09-08 10:02:33,790[0m][[34mutils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>[0m
[[36m2024-09-08 10:02:33,796[0m][[34mutils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <pytorch_lightning.callbacks.EarlyStopping>[0m
[[36m2024-09-08 10:02:33,797[0m][[34mutils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>[0m
[[36m2024-09-08 10:02:33,797[0m][[34mutils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <pytorch_lightning.callbacks.TQDMProgressBar>[0m
[[36m2024-09-08 10:02:33,798[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating loggers...[0m
[[36m2024-09-08 10:02:33,798[0m][[34mutils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating logger <pytorch_lightning.loggers.WandbLogger>[0m
[[36m2024-09-08 10:02:33,889[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating trainer <pytorch_lightning.trainer.Trainer>[0m
/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/lightning_fabric/connector.py:558: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!
Using 16bit Automatic Mixed Precision (AMP)
Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[[36m2024-09-08 10:02:34,054[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Logging hyperparameters![0m
wandb: Currently logged in as: shubhr. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.1
wandb: Run data is saved locally in /data/scratch/acw572/LHGNN/logs/train-audioset-new/runs/2024-09-08_10-02-26/wandb/run-20240908_100235-8z3rti9b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-cosmos-110
wandb: â­ï¸ View project at https://wandb.ai/shubhr/audioset-bal
wandb: ğŸš€ View run at https://wandb.ai/shubhr/audioset-bal/runs/8z3rti9b
[[36m2024-09-08 10:02:43,809[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Starting training![0m
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/3
