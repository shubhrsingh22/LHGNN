_target_: src.models.tagging_module.TaggingModule

optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 5e-5
  weight_decay: 5e-7
  betas: [0.95, 0.999]
  
scheduler:
  _target_: torch.optim.lr_scheduler.MultiStepLR
  _partial_: true
  milestones: [10,15,20,25,30,35,40]
  gamma: 0.5
 
net:
  _target_: src.models.components.TokenTrans_model.TokenTransformer
  num_classes: 200
  size: 's'
  freq_num: 128
  time_num: 1024
  n_iter: [1,1,1,1]
  stoken_size: [8,4,2,1]
  mlp_ratio: 4.0
  qkv_bias: true
  qk_scale: None
  drop_rate: 0.0
  attn_drop_rate: 0.0
  drop_path: 0.1
  projection: None
  init_values: 1e-6
  layerscale: [False,False,False,False]

compile: false
loss: 'bce'
opt_warmup: True

  

