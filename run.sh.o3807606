Variable OMP_NUM_THREADS has been set to 12
--------------------
Hostname: sbg15
Tue Aug 20 14:59:39 BST 2024
Free GPU: 0 of 1
--------------------
GPU0: [92mNot in use.[39m

User: [91macw572[39m JobID: [91m3807606[39m GPU Allocation: [91m1[39m Queue: [91mall.q[39m
User: [91mhhz049[39m JobID: [91m3807581[39m GPU Allocation: [91m1[39m Queue: [91mall.q[39m
User: [91mbty174[39m JobID: [91m3807539[39m GPU Allocation: [91m1[39m Queue: [91mall.q[39m
User: [91macw778[39m JobID: [91m3807006[39m GPU Allocation: [91m1[39m Queue: [91mall.q[39m
[91mWarning! GPUs requested but not used![39m
In main
[[36m2024-08-20 15:00:21,875[0m][[34mutils.utils[0m][[32mINFO[0m] - [rank: 0] Enforcing tags! <cfg.extras.enforce_tags=True>[0m
[[36m2024-08-20 15:00:21,879[0m][[34mutils.utils[0m][[32mINFO[0m] - [rank: 0] Printing config tree with Rich! <cfg.extras.print_config=True>[0m
CONFIG
‚îú‚îÄ‚îÄ data
‚îÇ   ‚îî‚îÄ‚îÄ _target_: src.data.fsd_datamodule.FSDDataModule                         
‚îÇ       json_path: /data/scratch/acw572/hdf_fsd50k/datafiles/                   
‚îÇ       data_dir: /data/EECS-MachineListeningLab/datasets/AudioSet              
‚îÇ       meta_path: /data/EECS-MachineListeningLab/datasets/AudioSet/ground_truth
‚îÇ       label_csv_pth: /data/scratch/acw572/LHGNN/datafiles/class_labels_indices
‚îÇ       samplr_csv_pth: /data/scratch/acw572/LHGNN/datafiles/fsd50k_tr_full_weig
‚îÇ       balance_samplr: true                                                    
‚îÇ       batch_size: 25                                                          
‚îÇ       num_workers: 8                                                          
‚îÇ       pin_memory: true                                                        
‚îÇ       persistent_workers: true                                                
‚îÇ       sr: 16000                                                               
‚îÇ       fmin: 20                                                                
‚îÇ       fmax: 8000                                                              
‚îÇ       num_mels: 128                                                           
‚îÇ       window_type: hanning                                                    
‚îÇ       target_len: 1024                                                        
‚îÇ       freqm: 48                                                               
‚îÇ       timem: 192                                                              
‚îÇ       mixup: 0.5                                                              
‚îÇ       norm_mean: -4.6476                                                      
‚îÇ       norm_std: 4.5699                                                        
‚îÇ       num_devices: 1                                                          
‚îÇ                                                                               
‚îú‚îÄ‚îÄ model
‚îÇ   ‚îî‚îÄ‚îÄ _target_: src.models.tagging_module.TaggingModule                       
‚îÇ       optimizer:                                                              
‚îÇ         _target_: torch.optim.Adam                                            
‚îÇ         _partial_: true                                                       
‚îÇ         lr: 0.0005                                                            
‚îÇ         weight_decay: 5.0e-07                                                 
‚îÇ         eps: 1.0e-08                                                          
‚îÇ         betas:                                                                
‚îÇ         - 0.95                                                                
‚îÇ         - 0.999                                                               
‚îÇ       scheduler:                                                              
‚îÇ         _target_: torch.optim.lr_scheduler.MultiStepLR                        
‚îÇ         _partial_: true                                                       
‚îÇ         milestones:                                                           
‚îÇ         - 10                                                                  
‚îÇ         - 15                                                                  
‚îÇ         - 20                                                                  
‚îÇ         - 25                                                                  
‚îÇ         - 30                                                                  
‚îÇ         - 35                                                                  
‚îÇ         - 40                                                                  
‚îÇ         gamma: 0.5                                                            
‚îÇ       net:                                                                    
‚îÇ         _target_: src.models.components.LHGNN.LHGNN                           
‚îÇ         k: 25                                                                 
‚îÇ         act: gelu                                                             
‚îÇ         norm: batch                                                           
‚îÇ         bias: true                                                            
‚îÇ         dropout: 0.0                                                          
‚îÇ         dilation: true                                                        
‚îÇ         epsilon: 0.2                                                          
‚îÇ         drop_path: 0.1                                                        
‚îÇ         size: s                                                               
‚îÇ         num_class: 200                                                        
‚îÇ         emb_dims: 1024                                                        
‚îÇ         freq_num: 128                                                         
‚îÇ         time_num: 1024                                                        
‚îÇ         clusters: 50                                                          
‚îÇ         cluster_ratio: 0.5                                                    
‚îÇ         conv: lhg                                                             
‚îÇ       compile: false                                                          
‚îÇ       loss: bce                                                               
‚îÇ       opt_warmup: true                                                        
‚îÇ       learning_rate: 0.0005                                                   
‚îÇ       lr_rate:                                                                
‚îÇ       - 0.05                                                                  
‚îÇ       - 0.02                                                                  
‚îÇ       - 0.01                                                                  
‚îÇ       - 0.005                                                                 
‚îÇ       - 0.002                                                                 
‚îÇ       - 0.001                                                                 
‚îÇ       - 0.0005                                                                
‚îÇ       - 0.0002                                                                
‚îÇ       lr_scheduler_epoch:                                                     
‚îÇ       - 10                                                                    
‚îÇ       - 15                                                                    
‚îÇ       - 20                                                                    
‚îÇ       - 25                                                                    
‚îÇ       - 30                                                                    
‚îÇ       - 35                                                                    
‚îÇ       - 50                                                                    
‚îÇ       - 45                                                                    
‚îÇ                                                                               
‚îú‚îÄ‚îÄ callbacks
‚îÇ   ‚îî‚îÄ‚îÄ model_checkpoint:                                                       
‚îÇ         _target_: pytorch_lightning.callbacks.ModelCheckpoint                 
‚îÇ         dirpath: /data/scratch/acw572/LHGNN/logs/train/runs/2024-08-20_15-00-2
‚îÇ         filename: epoch_{epoch:03d}                                           
‚îÇ         monitor: val/mAP                                                      
‚îÇ         verbose: false                                                        
‚îÇ         save_last: true                                                       
‚îÇ         save_top_k: 20                                                        
‚îÇ         mode: max                                                             
‚îÇ         auto_insert_metric_name: false                                        
‚îÇ         save_weights_only: false                                              
‚îÇ         every_n_train_steps: null                                             
‚îÇ         train_time_interval: null                                             
‚îÇ         every_n_epochs: null                                                  
‚îÇ         save_on_train_epoch_end: null                                         
‚îÇ       early_stopping:                                                         
‚îÇ         _target_: pytorch_lightning.callbacks.EarlyStopping                   
‚îÇ         monitor: val/loss                                                     
‚îÇ         min_delta: 0.0                                                        
‚îÇ         patience: 5                                                           
‚îÇ         verbose: false                                                        
‚îÇ         mode: min                                                             
‚îÇ         strict: true                                                          
‚îÇ         check_finite: true                                                    
‚îÇ         stopping_threshold: null                                              
‚îÇ         divergence_threshold: null                                            
‚îÇ         check_on_train_epoch_end: null                                        
‚îÇ       model_summary:                                                          
‚îÇ         _target_: pytorch_lightning.callbacks.RichModelSummary                
‚îÇ         max_depth: -1                                                         
‚îÇ       tqdm_progress_bar:                                                      
‚îÇ         _target_: pytorch_lightning.callbacks.TQDMProgressBar                 
‚îÇ                                                                               
‚îú‚îÄ‚îÄ logger
‚îÇ   ‚îî‚îÄ‚îÄ wandb:                                                                  
‚îÇ         _target_: pytorch_lightning.loggers.WandbLogger                       
‚îÇ         save_dir: /data/scratch/acw572/LHGNN/logs/train/runs/2024-08-20_15-00-
‚îÇ         offline: false                                                        
‚îÇ         id: null                                                              
‚îÇ         anonymous: null                                                       
‚îÇ         project: audioset-bal                                                 
‚îÇ         log_model: false                                                      
‚îÇ         prefix: ''                                                            
‚îÇ         group: Tagging                                                        
‚îÇ         tags:                                                                 
‚îÇ         - fsd                                                                 
‚îÇ         - hgcn                                                                
‚îÇ         job_type: ''                                                          
‚îÇ                                                                               
‚îú‚îÄ‚îÄ trainer
‚îÇ   ‚îî‚îÄ‚îÄ _target_: pytorch_lightning.trainer.Trainer                             
‚îÇ       default_root_dir: /data/scratch/acw572/LHGNN/logs/train/runs/2024-08-20_
‚îÇ       num_sanity_val_steps: 0                                                 
‚îÇ       min_epochs: 3                                                           
‚îÇ       max_epochs: 5                                                           
‚îÇ       accelerator: gpu                                                        
‚îÇ       devices: 1                                                              
‚îÇ       gradient_clip_val: 0.5                                                  
‚îÇ       precision: 32                                                           
‚îÇ       detect_anomaly: false                                                   
‚îÇ       check_val_every_n_epoch: 1                                              
‚îÇ       deterministic: false                                                    
‚îÇ       strategy: ddp                                                           
‚îÇ       num_nodes: 1                                                            
‚îÇ       sync_batchnorm: true                                                    
‚îÇ       use_distributed_sampler: true                                           
‚îÇ                                                                               
‚îú‚îÄ‚îÄ paths
‚îÇ   ‚îî‚îÄ‚îÄ root_dir: /data/home/acw572/hgann/HGANN                                 
‚îÇ       exp_dir: /data/scratch/acw572                                           
‚îÇ       data_dir: /data/EECS-MachineListeningLab/datasets/AudioSet              
‚îÇ       meta_dir: /data/EECS-MachineListeningLab/shubhr/hgann                   
‚îÇ       log_dir: /data/scratch/acw572/LHGNN/logs/                               
‚îÇ       output_dir: /data/scratch/acw572/LHGNN/logs/train/runs/2024-08-20_15-00-
‚îÇ       work_dir: /data/home/acw572/hgann/HGANN                                 
‚îÇ                                                                               
‚îú‚îÄ‚îÄ extras
‚îÇ   ‚îî‚îÄ‚îÄ ignore_warnings: false                                                  
‚îÇ       enforce_tags: true                                                      
‚îÇ       print_config: true                                                      
‚îÇ                                                                               
‚îú‚îÄ‚îÄ task_name
‚îÇ   ‚îî‚îÄ‚îÄ train                                                                   
‚îú‚îÄ‚îÄ pretrained
‚îÇ   ‚îî‚îÄ‚îÄ img                                                                     
‚îú‚îÄ‚îÄ tags
‚îÇ   ‚îî‚îÄ‚îÄ ['dev']                                                                 
‚îú‚îÄ‚îÄ train
‚îÇ   ‚îî‚îÄ‚îÄ True                                                                    
‚îú‚îÄ‚îÄ eval
‚îÇ   ‚îî‚îÄ‚îÄ True                                                                    
‚îú‚îÄ‚îÄ wa
‚îÇ   ‚îî‚îÄ‚îÄ True                                                                    
‚îú‚îÄ‚îÄ ckpt_path
‚îÇ   ‚îî‚îÄ‚îÄ /data/EECS-MachineListeningLab/shubhr/imagenet_weights/model_best.pth.ta
‚îî‚îÄ‚îÄ seed
    ‚îî‚îÄ‚îÄ None                                                                    
[[36m2024-08-20 15:00:21,978[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] In train[0m
[[36m2024-08-20 15:00:21,978[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating datamodule <src.data.fsd_datamodule.FSDDataModule>[0m
[[36m2024-08-20 15:00:23,957[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating model <src.models.tagging_module.TaggingModule>[0m
/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/utilities/parsing.py:198: Attribute 'net' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['net'])`.
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
[[36m2024-08-20 15:00:45,766[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Loading img pretrained weights[0m
[[36m2024-08-20 15:00:45,766[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating callbacks...[0m
[[36m2024-08-20 15:00:45,766[0m][[34mutils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>[0m
[[36m2024-08-20 15:00:45,776[0m][[34mutils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <pytorch_lightning.callbacks.EarlyStopping>[0m
[[36m2024-08-20 15:00:45,777[0m][[34mutils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>[0m
[[36m2024-08-20 15:00:45,777[0m][[34mutils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <pytorch_lightning.callbacks.TQDMProgressBar>[0m
[[36m2024-08-20 15:00:45,777[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating loggers...[0m
[[36m2024-08-20 15:00:45,778[0m][[34mutils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating logger <pytorch_lightning.loggers.WandbLogger>[0m
[[36m2024-08-20 15:00:45,936[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating trainer <pytorch_lightning.trainer.Trainer>[0m
Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[[36m2024-08-20 15:00:46,221[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Logging hyperparameters![0m
wandb: Currently logged in as: shubhr. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.1
wandb: Run data is saved locally in /data/scratch/acw572/LHGNN/logs/train/runs/2024-08-20_15-00-21/wandb/run-20240820_150048-s5cyp8ia
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-resonance-63
wandb: ‚≠êÔ∏è View project at https://wandb.ai/shubhr/audioset-bal
wandb: üöÄ View run at https://wandb.ai/shubhr/audioset-bal/runs/s5cyp8ia
[[36m2024-08-20 15:01:11,664[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Starting training![0m
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 1 processes
----------------------------------------------------------------------------------------------------

[[36m2024-08-20 15:01:12,381[0m][[34mutils.utils[0m][[31mERROR[0m] - [rank: 0] [0m
Traceback (most recent call last):
  File "/data/home/acw572/hgann/HGANN/src/utils/utils.py", line 101, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
                               ^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/hgann/HGANN/src/train.py", line 115, in train
    trainer.fit(model=model, datamodule=datamodule)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 102, in launch
    return function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 950, in _run
    call._call_setup_hook(self)  # allow user to setup lightning_module in accelerator environment
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 92, in _call_setup_hook
    _call_lightning_datamodule_hook(trainer, "setup", stage=fn)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 179, in _call_lightning_datamodule_hook
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/hgann/HGANN/src/data/fsd_datamodule.py", line 172, in setup
    self.eval_dataset = FSDDataset(self.eval_json,self.audio_conf,mode='eval',label_csv=self.label_csv_pth)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/hgann/HGANN/src/data/dataset.py", line 26, in __init__
    with open(data_json, 'r') as fp:
         ^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/data/scratch/acw572/hdf_fsd50k/datafiles/fsd_eval_full.json'
[[36m2024-08-20 15:01:12,499[0m][[34mutils.utils[0m][[32mINFO[0m] - [rank: 0] Output dir: /data/scratch/acw572/LHGNN/logs/train/runs/2024-08-20_15-00-21[0m
[[36m2024-08-20 15:01:12,499[0m][[34mutils.utils[0m][[32mINFO[0m] - [rank: 0] Closing wandb![0m
wandb: - 0.006 MB of 0.006 MB uploadedwandb: \ 0.006 MB of 0.019 MB uploadedwandb: | 0.006 MB of 0.019 MB uploadedwandb: / 0.022 MB of 0.022 MB uploadedwandb:                                                                                
wandb: üöÄ View run blooming-resonance-63 at: https://wandb.ai/shubhr/audioset-bal/runs/s5cyp8ia
wandb: Ô∏è‚ö° View job at https://wandb.ai/shubhr/audioset-bal/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjI0NzQ3OTYxNA==/version_details/v7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /data/scratch/acw572/LHGNN/logs/train/runs/2024-08-20_15-00-21/wandb/run-20240820_150048-s5cyp8ia/logs
Error executing job with overrides: ['trainer.max_epochs=5', 'trainer.min_epochs=3', 'trainer.devices=1', 'trainer.strategy=ddp', 'data.batch_size=25']
Traceback (most recent call last):
  File "/data/home/acw572/hgann/HGANN/src/train.py", line 197, in <module>
    main()
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
    raise ex
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           ^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            ^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/_internal/hydra.py", line 132, in run
    _ = ret.return_value
        ^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/core/utils.py", line 260, in return_value
    raise self._return_value
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
                       ^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/hgann/HGANN/src/train.py", line 181, in main
    metrics,_ = train(cfg)
                ^^^^^^^^^^
  File "/data/home/acw572/hgann/HGANN/src/utils/utils.py", line 111, in wrap
    raise ex
  File "/data/home/acw572/hgann/HGANN/src/utils/utils.py", line 101, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
                               ^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/hgann/HGANN/src/train.py", line 115, in train
    trainer.fit(model=model, datamodule=datamodule)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 102, in launch
    return function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 950, in _run
    call._call_setup_hook(self)  # allow user to setup lightning_module in accelerator environment
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 92, in _call_setup_hook
    _call_lightning_datamodule_hook(trainer, "setup", stage=fn)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 179, in _call_lightning_datamodule_hook
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/hgann/HGANN/src/data/fsd_datamodule.py", line 172, in setup
    self.eval_dataset = FSDDataset(self.eval_json,self.audio_conf,mode='eval',label_csv=self.label_csv_pth)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/hgann/HGANN/src/data/dataset.py", line 26, in __init__
    with open(data_json, 'r') as fp:
         ^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/data/scratch/acw572/hdf_fsd50k/datafiles/fsd_eval_full.json'
