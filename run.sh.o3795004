Variable OMP_NUM_THREADS has been set to 24
--------------------
Hostname: rdg1
Thu Aug 15 15:45:22 BST 2024
Free GPU: 1 of 2
--------------------
GPU0: [92mNot in use.[39m
GPU1: [92mNot in use.[39m

User: [91macw572[39m JobID: [91m3795004[39m GPU Allocation: [91m2[39m Queue: [91mshort.q[39m
User: [91macw676[39m JobID: [91m3794933[39m GPU Allocation: [91m0[39m Queue: [91mshort.q[39m
[91mWarning! GPUs requested but not used![39m
In main
[[36m2024-08-15 15:46:14,553[0m][[34mutils.utils[0m][[32mINFO[0m] - [rank: 0] Enforcing tags! <cfg.extras.enforce_tags=True>[0m
[[36m2024-08-15 15:46:14,560[0m][[34mutils.utils[0m][[32mINFO[0m] - [rank: 0] Printing config tree with Rich! <cfg.extras.print_config=True>[0m
CONFIG
â”œâ”€â”€ data
â”‚   â””â”€â”€ _target_: src.data.fsd_datamodule.FSDDataModule                         
â”‚       json_path: /data/scratch/acw572/LHGNN/datafiles/                        
â”‚       data_dir: /data/EECS-MachineListeningLab/datasets/AudioSet              
â”‚       meta_path: /data/EECS-MachineListeningLab/datasets/AudioSet/ground_truth
â”‚       label_csv_pth: /data/scratch/acw572/LHGNN/datafiles/class_labels_indices
â”‚       samplr_csv_pth: /data/scratch/acw572/LHGNN/datafiles/fsd50k_tr_full_weig
â”‚       balance_samplr: true                                                    
â”‚       batch_size: 50                                                          
â”‚       num_workers: 8                                                          
â”‚       pin_memory: true                                                        
â”‚       persistent_workers: true                                                
â”‚       sr: 16000                                                               
â”‚       fmin: 20                                                                
â”‚       fmax: 8000                                                              
â”‚       num_mels: 128                                                           
â”‚       window_type: hanning                                                    
â”‚       target_len: 1024                                                        
â”‚       freqm: 48                                                               
â”‚       timem: 192                                                              
â”‚       mixup: 0.5                                                              
â”‚       norm_mean: -4.6476                                                      
â”‚       norm_std: 4.5699                                                        
â”‚       num_devices: 2                                                          
â”‚                                                                               
â”œâ”€â”€ model
â”‚   â””â”€â”€ _target_: src.models.tagging_module_test.TaggingModule                  
â”‚       optimizer:                                                              
â”‚         _target_: torch.optim.Adam                                            
â”‚         _partial_: true                                                       
â”‚         lr: 0.0005                                                            
â”‚         weight_decay: 5.0e-07                                                 
â”‚         eps: 1.0e-08                                                          
â”‚         betas:                                                                
â”‚         - 0.95                                                                
â”‚         - 0.999                                                               
â”‚       scheduler:                                                              
â”‚         _target_: torch.optim.lr_scheduler.MultiStepLR                        
â”‚         _partial_: true                                                       
â”‚         milestones:                                                           
â”‚         - 10                                                                  
â”‚         - 15                                                                  
â”‚         - 20                                                                  
â”‚         - 25                                                                  
â”‚         - 30                                                                  
â”‚         - 35                                                                  
â”‚         - 40                                                                  
â”‚         gamma: 0.5                                                            
â”‚       net:                                                                    
â”‚         _target_: src.models.components.Hypergraph.HGCN                       
â”‚         k: 25                                                                 
â”‚         act: gelu                                                             
â”‚         norm: batch                                                           
â”‚         bias: true                                                            
â”‚         dropout: 0.0                                                          
â”‚         dilation: true                                                        
â”‚         epsilon: 0.2                                                          
â”‚         drop_path: 0.1                                                        
â”‚         size: s                                                               
â”‚         num_class: 200                                                        
â”‚         emb_dims: 1024                                                        
â”‚         freq_num: 128                                                         
â”‚         time_num: 1024                                                        
â”‚       compile: false                                                          
â”‚       loss: bce                                                               
â”‚       opt_warmup: true                                                        
â”‚       learning_rate: 0.0005                                                   
â”‚       lr_rate:                                                                
â”‚       - 0.05                                                                  
â”‚       - 0.02                                                                  
â”‚       - 0.01                                                                  
â”‚       - 0.005                                                                 
â”‚       - 0.002                                                                 
â”‚       - 0.001                                                                 
â”‚       - 0.0005                                                                
â”‚       - 0.0002                                                                
â”‚       lr_scheduler_epoch:                                                     
â”‚       - 10                                                                    
â”‚       - 15                                                                    
â”‚       - 20                                                                    
â”‚       - 25                                                                    
â”‚       - 30                                                                    
â”‚       - 35                                                                    
â”‚       - 50                                                                    
â”‚       - 45                                                                    
â”‚                                                                               
â”œâ”€â”€ callbacks
â”‚   â””â”€â”€ model_checkpoint:                                                       
â”‚         _target_: pytorch_lightning.callbacks.ModelCheckpoint                 
â”‚         dirpath: /data/scratch/acw572/LHGNN/logs/train/runs/2024-08-15_15-46-1
â”‚         filename: epoch_{epoch:03d}                                           
â”‚         monitor: val/mAP                                                      
â”‚         verbose: false                                                        
â”‚         save_last: true                                                       
â”‚         save_top_k: 20                                                        
â”‚         mode: max                                                             
â”‚         auto_insert_metric_name: false                                        
â”‚         save_weights_only: false                                              
â”‚         every_n_train_steps: null                                             
â”‚         train_time_interval: null                                             
â”‚         every_n_epochs: null                                                  
â”‚         save_on_train_epoch_end: null                                         
â”‚       early_stopping:                                                         
â”‚         _target_: pytorch_lightning.callbacks.EarlyStopping                   
â”‚         monitor: val/loss                                                     
â”‚         min_delta: 0.0                                                        
â”‚         patience: 5                                                           
â”‚         verbose: false                                                        
â”‚         mode: min                                                             
â”‚         strict: true                                                          
â”‚         check_finite: true                                                    
â”‚         stopping_threshold: null                                              
â”‚         divergence_threshold: null                                            
â”‚         check_on_train_epoch_end: null                                        
â”‚       model_summary:                                                          
â”‚         _target_: pytorch_lightning.callbacks.RichModelSummary                
â”‚         max_depth: -1                                                         
â”‚       tqdm_progress_bar:                                                      
â”‚         _target_: pytorch_lightning.callbacks.TQDMProgressBar                 
â”‚                                                                               
â”œâ”€â”€ logger
â”‚   â””â”€â”€ wandb:                                                                  
â”‚         _target_: pytorch_lightning.loggers.WandbLogger                       
â”‚         save_dir: /data/scratch/acw572/LHGNN/logs/train/runs/2024-08-15_15-46-
â”‚         offline: false                                                        
â”‚         id: null                                                              
â”‚         anonymous: null                                                       
â”‚         project: audioset-bal                                                 
â”‚         log_model: false                                                      
â”‚         prefix: ''                                                            
â”‚         group: Tagging                                                        
â”‚         tags:                                                                 
â”‚         - fsd                                                                 
â”‚         - hgcn                                                                
â”‚         job_type: ''                                                          
â”‚                                                                               
â”œâ”€â”€ trainer
â”‚   â””â”€â”€ _target_: pytorch_lightning.trainer.Trainer                             
â”‚       default_root_dir: /data/scratch/acw572/LHGNN/logs/train/runs/2024-08-15_
â”‚       num_sanity_val_steps: 0                                                 
â”‚       min_epochs: 3                                                           
â”‚       max_epochs: 5                                                           
â”‚       accelerator: gpu                                                        
â”‚       devices: 2                                                              
â”‚       gradient_clip_val: 0.5                                                  
â”‚       precision: 32                                                           
â”‚       detect_anomaly: false                                                   
â”‚       check_val_every_n_epoch: 1                                              
â”‚       deterministic: false                                                    
â”‚       strategy: ddp                                                           
â”‚       num_nodes: 1                                                            
â”‚       sync_batchnorm: false                                                   
â”‚       use_distributed_sampler: false                                          
â”‚                                                                               
â”œâ”€â”€ paths
â”‚   â””â”€â”€ root_dir: /data/home/acw572/hgann/HGANN                                 
â”‚       exp_dir: /data/scratch/acw572                                           
â”‚       data_dir: /data/EECS-MachineListeningLab/datasets/AudioSet              
â”‚       meta_dir: /data/EECS-MachineListeningLab/shubhr/hgann                   
â”‚       log_dir: /data/scratch/acw572/LHGNN/logs/                               
â”‚       output_dir: /data/scratch/acw572/LHGNN/logs/train/runs/2024-08-15_15-46-
â”‚       work_dir: /data/home/acw572/hgann/HGANN                                 
â”‚                                                                               
â”œâ”€â”€ extras
â”‚   â””â”€â”€ ignore_warnings: false                                                  
â”‚       enforce_tags: true                                                      
â”‚       print_config: true                                                      
â”‚                                                                               
â”œâ”€â”€ task_name
â”‚   â””â”€â”€ train                                                                   
â”œâ”€â”€ pretrained
â”‚   â””â”€â”€ img                                                                     
â”œâ”€â”€ tags
â”‚   â””â”€â”€ ['dev']                                                                 
â”œâ”€â”€ train
â”‚   â””â”€â”€ True                                                                    
â”œâ”€â”€ eval
â”‚   â””â”€â”€ True                                                                    
â”œâ”€â”€ wa
â”‚   â””â”€â”€ True                                                                    
â”œâ”€â”€ ckpt_path
â”‚   â””â”€â”€ /data/EECS-MachineListeningLab/shubhr/imagenet_weights/model_best.pth.ta
â””â”€â”€ seed
    â””â”€â”€ None                                                                    
[[36m2024-08-15 15:46:14,685[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] In train[0m
[[36m2024-08-15 15:46:14,685[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating datamodule <src.data.fsd_datamodule.FSDDataModule>[0m
[[36m2024-08-15 15:46:16,266[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating model <src.models.tagging_module_test.TaggingModule>[0m
/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/utilities/parsing.py:198: Attribute 'net' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['net'])`.
norm is batch
bias is True
drop_path is 0.1
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
[[36m2024-08-15 15:46:43,045[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Loading img pretrained weights[0m
[[36m2024-08-15 15:46:43,045[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating callbacks...[0m
[[36m2024-08-15 15:46:43,045[0m][[34mutils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>[0m
[[36m2024-08-15 15:46:43,048[0m][[34mutils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <pytorch_lightning.callbacks.EarlyStopping>[0m
[[36m2024-08-15 15:46:43,049[0m][[34mutils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>[0m
[[36m2024-08-15 15:46:43,049[0m][[34mutils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <pytorch_lightning.callbacks.TQDMProgressBar>[0m
[[36m2024-08-15 15:46:43,050[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating loggers...[0m
[[36m2024-08-15 15:46:43,050[0m][[34mutils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating logger <pytorch_lightning.loggers.WandbLogger>[0m
[[36m2024-08-15 15:46:43,292[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating trainer <pytorch_lightning.trainer.Trainer>[0m
Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[[36m2024-08-15 15:46:43,475[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Logging hyperparameters![0m
wandb: Currently logged in as: shubhr. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.6 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.1
wandb: Run data is saved locally in /data/scratch/acw572/LHGNN/logs/train/runs/2024-08-15_15-46-14/wandb/run-20240815_154645-yw9alst8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-totem-50
wandb: â­ï¸ View project at https://wandb.ai/shubhr/audioset-bal
wandb: ğŸš€ View run at https://wandb.ai/shubhr/audioset-bal/runs/yw9alst8
[[36m2024-08-15 15:47:03,565[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Starting training![0m
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”³â”â”â”“
â”ƒ   â”ƒ Name                                                              â”ƒ â€¦ â”ƒ  â”ƒ
â”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â•‡â”â”â”©
â”‚ 0 â”‚ net                                                               â”‚ â€¦ â”‚  â”‚
â”‚ 1 â”‚ net.stem                                                          â”‚ â€¦ â”‚  â”‚
â”‚ 2 â”‚ net.stem.convs                                                    â”‚ â€¦ â”‚  â”‚
â”‚ 3 â”‚ net.stem.convs.0                                                  â”‚ â€¦ â”‚  â”‚
â”‚ 4 â”‚ net.stem.convs.1                                                  â”‚ â€¦ â”‚  â”‚
â”‚ 5 â”‚ net.stem.convs.2                                                  â”‚ â€¦ â”‚  â”‚
â”‚ 6 â”‚ net.stem.convs.3                                                  â”‚ â€¦ â”‚  â”‚
â”‚ 7 â”‚ net.stem.convs.4                                                  â”‚ â€¦ â”‚  â”‚
â”‚ 8 â”‚ net.stem.convs.5                                                  â”‚ â€¦ â”‚  â”‚
â”‚ 9 â”‚ net.stem.convs.6                                                  â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.stem.convs.7                                                  â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone                                                      â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.0                                                    â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.0.0                                                  â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.0.0.fc1                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.0.0.fc1.0                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.0.0.fc1.1                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.0.0.graph_conv                                       â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.0.0.graph_conv.gconv                                 â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.0.0.graph_conv.gconv.nn                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.0.0.graph_conv.gconv.nn.0                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.0.0.graph_conv.gconv.nn.1                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.0.0.graph_conv.gconv.nn.2                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.0.0.graph_conv.gconv.get_centroids                   â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.0.0.graph_conv.gconv.get_centroids.centers_proposal  â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.0.0.graph_conv.dilated_knn_graph                     â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.0.0.graph_conv.dilated_knn_graph._dilated            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.0.0.fc2                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.0.0.fc2.0                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.0.0.fc2.1                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.0.0.drop_path                                        â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.0.1                                                  â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.0.1.fc1                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.0.1.fc1.0                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.0.1.fc1.1                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.0.1.act                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.0.1.fc2                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.0.1.fc2.0                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.0.1.fc2.1                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.0.1.conv                                             â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.0.1.conv.conv                                        â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.0.1.drop_path                                        â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.1                                                    â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.1.0                                                  â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.1.0.fc1                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.1.0.fc1.0                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.1.0.fc1.1                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.1.0.graph_conv                                       â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.1.0.graph_conv.gconv                                 â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.1.0.graph_conv.gconv.nn                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.1.0.graph_conv.gconv.nn.0                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.1.0.graph_conv.gconv.nn.1                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.1.0.graph_conv.gconv.nn.2                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.1.0.graph_conv.gconv.get_centroids                   â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.1.0.graph_conv.gconv.get_centroids.centers_proposal  â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.1.0.graph_conv.dilated_knn_graph                     â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.1.0.graph_conv.dilated_knn_graph._dilated            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.1.0.fc2                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.1.0.fc2.0                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.1.0.fc2.1                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.1.0.drop_path                                        â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.1.1                                                  â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.1.1.fc1                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.1.1.fc1.0                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.1.1.fc1.1                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.1.1.act                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.1.1.fc2                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.1.1.fc2.0                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.1.1.fc2.1                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.1.1.conv                                             â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.1.1.conv.conv                                        â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.1.1.drop_path                                        â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.2                                                    â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.2.conv                                               â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.2.conv.0                                             â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.2.conv.1                                             â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.3                                                    â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.3.0                                                  â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.3.0.fc1                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.3.0.fc1.0                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.3.0.fc1.1                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.3.0.graph_conv                                       â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.3.0.graph_conv.gconv                                 â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.3.0.graph_conv.gconv.nn                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.3.0.graph_conv.gconv.nn.0                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.3.0.graph_conv.gconv.nn.1                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.3.0.graph_conv.gconv.nn.2                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.3.0.graph_conv.gconv.get_centroids                   â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.3.0.graph_conv.gconv.get_centroids.centers_proposal  â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.3.0.graph_conv.dilated_knn_graph                     â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.3.0.graph_conv.dilated_knn_graph._dilated            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.3.0.fc2                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.3.0.fc2.0                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.3.0.fc2.1                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.3.0.drop_path                                        â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.3.1                                                  â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.3.1.fc1                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.3.1.fc1.0                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.3.1.fc1.1                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.3.1.act                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.3.1.fc2                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.3.1.fc2.0                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.3.1.fc2.1                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.3.1.conv                                             â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.3.1.conv.conv                                        â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.3.1.drop_path                                        â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.4                                                    â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.4.0                                                  â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.4.0.fc1                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.4.0.fc1.0                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.4.0.fc1.1                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.4.0.graph_conv                                       â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.4.0.graph_conv.gconv                                 â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.4.0.graph_conv.gconv.nn                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.4.0.graph_conv.gconv.nn.0                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.4.0.graph_conv.gconv.nn.1                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.4.0.graph_conv.gconv.nn.2                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.4.0.graph_conv.gconv.get_centroids                   â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.4.0.graph_conv.gconv.get_centroids.centers_proposal  â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.4.0.graph_conv.dilated_knn_graph                     â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.4.0.graph_conv.dilated_knn_graph._dilated            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.4.0.fc2                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.4.0.fc2.0                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.4.0.fc2.1                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.4.0.drop_path                                        â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.4.1                                                  â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.4.1.fc1                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.4.1.fc1.0                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.4.1.fc1.1                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.4.1.act                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.4.1.fc2                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.4.1.fc2.0                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.4.1.fc2.1                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.4.1.conv                                             â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.4.1.conv.conv                                        â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.4.1.drop_path                                        â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.5                                                    â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.5.conv                                               â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.5.conv.0                                             â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.5.conv.1                                             â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.6                                                    â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.6.0                                                  â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.6.0.fc1                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.6.0.fc1.0                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.6.0.fc1.1                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.6.0.graph_conv                                       â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.6.0.graph_conv.gconv                                 â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.6.0.graph_conv.gconv.nn                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.6.0.graph_conv.gconv.nn.0                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.6.0.graph_conv.gconv.nn.1                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.6.0.graph_conv.gconv.nn.2                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.6.0.graph_conv.gconv.get_centroids                   â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.6.0.graph_conv.gconv.get_centroids.centers_proposal  â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.6.0.graph_conv.dilated_knn_graph                     â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.6.0.graph_conv.dilated_knn_graph._dilated            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.6.0.fc2                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.6.0.fc2.0                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.6.0.fc2.1                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.6.0.drop_path                                        â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.6.1                                                  â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.6.1.fc1                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.6.1.fc1.0                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.6.1.fc1.1                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.6.1.act                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.6.1.fc2                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.6.1.fc2.0                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.6.1.fc2.1                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.6.1.conv                                             â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.6.1.conv.conv                                        â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.6.1.drop_path                                        â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.7                                                    â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.7.0                                                  â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.7.0.fc1                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.7.0.fc1.0                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.7.0.fc1.1                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.7.0.graph_conv                                       â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.7.0.graph_conv.gconv                                 â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.7.0.graph_conv.gconv.nn                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.7.0.graph_conv.gconv.nn.0                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.7.0.graph_conv.gconv.nn.1                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.7.0.graph_conv.gconv.nn.2                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.7.0.graph_conv.gconv.get_centroids                   â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.7.0.graph_conv.gconv.get_centroids.centers_proposal  â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.7.0.graph_conv.dilated_knn_graph                     â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.7.0.graph_conv.dilated_knn_graph._dilated            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.7.0.fc2                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.7.0.fc2.0                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.7.0.fc2.1                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.7.0.drop_path                                        â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.7.1                                                  â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.7.1.fc1                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.7.1.fc1.0                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.7.1.fc1.1                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.7.1.act                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.7.1.fc2                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.7.1.fc2.0                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.7.1.fc2.1                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.7.1.conv                                             â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.7.1.conv.conv                                        â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.7.1.drop_path                                        â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.8                                                    â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.8.0                                                  â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.8.0.fc1                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.8.0.fc1.0                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.8.0.fc1.1                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.8.0.graph_conv                                       â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.8.0.graph_conv.gconv                                 â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.8.0.graph_conv.gconv.nn                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.8.0.graph_conv.gconv.nn.0                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.8.0.graph_conv.gconv.nn.1                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.8.0.graph_conv.gconv.nn.2                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.8.0.graph_conv.gconv.get_centroids                   â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.8.0.graph_conv.gconv.get_centroids.centers_proposal  â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.8.0.graph_conv.dilated_knn_graph                     â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.8.0.graph_conv.dilated_knn_graph._dilated            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.8.0.fc2                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.8.0.fc2.0                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.8.0.fc2.1                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.8.0.drop_path                                        â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.8.1                                                  â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.8.1.fc1                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.8.1.fc1.0                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.8.1.fc1.1                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.8.1.act                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.8.1.fc2                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.8.1.fc2.0                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.8.1.fc2.1                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.8.1.conv                                             â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.8.1.conv.conv                                        â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.8.1.drop_path                                        â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.9                                                    â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.9.0                                                  â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.9.0.fc1                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.9.0.fc1.0                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.9.0.fc1.1                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.9.0.graph_conv                                       â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.9.0.graph_conv.gconv                                 â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.9.0.graph_conv.gconv.nn                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.9.0.graph_conv.gconv.nn.0                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.9.0.graph_conv.gconv.nn.1                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.9.0.graph_conv.gconv.nn.2                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.9.0.graph_conv.gconv.get_centroids                   â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.9.0.graph_conv.gconv.get_centroids.centers_proposal  â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.9.0.graph_conv.dilated_knn_graph                     â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.9.0.graph_conv.dilated_knn_graph._dilated            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.9.0.fc2                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.9.0.fc2.0                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.9.0.fc2.1                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.9.0.drop_path                                        â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.9.1                                                  â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.9.1.fc1                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.9.1.fc1.0                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.9.1.fc1.1                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.9.1.act                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.9.1.fc2                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.9.1.fc2.0                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.9.1.fc2.1                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.9.1.conv                                             â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.9.1.conv.conv                                        â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.9.1.drop_path                                        â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.10                                                   â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.10.0                                                 â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.10.0.fc1                                             â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.10.0.fc1.0                                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.10.0.fc1.1                                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.10.0.graph_conv                                      â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.10.0.graph_conv.gconv                                â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.10.0.graph_conv.gconv.nn                             â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.10.0.graph_conv.gconv.nn.0                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.10.0.graph_conv.gconv.nn.1                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.10.0.graph_conv.gconv.nn.2                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.10.0.graph_conv.gconv.get_centroids                  â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.10.0.graph_conv.gconv.get_centroids.centers_proposal â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.10.0.graph_conv.dilated_knn_graph                    â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.10.0.graph_conv.dilated_knn_graph._dilated           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.10.0.fc2                                             â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.10.0.fc2.0                                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.10.0.fc2.1                                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.10.0.drop_path                                       â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.10.1                                                 â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.10.1.fc1                                             â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.10.1.fc1.0                                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.10.1.fc1.1                                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.10.1.act                                             â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.10.1.fc2                                             â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.10.1.fc2.0                                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.10.1.fc2.1                                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.10.1.conv                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.10.1.conv.conv                                       â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.10.1.drop_path                                       â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.11                                                   â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.11.0                                                 â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.11.0.fc1                                             â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.11.0.fc1.0                                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.11.0.fc1.1                                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.11.0.graph_conv                                      â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.11.0.graph_conv.gconv                                â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.11.0.graph_conv.gconv.nn                             â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.11.0.graph_conv.gconv.nn.0                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.11.0.graph_conv.gconv.nn.1                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.11.0.graph_conv.gconv.nn.2                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.11.0.graph_conv.gconv.get_centroids                  â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.11.0.graph_conv.gconv.get_centroids.centers_proposal â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.11.0.graph_conv.dilated_knn_graph                    â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.11.0.graph_conv.dilated_knn_graph._dilated           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.11.0.fc2                                             â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.11.0.fc2.0                                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.11.0.fc2.1                                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.11.0.drop_path                                       â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.11.1                                                 â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.11.1.fc1                                             â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.11.1.fc1.0                                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.11.1.fc1.1                                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.11.1.act                                             â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.11.1.fc2                                             â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.11.1.fc2.0                                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.11.1.fc2.1                                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.11.1.conv                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.11.1.conv.conv                                       â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.11.1.drop_path                                       â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.12                                                   â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.12.conv                                              â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.12.conv.0                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.12.conv.1                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.13                                                   â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.13.0                                                 â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.13.0.fc1                                             â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.13.0.fc1.0                                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.13.0.fc1.1                                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.13.0.graph_conv                                      â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.13.0.graph_conv.gconv                                â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.13.0.graph_conv.gconv.nn                             â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.13.0.graph_conv.gconv.nn.0                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.13.0.graph_conv.gconv.nn.1                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.13.0.graph_conv.gconv.nn.2                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.13.0.graph_conv.gconv.get_centroids                  â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.13.0.graph_conv.gconv.get_centroids.centers_proposal â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.13.0.graph_conv.dilated_knn_graph                    â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.13.0.graph_conv.dilated_knn_graph._dilated           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.13.0.fc2                                             â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.13.0.fc2.0                                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.13.0.fc2.1                                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.13.0.drop_path                                       â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.13.1                                                 â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.13.1.fc1                                             â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.13.1.fc1.0                                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.13.1.fc1.1                                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.13.1.act                                             â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.13.1.fc2                                             â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.13.1.fc2.0                                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.13.1.fc2.1                                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.13.1.conv                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.13.1.conv.conv                                       â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.13.1.drop_path                                       â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.14                                                   â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.14.0                                                 â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.14.0.fc1                                             â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.14.0.fc1.0                                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.14.0.fc1.1                                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.14.0.graph_conv                                      â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.14.0.graph_conv.gconv                                â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.14.0.graph_conv.gconv.nn                             â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.14.0.graph_conv.gconv.nn.0                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.14.0.graph_conv.gconv.nn.1                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.14.0.graph_conv.gconv.nn.2                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.14.0.graph_conv.gconv.get_centroids                  â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.14.0.graph_conv.gconv.get_centroids.centers_proposal â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.14.0.graph_conv.dilated_knn_graph                    â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.14.0.graph_conv.dilated_knn_graph._dilated           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.14.0.fc2                                             â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.14.0.fc2.0                                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.14.0.fc2.1                                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.14.0.drop_path                                       â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.14.1                                                 â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.14.1.fc1                                             â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.14.1.fc1.0                                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.14.1.fc1.1                                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.14.1.act                                             â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.14.1.fc2                                             â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.14.1.fc2.0                                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.14.1.fc2.1                                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.14.1.conv                                            â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.14.1.conv.conv                                       â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.backbone.14.1.drop_path                                       â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.prediction                                                    â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.prediction.0                                                  â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.prediction.1                                                  â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.prediction.2                                                  â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.prediction.3                                                  â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ net.prediction.4                                                  â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ criterion                                                         â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ train_loss                                                        â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ val_loss                                                          â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ test_loss                                                         â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ val_mAP                                                           â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ test_mAP                                                          â”‚ â€¦ â”‚  â”‚
â”‚ â€¦ â”‚ val_mAP_best                                                      â”‚ â€¦ â”‚  â”‚
â””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”˜
Trainable params: 31.1 M                                                        
Non-trainable params: 12.1 M                                                    
Total params: 43.2 M                                                            
Total estimated model params size (MB): 172                                     
In main
norm is batch
bias is True
drop_path is 0.1
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/735 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/735 [00:00<?, ?it/s] hyperparameters: "compile":            False
"learning_rate":      0.0005
"loss":               bce
"lr_rate":            [0.05, 0.02, 0.01, 0.005, 0.002, 0.001, 0.0005, 0.0002]
"lr_scheduler_epoch": [10, 15, 20, 25, 30, 35, 50, 45]
"net":                HGCN(
  (stem): Stem_conv(
    (convs): Sequential(
      (0): Conv2d(1, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): GELU(approximate='none')
      (3): Conv2d(40, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (4): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): GELU(approximate='none')
      (6): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (backbone): Sequential(
    (0): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): Identity()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
        )
        (drop_path): Identity()
      )
    )
    (1): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
        )
        (drop_path): DropPath()
      )
    )
    (2): DownSample(
      (conv): Sequential(
        (0): Conv2d(80, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(480, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)
        )
        (drop_path): DropPath()
      )
    )
    (4): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(480, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)
        )
        (drop_path): DropPath()
      )
    )
    (5): DownSample(
      (conv): Sequential(
        (0): Conv2d(160, 400, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (7): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (8): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (9): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (10): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (11): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (12): DownSample(
      (conv): Sequential(
        (0): Conv2d(400, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (13): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1920, 1920, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(640, 2560, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(2560, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(2560, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(2560, 2560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2560)
        )
        (drop_path): DropPath()
      )
    )
    (14): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1920, 1920, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(640, 2560, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(2560, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(2560, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(2560, 2560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2560)
        )
        (drop_path): DropPath()
      )
    )
  )
  (prediction): Sequential(
    (0): Conv2d(640, 1024, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): GELU(approximate='none')
    (3): Dropout(p=0.0, inplace=False)
    (4): Conv2d(1024, 200, kernel_size=(1, 1), stride=(1, 1))
  )
)
"opt_warmup":         True
"optimizer":          functools.partial(<class 'torch.optim.adam.Adam'>, lr=0.0005, weight_decay=5e-07, eps=1e-08, betas=[0.95, 0.999])
"scheduler":          functools.partial(<class 'torch.optim.lr_scheduler.MultiStepLR'>, milestones=[10, 15, 20, 25, 30, 35, 40], gamma=0.5)
Epoch 0:   0%|          | 1/735 [00:15<3:05:14,  0.07it/s]Epoch 0:   0%|          | 1/735 [00:15<3:05:29,  0.07it/s, v_num=lst8, train/loss_step=0.790]Epoch 0:   0%|          | 2/735 [00:16<1:39:00,  0.12it/s, v_num=lst8, train/loss_step=0.790]Epoch 0:   0%|          | 2/735 [00:16<1:39:01,  0.12it/s, v_num=lst8, train/loss_step=0.791]Epoch 0:   0%|          | 3/735 [00:17<1:10:07,  0.17it/s, v_num=lst8, train/loss_step=0.791]Epoch 0:   0%|          | 3/735 [00:17<1:10:08,  0.17it/s, v_num=lst8, train/loss_step=0.786]Epoch 0:   1%|          | 4/735 [00:18<55:42,  0.22it/s, v_num=lst8, train/loss_step=0.786]  Epoch 0:   1%|          | 4/735 [00:18<55:42,  0.22it/s, v_num=lst8, train/loss_step=0.791]Epoch 0:   1%|          | 5/735 [00:19<47:10,  0.26it/s, v_num=lst8, train/loss_step=0.791]Epoch 0:   1%|          | 5/735 [00:19<47:10,  0.26it/s, v_num=lst8, train/loss_step=0.793]Epoch 0:   1%|          | 6/735 [00:20<41:24,  0.29it/s, v_num=lst8, train/loss_step=0.793]Epoch 0:   1%|          | 6/735 [00:20<41:25,  0.29it/s, v_num=lst8, train/loss_step=0.792]Epoch 0:   1%|          | 7/735 [00:21<37:14,  0.33it/s, v_num=lst8, train/loss_step=0.792]Epoch 0:   1%|          | 7/735 [00:21<37:14,  0.33it/s, v_num=lst8, train/loss_step=0.778]Epoch 0:   1%|          | 8/735 [00:22<34:05,  0.36it/s, v_num=lst8, train/loss_step=0.778]Epoch 0:   1%|          | 8/735 [00:22<34:05,  0.36it/s, v_num=lst8, train/loss_step=0.789]Epoch 0:   1%|          | 9/735 [00:23<31:38,  0.38it/s, v_num=lst8, train/loss_step=0.789]Epoch 0:   1%|          | 9/735 [00:23<31:38,  0.38it/s, v_num=lst8, train/loss_step=0.786]Epoch 0:   1%|â–         | 10/735 [00:24<29:42,  0.41it/s, v_num=lst8, train/loss_step=0.786]Epoch 0:   1%|â–         | 10/735 [00:24<29:43,  0.41it/s, v_num=lst8, train/loss_step=0.768]Epoch 0:   1%|â–         | 11/735 [00:25<28:08,  0.43it/s, v_num=lst8, train/loss_step=0.768]Epoch 0:   1%|â–         | 11/735 [00:25<28:08,  0.43it/s, v_num=lst8, train/loss_step=0.778]Epoch 0:   2%|â–         | 12/735 [00:26<26:49,  0.45it/s, v_num=lst8, train/loss_step=0.778]Epoch 0:   2%|â–         | 12/735 [00:26<26:49,  0.45it/s, v_num=lst8, train/loss_step=0.782]Epoch 0:   2%|â–         | 13/735 [00:27<25:41,  0.47it/s, v_num=lst8, train/loss_step=0.782]Epoch 0:   2%|â–         | 13/735 [00:27<25:41,  0.47it/s, v_num=lst8, train/loss_step=0.774]Epoch 0:   2%|â–         | 14/735 [00:28<24:43,  0.49it/s, v_num=lst8, train/loss_step=0.774]Epoch 0:   2%|â–         | 14/735 [00:28<24:43,  0.49it/s, v_num=lst8, train/loss_step=0.777]Epoch 0:   2%|â–         | 15/735 [00:29<23:52,  0.50it/s, v_num=lst8, train/loss_step=0.777]Epoch 0:   2%|â–         | 15/735 [00:29<23:52,  0.50it/s, v_num=lst8, train/loss_step=0.767]Epoch 0:   2%|â–         | 16/735 [00:30<23:07,  0.52it/s, v_num=lst8, train/loss_step=0.767]Epoch 0:   2%|â–         | 16/735 [00:30<23:07,  0.52it/s, v_num=lst8, train/loss_step=0.773]Epoch 0:   2%|â–         | 17/735 [00:31<22:27,  0.53it/s, v_num=lst8, train/loss_step=0.773]Epoch 0:   2%|â–         | 17/735 [00:31<22:28,  0.53it/s, v_num=lst8, train/loss_step=0.764]Epoch 0:   2%|â–         | 18/735 [00:32<21:52,  0.55it/s, v_num=lst8, train/loss_step=0.764]Epoch 0:   2%|â–         | 18/735 [00:32<21:53,  0.55it/s, v_num=lst8, train/loss_step=0.768]Epoch 0:   3%|â–         | 19/735 [00:34<21:21,  0.56it/s, v_num=lst8, train/loss_step=0.768]Epoch 0:   3%|â–         | 19/735 [00:34<21:21,  0.56it/s, v_num=lst8, train/loss_step=0.768]Epoch 0:   3%|â–         | 20/735 [00:35<20:52,  0.57it/s, v_num=lst8, train/loss_step=0.768]Epoch 0:   3%|â–         | 20/735 [00:35<20:52,  0.57it/s, v_num=lst8, train/loss_step=0.759]Epoch 0:   3%|â–         | 21/735 [00:36<20:26,  0.58it/s, v_num=lst8, train/loss_step=0.759]Epoch 0:   3%|â–         | 21/735 [00:36<20:26,  0.58it/s, v_num=lst8, train/loss_step=0.754]Epoch 0:   3%|â–         | 22/735 [00:37<20:03,  0.59it/s, v_num=lst8, train/loss_step=0.754]Epoch 0:   3%|â–         | 22/735 [00:37<20:03,  0.59it/s, v_num=lst8, train/loss_step=0.750]Epoch 0:   3%|â–         | 23/735 [00:38<19:41,  0.60it/s, v_num=lst8, train/loss_step=0.750]Epoch 0:   3%|â–         | 23/735 [00:38<19:41,  0.60it/s, v_num=lst8, train/loss_step=0.753]Epoch 0:   3%|â–         | 24/735 [00:39<19:21,  0.61it/s, v_num=lst8, train/loss_step=0.753]Epoch 0:   3%|â–         | 24/735 [00:39<19:21,  0.61it/s, v_num=lst8, train/loss_step=0.744]Epoch 0:   3%|â–         | 25/735 [00:40<19:03,  0.62it/s, v_num=lst8, train/loss_step=0.744]Epoch 0:   3%|â–         | 25/735 [00:40<19:03,  0.62it/s, v_num=lst8, train/loss_step=0.749]Epoch 0:   4%|â–         | 26/735 [00:41<18:46,  0.63it/s, v_num=lst8, train/loss_step=0.749]Epoch 0:   4%|â–         | 26/735 [00:41<18:46,  0.63it/s, v_num=lst8, train/loss_step=0.739]Epoch 0:   4%|â–         | 27/735 [00:42<18:30,  0.64it/s, v_num=lst8, train/loss_step=0.739]Epoch 0:   4%|â–         | 27/735 [00:42<18:30,  0.64it/s, v_num=lst8, train/loss_step=0.746]Epoch 0:   4%|â–         | 28/735 [00:43<18:15,  0.65it/s, v_num=lst8, train/loss_step=0.746]Epoch 0:   4%|â–         | 28/735 [00:43<18:15,  0.65it/s, v_num=lst8, train/loss_step=0.734]Epoch 0:   4%|â–         | 29/735 [00:44<18:01,  0.65it/s, v_num=lst8, train/loss_step=0.734]Epoch 0:   4%|â–         | 29/735 [00:44<18:01,  0.65it/s, v_num=lst8, train/loss_step=0.732]Epoch 0:   4%|â–         | 30/735 [00:45<17:48,  0.66it/s, v_num=lst8, train/loss_step=0.732]Epoch 0:   4%|â–         | 30/735 [00:45<17:48,  0.66it/s, v_num=lst8, train/loss_step=0.731]Epoch 0:   4%|â–         | 31/735 [00:46<17:36,  0.67it/s, v_num=lst8, train/loss_step=0.731]Epoch 0:   4%|â–         | 31/735 [00:46<17:36,  0.67it/s, v_num=lst8, train/loss_step=0.721]Epoch 0:   4%|â–         | 32/735 [00:47<17:25,  0.67it/s, v_num=lst8, train/loss_step=0.721]Epoch 0:   4%|â–         | 32/735 [00:47<17:25,  0.67it/s, v_num=lst8, train/loss_step=0.722]Epoch 0:   4%|â–         | 33/735 [00:48<17:14,  0.68it/s, v_num=lst8, train/loss_step=0.722]Epoch 0:   4%|â–         | 33/735 [00:48<17:14,  0.68it/s, v_num=lst8, train/loss_step=0.716]Epoch 0:   5%|â–         | 34/735 [00:49<17:03,  0.68it/s, v_num=lst8, train/loss_step=0.716]Epoch 0:   5%|â–         | 34/735 [00:49<17:03,  0.68it/s, v_num=lst8, train/loss_step=0.711]Epoch 0:   5%|â–         | 35/735 [00:50<16:54,  0.69it/s, v_num=lst8, train/loss_step=0.711]Epoch 0:   5%|â–         | 35/735 [00:50<16:54,  0.69it/s, v_num=lst8, train/loss_step=0.712]Epoch 0:   5%|â–         | 36/735 [00:51<16:44,  0.70it/s, v_num=lst8, train/loss_step=0.712]Epoch 0:   5%|â–         | 36/735 [00:51<16:44,  0.70it/s, v_num=lst8, train/loss_step=0.706]Epoch 0:   5%|â–Œ         | 37/735 [00:52<16:36,  0.70it/s, v_num=lst8, train/loss_step=0.706]Epoch 0:   5%|â–Œ         | 37/735 [00:52<16:36,  0.70it/s, v_num=lst8, train/loss_step=0.690]Epoch 0:   5%|â–Œ         | 38/735 [00:53<16:27,  0.71it/s, v_num=lst8, train/loss_step=0.690]Epoch 0:   5%|â–Œ         | 38/735 [00:53<16:27,  0.71it/s, v_num=lst8, train/loss_step=0.696]Epoch 0:   5%|â–Œ         | 39/735 [00:54<16:18,  0.71it/s, v_num=lst8, train/loss_step=0.696]Epoch 0:   5%|â–Œ         | 39/735 [00:54<16:18,  0.71it/s, v_num=lst8, train/loss_step=0.682]Epoch 0:   5%|â–Œ         | 40/735 [00:55<16:10,  0.72it/s, v_num=lst8, train/loss_step=0.682]Epoch 0:   5%|â–Œ         | 40/735 [00:55<16:10,  0.72it/s, v_num=lst8, train/loss_step=0.675]Epoch 0:   6%|â–Œ         | 41/735 [00:56<16:03,  0.72it/s, v_num=lst8, train/loss_step=0.675]Epoch 0:   6%|â–Œ         | 41/735 [00:56<16:03,  0.72it/s, v_num=lst8, train/loss_step=0.677]Epoch 0:   6%|â–Œ         | 42/735 [00:57<15:56,  0.72it/s, v_num=lst8, train/loss_step=0.677]Epoch 0:   6%|â–Œ         | 42/735 [00:57<15:56,  0.72it/s, v_num=lst8, train/loss_step=0.677]Epoch 0:   6%|â–Œ         | 43/735 [00:58<15:49,  0.73it/s, v_num=lst8, train/loss_step=0.677]Epoch 0:   6%|â–Œ         | 43/735 [00:58<15:49,  0.73it/s, v_num=lst8, train/loss_step=0.679]Epoch 0:   6%|â–Œ         | 44/735 [01:00<15:42,  0.73it/s, v_num=lst8, train/loss_step=0.679]Epoch 0:   6%|â–Œ         | 44/735 [01:00<15:42,  0.73it/s, v_num=lst8, train/loss_step=0.715]Epoch 0:   6%|â–Œ         | 45/735 [01:01<15:36,  0.74it/s, v_num=lst8, train/loss_step=0.715]Epoch 0:   6%|â–Œ         | 45/735 [01:01<15:36,  0.74it/s, v_num=lst8, train/loss_step=0.653]Epoch 0:   6%|â–‹         | 46/735 [01:02<15:30,  0.74it/s, v_num=lst8, train/loss_step=0.653]Epoch 0:   6%|â–‹         | 46/735 [01:02<15:30,  0.74it/s, v_num=lst8, train/loss_step=0.669]Epoch 0:   6%|â–‹         | 47/735 [01:03<15:24,  0.74it/s, v_num=lst8, train/loss_step=0.669]Epoch 0:   6%|â–‹         | 47/735 [01:03<15:24,  0.74it/s, v_num=lst8, train/loss_step=0.642]Epoch 0:   7%|â–‹         | 48/735 [01:04<15:19,  0.75it/s, v_num=lst8, train/loss_step=0.642]Epoch 0:   7%|â–‹         | 48/735 [01:04<15:19,  0.75it/s, v_num=lst8, train/loss_step=0.647]Epoch 0:   7%|â–‹         | 49/735 [01:05<15:13,  0.75it/s, v_num=lst8, train/loss_step=0.647]Epoch 0:   7%|â–‹         | 49/735 [01:05<15:13,  0.75it/s, v_num=lst8, train/loss_step=0.637]Epoch 0:   7%|â–‹         | 50/735 [01:06<15:08,  0.75it/s, v_num=lst8, train/loss_step=0.637]Epoch 0:   7%|â–‹         | 50/735 [01:06<15:08,  0.75it/s, v_num=lst8, train/loss_step=0.642]Epoch 0:   7%|â–‹         | 51/735 [01:07<15:03,  0.76it/s, v_num=lst8, train/loss_step=0.642]Epoch 0:   7%|â–‹         | 51/735 [01:07<15:03,  0.76it/s, v_num=lst8, train/loss_step=0.621]Epoch 0:   7%|â–‹         | 52/735 [01:08<14:58,  0.76it/s, v_num=lst8, train/loss_step=0.621]Epoch 0:   7%|â–‹         | 52/735 [01:08<14:58,  0.76it/s, v_num=lst8, train/loss_step=0.639]Epoch 0:   7%|â–‹         | 53/735 [01:09<14:53,  0.76it/s, v_num=lst8, train/loss_step=0.639]Epoch 0:   7%|â–‹         | 53/735 [01:09<14:53,  0.76it/s, v_num=lst8, train/loss_step=0.648]Epoch 0:   7%|â–‹         | 54/735 [01:10<14:49,  0.77it/s, v_num=lst8, train/loss_step=0.648]Epoch 0:   7%|â–‹         | 54/735 [01:10<14:49,  0.77it/s, v_num=lst8, train/loss_step=0.630]Epoch 0:   7%|â–‹         | 55/735 [01:11<14:44,  0.77it/s, v_num=lst8, train/loss_step=0.630]Epoch 0:   7%|â–‹         | 55/735 [01:11<14:44,  0.77it/s, v_num=lst8, train/loss_step=0.622]Epoch 0:   8%|â–Š         | 56/735 [01:12<14:40,  0.77it/s, v_num=lst8, train/loss_step=0.622]Epoch 0:   8%|â–Š         | 56/735 [01:12<14:40,  0.77it/s, v_num=lst8, train/loss_step=0.595]Epoch 0:   8%|â–Š         | 57/735 [01:13<14:36,  0.77it/s, v_num=lst8, train/loss_step=0.595]Epoch 0:   8%|â–Š         | 57/735 [01:13<14:36,  0.77it/s, v_num=lst8, train/loss_step=0.598]Epoch 0:   8%|â–Š         | 58/735 [01:14<14:31,  0.78it/s, v_num=lst8, train/loss_step=0.598]Epoch 0:   8%|â–Š         | 58/735 [01:14<14:31,  0.78it/s, v_num=lst8, train/loss_step=0.616]Epoch 0:   8%|â–Š         | 59/735 [01:15<14:27,  0.78it/s, v_num=lst8, train/loss_step=0.616]Epoch 0:   8%|â–Š         | 59/735 [01:15<14:27,  0.78it/s, v_num=lst8, train/loss_step=0.591]Epoch 0:   8%|â–Š         | 60/735 [01:16<14:23,  0.78it/s, v_num=lst8, train/loss_step=0.591]Epoch 0:   8%|â–Š         | 60/735 [01:16<14:23,  0.78it/s, v_num=lst8, train/loss_step=0.585]Epoch 0:   8%|â–Š         | 61/735 [01:17<14:20,  0.78it/s, v_num=lst8, train/loss_step=0.585]Epoch 0:   8%|â–Š         | 61/735 [01:17<14:20,  0.78it/s, v_num=lst8, train/loss_step=0.584]Epoch 0:   8%|â–Š         | 62/735 [01:18<14:16,  0.79it/s, v_num=lst8, train/loss_step=0.584]Epoch 0:   8%|â–Š         | 62/735 [01:18<14:16,  0.79it/s, v_num=lst8, train/loss_step=0.599]Epoch 0:   9%|â–Š         | 63/735 [01:19<14:12,  0.79it/s, v_num=lst8, train/loss_step=0.599]Epoch 0:   9%|â–Š         | 63/735 [01:19<14:12,  0.79it/s, v_num=lst8, train/loss_step=0.573]Epoch 0:   9%|â–Š         | 64/735 [01:20<14:09,  0.79it/s, v_num=lst8, train/loss_step=0.573]Epoch 0:   9%|â–Š         | 64/735 [01:20<14:09,  0.79it/s, v_num=lst8, train/loss_step=0.568]Epoch 0:   9%|â–‰         | 65/735 [01:22<14:05,  0.79it/s, v_num=lst8, train/loss_step=0.568]Epoch 0:   9%|â–‰         | 65/735 [01:22<14:05,  0.79it/s, v_num=lst8, train/loss_step=0.550]Epoch 0:   9%|â–‰         | 66/735 [01:23<14:02,  0.79it/s, v_num=lst8, train/loss_step=0.550]Epoch 0:   9%|â–‰         | 66/735 [01:23<14:02,  0.79it/s, v_num=lst8, train/loss_step=0.570]Epoch 0:   9%|â–‰         | 67/735 [01:24<13:58,  0.80it/s, v_num=lst8, train/loss_step=0.570]Epoch 0:   9%|â–‰         | 67/735 [01:24<13:58,  0.80it/s, v_num=lst8, train/loss_step=0.562]Epoch 0:   9%|â–‰         | 68/735 [01:25<13:55,  0.80it/s, v_num=lst8, train/loss_step=0.562]Epoch 0:   9%|â–‰         | 68/735 [01:25<13:55,  0.80it/s, v_num=lst8, train/loss_step=0.557]Epoch 0:   9%|â–‰         | 69/735 [01:26<13:52,  0.80it/s, v_num=lst8, train/loss_step=0.557]Epoch 0:   9%|â–‰         | 69/735 [01:26<13:52,  0.80it/s, v_num=lst8, train/loss_step=0.541]Epoch 0:  10%|â–‰         | 70/735 [01:27<13:49,  0.80it/s, v_num=lst8, train/loss_step=0.541]Epoch 0:  10%|â–‰         | 70/735 [01:27<13:49,  0.80it/s, v_num=lst8, train/loss_step=0.548]Epoch 0:  10%|â–‰         | 71/735 [01:28<13:46,  0.80it/s, v_num=lst8, train/loss_step=0.548]Epoch 0:  10%|â–‰         | 71/735 [01:28<13:46,  0.80it/s, v_num=lst8, train/loss_step=0.536]Epoch 0:  10%|â–‰         | 72/735 [01:29<13:43,  0.81it/s, v_num=lst8, train/loss_step=0.536]Epoch 0:  10%|â–‰         | 72/735 [01:29<13:43,  0.81it/s, v_num=lst8, train/loss_step=0.542]Epoch 0:  10%|â–‰         | 73/735 [01:30<13:40,  0.81it/s, v_num=lst8, train/loss_step=0.542]Epoch 0:  10%|â–‰         | 73/735 [01:30<13:40,  0.81it/s, v_num=lst8, train/loss_step=0.513]Epoch 0:  10%|â–ˆ         | 74/735 [01:31<13:37,  0.81it/s, v_num=lst8, train/loss_step=0.513]Epoch 0:  10%|â–ˆ         | 74/735 [01:31<13:37,  0.81it/s, v_num=lst8, train/loss_step=0.523]Epoch 0:  10%|â–ˆ         | 75/735 [01:32<13:34,  0.81it/s, v_num=lst8, train/loss_step=0.523]Epoch 0:  10%|â–ˆ         | 75/735 [01:32<13:34,  0.81it/s, v_num=lst8, train/loss_step=0.503]Epoch 0:  10%|â–ˆ         | 76/735 [01:33<13:31,  0.81it/s, v_num=lst8, train/loss_step=0.503]Epoch 0:  10%|â–ˆ         | 76/735 [01:33<13:31,  0.81it/s, v_num=lst8, train/loss_step=0.502]Epoch 0:  10%|â–ˆ         | 77/735 [01:34<13:28,  0.81it/s, v_num=lst8, train/loss_step=0.502]Epoch 0:  10%|â–ˆ         | 77/735 [01:34<13:28,  0.81it/s, v_num=lst8, train/loss_step=0.504]Epoch 0:  11%|â–ˆ         | 78/735 [01:35<13:26,  0.81it/s, v_num=lst8, train/loss_step=0.504]Epoch 0:  11%|â–ˆ         | 78/735 [01:35<13:26,  0.81it/s, v_num=lst8, train/loss_step=0.509]Epoch 0:  11%|â–ˆ         | 79/735 [01:36<13:23,  0.82it/s, v_num=lst8, train/loss_step=0.509]Epoch 0:  11%|â–ˆ         | 79/735 [01:36<13:23,  0.82it/s, v_num=lst8, train/loss_step=0.505]Epoch 0:  11%|â–ˆ         | 80/735 [01:37<13:20,  0.82it/s, v_num=lst8, train/loss_step=0.505]Epoch 0:  11%|â–ˆ         | 80/735 [01:37<13:20,  0.82it/s, v_num=lst8, train/loss_step=0.499]Epoch 0:  11%|â–ˆ         | 81/735 [01:38<13:18,  0.82it/s, v_num=lst8, train/loss_step=0.499]Epoch 0:  11%|â–ˆ         | 81/735 [01:38<13:18,  0.82it/s, v_num=lst8, train/loss_step=0.485]Epoch 0:  11%|â–ˆ         | 82/735 [01:39<13:15,  0.82it/s, v_num=lst8, train/loss_step=0.485]Epoch 0:  11%|â–ˆ         | 82/735 [01:39<13:15,  0.82it/s, v_num=lst8, train/loss_step=0.486]Epoch 0:  11%|â–ˆâ–        | 83/735 [01:40<13:13,  0.82it/s, v_num=lst8, train/loss_step=0.486]Epoch 0:  11%|â–ˆâ–        | 83/735 [01:40<13:13,  0.82it/s, v_num=lst8, train/loss_step=0.484]Epoch 0:  11%|â–ˆâ–        | 84/735 [01:42<13:10,  0.82it/s, v_num=lst8, train/loss_step=0.484]Epoch 0:  11%|â–ˆâ–        | 84/735 [01:42<13:10,  0.82it/s, v_num=lst8, train/loss_step=0.479]Epoch 0:  12%|â–ˆâ–        | 85/735 [01:43<13:08,  0.82it/s, v_num=lst8, train/loss_step=0.479]Epoch 0:  12%|â–ˆâ–        | 85/735 [01:43<13:08,  0.82it/s, v_num=lst8, train/loss_step=0.483]Epoch 0:  12%|â–ˆâ–        | 86/735 [01:44<13:05,  0.83it/s, v_num=lst8, train/loss_step=0.483]Epoch 0:  12%|â–ˆâ–        | 86/735 [01:44<13:05,  0.83it/s, v_num=lst8, train/loss_step=0.483]Epoch 0:  12%|â–ˆâ–        | 87/735 [01:45<13:03,  0.83it/s, v_num=lst8, train/loss_step=0.483]Epoch 0:  12%|â–ˆâ–        | 87/735 [01:45<13:03,  0.83it/s, v_num=lst8, train/loss_step=0.486]Epoch 0:  12%|â–ˆâ–        | 88/735 [01:46<13:00,  0.83it/s, v_num=lst8, train/loss_step=0.486]Epoch 0:  12%|â–ˆâ–        | 88/735 [01:46<13:00,  0.83it/s, v_num=lst8, train/loss_step=0.459]Epoch 0:  12%|â–ˆâ–        | 89/735 [01:47<12:58,  0.83it/s, v_num=lst8, train/loss_step=0.459]Epoch 0:  12%|â–ˆâ–        | 89/735 [01:47<12:58,  0.83it/s, v_num=lst8, train/loss_step=0.515]Epoch 0:  12%|â–ˆâ–        | 90/735 [01:48<12:55,  0.83it/s, v_num=lst8, train/loss_step=0.515]Epoch 0:  12%|â–ˆâ–        | 90/735 [01:48<12:55,  0.83it/s, v_num=lst8, train/loss_step=0.468]Epoch 0:  12%|â–ˆâ–        | 91/735 [01:49<12:53,  0.83it/s, v_num=lst8, train/loss_step=0.468]Epoch 0:  12%|â–ˆâ–        | 91/735 [01:49<12:53,  0.83it/s, v_num=lst8, train/loss_step=0.450]Epoch 0:  13%|â–ˆâ–        | 92/735 [01:50<12:51,  0.83it/s, v_num=lst8, train/loss_step=0.450]Epoch 0:  13%|â–ˆâ–        | 92/735 [01:50<12:51,  0.83it/s, v_num=lst8, train/loss_step=0.440]Epoch 0:  13%|â–ˆâ–        | 93/735 [01:51<12:48,  0.84it/s, v_num=lst8, train/loss_step=0.440]Epoch 0:  13%|â–ˆâ–        | 93/735 [01:51<12:48,  0.84it/s, v_num=lst8, train/loss_step=0.451]Epoch 0:  13%|â–ˆâ–        | 94/735 [01:52<12:46,  0.84it/s, v_num=lst8, train/loss_step=0.451]Epoch 0:  13%|â–ˆâ–        | 94/735 [01:52<12:46,  0.84it/s, v_num=lst8, train/loss_step=0.443]Epoch 0:  13%|â–ˆâ–        | 95/735 [01:53<12:43,  0.84it/s, v_num=lst8, train/loss_step=0.443]Epoch 0:  13%|â–ˆâ–        | 95/735 [01:53<12:43,  0.84it/s, v_num=lst8, train/loss_step=0.437]Epoch 0:  13%|â–ˆâ–        | 96/735 [01:54<12:41,  0.84it/s, v_num=lst8, train/loss_step=0.437]Epoch 0:  13%|â–ˆâ–        | 96/735 [01:54<12:41,  0.84it/s, v_num=lst8, train/loss_step=0.437]Epoch 0:  13%|â–ˆâ–        | 97/735 [01:55<12:39,  0.84it/s, v_num=lst8, train/loss_step=0.437]Epoch 0:  13%|â–ˆâ–        | 97/735 [01:55<12:39,  0.84it/s, v_num=lst8, train/loss_step=0.428]Epoch 0:  13%|â–ˆâ–        | 98/735 [01:56<12:37,  0.84it/s, v_num=lst8, train/loss_step=0.428]Epoch 0:  13%|â–ˆâ–        | 98/735 [01:56<12:37,  0.84it/s, v_num=lst8, train/loss_step=0.414]Epoch 0:  13%|â–ˆâ–        | 99/735 [01:57<12:34,  0.84it/s, v_num=lst8, train/loss_step=0.414]Epoch 0:  13%|â–ˆâ–        | 99/735 [01:57<12:34,  0.84it/s, v_num=lst8, train/loss_step=0.423]Epoch 0:  14%|â–ˆâ–        | 100/735 [01:58<12:32,  0.84it/s, v_num=lst8, train/loss_step=0.423]Epoch 0:  14%|â–ˆâ–        | 100/735 [01:58<12:32,  0.84it/s, v_num=lst8, train/loss_step=0.419]Epoch 0:  14%|â–ˆâ–        | 101/735 [01:59<12:30,  0.84it/s, v_num=lst8, train/loss_step=0.419]Epoch 0:  14%|â–ˆâ–        | 101/735 [01:59<12:30,  0.84it/s, v_num=lst8, train/loss_step=0.415]Epoch 0:  14%|â–ˆâ–        | 102/735 [02:00<12:28,  0.85it/s, v_num=lst8, train/loss_step=0.415]Epoch 0:  14%|â–ˆâ–        | 102/735 [02:00<12:28,  0.85it/s, v_num=lst8, train/loss_step=0.409]Epoch 0:  14%|â–ˆâ–        | 103/735 [02:01<12:26,  0.85it/s, v_num=lst8, train/loss_step=0.409]Epoch 0:  14%|â–ˆâ–        | 103/735 [02:01<12:26,  0.85it/s, v_num=lst8, train/loss_step=0.398]Epoch 0:  14%|â–ˆâ–        | 104/735 [02:02<12:23,  0.85it/s, v_num=lst8, train/loss_step=0.398]Epoch 0:  14%|â–ˆâ–        | 104/735 [02:02<12:23,  0.85it/s, v_num=lst8, train/loss_step=0.386]Epoch 0:  14%|â–ˆâ–        | 105/735 [02:03<12:21,  0.85it/s, v_num=lst8, train/loss_step=0.386]Epoch 0:  14%|â–ˆâ–        | 105/735 [02:03<12:21,  0.85it/s, v_num=lst8, train/loss_step=0.388]Epoch 0:  14%|â–ˆâ–        | 106/735 [02:04<12:19,  0.85it/s, v_num=lst8, train/loss_step=0.388]Epoch 0:  14%|â–ˆâ–        | 106/735 [02:04<12:19,  0.85it/s, v_num=lst8, train/loss_step=0.387]Epoch 0:  15%|â–ˆâ–        | 107/735 [02:05<12:17,  0.85it/s, v_num=lst8, train/loss_step=0.387]Epoch 0:  15%|â–ˆâ–        | 107/735 [02:05<12:17,  0.85it/s, v_num=lst8, train/loss_step=0.385]Epoch 0:  15%|â–ˆâ–        | 108/735 [02:06<12:15,  0.85it/s, v_num=lst8, train/loss_step=0.385]Epoch 0:  15%|â–ˆâ–        | 108/735 [02:06<12:15,  0.85it/s, v_num=lst8, train/loss_step=0.368]Epoch 0:  15%|â–ˆâ–        | 109/735 [02:07<12:13,  0.85it/s, v_num=lst8, train/loss_step=0.368]Epoch 0:  15%|â–ˆâ–        | 109/735 [02:07<12:13,  0.85it/s, v_num=lst8, train/loss_step=0.374]Epoch 0:  15%|â–ˆâ–        | 110/735 [02:08<12:11,  0.85it/s, v_num=lst8, train/loss_step=0.374]Epoch 0:  15%|â–ˆâ–        | 110/735 [02:08<12:11,  0.85it/s, v_num=lst8, train/loss_step=0.373]Epoch 0:  15%|â–ˆâ–Œ        | 111/735 [02:09<12:09,  0.86it/s, v_num=lst8, train/loss_step=0.373]Epoch 0:  15%|â–ˆâ–Œ        | 111/735 [02:09<12:09,  0.86it/s, v_num=lst8, train/loss_step=0.357]Epoch 0:  15%|â–ˆâ–Œ        | 112/735 [02:10<12:07,  0.86it/s, v_num=lst8, train/loss_step=0.357]Epoch 0:  15%|â–ˆâ–Œ        | 112/735 [02:10<12:07,  0.86it/s, v_num=lst8, train/loss_step=0.349]Epoch 0:  15%|â–ˆâ–Œ        | 113/735 [02:11<12:05,  0.86it/s, v_num=lst8, train/loss_step=0.349]Epoch 0:  15%|â–ˆâ–Œ        | 113/735 [02:11<12:05,  0.86it/s, v_num=lst8, train/loss_step=0.354]Epoch 0:  16%|â–ˆâ–Œ        | 114/735 [02:12<12:04,  0.86it/s, v_num=lst8, train/loss_step=0.354]Epoch 0:  16%|â–ˆâ–Œ        | 114/735 [02:12<12:04,  0.86it/s, v_num=lst8, train/loss_step=0.338]Epoch 0:  16%|â–ˆâ–Œ        | 115/735 [02:13<12:02,  0.86it/s, v_num=lst8, train/loss_step=0.338]Epoch 0:  16%|â–ˆâ–Œ        | 115/735 [02:13<12:02,  0.86it/s, v_num=lst8, train/loss_step=0.342]Epoch 0:  16%|â–ˆâ–Œ        | 116/735 [02:15<12:00,  0.86it/s, v_num=lst8, train/loss_step=0.342]Epoch 0:  16%|â–ˆâ–Œ        | 116/735 [02:15<12:00,  0.86it/s, v_num=lst8, train/loss_step=0.334]Epoch 0:  16%|â–ˆâ–Œ        | 117/735 [02:16<11:58,  0.86it/s, v_num=lst8, train/loss_step=0.334]Epoch 0:  16%|â–ˆâ–Œ        | 117/735 [02:16<11:58,  0.86it/s, v_num=lst8, train/loss_step=0.329]Epoch 0:  16%|â–ˆâ–Œ        | 118/735 [02:17<11:57,  0.86it/s, v_num=lst8, train/loss_step=0.329]Epoch 0:  16%|â–ˆâ–Œ        | 118/735 [02:17<11:57,  0.86it/s, v_num=lst8, train/loss_step=0.325]Epoch 0:  16%|â–ˆâ–Œ        | 119/735 [02:18<11:55,  0.86it/s, v_num=lst8, train/loss_step=0.325]Epoch 0:  16%|â–ˆâ–Œ        | 119/735 [02:18<11:55,  0.86it/s, v_num=lst8, train/loss_step=0.325]Epoch 0:  16%|â–ˆâ–‹        | 120/735 [02:19<11:53,  0.86it/s, v_num=lst8, train/loss_step=0.325]Epoch 0:  16%|â–ˆâ–‹        | 120/735 [02:19<11:53,  0.86it/s, v_num=lst8, train/loss_step=0.307]Epoch 0:  16%|â–ˆâ–‹        | 121/735 [02:20<11:51,  0.86it/s, v_num=lst8, train/loss_step=0.307]Epoch 0:  16%|â–ˆâ–‹        | 121/735 [02:20<11:51,  0.86it/s, v_num=lst8, train/loss_step=0.309]Epoch 0:  17%|â–ˆâ–‹        | 122/735 [02:21<11:50,  0.86it/s, v_num=lst8, train/loss_step=0.309]Epoch 0:  17%|â–ˆâ–‹        | 122/735 [02:21<11:50,  0.86it/s, v_num=lst8, train/loss_step=0.299]Epoch 0:  17%|â–ˆâ–‹        | 123/735 [02:22<11:48,  0.86it/s, v_num=lst8, train/loss_step=0.299]Epoch 0:  17%|â–ˆâ–‹        | 123/735 [02:22<11:48,  0.86it/s, v_num=lst8, train/loss_step=0.298]Epoch 0:  17%|â–ˆâ–‹        | 124/735 [02:23<11:46,  0.86it/s, v_num=lst8, train/loss_step=0.298]Epoch 0:  17%|â–ˆâ–‹        | 124/735 [02:23<11:46,  0.86it/s, v_num=lst8, train/loss_step=0.305]Epoch 0:  17%|â–ˆâ–‹        | 125/735 [02:24<11:44,  0.87it/s, v_num=lst8, train/loss_step=0.305]Epoch 0:  17%|â–ˆâ–‹        | 125/735 [02:24<11:44,  0.87it/s, v_num=lst8, train/loss_step=0.288]Epoch 0:  17%|â–ˆâ–‹        | 126/735 [02:25<11:43,  0.87it/s, v_num=lst8, train/loss_step=0.288]Epoch 0:  17%|â–ˆâ–‹        | 126/735 [02:25<11:43,  0.87it/s, v_num=lst8, train/loss_step=0.282]Epoch 0:  17%|â–ˆâ–‹        | 127/735 [02:26<11:41,  0.87it/s, v_num=lst8, train/loss_step=0.282]Epoch 0:  17%|â–ˆâ–‹        | 127/735 [02:26<11:41,  0.87it/s, v_num=lst8, train/loss_step=0.276]Epoch 0:  17%|â–ˆâ–‹        | 128/735 [02:27<11:39,  0.87it/s, v_num=lst8, train/loss_step=0.276]Epoch 0:  17%|â–ˆâ–‹        | 128/735 [02:27<11:39,  0.87it/s, v_num=lst8, train/loss_step=0.272]Epoch 0:  18%|â–ˆâ–Š        | 129/735 [02:28<11:38,  0.87it/s, v_num=lst8, train/loss_step=0.272]Epoch 0:  18%|â–ˆâ–Š        | 129/735 [02:28<11:38,  0.87it/s, v_num=lst8, train/loss_step=0.287]Epoch 0:  18%|â–ˆâ–Š        | 130/735 [02:29<11:36,  0.87it/s, v_num=lst8, train/loss_step=0.287]Epoch 0:  18%|â–ˆâ–Š        | 130/735 [02:29<11:36,  0.87it/s, v_num=lst8, train/loss_step=0.262]Epoch 0:  18%|â–ˆâ–Š        | 131/735 [02:30<11:35,  0.87it/s, v_num=lst8, train/loss_step=0.262]Epoch 0:  18%|â–ˆâ–Š        | 131/735 [02:30<11:35,  0.87it/s, v_num=lst8, train/loss_step=0.269]Epoch 0:  18%|â–ˆâ–Š        | 132/735 [02:31<11:33,  0.87it/s, v_num=lst8, train/loss_step=0.269]Epoch 0:  18%|â–ˆâ–Š        | 132/735 [02:31<11:33,  0.87it/s, v_num=lst8, train/loss_step=0.261]Epoch 0:  18%|â–ˆâ–Š        | 133/735 [02:32<11:31,  0.87it/s, v_num=lst8, train/loss_step=0.261]Epoch 0:  18%|â–ˆâ–Š        | 133/735 [02:32<11:31,  0.87it/s, v_num=lst8, train/loss_step=0.264]Epoch 0:  18%|â–ˆâ–Š        | 134/735 [02:33<11:30,  0.87it/s, v_num=lst8, train/loss_step=0.264]Epoch 0:  18%|â–ˆâ–Š        | 134/735 [02:33<11:30,  0.87it/s, v_num=lst8, train/loss_step=0.249]Epoch 0:  18%|â–ˆâ–Š        | 135/735 [02:34<11:28,  0.87it/s, v_num=lst8, train/loss_step=0.249]Epoch 0:  18%|â–ˆâ–Š        | 135/735 [02:34<11:28,  0.87it/s, v_num=lst8, train/loss_step=0.247]Epoch 0:  19%|â–ˆâ–Š        | 136/735 [02:36<11:27,  0.87it/s, v_num=lst8, train/loss_step=0.247]Epoch 0:  19%|â–ˆâ–Š        | 136/735 [02:36<11:27,  0.87it/s, v_num=lst8, train/loss_step=0.241]Epoch 0:  19%|â–ˆâ–Š        | 137/735 [02:37<11:25,  0.87it/s, v_num=lst8, train/loss_step=0.241]Epoch 0:  19%|â–ˆâ–Š        | 137/735 [02:37<11:25,  0.87it/s, v_num=lst8, train/loss_step=0.247]Epoch 0:  19%|â–ˆâ–‰        | 138/735 [02:38<11:23,  0.87it/s, v_num=lst8, train/loss_step=0.247]Epoch 0:  19%|â–ˆâ–‰        | 138/735 [02:38<11:23,  0.87it/s, v_num=lst8, train/loss_step=0.240]Epoch 0:  19%|â–ˆâ–‰        | 139/735 [02:39<11:22,  0.87it/s, v_num=lst8, train/loss_step=0.240]Epoch 0:  19%|â–ˆâ–‰        | 139/735 [02:39<11:22,  0.87it/s, v_num=lst8, train/loss_step=0.233]Epoch 0:  19%|â–ˆâ–‰        | 140/735 [02:40<11:20,  0.87it/s, v_num=lst8, train/loss_step=0.233]Epoch 0:  19%|â–ˆâ–‰        | 140/735 [02:40<11:20,  0.87it/s, v_num=lst8, train/loss_step=0.238]Epoch 0:  19%|â–ˆâ–‰        | 141/735 [02:41<11:19,  0.87it/s, v_num=lst8, train/loss_step=0.238]Epoch 0:  19%|â–ˆâ–‰        | 141/735 [02:41<11:19,  0.87it/s, v_num=lst8, train/loss_step=0.216]Epoch 0:  19%|â–ˆâ–‰        | 142/735 [02:42<11:17,  0.88it/s, v_num=lst8, train/loss_step=0.216]Epoch 0:  19%|â–ˆâ–‰        | 142/735 [02:42<11:17,  0.88it/s, v_num=lst8, train/loss_step=0.224]Epoch 0:  19%|â–ˆâ–‰        | 143/735 [02:43<11:16,  0.88it/s, v_num=lst8, train/loss_step=0.224]Epoch 0:  19%|â–ˆâ–‰        | 143/735 [02:43<11:16,  0.88it/s, v_num=lst8, train/loss_step=0.213]Epoch 0:  20%|â–ˆâ–‰        | 144/735 [02:44<11:14,  0.88it/s, v_num=lst8, train/loss_step=0.213]Epoch 0:  20%|â–ˆâ–‰        | 144/735 [02:44<11:14,  0.88it/s, v_num=lst8, train/loss_step=0.253]Epoch 0:  20%|â–ˆâ–‰        | 145/735 [02:45<11:13,  0.88it/s, v_num=lst8, train/loss_step=0.253]Epoch 0:  20%|â–ˆâ–‰        | 145/735 [02:45<11:13,  0.88it/s, v_num=lst8, train/loss_step=0.213]Epoch 0:  20%|â–ˆâ–‰        | 146/735 [02:46<11:11,  0.88it/s, v_num=lst8, train/loss_step=0.213]Epoch 0:  20%|â–ˆâ–‰        | 146/735 [02:46<11:11,  0.88it/s, v_num=lst8, train/loss_step=0.229]Epoch 0:  20%|â–ˆâ–ˆ        | 147/735 [02:47<11:10,  0.88it/s, v_num=lst8, train/loss_step=0.229]Epoch 0:  20%|â–ˆâ–ˆ        | 147/735 [02:47<11:10,  0.88it/s, v_num=lst8, train/loss_step=0.211]Epoch 0:  20%|â–ˆâ–ˆ        | 148/735 [02:48<11:08,  0.88it/s, v_num=lst8, train/loss_step=0.211]Epoch 0:  20%|â–ˆâ–ˆ        | 148/735 [02:48<11:08,  0.88it/s, v_num=lst8, train/loss_step=0.217]Epoch 0:  20%|â–ˆâ–ˆ        | 149/735 [02:49<11:07,  0.88it/s, v_num=lst8, train/loss_step=0.217]Epoch 0:  20%|â–ˆâ–ˆ        | 149/735 [02:49<11:07,  0.88it/s, v_num=lst8, train/loss_step=0.198]Epoch 0:  20%|â–ˆâ–ˆ        | 150/735 [02:50<11:05,  0.88it/s, v_num=lst8, train/loss_step=0.198]Epoch 0:  20%|â–ˆâ–ˆ        | 150/735 [02:50<11:05,  0.88it/s, v_num=lst8, train/loss_step=0.186]Epoch 0:  21%|â–ˆâ–ˆ        | 151/735 [02:51<11:04,  0.88it/s, v_num=lst8, train/loss_step=0.186]Epoch 0:  21%|â–ˆâ–ˆ        | 151/735 [02:51<11:04,  0.88it/s, v_num=lst8, train/loss_step=0.184]Epoch 0:  21%|â–ˆâ–ˆ        | 152/735 [02:52<11:02,  0.88it/s, v_num=lst8, train/loss_step=0.184]Epoch 0:  21%|â–ˆâ–ˆ        | 152/735 [02:52<11:02,  0.88it/s, v_num=lst8, train/loss_step=0.179]Epoch 0:  21%|â–ˆâ–ˆ        | 153/735 [02:53<11:01,  0.88it/s, v_num=lst8, train/loss_step=0.179]Epoch 0:  21%|â–ˆâ–ˆ        | 153/735 [02:53<11:01,  0.88it/s, v_num=lst8, train/loss_step=0.190]Epoch 0:  21%|â–ˆâ–ˆ        | 154/735 [02:54<10:59,  0.88it/s, v_num=lst8, train/loss_step=0.190]Epoch 0:  21%|â–ˆâ–ˆ        | 154/735 [02:54<10:59,  0.88it/s, v_num=lst8, train/loss_step=0.181]Epoch 0:  21%|â–ˆâ–ˆ        | 155/735 [02:55<10:58,  0.88it/s, v_num=lst8, train/loss_step=0.181]Epoch 0:  21%|â–ˆâ–ˆ        | 155/735 [02:55<10:58,  0.88it/s, v_num=lst8, train/loss_step=0.165]Epoch 0:  21%|â–ˆâ–ˆ        | 156/735 [02:56<10:56,  0.88it/s, v_num=lst8, train/loss_step=0.165]Epoch 0:  21%|â–ˆâ–ˆ        | 156/735 [02:56<10:56,  0.88it/s, v_num=lst8, train/loss_step=0.169]Epoch 0:  21%|â–ˆâ–ˆâ–       | 157/735 [02:58<10:55,  0.88it/s, v_num=lst8, train/loss_step=0.169]Epoch 0:  21%|â–ˆâ–ˆâ–       | 157/735 [02:58<10:55,  0.88it/s, v_num=lst8, train/loss_step=0.160]Epoch 0:  21%|â–ˆâ–ˆâ–       | 158/735 [02:59<10:53,  0.88it/s, v_num=lst8, train/loss_step=0.160]Epoch 0:  21%|â–ˆâ–ˆâ–       | 158/735 [02:59<10:53,  0.88it/s, v_num=lst8, train/loss_step=0.165]Epoch 0:  22%|â–ˆâ–ˆâ–       | 159/735 [03:00<10:52,  0.88it/s, v_num=lst8, train/loss_step=0.165]Epoch 0:  22%|â–ˆâ–ˆâ–       | 159/735 [03:00<10:52,  0.88it/s, v_num=lst8, train/loss_step=0.156]Epoch 0:  22%|â–ˆâ–ˆâ–       | 160/735 [03:01<10:51,  0.88it/s, v_num=lst8, train/loss_step=0.156]Epoch 0:  22%|â–ˆâ–ˆâ–       | 160/735 [03:01<10:51,  0.88it/s, v_num=lst8, train/loss_step=0.145]Epoch 0:  22%|â–ˆâ–ˆâ–       | 161/735 [03:02<10:49,  0.88it/s, v_num=lst8, train/loss_step=0.145]Epoch 0:  22%|â–ˆâ–ˆâ–       | 161/735 [03:02<10:49,  0.88it/s, v_num=lst8, train/loss_step=0.152]Epoch 0:  22%|â–ˆâ–ˆâ–       | 162/735 [03:03<10:48,  0.88it/s, v_num=lst8, train/loss_step=0.152]Epoch 0:  22%|â–ˆâ–ˆâ–       | 162/735 [03:03<10:48,  0.88it/s, v_num=lst8, train/loss_step=0.146]Epoch 0:  22%|â–ˆâ–ˆâ–       | 163/735 [03:04<10:46,  0.88it/s, v_num=lst8, train/loss_step=0.146]Epoch 0:  22%|â–ˆâ–ˆâ–       | 163/735 [03:04<10:46,  0.88it/s, v_num=lst8, train/loss_step=0.133]Epoch 0:  22%|â–ˆâ–ˆâ–       | 164/735 [03:05<10:45,  0.88it/s, v_num=lst8, train/loss_step=0.133]Epoch 0:  22%|â–ˆâ–ˆâ–       | 164/735 [03:05<10:45,  0.88it/s, v_num=lst8, train/loss_step=0.134]Epoch 0:  22%|â–ˆâ–ˆâ–       | 165/735 [03:06<10:44,  0.89it/s, v_num=lst8, train/loss_step=0.134]Epoch 0:  22%|â–ˆâ–ˆâ–       | 165/735 [03:06<10:44,  0.89it/s, v_num=lst8, train/loss_step=0.137]Epoch 0:  23%|â–ˆâ–ˆâ–       | 166/735 [03:07<10:42,  0.89it/s, v_num=lst8, train/loss_step=0.137]Epoch 0:  23%|â–ˆâ–ˆâ–       | 166/735 [03:07<10:42,  0.89it/s, v_num=lst8, train/loss_step=0.139]Epoch 0:  23%|â–ˆâ–ˆâ–       | 167/735 [03:08<10:41,  0.89it/s, v_num=lst8, train/loss_step=0.139]Epoch 0:  23%|â–ˆâ–ˆâ–       | 167/735 [03:08<10:41,  0.89it/s, v_num=lst8, train/loss_step=0.135]Epoch 0:  23%|â–ˆâ–ˆâ–       | 168/735 [03:09<10:39,  0.89it/s, v_num=lst8, train/loss_step=0.135]Epoch 0:  23%|â–ˆâ–ˆâ–       | 168/735 [03:09<10:39,  0.89it/s, v_num=lst8, train/loss_step=0.121]Epoch 0:  23%|â–ˆâ–ˆâ–       | 169/735 [03:10<10:38,  0.89it/s, v_num=lst8, train/loss_step=0.121]Epoch 0:  23%|â–ˆâ–ˆâ–       | 169/735 [03:10<10:38,  0.89it/s, v_num=lst8, train/loss_step=0.117]Epoch 0:  23%|â–ˆâ–ˆâ–       | 170/735 [03:11<10:37,  0.89it/s, v_num=lst8, train/loss_step=0.117]Epoch 0:  23%|â–ˆâ–ˆâ–       | 170/735 [03:11<10:37,  0.89it/s, v_num=lst8, train/loss_step=0.120]Epoch 0:  23%|â–ˆâ–ˆâ–       | 171/735 [03:12<10:35,  0.89it/s, v_num=lst8, train/loss_step=0.120]Epoch 0:  23%|â–ˆâ–ˆâ–       | 171/735 [03:12<10:35,  0.89it/s, v_num=lst8, train/loss_step=0.109]Epoch 0:  23%|â–ˆâ–ˆâ–       | 172/735 [03:13<10:34,  0.89it/s, v_num=lst8, train/loss_step=0.109]Epoch 0:  23%|â–ˆâ–ˆâ–       | 172/735 [03:13<10:34,  0.89it/s, v_num=lst8, train/loss_step=0.106]Epoch 0:  24%|â–ˆâ–ˆâ–       | 173/735 [03:14<10:32,  0.89it/s, v_num=lst8, train/loss_step=0.106]Epoch 0:  24%|â–ˆâ–ˆâ–       | 173/735 [03:14<10:32,  0.89it/s, v_num=lst8, train/loss_step=0.107]Epoch 0:  24%|â–ˆâ–ˆâ–       | 174/735 [03:15<10:31,  0.89it/s, v_num=lst8, train/loss_step=0.107]Epoch 0:  24%|â–ˆâ–ˆâ–       | 174/735 [03:15<10:31,  0.89it/s, v_num=lst8, train/loss_step=0.102]Epoch 0:  24%|â–ˆâ–ˆâ–       | 175/735 [03:16<10:30,  0.89it/s, v_num=lst8, train/loss_step=0.102]Epoch 0:  24%|â–ˆâ–ˆâ–       | 175/735 [03:16<10:30,  0.89it/s, v_num=lst8, train/loss_step=0.0974]Epoch 0:  24%|â–ˆâ–ˆâ–       | 176/735 [03:17<10:28,  0.89it/s, v_num=lst8, train/loss_step=0.0974]Epoch 0:  24%|â–ˆâ–ˆâ–       | 176/735 [03:17<10:28,  0.89it/s, v_num=lst8, train/loss_step=0.099] Epoch 0:  24%|â–ˆâ–ˆâ–       | 177/735 [03:18<10:27,  0.89it/s, v_num=lst8, train/loss_step=0.099]Epoch 0:  24%|â–ˆâ–ˆâ–       | 177/735 [03:18<10:27,  0.89it/s, v_num=lst8, train/loss_step=0.100]Epoch 0:  24%|â–ˆâ–ˆâ–       | 178/735 [03:20<10:25,  0.89it/s, v_num=lst8, train/loss_step=0.100]Epoch 0:  24%|â–ˆâ–ˆâ–       | 178/735 [03:20<10:25,  0.89it/s, v_num=lst8, train/loss_step=0.0889]Epoch 0:  24%|â–ˆâ–ˆâ–       | 179/735 [03:21<10:24,  0.89it/s, v_num=lst8, train/loss_step=0.0889]Epoch 0:  24%|â–ˆâ–ˆâ–       | 179/735 [03:21<10:24,  0.89it/s, v_num=lst8, train/loss_step=0.0886]Epoch 0:  24%|â–ˆâ–ˆâ–       | 180/735 [03:22<10:23,  0.89it/s, v_num=lst8, train/loss_step=0.0886]Epoch 0:  24%|â–ˆâ–ˆâ–       | 180/735 [03:22<10:23,  0.89it/s, v_num=lst8, train/loss_step=0.0904]Epoch 0:  25%|â–ˆâ–ˆâ–       | 181/735 [03:23<10:21,  0.89it/s, v_num=lst8, train/loss_step=0.0904]Epoch 0:  25%|â–ˆâ–ˆâ–       | 181/735 [03:23<10:21,  0.89it/s, v_num=lst8, train/loss_step=0.090] Epoch 0:  25%|â–ˆâ–ˆâ–       | 182/735 [03:24<10:20,  0.89it/s, v_num=lst8, train/loss_step=0.090]Epoch 0:  25%|â–ˆâ–ˆâ–       | 182/735 [03:24<10:20,  0.89it/s, v_num=lst8, train/loss_step=0.0842]Epoch 0:  25%|â–ˆâ–ˆâ–       | 183/735 [03:25<10:19,  0.89it/s, v_num=lst8, train/loss_step=0.0842]Epoch 0:  25%|â–ˆâ–ˆâ–       | 183/735 [03:25<10:19,  0.89it/s, v_num=lst8, train/loss_step=0.0861]Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 184/735 [03:26<10:17,  0.89it/s, v_num=lst8, train/loss_step=0.0861]Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 184/735 [03:26<10:17,  0.89it/s, v_num=lst8, train/loss_step=0.0818]Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 185/735 [03:27<10:16,  0.89it/s, v_num=lst8, train/loss_step=0.0818]Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 185/735 [03:27<10:16,  0.89it/s, v_num=lst8, train/loss_step=0.0792]Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 186/735 [03:28<10:15,  0.89it/s, v_num=lst8, train/loss_step=0.0792]Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 186/735 [03:28<10:15,  0.89it/s, v_num=lst8, train/loss_step=0.0852]Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 187/735 [03:29<10:13,  0.89it/s, v_num=lst8, train/loss_step=0.0852]Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 187/735 [03:29<10:13,  0.89it/s, v_num=lst8, train/loss_step=0.0782]Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 188/735 [03:30<10:12,  0.89it/s, v_num=lst8, train/loss_step=0.0782]Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 188/735 [03:30<10:12,  0.89it/s, v_num=lst8, train/loss_step=0.075] Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 189/735 [03:31<10:11,  0.89it/s, v_num=lst8, train/loss_step=0.075]Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 189/735 [03:31<10:11,  0.89it/s, v_num=lst8, train/loss_step=0.0793]Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 190/735 [03:32<10:09,  0.89it/s, v_num=lst8, train/loss_step=0.0793]Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 190/735 [03:32<10:09,  0.89it/s, v_num=lst8, train/loss_step=0.0731]Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 191/735 [03:33<10:08,  0.89it/s, v_num=lst8, train/loss_step=0.0731]Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 191/735 [03:33<10:08,  0.89it/s, v_num=lst8, train/loss_step=0.0733]Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 192/735 [03:34<10:07,  0.89it/s, v_num=lst8, train/loss_step=0.0733]Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 192/735 [03:34<10:07,  0.89it/s, v_num=lst8, train/loss_step=0.0702]Epoch 0:  26%|â–ˆâ–ˆâ–‹       | 193/735 [03:35<10:05,  0.89it/s, v_num=lst8, train/loss_step=0.0702]Epoch 0:  26%|â–ˆâ–ˆâ–‹       | 193/735 [03:35<10:05,  0.89it/s, v_num=lst8, train/loss_step=0.0696]Epoch 0:  26%|â–ˆâ–ˆâ–‹       | 194/735 [03:36<10:04,  0.89it/s, v_num=lst8, train/loss_step=0.0696]Epoch 0:  26%|â–ˆâ–ˆâ–‹       | 194/735 [03:36<10:04,  0.89it/s, v_num=lst8, train/loss_step=0.0724]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 195/735 [03:37<10:03,  0.90it/s, v_num=lst8, train/loss_step=0.0724]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 195/735 [03:37<10:03,  0.90it/s, v_num=lst8, train/loss_step=0.0681]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 196/735 [03:39<10:02,  0.89it/s, v_num=lst8, train/loss_step=0.0681]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 196/735 [03:39<10:02,  0.89it/s, v_num=lst8, train/loss_step=0.0678]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 197/735 [03:40<10:00,  0.90it/s, v_num=lst8, train/loss_step=0.0678]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 197/735 [03:40<10:00,  0.90it/s, v_num=lst8, train/loss_step=0.0689]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 198/735 [03:41<09:59,  0.90it/s, v_num=lst8, train/loss_step=0.0689]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 198/735 [03:41<09:59,  0.90it/s, v_num=lst8, train/loss_step=0.0694]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 199/735 [03:42<09:58,  0.90it/s, v_num=lst8, train/loss_step=0.0694]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 199/735 [03:42<09:58,  0.90it/s, v_num=lst8, train/loss_step=0.0795]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 200/735 [03:43<09:56,  0.90it/s, v_num=lst8, train/loss_step=0.0795]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 200/735 [03:43<09:56,  0.90it/s, v_num=lst8, train/loss_step=0.0695]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 201/735 [03:44<09:55,  0.90it/s, v_num=lst8, train/loss_step=0.0695]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 201/735 [03:44<09:55,  0.90it/s, v_num=lst8, train/loss_step=0.0655]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 202/735 [03:45<09:54,  0.90it/s, v_num=lst8, train/loss_step=0.0655]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 202/735 [03:45<09:54,  0.90it/s, v_num=lst8, train/loss_step=0.0666]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 203/735 [03:46<09:52,  0.90it/s, v_num=lst8, train/loss_step=0.0666]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 203/735 [03:46<09:52,  0.90it/s, v_num=lst8, train/loss_step=0.062] Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 204/735 [03:47<09:51,  0.90it/s, v_num=lst8, train/loss_step=0.062]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 204/735 [03:47<09:51,  0.90it/s, v_num=lst8, train/loss_step=0.0598]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 205/735 [03:48<09:50,  0.90it/s, v_num=lst8, train/loss_step=0.0598]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 205/735 [03:48<09:50,  0.90it/s, v_num=lst8, train/loss_step=0.0606]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 206/735 [03:49<09:48,  0.90it/s, v_num=lst8, train/loss_step=0.0606]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 206/735 [03:49<09:48,  0.90it/s, v_num=lst8, train/loss_step=0.0639]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 207/735 [03:50<09:47,  0.90it/s, v_num=lst8, train/loss_step=0.0639]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 207/735 [03:50<09:47,  0.90it/s, v_num=lst8, train/loss_step=0.0584]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 208/735 [03:51<09:46,  0.90it/s, v_num=lst8, train/loss_step=0.0584]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 208/735 [03:51<09:46,  0.90it/s, v_num=lst8, train/loss_step=0.063] Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 209/735 [03:52<09:44,  0.90it/s, v_num=lst8, train/loss_step=0.063]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 209/735 [03:52<09:44,  0.90it/s, v_num=lst8, train/loss_step=0.0624]Epoch 0:  29%|â–ˆâ–ˆâ–Š       | 210/735 [03:53<09:43,  0.90it/s, v_num=lst8, train/loss_step=0.0624]Epoch 0:  29%|â–ˆâ–ˆâ–Š       | 210/735 [03:53<09:43,  0.90it/s, v_num=lst8, train/loss_step=0.0589]Epoch 0:  29%|â–ˆâ–ˆâ–Š       | 211/735 [03:54<09:42,  0.90it/s, v_num=lst8, train/loss_step=0.0589]Epoch 0:  29%|â–ˆâ–ˆâ–Š       | 211/735 [03:54<09:42,  0.90it/s, v_num=lst8, train/loss_step=0.0607]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 212/735 [03:55<09:40,  0.90it/s, v_num=lst8, train/loss_step=0.0607]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 212/735 [03:55<09:40,  0.90it/s, v_num=lst8, train/loss_step=0.0592]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 213/735 [03:56<09:39,  0.90it/s, v_num=lst8, train/loss_step=0.0592]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 213/735 [03:56<09:39,  0.90it/s, v_num=lst8, train/loss_step=0.0616]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 214/735 [03:57<09:38,  0.90it/s, v_num=lst8, train/loss_step=0.0616]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 214/735 [03:57<09:38,  0.90it/s, v_num=lst8, train/loss_step=0.064] Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 215/735 [03:58<09:36,  0.90it/s, v_num=lst8, train/loss_step=0.064]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 215/735 [03:58<09:36,  0.90it/s, v_num=lst8, train/loss_step=0.063]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 216/735 [03:59<09:35,  0.90it/s, v_num=lst8, train/loss_step=0.063]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 216/735 [03:59<09:35,  0.90it/s, v_num=lst8, train/loss_step=0.0595]Epoch 0:  30%|â–ˆâ–ˆâ–‰       | 217/735 [04:00<09:34,  0.90it/s, v_num=lst8, train/loss_step=0.0595]Epoch 0:  30%|â–ˆâ–ˆâ–‰       | 217/735 [04:00<09:34,  0.90it/s, v_num=lst8, train/loss_step=0.066] Epoch 0:  30%|â–ˆâ–ˆâ–‰       | 218/735 [04:01<09:33,  0.90it/s, v_num=lst8, train/loss_step=0.066]Epoch 0:  30%|â–ˆâ–ˆâ–‰       | 218/735 [04:01<09:33,  0.90it/s, v_num=lst8, train/loss_step=0.0602]Epoch 0:  30%|â–ˆâ–ˆâ–‰       | 219/735 [04:02<09:31,  0.90it/s, v_num=lst8, train/loss_step=0.0602]Epoch 0:  30%|â–ˆâ–ˆâ–‰       | 219/735 [04:02<09:31,  0.90it/s, v_num=lst8, train/loss_step=0.0618]Epoch 0:  30%|â–ˆâ–ˆâ–‰       | 220/735 [04:03<09:30,  0.90it/s, v_num=lst8, train/loss_step=0.0618]Epoch 0:  30%|â–ˆâ–ˆâ–‰       | 220/735 [04:03<09:30,  0.90it/s, v_num=lst8, train/loss_step=0.0616]Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 221/735 [04:04<09:29,  0.90it/s, v_num=lst8, train/loss_step=0.0616]Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 221/735 [04:04<09:29,  0.90it/s, v_num=lst8, train/loss_step=0.0576]Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 222/735 [04:05<09:27,  0.90it/s, v_num=lst8, train/loss_step=0.0576]Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 222/735 [04:05<09:27,  0.90it/s, v_num=lst8, train/loss_step=0.0631]Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 223/735 [04:06<09:26,  0.90it/s, v_num=lst8, train/loss_step=0.0631]Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 223/735 [04:06<09:26,  0.90it/s, v_num=lst8, train/loss_step=0.0569]Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 224/735 [04:07<09:25,  0.90it/s, v_num=lst8, train/loss_step=0.0569]Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 224/735 [04:07<09:25,  0.90it/s, v_num=lst8, train/loss_step=0.0567]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 225/735 [04:08<09:24,  0.90it/s, v_num=lst8, train/loss_step=0.0567]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 225/735 [04:08<09:24,  0.90it/s, v_num=lst8, train/loss_step=0.0569]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 226/735 [04:09<09:22,  0.90it/s, v_num=lst8, train/loss_step=0.0569]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 226/735 [04:09<09:22,  0.90it/s, v_num=lst8, train/loss_step=0.0577]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 227/735 [04:10<09:21,  0.90it/s, v_num=lst8, train/loss_step=0.0577]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 227/735 [04:10<09:21,  0.90it/s, v_num=lst8, train/loss_step=0.0553]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 228/735 [04:12<09:20,  0.90it/s, v_num=lst8, train/loss_step=0.0553]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 228/735 [04:12<09:20,  0.90it/s, v_num=lst8, train/loss_step=0.0617]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 229/735 [04:13<09:19,  0.90it/s, v_num=lst8, train/loss_step=0.0617]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 229/735 [04:13<09:19,  0.90it/s, v_num=lst8, train/loss_step=0.0564]Epoch 0:  31%|â–ˆâ–ˆâ–ˆâ–      | 230/735 [04:14<09:17,  0.91it/s, v_num=lst8, train/loss_step=0.0564]Epoch 0:  31%|â–ˆâ–ˆâ–ˆâ–      | 230/735 [04:14<09:17,  0.91it/s, v_num=lst8, train/loss_step=0.0521]Epoch 0:  31%|â–ˆâ–ˆâ–ˆâ–      | 231/735 [04:15<09:16,  0.91it/s, v_num=lst8, train/loss_step=0.0521]Epoch 0:  31%|â–ˆâ–ˆâ–ˆâ–      | 231/735 [04:15<09:16,  0.91it/s, v_num=lst8, train/loss_step=0.0565]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 232/735 [04:16<09:15,  0.91it/s, v_num=lst8, train/loss_step=0.0565]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 232/735 [04:16<09:15,  0.91it/s, v_num=lst8, train/loss_step=0.0531]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 233/735 [04:17<09:14,  0.91it/s, v_num=lst8, train/loss_step=0.0531]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 233/735 [04:17<09:14,  0.91it/s, v_num=lst8, train/loss_step=0.0521]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 234/735 [04:18<09:13,  0.91it/s, v_num=lst8, train/loss_step=0.0521]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 234/735 [04:18<09:13,  0.91it/s, v_num=lst8, train/loss_step=0.0557]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 235/735 [04:19<09:11,  0.91it/s, v_num=lst8, train/loss_step=0.0557]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 235/735 [04:19<09:11,  0.91it/s, v_num=lst8, train/loss_step=0.0555]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 236/735 [04:20<09:10,  0.91it/s, v_num=lst8, train/loss_step=0.0555]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 236/735 [04:20<09:10,  0.91it/s, v_num=lst8, train/loss_step=0.0573]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 237/735 [04:21<09:09,  0.91it/s, v_num=lst8, train/loss_step=0.0573]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 237/735 [04:21<09:09,  0.91it/s, v_num=lst8, train/loss_step=0.0559]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 238/735 [04:22<09:08,  0.91it/s, v_num=lst8, train/loss_step=0.0559]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 238/735 [04:22<09:08,  0.91it/s, v_num=lst8, train/loss_step=0.0558]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–      | 239/735 [04:23<09:06,  0.91it/s, v_num=lst8, train/loss_step=0.0558]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–      | 239/735 [04:23<09:06,  0.91it/s, v_num=lst8, train/loss_step=0.0576]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–      | 240/735 [04:24<09:05,  0.91it/s, v_num=lst8, train/loss_step=0.0576]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–      | 240/735 [04:24<09:05,  0.91it/s, v_num=lst8, train/loss_step=0.0543]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–      | 241/735 [04:25<09:04,  0.91it/s, v_num=lst8, train/loss_step=0.0543]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–      | 241/735 [04:25<09:04,  0.91it/s, v_num=lst8, train/loss_step=0.0496]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–      | 242/735 [04:26<09:02,  0.91it/s, v_num=lst8, train/loss_step=0.0496]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–      | 242/735 [04:26<09:02,  0.91it/s, v_num=lst8, train/loss_step=0.0548]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–      | 243/735 [04:27<09:01,  0.91it/s, v_num=lst8, train/loss_step=0.0548]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–      | 243/735 [04:27<09:01,  0.91it/s, v_num=lst8, train/loss_step=0.0537]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–      | 244/735 [04:28<09:00,  0.91it/s, v_num=lst8, train/loss_step=0.0537]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–      | 244/735 [04:28<09:00,  0.91it/s, v_num=lst8, train/loss_step=0.0501]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–      | 245/735 [04:29<08:59,  0.91it/s, v_num=lst8, train/loss_step=0.0501]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–      | 245/735 [04:29<08:59,  0.91it/s, v_num=lst8, train/loss_step=0.0525]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–      | 246/735 [04:30<08:57,  0.91it/s, v_num=lst8, train/loss_step=0.0525]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–      | 246/735 [04:30<08:57,  0.91it/s, v_num=lst8, train/loss_step=0.0554]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 247/735 [04:31<08:56,  0.91it/s, v_num=lst8, train/loss_step=0.0554]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 247/735 [04:31<08:56,  0.91it/s, v_num=lst8, train/loss_step=0.0556]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 248/735 [04:32<08:55,  0.91it/s, v_num=lst8, train/loss_step=0.0556]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 248/735 [04:32<08:55,  0.91it/s, v_num=lst8, train/loss_step=0.0557]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 249/735 [04:33<08:54,  0.91it/s, v_num=lst8, train/loss_step=0.0557]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 249/735 [04:33<08:54,  0.91it/s, v_num=lst8, train/loss_step=0.0534]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 250/735 [04:34<08:52,  0.91it/s, v_num=lst8, train/loss_step=0.0534]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 250/735 [04:34<08:52,  0.91it/s, v_num=lst8, train/loss_step=0.0541]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 251/735 [04:35<08:51,  0.91it/s, v_num=lst8, train/loss_step=0.0541]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 251/735 [04:35<08:51,  0.91it/s, v_num=lst8, train/loss_step=0.0531]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 252/735 [04:36<08:50,  0.91it/s, v_num=lst8, train/loss_step=0.0531]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 252/735 [04:36<08:50,  0.91it/s, v_num=lst8, train/loss_step=0.0518]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 253/735 [04:37<08:49,  0.91it/s, v_num=lst8, train/loss_step=0.0518]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 253/735 [04:37<08:49,  0.91it/s, v_num=lst8, train/loss_step=0.052] Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–      | 254/735 [04:38<08:47,  0.91it/s, v_num=lst8, train/loss_step=0.052]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–      | 254/735 [04:38<08:47,  0.91it/s, v_num=lst8, train/loss_step=0.056]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–      | 255/735 [04:39<08:46,  0.91it/s, v_num=lst8, train/loss_step=0.056]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–      | 255/735 [04:39<08:46,  0.91it/s, v_num=lst8, train/loss_step=0.0488]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–      | 256/735 [04:40<08:45,  0.91it/s, v_num=lst8, train/loss_step=0.0488]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–      | 256/735 [04:40<08:45,  0.91it/s, v_num=lst8, train/loss_step=0.0548]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–      | 257/735 [04:41<08:44,  0.91it/s, v_num=lst8, train/loss_step=0.0548]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–      | 257/735 [04:41<08:44,  0.91it/s, v_num=lst8, train/loss_step=0.0576]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 258/735 [04:42<08:43,  0.91it/s, v_num=lst8, train/loss_step=0.0576]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 258/735 [04:42<08:43,  0.91it/s, v_num=lst8, train/loss_step=0.0496]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 259/735 [04:43<08:41,  0.91it/s, v_num=lst8, train/loss_step=0.0496]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 259/735 [04:43<08:41,  0.91it/s, v_num=lst8, train/loss_step=0.0505]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 260/735 [04:44<08:40,  0.91it/s, v_num=lst8, train/loss_step=0.0505]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 260/735 [04:44<08:40,  0.91it/s, v_num=lst8, train/loss_step=0.052] Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 261/735 [04:46<08:39,  0.91it/s, v_num=lst8, train/loss_step=0.052]Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 261/735 [04:46<08:39,  0.91it/s, v_num=lst8, train/loss_step=0.0542]Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 262/735 [04:47<08:38,  0.91it/s, v_num=lst8, train/loss_step=0.0542]Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 262/735 [04:47<08:38,  0.91it/s, v_num=lst8, train/loss_step=0.0523]Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 263/735 [04:48<08:37,  0.91it/s, v_num=lst8, train/loss_step=0.0523]Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 263/735 [04:48<08:37,  0.91it/s, v_num=lst8, train/loss_step=0.0573]Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 264/735 [04:49<08:35,  0.91it/s, v_num=lst8, train/loss_step=0.0573]Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 264/735 [04:49<08:35,  0.91it/s, v_num=lst8, train/loss_step=0.0525]Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 265/735 [04:50<08:34,  0.91it/s, v_num=lst8, train/loss_step=0.0525]Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 265/735 [04:50<08:34,  0.91it/s, v_num=lst8, train/loss_step=0.051] Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 266/735 [04:51<08:33,  0.91it/s, v_num=lst8, train/loss_step=0.051]Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 266/735 [04:51<08:33,  0.91it/s, v_num=lst8, train/loss_step=0.0521]Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 267/735 [04:52<08:32,  0.91it/s, v_num=lst8, train/loss_step=0.0521]Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 267/735 [04:52<08:32,  0.91it/s, v_num=lst8, train/loss_step=0.0483]Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 268/735 [04:53<08:31,  0.91it/s, v_num=lst8, train/loss_step=0.0483]Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 268/735 [04:53<08:31,  0.91it/s, v_num=lst8, train/loss_step=0.0593]Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 269/735 [04:54<08:30,  0.91it/s, v_num=lst8, train/loss_step=0.0593]Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 269/735 [04:54<08:30,  0.91it/s, v_num=lst8, train/loss_step=0.0553]Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 270/735 [04:55<08:28,  0.91it/s, v_num=lst8, train/loss_step=0.0553]Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 270/735 [04:55<08:28,  0.91it/s, v_num=lst8, train/loss_step=0.0557]Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 271/735 [04:56<08:27,  0.91it/s, v_num=lst8, train/loss_step=0.0557]Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 271/735 [04:56<08:27,  0.91it/s, v_num=lst8, train/loss_step=0.0537]Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 272/735 [04:57<08:26,  0.91it/s, v_num=lst8, train/loss_step=0.0537]Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 272/735 [04:57<08:26,  0.91it/s, v_num=lst8, train/loss_step=0.0569]Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 273/735 [04:58<08:25,  0.91it/s, v_num=lst8, train/loss_step=0.0569]Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 273/735 [04:58<08:25,  0.91it/s, v_num=lst8, train/loss_step=0.0526]Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 274/735 [04:59<08:24,  0.91it/s, v_num=lst8, train/loss_step=0.0526]Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 274/735 [04:59<08:24,  0.91it/s, v_num=lst8, train/loss_step=0.0572]Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 275/735 [05:00<08:22,  0.91it/s, v_num=lst8, train/loss_step=0.0572]Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 275/735 [05:00<08:22,  0.91it/s, v_num=lst8, train/loss_step=0.0575]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 276/735 [05:01<08:21,  0.91it/s, v_num=lst8, train/loss_step=0.0575]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 276/735 [05:01<08:21,  0.91it/s, v_num=lst8, train/loss_step=0.0522]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 277/735 [05:02<08:20,  0.92it/s, v_num=lst8, train/loss_step=0.0522]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 277/735 [05:02<08:20,  0.92it/s, v_num=lst8, train/loss_step=0.0533]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 278/735 [05:03<08:19,  0.92it/s, v_num=lst8, train/loss_step=0.0533]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 278/735 [05:03<08:19,  0.92it/s, v_num=lst8, train/loss_step=0.0505]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 279/735 [05:04<08:18,  0.92it/s, v_num=lst8, train/loss_step=0.0505]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 279/735 [05:04<08:18,  0.92it/s, v_num=lst8, train/loss_step=0.0498]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 280/735 [05:05<08:17,  0.92it/s, v_num=lst8, train/loss_step=0.0498]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 280/735 [05:05<08:17,  0.92it/s, v_num=lst8, train/loss_step=0.0556]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 281/735 [05:06<08:15,  0.92it/s, v_num=lst8, train/loss_step=0.0556]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 281/735 [05:06<08:15,  0.92it/s, v_num=lst8, train/loss_step=0.0513]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 282/735 [05:07<08:14,  0.92it/s, v_num=lst8, train/loss_step=0.0513]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 282/735 [05:07<08:14,  0.92it/s, v_num=lst8, train/loss_step=0.049] Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 283/735 [05:09<08:13,  0.92it/s, v_num=lst8, train/loss_step=0.049]Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 283/735 [05:09<08:13,  0.92it/s, v_num=lst8, train/loss_step=0.0568]Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 284/735 [05:10<08:12,  0.92it/s, v_num=lst8, train/loss_step=0.0568]Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 284/735 [05:10<08:12,  0.92it/s, v_num=lst8, train/loss_step=0.0485]Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 285/735 [05:11<08:11,  0.92it/s, v_num=lst8, train/loss_step=0.0485]Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 285/735 [05:11<08:11,  0.92it/s, v_num=lst8, train/loss_step=0.0542]Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 286/735 [05:12<08:10,  0.92it/s, v_num=lst8, train/loss_step=0.0542]Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 286/735 [05:12<08:10,  0.92it/s, v_num=lst8, train/loss_step=0.0529]Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 287/735 [05:13<08:08,  0.92it/s, v_num=lst8, train/loss_step=0.0529]Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 287/735 [05:13<08:08,  0.92it/s, v_num=lst8, train/loss_step=0.053] Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 288/735 [05:14<08:07,  0.92it/s, v_num=lst8, train/loss_step=0.053]Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 288/735 [05:14<08:07,  0.92it/s, v_num=lst8, train/loss_step=0.0502]Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 289/735 [05:15<08:06,  0.92it/s, v_num=lst8, train/loss_step=0.0502]Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 289/735 [05:15<08:06,  0.92it/s, v_num=lst8, train/loss_step=0.0571]Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 290/735 [05:16<08:05,  0.92it/s, v_num=lst8, train/loss_step=0.0571]Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 290/735 [05:16<08:05,  0.92it/s, v_num=lst8, train/loss_step=0.0561]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 291/735 [05:17<08:04,  0.92it/s, v_num=lst8, train/loss_step=0.0561]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 291/735 [05:17<08:04,  0.92it/s, v_num=lst8, train/loss_step=0.0638]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 292/735 [05:18<08:03,  0.92it/s, v_num=lst8, train/loss_step=0.0638]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 292/735 [05:18<08:03,  0.92it/s, v_num=lst8, train/loss_step=0.0569]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 293/735 [05:19<08:01,  0.92it/s, v_num=lst8, train/loss_step=0.0569]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 293/735 [05:19<08:01,  0.92it/s, v_num=lst8, train/loss_step=0.0485]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 294/735 [05:20<08:00,  0.92it/s, v_num=lst8, train/loss_step=0.0485]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 294/735 [05:20<08:00,  0.92it/s, v_num=lst8, train/loss_step=0.053] Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 295/735 [05:21<07:59,  0.92it/s, v_num=lst8, train/loss_step=0.053]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 295/735 [05:21<07:59,  0.92it/s, v_num=lst8, train/loss_step=0.052]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 296/735 [05:22<07:58,  0.92it/s, v_num=lst8, train/loss_step=0.052]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 296/735 [05:22<07:58,  0.92it/s, v_num=lst8, train/loss_step=0.0535]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 297/735 [05:23<07:57,  0.92it/s, v_num=lst8, train/loss_step=0.0535]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 297/735 [05:23<07:57,  0.92it/s, v_num=lst8, train/loss_step=0.0518]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 298/735 [05:24<07:56,  0.92it/s, v_num=lst8, train/loss_step=0.0518]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 298/735 [05:24<07:56,  0.92it/s, v_num=lst8, train/loss_step=0.0509]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 299/735 [05:25<07:55,  0.92it/s, v_num=lst8, train/loss_step=0.0509]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 299/735 [05:25<07:55,  0.92it/s, v_num=lst8, train/loss_step=0.053] Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 300/735 [05:26<07:53,  0.92it/s, v_num=lst8, train/loss_step=0.053]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 300/735 [05:26<07:53,  0.92it/s, v_num=lst8, train/loss_step=0.0528]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 301/735 [05:27<07:52,  0.92it/s, v_num=lst8, train/loss_step=0.0528]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 301/735 [05:27<07:52,  0.92it/s, v_num=lst8, train/loss_step=0.0527]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 302/735 [05:28<07:51,  0.92it/s, v_num=lst8, train/loss_step=0.0527]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 302/735 [05:28<07:51,  0.92it/s, v_num=lst8, train/loss_step=0.0539]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 303/735 [05:29<07:50,  0.92it/s, v_num=lst8, train/loss_step=0.0539]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 303/735 [05:29<07:50,  0.92it/s, v_num=lst8, train/loss_step=0.050] Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 304/735 [05:30<07:49,  0.92it/s, v_num=lst8, train/loss_step=0.050]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 304/735 [05:30<07:49,  0.92it/s, v_num=lst8, train/loss_step=0.0511]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 305/735 [05:31<07:48,  0.92it/s, v_num=lst8, train/loss_step=0.0511]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 305/735 [05:31<07:48,  0.92it/s, v_num=lst8, train/loss_step=0.052] Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 306/735 [05:33<07:46,  0.92it/s, v_num=lst8, train/loss_step=0.052]Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 306/735 [05:33<07:46,  0.92it/s, v_num=lst8, train/loss_step=0.0453]Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 307/735 [05:34<07:45,  0.92it/s, v_num=lst8, train/loss_step=0.0453]Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 307/735 [05:34<07:45,  0.92it/s, v_num=lst8, train/loss_step=0.0473]Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 308/735 [05:35<07:44,  0.92it/s, v_num=lst8, train/loss_step=0.0473]Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 308/735 [05:35<07:44,  0.92it/s, v_num=lst8, train/loss_step=0.050] Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 309/735 [05:36<07:43,  0.92it/s, v_num=lst8, train/loss_step=0.050]Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 309/735 [05:36<07:43,  0.92it/s, v_num=lst8, train/loss_step=0.0519]Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 310/735 [05:37<07:42,  0.92it/s, v_num=lst8, train/loss_step=0.0519]Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 310/735 [05:37<07:42,  0.92it/s, v_num=lst8, train/loss_step=0.0541]Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 311/735 [05:38<07:41,  0.92it/s, v_num=lst8, train/loss_step=0.0541]Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 311/735 [05:38<07:41,  0.92it/s, v_num=lst8, train/loss_step=0.0532]Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 312/735 [05:39<07:40,  0.92it/s, v_num=lst8, train/loss_step=0.0532]Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 312/735 [05:39<07:40,  0.92it/s, v_num=lst8, train/loss_step=0.0507]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 313/735 [05:40<07:38,  0.92it/s, v_num=lst8, train/loss_step=0.0507]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 313/735 [05:40<07:38,  0.92it/s, v_num=lst8, train/loss_step=0.0533]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 314/735 [05:41<07:37,  0.92it/s, v_num=lst8, train/loss_step=0.0533]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 314/735 [05:41<07:37,  0.92it/s, v_num=lst8, train/loss_step=0.049] Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 315/735 [05:42<07:36,  0.92it/s, v_num=lst8, train/loss_step=0.049]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 315/735 [05:42<07:36,  0.92it/s, v_num=lst8, train/loss_step=0.0477]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 316/735 [05:43<07:35,  0.92it/s, v_num=lst8, train/loss_step=0.0477]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 316/735 [05:43<07:35,  0.92it/s, v_num=lst8, train/loss_step=0.0506]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 317/735 [05:44<07:34,  0.92it/s, v_num=lst8, train/loss_step=0.0506]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 317/735 [05:44<07:34,  0.92it/s, v_num=lst8, train/loss_step=0.0508]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 318/735 [05:45<07:33,  0.92it/s, v_num=lst8, train/loss_step=0.0508]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 318/735 [05:45<07:33,  0.92it/s, v_num=lst8, train/loss_step=0.050] Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 319/735 [05:46<07:32,  0.92it/s, v_num=lst8, train/loss_step=0.050]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 319/735 [05:46<07:32,  0.92it/s, v_num=lst8, train/loss_step=0.0528]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 320/735 [05:47<07:30,  0.92it/s, v_num=lst8, train/loss_step=0.0528]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 320/735 [05:47<07:30,  0.92it/s, v_num=lst8, train/loss_step=0.0544]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 321/735 [05:48<07:29,  0.92it/s, v_num=lst8, train/loss_step=0.0544]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 321/735 [05:48<07:29,  0.92it/s, v_num=lst8, train/loss_step=0.0469]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 322/735 [05:49<07:28,  0.92it/s, v_num=lst8, train/loss_step=0.0469]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 322/735 [05:49<07:28,  0.92it/s, v_num=lst8, train/loss_step=0.0476]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 323/735 [05:50<07:27,  0.92it/s, v_num=lst8, train/loss_step=0.0476]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 323/735 [05:50<07:27,  0.92it/s, v_num=lst8, train/loss_step=0.0499]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 324/735 [05:51<07:26,  0.92it/s, v_num=lst8, train/loss_step=0.0499]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 324/735 [05:51<07:26,  0.92it/s, v_num=lst8, train/loss_step=0.0488]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 325/735 [05:52<07:25,  0.92it/s, v_num=lst8, train/loss_step=0.0488]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 325/735 [05:52<07:25,  0.92it/s, v_num=lst8, train/loss_step=0.0484]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 326/735 [05:54<07:24,  0.92it/s, v_num=lst8, train/loss_step=0.0484]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 326/735 [05:54<07:24,  0.92it/s, v_num=lst8, train/loss_step=0.0497]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 327/735 [05:55<07:23,  0.92it/s, v_num=lst8, train/loss_step=0.0497]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 327/735 [05:55<07:23,  0.92it/s, v_num=lst8, train/loss_step=0.0468]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 328/735 [05:56<07:21,  0.92it/s, v_num=lst8, train/loss_step=0.0468]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 328/735 [05:56<07:21,  0.92it/s, v_num=lst8, train/loss_step=0.0485]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 329/735 [05:57<07:20,  0.92it/s, v_num=lst8, train/loss_step=0.0485]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 329/735 [05:57<07:20,  0.92it/s, v_num=lst8, train/loss_step=0.0502]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 330/735 [05:58<07:19,  0.92it/s, v_num=lst8, train/loss_step=0.0502]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 330/735 [05:58<07:19,  0.92it/s, v_num=lst8, train/loss_step=0.0495]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 331/735 [05:59<07:18,  0.92it/s, v_num=lst8, train/loss_step=0.0495]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 331/735 [05:59<07:18,  0.92it/s, v_num=lst8, train/loss_step=0.0497]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 332/735 [06:00<07:17,  0.92it/s, v_num=lst8, train/loss_step=0.0497]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 332/735 [06:00<07:17,  0.92it/s, v_num=lst8, train/loss_step=0.0538]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 333/735 [06:01<07:16,  0.92it/s, v_num=lst8, train/loss_step=0.0538]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 333/735 [06:01<07:16,  0.92it/s, v_num=lst8, train/loss_step=0.0491]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 334/735 [06:02<07:15,  0.92it/s, v_num=lst8, train/loss_step=0.0491]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 334/735 [06:02<07:15,  0.92it/s, v_num=lst8, train/loss_step=0.0532]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 335/735 [06:03<07:13,  0.92it/s, v_num=lst8, train/loss_step=0.0532]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 335/735 [06:03<07:13,  0.92it/s, v_num=lst8, train/loss_step=0.0505]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 336/735 [06:04<07:12,  0.92it/s, v_num=lst8, train/loss_step=0.0505]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 336/735 [06:04<07:12,  0.92it/s, v_num=lst8, train/loss_step=0.0507]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 337/735 [06:05<07:11,  0.92it/s, v_num=lst8, train/loss_step=0.0507]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 337/735 [06:05<07:11,  0.92it/s, v_num=lst8, train/loss_step=0.0493]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 338/735 [06:06<07:10,  0.92it/s, v_num=lst8, train/loss_step=0.0493]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 338/735 [06:06<07:10,  0.92it/s, v_num=lst8, train/loss_step=0.0481]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 339/735 [06:07<07:09,  0.92it/s, v_num=lst8, train/loss_step=0.0481]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 339/735 [06:07<07:09,  0.92it/s, v_num=lst8, train/loss_step=0.0477]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 340/735 [06:08<07:08,  0.92it/s, v_num=lst8, train/loss_step=0.0477]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 340/735 [06:08<07:08,  0.92it/s, v_num=lst8, train/loss_step=0.0508]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 341/735 [06:09<07:07,  0.92it/s, v_num=lst8, train/loss_step=0.0508]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 341/735 [06:09<07:07,  0.92it/s, v_num=lst8, train/loss_step=0.0441]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 342/735 [06:10<07:06,  0.92it/s, v_num=lst8, train/loss_step=0.0441]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 342/735 [06:10<07:06,  0.92it/s, v_num=lst8, train/loss_step=0.0457]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 343/735 [06:11<07:04,  0.92it/s, v_num=lst8, train/loss_step=0.0457]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 343/735 [06:11<07:04,  0.92it/s, v_num=lst8, train/loss_step=0.0443]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 344/735 [06:12<07:03,  0.92it/s, v_num=lst8, train/loss_step=0.0443]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 344/735 [06:12<07:03,  0.92it/s, v_num=lst8, train/loss_step=0.047] Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 345/735 [06:13<07:02,  0.92it/s, v_num=lst8, train/loss_step=0.047]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 345/735 [06:13<07:02,  0.92it/s, v_num=lst8, train/loss_step=0.0473]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 346/735 [06:14<07:01,  0.92it/s, v_num=lst8, train/loss_step=0.0473]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 346/735 [06:14<07:01,  0.92it/s, v_num=lst8, train/loss_step=0.0481]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 347/735 [06:15<07:00,  0.92it/s, v_num=lst8, train/loss_step=0.0481]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 347/735 [06:15<07:00,  0.92it/s, v_num=lst8, train/loss_step=0.0481]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 348/735 [06:16<06:59,  0.92it/s, v_num=lst8, train/loss_step=0.0481]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 348/735 [06:16<06:59,  0.92it/s, v_num=lst8, train/loss_step=0.0487]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 349/735 [06:17<06:58,  0.92it/s, v_num=lst8, train/loss_step=0.0487]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 349/735 [06:17<06:58,  0.92it/s, v_num=lst8, train/loss_step=0.0544]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 350/735 [06:18<06:56,  0.92it/s, v_num=lst8, train/loss_step=0.0544]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 350/735 [06:18<06:56,  0.92it/s, v_num=lst8, train/loss_step=0.0507]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 351/735 [06:20<06:55,  0.92it/s, v_num=lst8, train/loss_step=0.0507]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 351/735 [06:20<06:55,  0.92it/s, v_num=lst8, train/loss_step=0.0471]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 352/735 [06:21<06:54,  0.92it/s, v_num=lst8, train/loss_step=0.0471]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 352/735 [06:21<06:54,  0.92it/s, v_num=lst8, train/loss_step=0.0463]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 353/735 [06:22<06:53,  0.92it/s, v_num=lst8, train/loss_step=0.0463]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 353/735 [06:22<06:53,  0.92it/s, v_num=lst8, train/loss_step=0.0502]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 354/735 [06:23<06:52,  0.92it/s, v_num=lst8, train/loss_step=0.0502]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 354/735 [06:23<06:52,  0.92it/s, v_num=lst8, train/loss_step=0.0499]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 355/735 [06:24<06:51,  0.92it/s, v_num=lst8, train/loss_step=0.0499]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 355/735 [06:24<06:51,  0.92it/s, v_num=lst8, train/loss_step=0.0528]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 356/735 [06:25<06:50,  0.92it/s, v_num=lst8, train/loss_step=0.0528]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 356/735 [06:25<06:50,  0.92it/s, v_num=lst8, train/loss_step=0.0475]Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 357/735 [06:26<06:49,  0.92it/s, v_num=lst8, train/loss_step=0.0475]Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 357/735 [06:26<06:49,  0.92it/s, v_num=lst8, train/loss_step=0.0474]Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 358/735 [06:27<06:47,  0.92it/s, v_num=lst8, train/loss_step=0.0474]Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 358/735 [06:27<06:47,  0.92it/s, v_num=lst8, train/loss_step=0.0511]Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 359/735 [06:28<06:46,  0.92it/s, v_num=lst8, train/loss_step=0.0511]Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 359/735 [06:28<06:46,  0.92it/s, v_num=lst8, train/loss_step=0.0497]Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 360/735 [06:29<06:45,  0.92it/s, v_num=lst8, train/loss_step=0.0497]Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 360/735 [06:29<06:45,  0.92it/s, v_num=lst8, train/loss_step=0.0452]Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 361/735 [06:30<06:44,  0.92it/s, v_num=lst8, train/loss_step=0.0452]Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 361/735 [06:30<06:44,  0.92it/s, v_num=lst8, train/loss_step=0.0479]Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 362/735 [06:31<06:43,  0.92it/s, v_num=lst8, train/loss_step=0.0479]Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 362/735 [06:31<06:43,  0.92it/s, v_num=lst8, train/loss_step=0.0463]Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 363/735 [06:32<06:42,  0.92it/s, v_num=lst8, train/loss_step=0.0463]Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 363/735 [06:32<06:42,  0.92it/s, v_num=lst8, train/loss_step=0.0547]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 364/735 [06:33<06:41,  0.92it/s, v_num=lst8, train/loss_step=0.0547]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 364/735 [06:33<06:41,  0.92it/s, v_num=lst8, train/loss_step=0.052] Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 365/735 [06:34<06:40,  0.92it/s, v_num=lst8, train/loss_step=0.052]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 365/735 [06:34<06:40,  0.92it/s, v_num=lst8, train/loss_step=0.0491]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 366/735 [06:35<06:39,  0.92it/s, v_num=lst8, train/loss_step=0.0491]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 366/735 [06:35<06:39,  0.92it/s, v_num=lst8, train/loss_step=0.0506]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 367/735 [06:36<06:37,  0.92it/s, v_num=lst8, train/loss_step=0.0506]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 367/735 [06:36<06:37,  0.92it/s, v_num=lst8, train/loss_step=0.047] Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 368/735 [06:37<06:36,  0.92it/s, v_num=lst8, train/loss_step=0.047]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 368/735 [06:37<06:36,  0.92it/s, v_num=lst8, train/loss_step=0.0508]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 369/735 [06:38<06:35,  0.92it/s, v_num=lst8, train/loss_step=0.0508]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 369/735 [06:38<06:35,  0.92it/s, v_num=lst8, train/loss_step=0.0468]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 370/735 [06:39<06:34,  0.93it/s, v_num=lst8, train/loss_step=0.0468]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 370/735 [06:39<06:34,  0.93it/s, v_num=lst8, train/loss_step=0.0458]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 371/735 [06:41<06:33,  0.93it/s, v_num=lst8, train/loss_step=0.0458]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 371/735 [06:41<06:33,  0.93it/s, v_num=lst8, train/loss_step=0.0519]Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 372/735 [06:42<06:32,  0.93it/s, v_num=lst8, train/loss_step=0.0519]Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 372/735 [06:42<06:32,  0.93it/s, v_num=lst8, train/loss_step=0.0541]Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 373/735 [06:43<06:31,  0.93it/s, v_num=lst8, train/loss_step=0.0541]Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 373/735 [06:43<06:31,  0.93it/s, v_num=lst8, train/loss_step=0.0439]Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 374/735 [06:44<06:30,  0.93it/s, v_num=lst8, train/loss_step=0.0439]Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 374/735 [06:44<06:30,  0.93it/s, v_num=lst8, train/loss_step=0.0458]Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 375/735 [06:45<06:29,  0.93it/s, v_num=lst8, train/loss_step=0.0458]Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 375/735 [06:45<06:29,  0.93it/s, v_num=lst8, train/loss_step=0.0481]Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 376/735 [06:46<06:27,  0.93it/s, v_num=lst8, train/loss_step=0.0481]Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 376/735 [06:46<06:27,  0.93it/s, v_num=lst8, train/loss_step=0.044] Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 377/735 [06:47<06:26,  0.93it/s, v_num=lst8, train/loss_step=0.044]Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 377/735 [06:47<06:26,  0.93it/s, v_num=lst8, train/loss_step=0.0481]Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 378/735 [06:48<06:25,  0.93it/s, v_num=lst8, train/loss_step=0.0481]Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 378/735 [06:48<06:25,  0.93it/s, v_num=lst8, train/loss_step=0.0496]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 379/735 [06:49<06:24,  0.93it/s, v_num=lst8, train/loss_step=0.0496]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 379/735 [06:49<06:24,  0.93it/s, v_num=lst8, train/loss_step=0.044] Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 380/735 [06:50<06:23,  0.93it/s, v_num=lst8, train/loss_step=0.044]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 380/735 [06:50<06:23,  0.93it/s, v_num=lst8, train/loss_step=0.0453]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 381/735 [06:51<06:22,  0.93it/s, v_num=lst8, train/loss_step=0.0453]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 381/735 [06:51<06:22,  0.93it/s, v_num=lst8, train/loss_step=0.0423]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 382/735 [06:52<06:21,  0.93it/s, v_num=lst8, train/loss_step=0.0423]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 382/735 [06:52<06:21,  0.93it/s, v_num=lst8, train/loss_step=0.0457]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 383/735 [06:53<06:20,  0.93it/s, v_num=lst8, train/loss_step=0.0457]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 383/735 [06:53<06:20,  0.93it/s, v_num=lst8, train/loss_step=0.0459]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 384/735 [06:54<06:18,  0.93it/s, v_num=lst8, train/loss_step=0.0459]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 384/735 [06:54<06:18,  0.93it/s, v_num=lst8, train/loss_step=0.0478]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 385/735 [06:55<06:17,  0.93it/s, v_num=lst8, train/loss_step=0.0478]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 385/735 [06:55<06:17,  0.93it/s, v_num=lst8, train/loss_step=0.0488]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 386/735 [06:56<06:16,  0.93it/s, v_num=lst8, train/loss_step=0.0488]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 386/735 [06:56<06:16,  0.93it/s, v_num=lst8, train/loss_step=0.0471]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 387/735 [06:57<06:15,  0.93it/s, v_num=lst8, train/loss_step=0.0471]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 387/735 [06:57<06:15,  0.93it/s, v_num=lst8, train/loss_step=0.0511]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 388/735 [06:58<06:14,  0.93it/s, v_num=lst8, train/loss_step=0.0511]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 388/735 [06:58<06:14,  0.93it/s, v_num=lst8, train/loss_step=0.042] Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 389/735 [06:59<06:13,  0.93it/s, v_num=lst8, train/loss_step=0.042]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 389/735 [06:59<06:13,  0.93it/s, v_num=lst8, train/loss_step=0.042]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 390/735 [07:00<06:12,  0.93it/s, v_num=lst8, train/loss_step=0.042]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 390/735 [07:00<06:12,  0.93it/s, v_num=lst8, train/loss_step=0.0447]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 391/735 [07:01<06:11,  0.93it/s, v_num=lst8, train/loss_step=0.0447]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 391/735 [07:01<06:11,  0.93it/s, v_num=lst8, train/loss_step=0.0413]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 392/735 [07:03<06:10,  0.93it/s, v_num=lst8, train/loss_step=0.0413]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 392/735 [07:03<06:10,  0.93it/s, v_num=lst8, train/loss_step=0.0422]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 393/735 [07:04<06:09,  0.93it/s, v_num=lst8, train/loss_step=0.0422]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 393/735 [07:04<06:09,  0.93it/s, v_num=lst8, train/loss_step=0.0464]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 394/735 [07:05<06:07,  0.93it/s, v_num=lst8, train/loss_step=0.0464]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 394/735 [07:05<06:07,  0.93it/s, v_num=lst8, train/loss_step=0.0414]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 395/735 [07:06<06:06,  0.93it/s, v_num=lst8, train/loss_step=0.0414]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 395/735 [07:06<06:06,  0.93it/s, v_num=lst8, train/loss_step=0.0444]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 396/735 [07:07<06:05,  0.93it/s, v_num=lst8, train/loss_step=0.0444]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 396/735 [07:07<06:05,  0.93it/s, v_num=lst8, train/loss_step=0.0418]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 397/735 [07:08<06:04,  0.93it/s, v_num=lst8, train/loss_step=0.0418]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 397/735 [07:08<06:04,  0.93it/s, v_num=lst8, train/loss_step=0.0494]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 398/735 [07:09<06:03,  0.93it/s, v_num=lst8, train/loss_step=0.0494]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 398/735 [07:09<06:03,  0.93it/s, v_num=lst8, train/loss_step=0.044] Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 399/735 [07:10<06:02,  0.93it/s, v_num=lst8, train/loss_step=0.044]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 399/735 [07:10<06:02,  0.93it/s, v_num=lst8, train/loss_step=0.0471]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 400/735 [07:11<06:01,  0.93it/s, v_num=lst8, train/loss_step=0.0471]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 400/735 [07:11<06:01,  0.93it/s, v_num=lst8, train/loss_step=0.0485]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 401/735 [07:12<06:00,  0.93it/s, v_num=lst8, train/loss_step=0.0485]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 401/735 [07:12<06:00,  0.93it/s, v_num=lst8, train/loss_step=0.047] Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 402/735 [07:13<05:59,  0.93it/s, v_num=lst8, train/loss_step=0.047]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 402/735 [07:13<05:59,  0.93it/s, v_num=lst8, train/loss_step=0.0455]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 403/735 [07:14<05:58,  0.93it/s, v_num=lst8, train/loss_step=0.0455]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 403/735 [07:14<05:58,  0.93it/s, v_num=lst8, train/loss_step=0.0405]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 404/735 [07:15<05:56,  0.93it/s, v_num=lst8, train/loss_step=0.0405]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 404/735 [07:15<05:56,  0.93it/s, v_num=lst8, train/loss_step=0.0516]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 405/735 [07:16<05:55,  0.93it/s, v_num=lst8, train/loss_step=0.0516]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 405/735 [07:16<05:55,  0.93it/s, v_num=lst8, train/loss_step=0.0471]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 406/735 [07:17<05:54,  0.93it/s, v_num=lst8, train/loss_step=0.0471]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 406/735 [07:17<05:54,  0.93it/s, v_num=lst8, train/loss_step=0.0447]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 407/735 [07:18<05:53,  0.93it/s, v_num=lst8, train/loss_step=0.0447]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 407/735 [07:18<05:53,  0.93it/s, v_num=lst8, train/loss_step=0.0446]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 408/735 [07:19<05:52,  0.93it/s, v_num=lst8, train/loss_step=0.0446]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 408/735 [07:19<05:52,  0.93it/s, v_num=lst8, train/loss_step=0.0496]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 409/735 [07:20<05:51,  0.93it/s, v_num=lst8, train/loss_step=0.0496]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 409/735 [07:20<05:51,  0.93it/s, v_num=lst8, train/loss_step=0.0501]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 410/735 [07:21<05:50,  0.93it/s, v_num=lst8, train/loss_step=0.0501]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 410/735 [07:21<05:50,  0.93it/s, v_num=lst8, train/loss_step=0.0499]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 411/735 [07:22<05:49,  0.93it/s, v_num=lst8, train/loss_step=0.0499]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 411/735 [07:22<05:49,  0.93it/s, v_num=lst8, train/loss_step=0.0455]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 412/735 [07:23<05:48,  0.93it/s, v_num=lst8, train/loss_step=0.0455]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 412/735 [07:23<05:48,  0.93it/s, v_num=lst8, train/loss_step=0.0466]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 413/735 [07:25<05:46,  0.93it/s, v_num=lst8, train/loss_step=0.0466]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 413/735 [07:25<05:46,  0.93it/s, v_num=lst8, train/loss_step=0.048] Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 414/735 [07:26<05:45,  0.93it/s, v_num=lst8, train/loss_step=0.048]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 414/735 [07:26<05:45,  0.93it/s, v_num=lst8, train/loss_step=0.0496]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 415/735 [07:27<05:44,  0.93it/s, v_num=lst8, train/loss_step=0.0496]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 415/735 [07:27<05:44,  0.93it/s, v_num=lst8, train/loss_step=0.0443]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 416/735 [07:28<05:43,  0.93it/s, v_num=lst8, train/loss_step=0.0443]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 416/735 [07:28<05:43,  0.93it/s, v_num=lst8, train/loss_step=0.0454]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 417/735 [07:29<05:42,  0.93it/s, v_num=lst8, train/loss_step=0.0454]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 417/735 [07:29<05:42,  0.93it/s, v_num=lst8, train/loss_step=0.045] Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 418/735 [07:30<05:41,  0.93it/s, v_num=lst8, train/loss_step=0.045]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 418/735 [07:30<05:41,  0.93it/s, v_num=lst8, train/loss_step=0.0444]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 419/735 [07:31<05:40,  0.93it/s, v_num=lst8, train/loss_step=0.0444]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 419/735 [07:31<05:40,  0.93it/s, v_num=lst8, train/loss_step=0.0417]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 420/735 [07:32<05:39,  0.93it/s, v_num=lst8, train/loss_step=0.0417]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 420/735 [07:32<05:39,  0.93it/s, v_num=lst8, train/loss_step=0.0412]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 421/735 [07:33<05:38,  0.93it/s, v_num=lst8, train/loss_step=0.0412]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 421/735 [07:33<05:38,  0.93it/s, v_num=lst8, train/loss_step=0.045] Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 422/735 [07:34<05:37,  0.93it/s, v_num=lst8, train/loss_step=0.045]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 422/735 [07:34<05:37,  0.93it/s, v_num=lst8, train/loss_step=0.0442]Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 423/735 [07:35<05:35,  0.93it/s, v_num=lst8, train/loss_step=0.0442]Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 423/735 [07:35<05:35,  0.93it/s, v_num=lst8, train/loss_step=0.045] Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 424/735 [07:36<05:34,  0.93it/s, v_num=lst8, train/loss_step=0.045]Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 424/735 [07:36<05:34,  0.93it/s, v_num=lst8, train/loss_step=0.0464]Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 425/735 [07:37<05:33,  0.93it/s, v_num=lst8, train/loss_step=0.0464]Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 425/735 [07:37<05:33,  0.93it/s, v_num=lst8, train/loss_step=0.0462]Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 426/735 [07:38<05:32,  0.93it/s, v_num=lst8, train/loss_step=0.0462]Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 426/735 [07:38<05:32,  0.93it/s, v_num=lst8, train/loss_step=0.0438]Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 427/735 [07:39<05:31,  0.93it/s, v_num=lst8, train/loss_step=0.0438]Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 427/735 [07:39<05:31,  0.93it/s, v_num=lst8, train/loss_step=0.0473]Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 428/735 [07:40<05:30,  0.93it/s, v_num=lst8, train/loss_step=0.0473]Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 428/735 [07:40<05:30,  0.93it/s, v_num=lst8, train/loss_step=0.0422]Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 429/735 [07:41<05:29,  0.93it/s, v_num=lst8, train/loss_step=0.0422]Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 429/735 [07:41<05:29,  0.93it/s, v_num=lst8, train/loss_step=0.0436]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 430/735 [07:42<05:28,  0.93it/s, v_num=lst8, train/loss_step=0.0436]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 430/735 [07:42<05:28,  0.93it/s, v_num=lst8, train/loss_step=0.0461]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 431/735 [07:43<05:27,  0.93it/s, v_num=lst8, train/loss_step=0.0461]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 431/735 [07:43<05:27,  0.93it/s, v_num=lst8, train/loss_step=0.0443]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 432/735 [07:44<05:26,  0.93it/s, v_num=lst8, train/loss_step=0.0443]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 432/735 [07:44<05:26,  0.93it/s, v_num=lst8, train/loss_step=0.0452]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 433/735 [07:45<05:25,  0.93it/s, v_num=lst8, train/loss_step=0.0452]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 433/735 [07:45<05:25,  0.93it/s, v_num=lst8, train/loss_step=0.0428]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 434/735 [07:47<05:23,  0.93it/s, v_num=lst8, train/loss_step=0.0428]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 434/735 [07:47<05:23,  0.93it/s, v_num=lst8, train/loss_step=0.0405]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 435/735 [07:48<05:22,  0.93it/s, v_num=lst8, train/loss_step=0.0405]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 435/735 [07:48<05:22,  0.93it/s, v_num=lst8, train/loss_step=0.0546]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 436/735 [07:49<05:21,  0.93it/s, v_num=lst8, train/loss_step=0.0546]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 436/735 [07:49<05:21,  0.93it/s, v_num=lst8, train/loss_step=0.0441]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 437/735 [07:50<05:20,  0.93it/s, v_num=lst8, train/loss_step=0.0441]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 437/735 [07:50<05:20,  0.93it/s, v_num=lst8, train/loss_step=0.0427]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 438/735 [07:51<05:19,  0.93it/s, v_num=lst8, train/loss_step=0.0427]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 438/735 [07:51<05:19,  0.93it/s, v_num=lst8, train/loss_step=0.0417]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 439/735 [07:52<05:18,  0.93it/s, v_num=lst8, train/loss_step=0.0417]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 439/735 [07:52<05:18,  0.93it/s, v_num=lst8, train/loss_step=0.0435]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 440/735 [07:53<05:17,  0.93it/s, v_num=lst8, train/loss_step=0.0435]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 440/735 [07:53<05:17,  0.93it/s, v_num=lst8, train/loss_step=0.0459]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 441/735 [07:54<05:16,  0.93it/s, v_num=lst8, train/loss_step=0.0459]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 441/735 [07:54<05:16,  0.93it/s, v_num=lst8, train/loss_step=0.0462]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 442/735 [07:55<05:15,  0.93it/s, v_num=lst8, train/loss_step=0.0462]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 442/735 [07:55<05:15,  0.93it/s, v_num=lst8, train/loss_step=0.038] Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 443/735 [07:56<05:13,  0.93it/s, v_num=lst8, train/loss_step=0.038]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 443/735 [07:56<05:13,  0.93it/s, v_num=lst8, train/loss_step=0.042]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 444/735 [07:57<05:12,  0.93it/s, v_num=lst8, train/loss_step=0.042]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 444/735 [07:57<05:12,  0.93it/s, v_num=lst8, train/loss_step=0.0431]Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 445/735 [07:58<05:11,  0.93it/s, v_num=lst8, train/loss_step=0.0431]Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 445/735 [07:58<05:11,  0.93it/s, v_num=lst8, train/loss_step=0.0474]Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 446/735 [07:59<05:10,  0.93it/s, v_num=lst8, train/loss_step=0.0474]Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 446/735 [07:59<05:10,  0.93it/s, v_num=lst8, train/loss_step=0.0428]Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 447/735 [08:00<05:09,  0.93it/s, v_num=lst8, train/loss_step=0.0428]Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 447/735 [08:00<05:09,  0.93it/s, v_num=lst8, train/loss_step=0.0424]Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 448/735 [08:01<05:08,  0.93it/s, v_num=lst8, train/loss_step=0.0424]Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 448/735 [08:01<05:08,  0.93it/s, v_num=lst8, train/loss_step=0.041] Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 449/735 [08:02<05:07,  0.93it/s, v_num=lst8, train/loss_step=0.041]Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 449/735 [08:02<05:07,  0.93it/s, v_num=lst8, train/loss_step=0.0474]Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 450/735 [08:03<05:06,  0.93it/s, v_num=lst8, train/loss_step=0.0474]Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 450/735 [08:03<05:06,  0.93it/s, v_num=lst8, train/loss_step=0.0428]Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 451/735 [08:04<05:05,  0.93it/s, v_num=lst8, train/loss_step=0.0428]Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 451/735 [08:04<05:05,  0.93it/s, v_num=lst8, train/loss_step=0.0494]Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 452/735 [08:05<05:04,  0.93it/s, v_num=lst8, train/loss_step=0.0494]Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 452/735 [08:05<05:04,  0.93it/s, v_num=lst8, train/loss_step=0.0428]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 453/735 [08:06<05:03,  0.93it/s, v_num=lst8, train/loss_step=0.0428]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 453/735 [08:06<05:03,  0.93it/s, v_num=lst8, train/loss_step=0.046] Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 454/735 [08:07<05:01,  0.93it/s, v_num=lst8, train/loss_step=0.046]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 454/735 [08:07<05:01,  0.93it/s, v_num=lst8, train/loss_step=0.049]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 455/735 [08:08<05:00,  0.93it/s, v_num=lst8, train/loss_step=0.049]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 455/735 [08:08<05:00,  0.93it/s, v_num=lst8, train/loss_step=0.0449]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 456/735 [08:09<04:59,  0.93it/s, v_num=lst8, train/loss_step=0.0449]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 456/735 [08:09<04:59,  0.93it/s, v_num=lst8, train/loss_step=0.0412]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 457/735 [08:10<04:58,  0.93it/s, v_num=lst8, train/loss_step=0.0412]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 457/735 [08:10<04:58,  0.93it/s, v_num=lst8, train/loss_step=0.0451]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 458/735 [08:12<04:57,  0.93it/s, v_num=lst8, train/loss_step=0.0451]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 458/735 [08:12<04:57,  0.93it/s, v_num=lst8, train/loss_step=0.048] Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 459/735 [08:13<04:56,  0.93it/s, v_num=lst8, train/loss_step=0.048]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 459/735 [08:13<04:56,  0.93it/s, v_num=lst8, train/loss_step=0.045]Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 460/735 [08:14<04:55,  0.93it/s, v_num=lst8, train/loss_step=0.045]Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 460/735 [08:14<04:55,  0.93it/s, v_num=lst8, train/loss_step=0.0357]Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 461/735 [08:15<04:54,  0.93it/s, v_num=lst8, train/loss_step=0.0357]Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 461/735 [08:15<04:54,  0.93it/s, v_num=lst8, train/loss_step=0.0431]Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 462/735 [08:16<04:53,  0.93it/s, v_num=lst8, train/loss_step=0.0431]Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 462/735 [08:16<04:53,  0.93it/s, v_num=lst8, train/loss_step=0.0417]Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 463/735 [08:17<04:52,  0.93it/s, v_num=lst8, train/loss_step=0.0417]Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 463/735 [08:17<04:52,  0.93it/s, v_num=lst8, train/loss_step=0.0438]Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 464/735 [08:18<04:51,  0.93it/s, v_num=lst8, train/loss_step=0.0438]Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 464/735 [08:18<04:51,  0.93it/s, v_num=lst8, train/loss_step=0.0405]Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 465/735 [08:19<04:49,  0.93it/s, v_num=lst8, train/loss_step=0.0405]Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 465/735 [08:19<04:49,  0.93it/s, v_num=lst8, train/loss_step=0.0438]Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 466/735 [08:20<04:48,  0.93it/s, v_num=lst8, train/loss_step=0.0438]Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 466/735 [08:20<04:48,  0.93it/s, v_num=lst8, train/loss_step=0.0481]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 467/735 [08:21<04:47,  0.93it/s, v_num=lst8, train/loss_step=0.0481]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 467/735 [08:21<04:47,  0.93it/s, v_num=lst8, train/loss_step=0.0419]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 468/735 [08:22<04:46,  0.93it/s, v_num=lst8, train/loss_step=0.0419]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 468/735 [08:22<04:46,  0.93it/s, v_num=lst8, train/loss_step=0.044] Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 469/735 [08:23<04:45,  0.93it/s, v_num=lst8, train/loss_step=0.044]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 469/735 [08:23<04:45,  0.93it/s, v_num=lst8, train/loss_step=0.0424]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 470/735 [08:24<04:44,  0.93it/s, v_num=lst8, train/loss_step=0.0424]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 470/735 [08:24<04:44,  0.93it/s, v_num=lst8, train/loss_step=0.0474]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 471/735 [08:25<04:43,  0.93it/s, v_num=lst8, train/loss_step=0.0474]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 471/735 [08:25<04:43,  0.93it/s, v_num=lst8, train/loss_step=0.0418]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 472/735 [08:26<04:42,  0.93it/s, v_num=lst8, train/loss_step=0.0418]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 472/735 [08:26<04:42,  0.93it/s, v_num=lst8, train/loss_step=0.0373]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 473/735 [08:27<04:41,  0.93it/s, v_num=lst8, train/loss_step=0.0373]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 473/735 [08:27<04:41,  0.93it/s, v_num=lst8, train/loss_step=0.0459]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 474/735 [08:28<04:39,  0.93it/s, v_num=lst8, train/loss_step=0.0459]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 474/735 [08:28<04:39,  0.93it/s, v_num=lst8, train/loss_step=0.0443]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 475/735 [08:29<04:38,  0.93it/s, v_num=lst8, train/loss_step=0.0443]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 475/735 [08:29<04:38,  0.93it/s, v_num=lst8, train/loss_step=0.038] Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 476/735 [08:30<04:37,  0.93it/s, v_num=lst8, train/loss_step=0.038]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 476/735 [08:30<04:37,  0.93it/s, v_num=lst8, train/loss_step=0.0396]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 477/735 [08:31<04:36,  0.93it/s, v_num=lst8, train/loss_step=0.0396]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 477/735 [08:31<04:36,  0.93it/s, v_num=lst8, train/loss_step=0.0434]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 478/735 [08:32<04:35,  0.93it/s, v_num=lst8, train/loss_step=0.0434]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 478/735 [08:32<04:35,  0.93it/s, v_num=lst8, train/loss_step=0.0444]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 479/735 [08:33<04:34,  0.93it/s, v_num=lst8, train/loss_step=0.0444]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 479/735 [08:33<04:34,  0.93it/s, v_num=lst8, train/loss_step=0.0432]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 480/735 [08:34<04:33,  0.93it/s, v_num=lst8, train/loss_step=0.0432]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 480/735 [08:34<04:33,  0.93it/s, v_num=lst8, train/loss_step=0.0369]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 481/735 [08:35<04:32,  0.93it/s, v_num=lst8, train/loss_step=0.0369]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 481/735 [08:35<04:32,  0.93it/s, v_num=lst8, train/loss_step=0.0402]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 482/735 [08:36<04:31,  0.93it/s, v_num=lst8, train/loss_step=0.0402]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 482/735 [08:36<04:31,  0.93it/s, v_num=lst8, train/loss_step=0.0452]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 483/735 [08:37<04:30,  0.93it/s, v_num=lst8, train/loss_step=0.0452]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 483/735 [08:37<04:30,  0.93it/s, v_num=lst8, train/loss_step=0.0503]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 484/735 [08:38<04:29,  0.93it/s, v_num=lst8, train/loss_step=0.0503]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 484/735 [08:38<04:29,  0.93it/s, v_num=lst8, train/loss_step=0.0402]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 485/735 [08:40<04:28,  0.93it/s, v_num=lst8, train/loss_step=0.0402]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 485/735 [08:40<04:28,  0.93it/s, v_num=lst8, train/loss_step=0.0452]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 486/735 [08:41<04:26,  0.93it/s, v_num=lst8, train/loss_step=0.0452]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 486/735 [08:41<04:26,  0.93it/s, v_num=lst8, train/loss_step=0.0454]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 487/735 [08:42<04:25,  0.93it/s, v_num=lst8, train/loss_step=0.0454]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 487/735 [08:42<04:25,  0.93it/s, v_num=lst8, train/loss_step=0.0424]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 488/735 [08:43<04:24,  0.93it/s, v_num=lst8, train/loss_step=0.0424]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 488/735 [08:43<04:24,  0.93it/s, v_num=lst8, train/loss_step=0.0465]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 489/735 [08:44<04:23,  0.93it/s, v_num=lst8, train/loss_step=0.0465]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 489/735 [08:44<04:23,  0.93it/s, v_num=lst8, train/loss_step=0.0368]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 490/735 [08:45<04:22,  0.93it/s, v_num=lst8, train/loss_step=0.0368]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 490/735 [08:45<04:22,  0.93it/s, v_num=lst8, train/loss_step=0.0367]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 491/735 [08:46<04:21,  0.93it/s, v_num=lst8, train/loss_step=0.0367]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 491/735 [08:46<04:21,  0.93it/s, v_num=lst8, train/loss_step=0.0383]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 492/735 [08:47<04:20,  0.93it/s, v_num=lst8, train/loss_step=0.0383]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 492/735 [08:47<04:20,  0.93it/s, v_num=lst8, train/loss_step=0.0403]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 493/735 [08:48<04:19,  0.93it/s, v_num=lst8, train/loss_step=0.0403]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 493/735 [08:48<04:19,  0.93it/s, v_num=lst8, train/loss_step=0.0399]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 494/735 [08:49<04:18,  0.93it/s, v_num=lst8, train/loss_step=0.0399]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 494/735 [08:49<04:18,  0.93it/s, v_num=lst8, train/loss_step=0.0364]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 495/735 [08:50<04:17,  0.93it/s, v_num=lst8, train/loss_step=0.0364]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 495/735 [08:50<04:17,  0.93it/s, v_num=lst8, train/loss_step=0.0357]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 496/735 [08:51<04:16,  0.93it/s, v_num=lst8, train/loss_step=0.0357]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 496/735 [08:51<04:16,  0.93it/s, v_num=lst8, train/loss_step=0.043] Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 497/735 [08:52<04:15,  0.93it/s, v_num=lst8, train/loss_step=0.043]Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 497/735 [08:52<04:15,  0.93it/s, v_num=lst8, train/loss_step=0.0451]Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 498/735 [08:53<04:13,  0.93it/s, v_num=lst8, train/loss_step=0.0451]Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 498/735 [08:53<04:13,  0.93it/s, v_num=lst8, train/loss_step=0.0439]Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 499/735 [08:54<04:12,  0.93it/s, v_num=lst8, train/loss_step=0.0439]Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 499/735 [08:54<04:12,  0.93it/s, v_num=lst8, train/loss_step=0.036] Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 500/735 [08:55<04:11,  0.93it/s, v_num=lst8, train/loss_step=0.036]Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 500/735 [08:55<04:11,  0.93it/s, v_num=lst8, train/loss_step=0.0403]Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 501/735 [08:56<04:10,  0.93it/s, v_num=lst8, train/loss_step=0.0403]Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 501/735 [08:56<04:10,  0.93it/s, v_num=lst8, train/loss_step=0.0386]Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 502/735 [08:57<04:09,  0.93it/s, v_num=lst8, train/loss_step=0.0386]Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 502/735 [08:57<04:09,  0.93it/s, v_num=lst8, train/loss_step=0.0406]Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 503/735 [08:58<04:08,  0.93it/s, v_num=lst8, train/loss_step=0.0406]Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 503/735 [08:58<04:08,  0.93it/s, v_num=lst8, train/loss_step=0.0385]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 504/735 [08:59<04:07,  0.93it/s, v_num=lst8, train/loss_step=0.0385]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 504/735 [08:59<04:07,  0.93it/s, v_num=lst8, train/loss_step=0.0386]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 505/735 [09:00<04:06,  0.93it/s, v_num=lst8, train/loss_step=0.0386]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 505/735 [09:00<04:06,  0.93it/s, v_num=lst8, train/loss_step=0.037] Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 506/735 [09:01<04:05,  0.93it/s, v_num=lst8, train/loss_step=0.037]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 506/735 [09:01<04:05,  0.93it/s, v_num=lst8, train/loss_step=0.0431]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 507/735 [09:03<04:04,  0.93it/s, v_num=lst8, train/loss_step=0.0431]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 507/735 [09:03<04:04,  0.93it/s, v_num=lst8, train/loss_step=0.0449]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 508/735 [09:04<04:03,  0.93it/s, v_num=lst8, train/loss_step=0.0449]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 508/735 [09:04<04:03,  0.93it/s, v_num=lst8, train/loss_step=0.0396]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 509/735 [09:05<04:02,  0.93it/s, v_num=lst8, train/loss_step=0.0396]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 509/735 [09:05<04:02,  0.93it/s, v_num=lst8, train/loss_step=0.0453]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 510/735 [09:06<04:00,  0.93it/s, v_num=lst8, train/loss_step=0.0453]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 510/735 [09:06<04:00,  0.93it/s, v_num=lst8, train/loss_step=0.0384]Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 511/735 [09:07<03:59,  0.93it/s, v_num=lst8, train/loss_step=0.0384]Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 511/735 [09:07<03:59,  0.93it/s, v_num=lst8, train/loss_step=0.0359]Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 512/735 [09:08<03:58,  0.93it/s, v_num=lst8, train/loss_step=0.0359]Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 512/735 [09:08<03:58,  0.93it/s, v_num=lst8, train/loss_step=0.0397]Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 513/735 [09:09<03:57,  0.93it/s, v_num=lst8, train/loss_step=0.0397]Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 513/735 [09:09<03:57,  0.93it/s, v_num=lst8, train/loss_step=0.0426]Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 514/735 [09:10<03:56,  0.93it/s, v_num=lst8, train/loss_step=0.0426]Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 514/735 [09:10<03:56,  0.93it/s, v_num=lst8, train/loss_step=0.0437]Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 515/735 [09:11<03:55,  0.93it/s, v_num=lst8, train/loss_step=0.0437]Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 515/735 [09:11<03:55,  0.93it/s, v_num=lst8, train/loss_step=0.0408]Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 516/735 [09:12<03:54,  0.93it/s, v_num=lst8, train/loss_step=0.0408]Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 516/735 [09:12<03:54,  0.93it/s, v_num=lst8, train/loss_step=0.0371]Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 517/735 [09:13<03:53,  0.93it/s, v_num=lst8, train/loss_step=0.0371]Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 517/735 [09:13<03:53,  0.93it/s, v_num=lst8, train/loss_step=0.042] Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 518/735 [09:14<03:52,  0.93it/s, v_num=lst8, train/loss_step=0.042]Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 518/735 [09:14<03:52,  0.93it/s, v_num=lst8, train/loss_step=0.0432]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 519/735 [09:15<03:51,  0.93it/s, v_num=lst8, train/loss_step=0.0432]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 519/735 [09:15<03:51,  0.93it/s, v_num=lst8, train/loss_step=0.0403]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 520/735 [09:16<03:50,  0.93it/s, v_num=lst8, train/loss_step=0.0403]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 520/735 [09:16<03:50,  0.93it/s, v_num=lst8, train/loss_step=0.0404]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 521/735 [09:17<03:49,  0.93it/s, v_num=lst8, train/loss_step=0.0404]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 521/735 [09:17<03:49,  0.93it/s, v_num=lst8, train/loss_step=0.0369]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 522/735 [09:18<03:47,  0.93it/s, v_num=lst8, train/loss_step=0.0369]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 522/735 [09:18<03:47,  0.93it/s, v_num=lst8, train/loss_step=0.0515]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 523/735 [09:19<03:46,  0.93it/s, v_num=lst8, train/loss_step=0.0515]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 523/735 [09:19<03:46,  0.93it/s, v_num=lst8, train/loss_step=0.0384]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 524/735 [09:20<03:45,  0.93it/s, v_num=lst8, train/loss_step=0.0384]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 524/735 [09:20<03:45,  0.93it/s, v_num=lst8, train/loss_step=0.0362]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 525/735 [09:21<03:44,  0.93it/s, v_num=lst8, train/loss_step=0.0362]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 525/735 [09:21<03:44,  0.93it/s, v_num=lst8, train/loss_step=0.0489]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 526/735 [09:22<03:43,  0.93it/s, v_num=lst8, train/loss_step=0.0489]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 526/735 [09:22<03:43,  0.93it/s, v_num=lst8, train/loss_step=0.0378]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 527/735 [09:23<03:42,  0.93it/s, v_num=lst8, train/loss_step=0.0378]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 527/735 [09:23<03:42,  0.93it/s, v_num=lst8, train/loss_step=0.0417]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 528/735 [09:24<03:41,  0.93it/s, v_num=lst8, train/loss_step=0.0417]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 528/735 [09:24<03:41,  0.93it/s, v_num=lst8, train/loss_step=0.0425]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 529/735 [09:25<03:40,  0.93it/s, v_num=lst8, train/loss_step=0.0425]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 529/735 [09:25<03:40,  0.93it/s, v_num=lst8, train/loss_step=0.0386]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 530/735 [09:26<03:39,  0.93it/s, v_num=lst8, train/loss_step=0.0386]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 530/735 [09:26<03:39,  0.93it/s, v_num=lst8, train/loss_step=0.0474]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 531/735 [09:27<03:38,  0.94it/s, v_num=lst8, train/loss_step=0.0474]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 531/735 [09:27<03:38,  0.94it/s, v_num=lst8, train/loss_step=0.0395]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 532/735 [09:28<03:37,  0.94it/s, v_num=lst8, train/loss_step=0.0395]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 532/735 [09:28<03:37,  0.94it/s, v_num=lst8, train/loss_step=0.0422]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 533/735 [09:29<03:36,  0.94it/s, v_num=lst8, train/loss_step=0.0422]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 533/735 [09:29<03:36,  0.94it/s, v_num=lst8, train/loss_step=0.0378]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 534/735 [09:31<03:34,  0.94it/s, v_num=lst8, train/loss_step=0.0378]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 534/735 [09:31<03:34,  0.94it/s, v_num=lst8, train/loss_step=0.037] Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 535/735 [09:32<03:33,  0.94it/s, v_num=lst8, train/loss_step=0.037]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 535/735 [09:32<03:33,  0.94it/s, v_num=lst8, train/loss_step=0.0409]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 536/735 [09:33<03:32,  0.94it/s, v_num=lst8, train/loss_step=0.0409]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 536/735 [09:33<03:32,  0.94it/s, v_num=lst8, train/loss_step=0.0392]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 537/735 [09:34<03:31,  0.94it/s, v_num=lst8, train/loss_step=0.0392]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 537/735 [09:34<03:31,  0.94it/s, v_num=lst8, train/loss_step=0.0417]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 538/735 [09:35<03:30,  0.94it/s, v_num=lst8, train/loss_step=0.0417]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 538/735 [09:35<03:30,  0.94it/s, v_num=lst8, train/loss_step=0.0342]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 539/735 [09:36<03:29,  0.94it/s, v_num=lst8, train/loss_step=0.0342]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 539/735 [09:36<03:29,  0.94it/s, v_num=lst8, train/loss_step=0.0391]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 540/735 [09:37<03:28,  0.94it/s, v_num=lst8, train/loss_step=0.0391]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 540/735 [09:37<03:28,  0.94it/s, v_num=lst8, train/loss_step=0.0416]Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 541/735 [09:38<03:27,  0.94it/s, v_num=lst8, train/loss_step=0.0416]Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 541/735 [09:38<03:27,  0.94it/s, v_num=lst8, train/loss_step=0.038] Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 542/735 [09:39<03:26,  0.94it/s, v_num=lst8, train/loss_step=0.038]Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 542/735 [09:39<03:26,  0.94it/s, v_num=lst8, train/loss_step=0.0479]Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 543/735 [09:40<03:25,  0.94it/s, v_num=lst8, train/loss_step=0.0479]Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 543/735 [09:40<03:25,  0.94it/s, v_num=lst8, train/loss_step=0.0455]Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 544/735 [09:41<03:24,  0.94it/s, v_num=lst8, train/loss_step=0.0455]Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 544/735 [09:41<03:24,  0.94it/s, v_num=lst8, train/loss_step=0.0403]Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 545/735 [09:42<03:23,  0.94it/s, v_num=lst8, train/loss_step=0.0403]Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 545/735 [09:42<03:23,  0.94it/s, v_num=lst8, train/loss_step=0.0383]Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 546/735 [09:43<03:22,  0.94it/s, v_num=lst8, train/loss_step=0.0383]Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 546/735 [09:43<03:22,  0.94it/s, v_num=lst8, train/loss_step=0.0374]Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 547/735 [09:44<03:20,  0.94it/s, v_num=lst8, train/loss_step=0.0374]Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 547/735 [09:44<03:20,  0.94it/s, v_num=lst8, train/loss_step=0.0432]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 548/735 [09:45<03:19,  0.94it/s, v_num=lst8, train/loss_step=0.0432]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 548/735 [09:45<03:19,  0.94it/s, v_num=lst8, train/loss_step=0.0421]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 549/735 [09:46<03:18,  0.94it/s, v_num=lst8, train/loss_step=0.0421]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 549/735 [09:46<03:18,  0.94it/s, v_num=lst8, train/loss_step=0.0411]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 550/735 [09:47<03:17,  0.94it/s, v_num=lst8, train/loss_step=0.0411]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 550/735 [09:47<03:17,  0.94it/s, v_num=lst8, train/loss_step=0.0378]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 551/735 [09:48<03:16,  0.94it/s, v_num=lst8, train/loss_step=0.0378]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 551/735 [09:48<03:16,  0.94it/s, v_num=lst8, train/loss_step=0.0436]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 552/735 [09:49<03:15,  0.94it/s, v_num=lst8, train/loss_step=0.0436]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 552/735 [09:49<03:15,  0.94it/s, v_num=lst8, train/loss_step=0.0411]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 553/735 [09:50<03:14,  0.94it/s, v_num=lst8, train/loss_step=0.0411]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 553/735 [09:50<03:14,  0.94it/s, v_num=lst8, train/loss_step=0.0422]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 554/735 [09:51<03:13,  0.94it/s, v_num=lst8, train/loss_step=0.0422]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 554/735 [09:51<03:13,  0.94it/s, v_num=lst8, train/loss_step=0.043] Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 555/735 [09:52<03:12,  0.94it/s, v_num=lst8, train/loss_step=0.043]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 555/735 [09:52<03:12,  0.94it/s, v_num=lst8, train/loss_step=0.0405]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 556/735 [09:53<03:11,  0.94it/s, v_num=lst8, train/loss_step=0.0405]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 556/735 [09:53<03:11,  0.94it/s, v_num=lst8, train/loss_step=0.0431]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 557/735 [09:54<03:10,  0.94it/s, v_num=lst8, train/loss_step=0.0431]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 557/735 [09:54<03:10,  0.94it/s, v_num=lst8, train/loss_step=0.0358]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 558/735 [09:56<03:09,  0.94it/s, v_num=lst8, train/loss_step=0.0358]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 558/735 [09:56<03:09,  0.94it/s, v_num=lst8, train/loss_step=0.0455]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 559/735 [09:57<03:07,  0.94it/s, v_num=lst8, train/loss_step=0.0455]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 559/735 [09:57<03:07,  0.94it/s, v_num=lst8, train/loss_step=0.0389]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 560/735 [09:58<03:06,  0.94it/s, v_num=lst8, train/loss_step=0.0389]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 560/735 [09:58<03:06,  0.94it/s, v_num=lst8, train/loss_step=0.0456]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 561/735 [09:59<03:05,  0.94it/s, v_num=lst8, train/loss_step=0.0456]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 561/735 [09:59<03:05,  0.94it/s, v_num=lst8, train/loss_step=0.0393]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 562/735 [10:00<03:04,  0.94it/s, v_num=lst8, train/loss_step=0.0393]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 562/735 [10:00<03:04,  0.94it/s, v_num=lst8, train/loss_step=0.0405]Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 563/735 [10:01<03:03,  0.94it/s, v_num=lst8, train/loss_step=0.0405]Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 563/735 [10:01<03:03,  0.94it/s, v_num=lst8, train/loss_step=0.042] Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 564/735 [10:02<03:02,  0.94it/s, v_num=lst8, train/loss_step=0.042]Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 564/735 [10:02<03:02,  0.94it/s, v_num=lst8, train/loss_step=0.0395]Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 565/735 [10:03<03:01,  0.94it/s, v_num=lst8, train/loss_step=0.0395]Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 565/735 [10:03<03:01,  0.94it/s, v_num=lst8, train/loss_step=0.0409]Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 566/735 [10:04<03:00,  0.94it/s, v_num=lst8, train/loss_step=0.0409]Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 566/735 [10:04<03:00,  0.94it/s, v_num=lst8, train/loss_step=0.0419]Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 567/735 [10:05<02:59,  0.94it/s, v_num=lst8, train/loss_step=0.0419]Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 567/735 [10:05<02:59,  0.94it/s, v_num=lst8, train/loss_step=0.0374]Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 568/735 [10:06<02:58,  0.94it/s, v_num=lst8, train/loss_step=0.0374]Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 568/735 [10:06<02:58,  0.94it/s, v_num=lst8, train/loss_step=0.044] Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 569/735 [10:07<02:57,  0.94it/s, v_num=lst8, train/loss_step=0.044]Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 569/735 [10:07<02:57,  0.94it/s, v_num=lst8, train/loss_step=0.0348]Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 570/735 [10:08<02:56,  0.94it/s, v_num=lst8, train/loss_step=0.0348]Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 570/735 [10:08<02:56,  0.94it/s, v_num=lst8, train/loss_step=0.0383]Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 571/735 [10:09<02:55,  0.94it/s, v_num=lst8, train/loss_step=0.0383]Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 571/735 [10:09<02:55,  0.94it/s, v_num=lst8, train/loss_step=0.0377]Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 572/735 [10:10<02:54,  0.94it/s, v_num=lst8, train/loss_step=0.0377]Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 572/735 [10:10<02:54,  0.94it/s, v_num=lst8, train/loss_step=0.0432]Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 573/735 [10:11<02:52,  0.94it/s, v_num=lst8, train/loss_step=0.0432]Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 573/735 [10:11<02:52,  0.94it/s, v_num=lst8, train/loss_step=0.048] Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 574/735 [10:12<02:51,  0.94it/s, v_num=lst8, train/loss_step=0.048]Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 574/735 [10:12<02:51,  0.94it/s, v_num=lst8, train/loss_step=0.0431]Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 575/735 [10:13<02:50,  0.94it/s, v_num=lst8, train/loss_step=0.0431]Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 575/735 [10:13<02:50,  0.94it/s, v_num=lst8, train/loss_step=0.0463]Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 576/735 [10:14<02:49,  0.94it/s, v_num=lst8, train/loss_step=0.0463]Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 576/735 [10:14<02:49,  0.94it/s, v_num=lst8, train/loss_step=0.0396]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 577/735 [10:15<02:48,  0.94it/s, v_num=lst8, train/loss_step=0.0396]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 577/735 [10:15<02:48,  0.94it/s, v_num=lst8, train/loss_step=0.0411]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 578/735 [10:17<02:47,  0.94it/s, v_num=lst8, train/loss_step=0.0411]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 578/735 [10:17<02:47,  0.94it/s, v_num=lst8, train/loss_step=0.0388]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 579/735 [10:18<02:46,  0.94it/s, v_num=lst8, train/loss_step=0.0388]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 579/735 [10:18<02:46,  0.94it/s, v_num=lst8, train/loss_step=0.0376]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 580/735 [10:19<02:45,  0.94it/s, v_num=lst8, train/loss_step=0.0376]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 580/735 [10:19<02:45,  0.94it/s, v_num=lst8, train/loss_step=0.0443]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 581/735 [10:20<02:44,  0.94it/s, v_num=lst8, train/loss_step=0.0443]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 581/735 [10:20<02:44,  0.94it/s, v_num=lst8, train/loss_step=0.0429]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 582/735 [10:21<02:43,  0.94it/s, v_num=lst8, train/loss_step=0.0429]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 582/735 [10:21<02:43,  0.94it/s, v_num=lst8, train/loss_step=0.0381]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 583/735 [10:22<02:42,  0.94it/s, v_num=lst8, train/loss_step=0.0381]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 583/735 [10:22<02:42,  0.94it/s, v_num=lst8, train/loss_step=0.0374]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 584/735 [10:23<02:41,  0.94it/s, v_num=lst8, train/loss_step=0.0374]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 584/735 [10:23<02:41,  0.94it/s, v_num=lst8, train/loss_step=0.0401]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 585/735 [10:24<02:40,  0.94it/s, v_num=lst8, train/loss_step=0.0401]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 585/735 [10:24<02:40,  0.94it/s, v_num=lst8, train/loss_step=0.0405]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 586/735 [10:25<02:39,  0.94it/s, v_num=lst8, train/loss_step=0.0405]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 586/735 [10:25<02:39,  0.94it/s, v_num=lst8, train/loss_step=0.0357]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 587/735 [10:26<02:37,  0.94it/s, v_num=lst8, train/loss_step=0.0357]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 587/735 [10:26<02:37,  0.94it/s, v_num=lst8, train/loss_step=0.0384]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 588/735 [10:27<02:36,  0.94it/s, v_num=lst8, train/loss_step=0.0384]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 588/735 [10:27<02:36,  0.94it/s, v_num=lst8, train/loss_step=0.0382]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 589/735 [10:28<02:35,  0.94it/s, v_num=lst8, train/loss_step=0.0382]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 589/735 [10:28<02:35,  0.94it/s, v_num=lst8, train/loss_step=0.0371]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 590/735 [10:29<02:34,  0.94it/s, v_num=lst8, train/loss_step=0.0371]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 590/735 [10:29<02:34,  0.94it/s, v_num=lst8, train/loss_step=0.0333]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 591/735 [10:30<02:33,  0.94it/s, v_num=lst8, train/loss_step=0.0333]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 591/735 [10:30<02:33,  0.94it/s, v_num=lst8, train/loss_step=0.0406]Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 592/735 [10:31<02:32,  0.94it/s, v_num=lst8, train/loss_step=0.0406]Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 592/735 [10:31<02:32,  0.94it/s, v_num=lst8, train/loss_step=0.0354]Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 593/735 [10:32<02:31,  0.94it/s, v_num=lst8, train/loss_step=0.0354]Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 593/735 [10:32<02:31,  0.94it/s, v_num=lst8, train/loss_step=0.0368]Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 594/735 [10:33<02:30,  0.94it/s, v_num=lst8, train/loss_step=0.0368]Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 594/735 [10:33<02:30,  0.94it/s, v_num=lst8, train/loss_step=0.0415]Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 595/735 [10:34<02:29,  0.94it/s, v_num=lst8, train/loss_step=0.0415]Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 595/735 [10:34<02:29,  0.94it/s, v_num=lst8, train/loss_step=0.0429]Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 596/735 [10:35<02:28,  0.94it/s, v_num=lst8, train/loss_step=0.0429]Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 596/735 [10:35<02:28,  0.94it/s, v_num=lst8, train/loss_step=0.0401]Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 597/735 [10:36<02:27,  0.94it/s, v_num=lst8, train/loss_step=0.0401]Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 597/735 [10:36<02:27,  0.94it/s, v_num=lst8, train/loss_step=0.0446]Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 598/735 [10:37<02:26,  0.94it/s, v_num=lst8, train/loss_step=0.0446]Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 598/735 [10:37<02:26,  0.94it/s, v_num=lst8, train/loss_step=0.0379]Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 599/735 [10:38<02:25,  0.94it/s, v_num=lst8, train/loss_step=0.0379]Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 599/735 [10:38<02:25,  0.94it/s, v_num=lst8, train/loss_step=0.0385]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 600/735 [10:39<02:23,  0.94it/s, v_num=lst8, train/loss_step=0.0385]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 600/735 [10:39<02:23,  0.94it/s, v_num=lst8, train/loss_step=0.0399]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 601/735 [10:40<02:22,  0.94it/s, v_num=lst8, train/loss_step=0.0399]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 601/735 [10:40<02:22,  0.94it/s, v_num=lst8, train/loss_step=0.0384]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 602/735 [10:41<02:21,  0.94it/s, v_num=lst8, train/loss_step=0.0384]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 602/735 [10:41<02:21,  0.94it/s, v_num=lst8, train/loss_step=0.0378]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 603/735 [10:42<02:20,  0.94it/s, v_num=lst8, train/loss_step=0.0378]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 603/735 [10:42<02:20,  0.94it/s, v_num=lst8, train/loss_step=0.0411]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 604/735 [10:43<02:19,  0.94it/s, v_num=lst8, train/loss_step=0.0411]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 604/735 [10:43<02:19,  0.94it/s, v_num=lst8, train/loss_step=0.0399]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 605/735 [10:44<02:18,  0.94it/s, v_num=lst8, train/loss_step=0.0399]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 605/735 [10:44<02:18,  0.94it/s, v_num=lst8, train/loss_step=0.0373]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 606/735 [10:45<02:17,  0.94it/s, v_num=lst8, train/loss_step=0.0373]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 606/735 [10:45<02:17,  0.94it/s, v_num=lst8, train/loss_step=0.0402]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 607/735 [10:47<02:16,  0.94it/s, v_num=lst8, train/loss_step=0.0402]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 607/735 [10:47<02:16,  0.94it/s, v_num=lst8, train/loss_step=0.0357]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 608/735 [10:48<02:15,  0.94it/s, v_num=lst8, train/loss_step=0.0357]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 608/735 [10:48<02:15,  0.94it/s, v_num=lst8, train/loss_step=0.0379]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 609/735 [10:49<02:14,  0.94it/s, v_num=lst8, train/loss_step=0.0379]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 609/735 [10:49<02:14,  0.94it/s, v_num=lst8, train/loss_step=0.0407]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 610/735 [10:50<02:13,  0.94it/s, v_num=lst8, train/loss_step=0.0407]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 610/735 [10:50<02:13,  0.94it/s, v_num=lst8, train/loss_step=0.0392]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 611/735 [10:51<02:12,  0.94it/s, v_num=lst8, train/loss_step=0.0392]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 611/735 [10:51<02:12,  0.94it/s, v_num=lst8, train/loss_step=0.0386]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 612/735 [10:52<02:11,  0.94it/s, v_num=lst8, train/loss_step=0.0386]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 612/735 [10:52<02:11,  0.94it/s, v_num=lst8, train/loss_step=0.042] Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 613/735 [10:53<02:10,  0.94it/s, v_num=lst8, train/loss_step=0.042]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 613/735 [10:53<02:10,  0.94it/s, v_num=lst8, train/loss_step=0.0404]Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 614/735 [10:54<02:08,  0.94it/s, v_num=lst8, train/loss_step=0.0404]Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 614/735 [10:54<02:08,  0.94it/s, v_num=lst8, train/loss_step=0.0403]Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 615/735 [10:55<02:07,  0.94it/s, v_num=lst8, train/loss_step=0.0403]Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 615/735 [10:55<02:07,  0.94it/s, v_num=lst8, train/loss_step=0.0357]Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 616/735 [10:56<02:06,  0.94it/s, v_num=lst8, train/loss_step=0.0357]Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 616/735 [10:56<02:06,  0.94it/s, v_num=lst8, train/loss_step=0.0385]Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 617/735 [10:57<02:05,  0.94it/s, v_num=lst8, train/loss_step=0.0385]Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 617/735 [10:57<02:05,  0.94it/s, v_num=lst8, train/loss_step=0.0392]Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 618/735 [10:58<02:04,  0.94it/s, v_num=lst8, train/loss_step=0.0392]Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 618/735 [10:58<02:04,  0.94it/s, v_num=lst8, train/loss_step=0.0392]Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 619/735 [10:59<02:03,  0.94it/s, v_num=lst8, train/loss_step=0.0392]Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 619/735 [10:59<02:03,  0.94it/s, v_num=lst8, train/loss_step=0.037] Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 620/735 [11:00<02:02,  0.94it/s, v_num=lst8, train/loss_step=0.037]Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 620/735 [11:00<02:02,  0.94it/s, v_num=lst8, train/loss_step=0.0376]Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 621/735 [11:01<02:01,  0.94it/s, v_num=lst8, train/loss_step=0.0376]Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 621/735 [11:01<02:01,  0.94it/s, v_num=lst8, train/loss_step=0.0398]Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 622/735 [11:02<02:00,  0.94it/s, v_num=lst8, train/loss_step=0.0398]Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 622/735 [11:02<02:00,  0.94it/s, v_num=lst8, train/loss_step=0.0404]Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 623/735 [11:03<01:59,  0.94it/s, v_num=lst8, train/loss_step=0.0404]Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 623/735 [11:03<01:59,  0.94it/s, v_num=lst8, train/loss_step=0.0431]Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 624/735 [11:04<01:58,  0.94it/s, v_num=lst8, train/loss_step=0.0431]Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 624/735 [11:04<01:58,  0.94it/s, v_num=lst8, train/loss_step=0.0378]Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 625/735 [11:05<01:57,  0.94it/s, v_num=lst8, train/loss_step=0.0378]Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 625/735 [11:05<01:57,  0.94it/s, v_num=lst8, train/loss_step=0.0455]Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 626/735 [11:06<01:56,  0.94it/s, v_num=lst8, train/loss_step=0.0455]Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 626/735 [11:06<01:56,  0.94it/s, v_num=lst8, train/loss_step=0.0491]Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 627/735 [11:07<01:54,  0.94it/s, v_num=lst8, train/loss_step=0.0491]Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 627/735 [11:07<01:54,  0.94it/s, v_num=lst8, train/loss_step=0.0378]Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 628/735 [11:08<01:53,  0.94it/s, v_num=lst8, train/loss_step=0.0378]Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 628/735 [11:08<01:53,  0.94it/s, v_num=lst8, train/loss_step=0.0407]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 629/735 [11:09<01:52,  0.94it/s, v_num=lst8, train/loss_step=0.0407]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 629/735 [11:09<01:52,  0.94it/s, v_num=lst8, train/loss_step=0.0415]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 630/735 [11:10<01:51,  0.94it/s, v_num=lst8, train/loss_step=0.0415]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 630/735 [11:10<01:51,  0.94it/s, v_num=lst8, train/loss_step=0.0357]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 631/735 [11:11<01:50,  0.94it/s, v_num=lst8, train/loss_step=0.0357]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 631/735 [11:11<01:50,  0.94it/s, v_num=lst8, train/loss_step=0.0372]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 632/735 [11:12<01:49,  0.94it/s, v_num=lst8, train/loss_step=0.0372]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 632/735 [11:12<01:49,  0.94it/s, v_num=lst8, train/loss_step=0.0416]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 633/735 [11:13<01:48,  0.94it/s, v_num=lst8, train/loss_step=0.0416]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 633/735 [11:13<01:48,  0.94it/s, v_num=lst8, train/loss_step=0.0405]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 634/735 [11:14<01:47,  0.94it/s, v_num=lst8, train/loss_step=0.0405]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 634/735 [11:14<01:47,  0.94it/s, v_num=lst8, train/loss_step=0.0338]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 635/735 [11:15<01:46,  0.94it/s, v_num=lst8, train/loss_step=0.0338]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 635/735 [11:15<01:46,  0.94it/s, v_num=lst8, train/loss_step=0.0362]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 636/735 [11:16<01:45,  0.94it/s, v_num=lst8, train/loss_step=0.0362]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 636/735 [11:16<01:45,  0.94it/s, v_num=lst8, train/loss_step=0.0426]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 637/735 [11:17<01:44,  0.94it/s, v_num=lst8, train/loss_step=0.0426]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 637/735 [11:17<01:44,  0.94it/s, v_num=lst8, train/loss_step=0.0401]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 638/735 [11:18<01:43,  0.94it/s, v_num=lst8, train/loss_step=0.0401]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 638/735 [11:18<01:43,  0.94it/s, v_num=lst8, train/loss_step=0.0396]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 639/735 [11:19<01:42,  0.94it/s, v_num=lst8, train/loss_step=0.0396]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 639/735 [11:19<01:42,  0.94it/s, v_num=lst8, train/loss_step=0.0373]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 640/735 [11:20<01:41,  0.94it/s, v_num=lst8, train/loss_step=0.0373]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 640/735 [11:20<01:41,  0.94it/s, v_num=lst8, train/loss_step=0.040] Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 641/735 [11:22<01:40,  0.94it/s, v_num=lst8, train/loss_step=0.040]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 641/735 [11:22<01:40,  0.94it/s, v_num=lst8, train/loss_step=0.038]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 642/735 [11:23<01:38,  0.94it/s, v_num=lst8, train/loss_step=0.038]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 642/735 [11:23<01:38,  0.94it/s, v_num=lst8, train/loss_step=0.0389]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 643/735 [11:24<01:37,  0.94it/s, v_num=lst8, train/loss_step=0.0389]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 643/735 [11:24<01:37,  0.94it/s, v_num=lst8, train/loss_step=0.0427]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 644/735 [11:25<01:36,  0.94it/s, v_num=lst8, train/loss_step=0.0427]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 644/735 [11:25<01:36,  0.94it/s, v_num=lst8, train/loss_step=0.0384]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 645/735 [11:26<01:35,  0.94it/s, v_num=lst8, train/loss_step=0.0384]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 645/735 [11:26<01:35,  0.94it/s, v_num=lst8, train/loss_step=0.0392]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 646/735 [11:27<01:34,  0.94it/s, v_num=lst8, train/loss_step=0.0392]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 646/735 [11:27<01:34,  0.94it/s, v_num=lst8, train/loss_step=0.0373]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 647/735 [11:28<01:33,  0.94it/s, v_num=lst8, train/loss_step=0.0373]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 647/735 [11:28<01:33,  0.94it/s, v_num=lst8, train/loss_step=0.0409]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 648/735 [11:29<01:32,  0.94it/s, v_num=lst8, train/loss_step=0.0409]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 648/735 [11:29<01:32,  0.94it/s, v_num=lst8, train/loss_step=0.0379]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 649/735 [11:30<01:31,  0.94it/s, v_num=lst8, train/loss_step=0.0379]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 649/735 [11:30<01:31,  0.94it/s, v_num=lst8, train/loss_step=0.0358]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 650/735 [11:31<01:30,  0.94it/s, v_num=lst8, train/loss_step=0.0358]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 650/735 [11:31<01:30,  0.94it/s, v_num=lst8, train/loss_step=0.040] Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 651/735 [11:32<01:29,  0.94it/s, v_num=lst8, train/loss_step=0.040]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 651/735 [11:32<01:29,  0.94it/s, v_num=lst8, train/loss_step=0.0398]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 652/735 [11:33<01:28,  0.94it/s, v_num=lst8, train/loss_step=0.0398]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 652/735 [11:33<01:28,  0.94it/s, v_num=lst8, train/loss_step=0.0321]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 653/735 [11:34<01:27,  0.94it/s, v_num=lst8, train/loss_step=0.0321]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 653/735 [11:34<01:27,  0.94it/s, v_num=lst8, train/loss_step=0.0342]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 654/735 [11:35<01:26,  0.94it/s, v_num=lst8, train/loss_step=0.0342]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 654/735 [11:35<01:26,  0.94it/s, v_num=lst8, train/loss_step=0.0368]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 655/735 [11:36<01:25,  0.94it/s, v_num=lst8, train/loss_step=0.0368]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 655/735 [11:36<01:25,  0.94it/s, v_num=lst8, train/loss_step=0.0418]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 656/735 [11:37<01:24,  0.94it/s, v_num=lst8, train/loss_step=0.0418]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 656/735 [11:37<01:24,  0.94it/s, v_num=lst8, train/loss_step=0.0409]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 657/735 [11:38<01:22,  0.94it/s, v_num=lst8, train/loss_step=0.0409]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 657/735 [11:38<01:22,  0.94it/s, v_num=lst8, train/loss_step=0.0376]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 658/735 [11:39<01:21,  0.94it/s, v_num=lst8, train/loss_step=0.0376]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 658/735 [11:39<01:21,  0.94it/s, v_num=lst8, train/loss_step=0.0391]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 659/735 [11:40<01:20,  0.94it/s, v_num=lst8, train/loss_step=0.0391]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 659/735 [11:40<01:20,  0.94it/s, v_num=lst8, train/loss_step=0.0425]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 660/735 [11:41<01:19,  0.94it/s, v_num=lst8, train/loss_step=0.0425]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 660/735 [11:41<01:19,  0.94it/s, v_num=lst8, train/loss_step=0.0361]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 661/735 [11:42<01:18,  0.94it/s, v_num=lst8, train/loss_step=0.0361]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 661/735 [11:42<01:18,  0.94it/s, v_num=lst8, train/loss_step=0.0297]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 662/735 [11:43<01:17,  0.94it/s, v_num=lst8, train/loss_step=0.0297]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 662/735 [11:43<01:17,  0.94it/s, v_num=lst8, train/loss_step=0.0316]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 663/735 [11:44<01:16,  0.94it/s, v_num=lst8, train/loss_step=0.0316]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 663/735 [11:44<01:16,  0.94it/s, v_num=lst8, train/loss_step=0.0356]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 664/735 [11:45<01:15,  0.94it/s, v_num=lst8, train/loss_step=0.0356]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 664/735 [11:45<01:15,  0.94it/s, v_num=lst8, train/loss_step=0.0361]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 665/735 [11:47<01:14,  0.94it/s, v_num=lst8, train/loss_step=0.0361]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 665/735 [11:47<01:14,  0.94it/s, v_num=lst8, train/loss_step=0.0411]Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 666/735 [11:48<01:13,  0.94it/s, v_num=lst8, train/loss_step=0.0411]Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 666/735 [11:48<01:13,  0.94it/s, v_num=lst8, train/loss_step=0.0422]Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 667/735 [11:49<01:12,  0.94it/s, v_num=lst8, train/loss_step=0.0422]Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 667/735 [11:49<01:12,  0.94it/s, v_num=lst8, train/loss_step=0.0375]Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 668/735 [11:50<01:11,  0.94it/s, v_num=lst8, train/loss_step=0.0375]Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 668/735 [11:50<01:11,  0.94it/s, v_num=lst8, train/loss_step=0.0418]Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 669/735 [11:51<01:10,  0.94it/s, v_num=lst8, train/loss_step=0.0418]Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 669/735 [11:51<01:10,  0.94it/s, v_num=lst8, train/loss_step=0.0341]Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 670/735 [11:52<01:09,  0.94it/s, v_num=lst8, train/loss_step=0.0341]Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 670/735 [11:52<01:09,  0.94it/s, v_num=lst8, train/loss_step=0.0371]Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 671/735 [11:53<01:08,  0.94it/s, v_num=lst8, train/loss_step=0.0371]Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 671/735 [11:53<01:08,  0.94it/s, v_num=lst8, train/loss_step=0.0404]Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 672/735 [11:54<01:06,  0.94it/s, v_num=lst8, train/loss_step=0.0404]Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 672/735 [11:54<01:06,  0.94it/s, v_num=lst8, train/loss_step=0.0393]Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 673/735 [11:55<01:05,  0.94it/s, v_num=lst8, train/loss_step=0.0393]Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 673/735 [11:55<01:05,  0.94it/s, v_num=lst8, train/loss_step=0.0359]Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 674/735 [11:56<01:04,  0.94it/s, v_num=lst8, train/loss_step=0.0359]Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 674/735 [11:56<01:04,  0.94it/s, v_num=lst8, train/loss_step=0.0403]Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 675/735 [11:57<01:03,  0.94it/s, v_num=lst8, train/loss_step=0.0403]Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 675/735 [11:57<01:03,  0.94it/s, v_num=lst8, train/loss_step=0.0356]Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 676/735 [11:58<01:02,  0.94it/s, v_num=lst8, train/loss_step=0.0356]Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 676/735 [11:58<01:02,  0.94it/s, v_num=lst8, train/loss_step=0.0344]Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 677/735 [11:59<01:01,  0.94it/s, v_num=lst8, train/loss_step=0.0344]Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 677/735 [11:59<01:01,  0.94it/s, v_num=lst8, train/loss_step=0.0347]Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 678/735 [12:00<01:00,  0.94it/s, v_num=lst8, train/loss_step=0.0347]Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 678/735 [12:00<01:00,  0.94it/s, v_num=lst8, train/loss_step=0.0401]Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 679/735 [12:01<00:59,  0.94it/s, v_num=lst8, train/loss_step=0.0401]Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 679/735 [12:01<00:59,  0.94it/s, v_num=lst8, train/loss_step=0.0383]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 680/735 [12:02<00:58,  0.94it/s, v_num=lst8, train/loss_step=0.0383]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 680/735 [12:02<00:58,  0.94it/s, v_num=lst8, train/loss_step=0.0432]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 681/735 [12:03<00:57,  0.94it/s, v_num=lst8, train/loss_step=0.0432]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 681/735 [12:03<00:57,  0.94it/s, v_num=lst8, train/loss_step=0.0364]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 682/735 [12:04<00:56,  0.94it/s, v_num=lst8, train/loss_step=0.0364]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 682/735 [12:04<00:56,  0.94it/s, v_num=lst8, train/loss_step=0.0407]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 683/735 [12:05<00:55,  0.94it/s, v_num=lst8, train/loss_step=0.0407]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 683/735 [12:05<00:55,  0.94it/s, v_num=lst8, train/loss_step=0.0373]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 684/735 [12:06<00:54,  0.94it/s, v_num=lst8, train/loss_step=0.0373]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 684/735 [12:06<00:54,  0.94it/s, v_num=lst8, train/loss_step=0.0382]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 685/735 [12:07<00:53,  0.94it/s, v_num=lst8, train/loss_step=0.0382]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 685/735 [12:07<00:53,  0.94it/s, v_num=lst8, train/loss_step=0.0392]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 686/735 [12:08<00:52,  0.94it/s, v_num=lst8, train/loss_step=0.0392]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 686/735 [12:08<00:52,  0.94it/s, v_num=lst8, train/loss_step=0.0378]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 687/735 [12:10<00:51,  0.94it/s, v_num=lst8, train/loss_step=0.0378]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 687/735 [12:10<00:51,  0.94it/s, v_num=lst8, train/loss_step=0.0393]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 688/735 [12:11<00:49,  0.94it/s, v_num=lst8, train/loss_step=0.0393]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 688/735 [12:11<00:49,  0.94it/s, v_num=lst8, train/loss_step=0.0411]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 689/735 [12:12<00:48,  0.94it/s, v_num=lst8, train/loss_step=0.0411]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 689/735 [12:12<00:48,  0.94it/s, v_num=lst8, train/loss_step=0.0368]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 690/735 [12:13<00:47,  0.94it/s, v_num=lst8, train/loss_step=0.0368]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 690/735 [12:13<00:47,  0.94it/s, v_num=lst8, train/loss_step=0.0386]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 691/735 [12:14<00:46,  0.94it/s, v_num=lst8, train/loss_step=0.0386]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 691/735 [12:14<00:46,  0.94it/s, v_num=lst8, train/loss_step=0.0402]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 692/735 [12:15<00:45,  0.94it/s, v_num=lst8, train/loss_step=0.0402]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 692/735 [12:15<00:45,  0.94it/s, v_num=lst8, train/loss_step=0.0393]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 693/735 [12:16<00:44,  0.94it/s, v_num=lst8, train/loss_step=0.0393]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 693/735 [12:16<00:44,  0.94it/s, v_num=lst8, train/loss_step=0.0372]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 694/735 [12:17<00:43,  0.94it/s, v_num=lst8, train/loss_step=0.0372]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 694/735 [12:17<00:43,  0.94it/s, v_num=lst8, train/loss_step=0.0417]Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 695/735 [12:18<00:42,  0.94it/s, v_num=lst8, train/loss_step=0.0417]Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 695/735 [12:18<00:42,  0.94it/s, v_num=lst8, train/loss_step=0.0393]Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 696/735 [12:19<00:41,  0.94it/s, v_num=lst8, train/loss_step=0.0393]Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 696/735 [12:19<00:41,  0.94it/s, v_num=lst8, train/loss_step=0.0394]Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 697/735 [12:20<00:40,  0.94it/s, v_num=lst8, train/loss_step=0.0394]Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 697/735 [12:20<00:40,  0.94it/s, v_num=lst8, train/loss_step=0.0434]Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 698/735 [12:21<00:39,  0.94it/s, v_num=lst8, train/loss_step=0.0434]Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 698/735 [12:21<00:39,  0.94it/s, v_num=lst8, train/loss_step=0.0423]Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 699/735 [12:22<00:38,  0.94it/s, v_num=lst8, train/loss_step=0.0423]Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 699/735 [12:22<00:38,  0.94it/s, v_num=lst8, train/loss_step=0.0339]Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 700/735 [12:23<00:37,  0.94it/s, v_num=lst8, train/loss_step=0.0339]Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 700/735 [12:23<00:37,  0.94it/s, v_num=lst8, train/loss_step=0.0359]Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 701/735 [12:24<00:36,  0.94it/s, v_num=lst8, train/loss_step=0.0359]Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 701/735 [12:24<00:36,  0.94it/s, v_num=lst8, train/loss_step=0.0378]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 702/735 [12:25<00:35,  0.94it/s, v_num=lst8, train/loss_step=0.0378]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 702/735 [12:25<00:35,  0.94it/s, v_num=lst8, train/loss_step=0.0374]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 703/735 [12:26<00:33,  0.94it/s, v_num=lst8, train/loss_step=0.0374]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 703/735 [12:26<00:33,  0.94it/s, v_num=lst8, train/loss_step=0.0357]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 704/735 [12:27<00:32,  0.94it/s, v_num=lst8, train/loss_step=0.0357]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 704/735 [12:27<00:32,  0.94it/s, v_num=lst8, train/loss_step=0.0392]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 705/735 [12:28<00:31,  0.94it/s, v_num=lst8, train/loss_step=0.0392]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 705/735 [12:28<00:31,  0.94it/s, v_num=lst8, train/loss_step=0.0357]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 706/735 [12:29<00:30,  0.94it/s, v_num=lst8, train/loss_step=0.0357]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 706/735 [12:29<00:30,  0.94it/s, v_num=lst8, train/loss_step=0.0377]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 707/735 [12:30<00:29,  0.94it/s, v_num=lst8, train/loss_step=0.0377]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 707/735 [12:30<00:29,  0.94it/s, v_num=lst8, train/loss_step=0.0343]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 708/735 [12:31<00:28,  0.94it/s, v_num=lst8, train/loss_step=0.0343]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 708/735 [12:31<00:28,  0.94it/s, v_num=lst8, train/loss_step=0.0393]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 709/735 [12:32<00:27,  0.94it/s, v_num=lst8, train/loss_step=0.0393]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 709/735 [12:32<00:27,  0.94it/s, v_num=lst8, train/loss_step=0.0348]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 710/735 [12:34<00:26,  0.94it/s, v_num=lst8, train/loss_step=0.0348]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 710/735 [12:34<00:26,  0.94it/s, v_num=lst8, train/loss_step=0.0336]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 711/735 [12:35<00:25,  0.94it/s, v_num=lst8, train/loss_step=0.0336]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 711/735 [12:35<00:25,  0.94it/s, v_num=lst8, train/loss_step=0.0346]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 712/735 [12:36<00:24,  0.94it/s, v_num=lst8, train/loss_step=0.0346]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 712/735 [12:36<00:24,  0.94it/s, v_num=lst8, train/loss_step=0.0399]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 713/735 [12:37<00:23,  0.94it/s, v_num=lst8, train/loss_step=0.0399]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 713/735 [12:37<00:23,  0.94it/s, v_num=lst8, train/loss_step=0.0384]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 714/735 [12:38<00:22,  0.94it/s, v_num=lst8, train/loss_step=0.0384]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 714/735 [12:38<00:22,  0.94it/s, v_num=lst8, train/loss_step=0.0331]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 715/735 [12:39<00:21,  0.94it/s, v_num=lst8, train/loss_step=0.0331]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 715/735 [12:39<00:21,  0.94it/s, v_num=lst8, train/loss_step=0.0341]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 716/735 [12:40<00:20,  0.94it/s, v_num=lst8, train/loss_step=0.0341]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 716/735 [12:40<00:20,  0.94it/s, v_num=lst8, train/loss_step=0.0383]Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 717/735 [12:41<00:19,  0.94it/s, v_num=lst8, train/loss_step=0.0383]Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 717/735 [12:41<00:19,  0.94it/s, v_num=lst8, train/loss_step=0.0458]Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 718/735 [12:42<00:18,  0.94it/s, v_num=lst8, train/loss_step=0.0458]Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 718/735 [12:42<00:18,  0.94it/s, v_num=lst8, train/loss_step=0.037] Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 719/735 [12:43<00:16,  0.94it/s, v_num=lst8, train/loss_step=0.037]Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 719/735 [12:43<00:16,  0.94it/s, v_num=lst8, train/loss_step=0.0385]Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 720/735 [12:44<00:15,  0.94it/s, v_num=lst8, train/loss_step=0.0385]Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 720/735 [12:44<00:15,  0.94it/s, v_num=lst8, train/loss_step=0.0406]Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 721/735 [12:45<00:14,  0.94it/s, v_num=lst8, train/loss_step=0.0406]Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 721/735 [12:45<00:14,  0.94it/s, v_num=lst8, train/loss_step=0.042] Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 722/735 [12:46<00:13,  0.94it/s, v_num=lst8, train/loss_step=0.042]Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 722/735 [12:46<00:13,  0.94it/s, v_num=lst8, train/loss_step=0.0381]Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 723/735 [12:47<00:12,  0.94it/s, v_num=lst8, train/loss_step=0.0381]Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 723/735 [12:47<00:12,  0.94it/s, v_num=lst8, train/loss_step=0.0314]Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 724/735 [12:48<00:11,  0.94it/s, v_num=lst8, train/loss_step=0.0314]Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 724/735 [12:48<00:11,  0.94it/s, v_num=lst8, train/loss_step=0.0358]Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 725/735 [12:49<00:10,  0.94it/s, v_num=lst8, train/loss_step=0.0358]Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 725/735 [12:49<00:10,  0.94it/s, v_num=lst8, train/loss_step=0.0384]Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 726/735 [12:50<00:09,  0.94it/s, v_num=lst8, train/loss_step=0.0384]Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 726/735 [12:50<00:09,  0.94it/s, v_num=lst8, train/loss_step=0.0389]Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 727/735 [12:51<00:08,  0.94it/s, v_num=lst8, train/loss_step=0.0389]Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 727/735 [12:51<00:08,  0.94it/s, v_num=lst8, train/loss_step=0.0336]Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 728/735 [12:52<00:07,  0.94it/s, v_num=lst8, train/loss_step=0.0336]Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 728/735 [12:52<00:07,  0.94it/s, v_num=lst8, train/loss_step=0.0408]Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 729/735 [12:53<00:06,  0.94it/s, v_num=lst8, train/loss_step=0.0408]Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 729/735 [12:53<00:06,  0.94it/s, v_num=lst8, train/loss_step=0.0309]Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 730/735 [12:54<00:05,  0.94it/s, v_num=lst8, train/loss_step=0.0309]Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 730/735 [12:54<00:05,  0.94it/s, v_num=lst8, train/loss_step=0.0363]Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 731/735 [12:55<00:04,  0.94it/s, v_num=lst8, train/loss_step=0.0363]Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 731/735 [12:55<00:04,  0.94it/s, v_num=lst8, train/loss_step=0.0364]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 732/735 [12:56<00:03,  0.94it/s, v_num=lst8, train/loss_step=0.0364]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 732/735 [12:56<00:03,  0.94it/s, v_num=lst8, train/loss_step=0.0365]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 733/735 [12:57<00:02,  0.94it/s, v_num=lst8, train/loss_step=0.0365]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 733/735 [12:57<00:02,  0.94it/s, v_num=lst8, train/loss_step=0.0367]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 734/735 [12:59<00:01,  0.94it/s, v_num=lst8, train/loss_step=0.0367]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 734/735 [12:59<00:01,  0.94it/s, v_num=lst8, train/loss_step=0.0332]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 735/735 [13:00<00:00,  0.94it/s, v_num=lst8, train/loss_step=0.0332]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 735/735 [13:00<00:00,  0.94it/s, v_num=lst8, train/loss_step=0.0344]hyperparameters: "compile":            False
"learning_rate":      0.0005
"loss":               bce
"lr_rate":            [0.05, 0.02, 0.01, 0.005, 0.002, 0.001, 0.0005, 0.0002]
"lr_scheduler_epoch": [10, 15, 20, 25, 30, 35, 50, 45]
"net":                HGCN(
  (stem): Stem_conv(
    (convs): Sequential(
      (0): Conv2d(1, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): GELU(approximate='none')
      (3): Conv2d(40, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (4): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): GELU(approximate='none')
      (6): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (backbone): Sequential(
    (0): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): Identity()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
        )
        (drop_path): Identity()
      )
    )
    (1): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
        )
        (drop_path): DropPath()
      )
    )
    (2): DownSample(
      (conv): Sequential(
        (0): Conv2d(80, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(480, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)
        )
        (drop_path): DropPath()
      )
    )
    (4): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(480, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)
        )
        (drop_path): DropPath()
      )
    )
    (5): DownSample(
      (conv): Sequential(
        (0): Conv2d(160, 400, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (7): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (8): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (9): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (10): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (11): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (12): DownSample(
      (conv): Sequential(
        (0): Conv2d(400, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (13): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1920, 1920, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(640, 2560, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(2560, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(2560, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(2560, 2560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2560)
        )
        (drop_path): DropPath()
      )
    )
    (14): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1920, 1920, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(640, 2560, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(2560, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(2560, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(2560, 2560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2560)
        )
        (drop_path): DropPath()
      )
    )
  )
  (prediction): Sequential(
    (0): Conv2d(640, 1024, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): GELU(approximate='none')
    (3): Dropout(p=0.0, inplace=False)
    (4): Conv2d(1024, 200, kernel_size=(1, 1), stride=(1, 1))
  )
)
"opt_warmup":         True
"optimizer":          functools.partial(<class 'torch.optim.adam.Adam'>, lr=0.0005, weight_decay=5e-07, eps=1e-08, betas=[0.95, 0.999])
"scheduler":          functools.partial(<class 'torch.optim.lr_scheduler.MultiStepLR'>, milestones=[10, 15, 20, 25, 30, 35, 40], gamma=0.5)

Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/83 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/83 [00:00<?, ?it/s][A
Validation DataLoader 0:   1%|          | 1/83 [00:00<00:59,  1.37it/s][A
Validation DataLoader 0:   2%|â–         | 2/83 [00:01<00:52,  1.53it/s][A
Validation DataLoader 0:   4%|â–         | 3/83 [00:01<00:49,  1.62it/s][A
Validation DataLoader 0:   5%|â–         | 4/83 [00:02<00:47,  1.66it/s][A
Validation DataLoader 0:   6%|â–Œ         | 5/83 [00:02<00:46,  1.68it/s][A
Validation DataLoader 0:   7%|â–‹         | 6/83 [00:03<00:45,  1.70it/s][A
Validation DataLoader 0:   8%|â–Š         | 7/83 [00:04<00:44,  1.72it/s][A
Validation DataLoader 0:  10%|â–‰         | 8/83 [00:04<00:43,  1.73it/s][A
Validation DataLoader 0:  11%|â–ˆ         | 9/83 [00:05<00:42,  1.74it/s][A
Validation DataLoader 0:  12%|â–ˆâ–        | 10/83 [00:05<00:41,  1.75it/s][A
Validation DataLoader 0:  13%|â–ˆâ–        | 11/83 [00:06<00:40,  1.76it/s][A
Validation DataLoader 0:  14%|â–ˆâ–        | 12/83 [00:06<00:40,  1.77it/s][A
Validation DataLoader 0:  16%|â–ˆâ–Œ        | 13/83 [00:07<00:39,  1.77it/s][A
Validation DataLoader 0:  17%|â–ˆâ–‹        | 14/83 [00:07<00:38,  1.78it/s][A
Validation DataLoader 0:  18%|â–ˆâ–Š        | 15/83 [00:08<00:38,  1.78it/s][A
Validation DataLoader 0:  19%|â–ˆâ–‰        | 16/83 [00:08<00:37,  1.78it/s][A
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 17/83 [00:09<00:36,  1.79it/s][A
Validation DataLoader 0:  22%|â–ˆâ–ˆâ–       | 18/83 [00:10<00:36,  1.79it/s][A
Validation DataLoader 0:  23%|â–ˆâ–ˆâ–       | 19/83 [00:10<00:35,  1.79it/s][A
Validation DataLoader 0:  24%|â–ˆâ–ˆâ–       | 20/83 [00:11<00:35,  1.80it/s][A
Validation DataLoader 0:  25%|â–ˆâ–ˆâ–Œ       | 21/83 [00:11<00:34,  1.80it/s][A
Validation DataLoader 0:  27%|â–ˆâ–ˆâ–‹       | 22/83 [00:12<00:33,  1.80it/s][A
Validation DataLoader 0:  28%|â–ˆâ–ˆâ–Š       | 23/83 [00:12<00:33,  1.80it/s][A
Validation DataLoader 0:  29%|â–ˆâ–ˆâ–‰       | 24/83 [00:13<00:32,  1.80it/s][A
Validation DataLoader 0:  30%|â–ˆâ–ˆâ–ˆ       | 25/83 [00:13<00:32,  1.81it/s][A
Validation DataLoader 0:  31%|â–ˆâ–ˆâ–ˆâ–      | 26/83 [00:14<00:31,  1.81it/s][A
Validation DataLoader 0:  33%|â–ˆâ–ˆâ–ˆâ–      | 27/83 [00:14<00:30,  1.81it/s][A
Validation DataLoader 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 28/83 [00:15<00:30,  1.81it/s][A
Validation DataLoader 0:  35%|â–ˆâ–ˆâ–ˆâ–      | 29/83 [00:16<00:29,  1.81it/s][A
Validation DataLoader 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 30/83 [00:16<00:29,  1.81it/s][A
Validation DataLoader 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 31/83 [00:17<00:28,  1.81it/s][A
Validation DataLoader 0:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 32/83 [00:17<00:28,  1.81it/s][A
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 33/83 [00:18<00:27,  1.81it/s][A
Validation DataLoader 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 34/83 [00:18<00:27,  1.81it/s][A
Validation DataLoader 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 35/83 [00:19<00:26,  1.81it/s][A
Validation DataLoader 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 36/83 [00:19<00:25,  1.82it/s][A
Validation DataLoader 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 37/83 [00:20<00:25,  1.82it/s][A
Validation DataLoader 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 38/83 [00:20<00:24,  1.82it/s][A
Validation DataLoader 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 39/83 [00:21<00:24,  1.82it/s][A
Validation DataLoader 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 40/83 [00:22<00:23,  1.82it/s][A
Validation DataLoader 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 41/83 [00:22<00:23,  1.82it/s][A
Validation DataLoader 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 42/83 [00:23<00:22,  1.82it/s][A
Validation DataLoader 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 43/83 [00:23<00:21,  1.82it/s][A
Validation DataLoader 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 44/83 [00:24<00:21,  1.82it/s][A
Validation DataLoader 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 45/83 [00:24<00:20,  1.82it/s][A
Validation DataLoader 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 46/83 [00:25<00:20,  1.82it/s][A
Validation DataLoader 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 47/83 [00:25<00:19,  1.82it/s][A
Validation DataLoader 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 48/83 [00:26<00:19,  1.82it/s][A
Validation DataLoader 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 49/83 [00:26<00:18,  1.82it/s][A
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 50/83 [00:27<00:18,  1.82it/s][A
Validation DataLoader 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 51/83 [00:28<00:17,  1.82it/s][A
Validation DataLoader 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 52/83 [00:28<00:17,  1.82it/s][A
Validation DataLoader 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 53/83 [00:29<00:16,  1.82it/s][A
Validation DataLoader 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 54/83 [00:29<00:15,  1.82it/s][A
Validation DataLoader 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 55/83 [00:30<00:15,  1.82it/s][A
Validation DataLoader 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 56/83 [00:30<00:14,  1.82it/s][A
Validation DataLoader 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 57/83 [00:31<00:14,  1.82it/s][A
Validation DataLoader 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 58/83 [00:31<00:13,  1.82it/s][A
Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 59/83 [00:32<00:13,  1.82it/s][A
Validation DataLoader 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 60/83 [00:32<00:12,  1.82it/s][A
Validation DataLoader 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 61/83 [00:33<00:12,  1.82it/s][A
Validation DataLoader 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 62/83 [00:34<00:11,  1.82it/s][A
Validation DataLoader 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 63/83 [00:34<00:10,  1.82it/s][A
Validation DataLoader 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 64/83 [00:35<00:10,  1.82it/s][A
Validation DataLoader 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 65/83 [00:35<00:09,  1.82it/s][A
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 66/83 [00:36<00:09,  1.82it/s][A
Validation DataLoader 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 67/83 [00:36<00:08,  1.82it/s][A
Validation DataLoader 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 68/83 [00:37<00:08,  1.82it/s][A
Validation DataLoader 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 69/83 [00:37<00:07,  1.82it/s][A
Validation DataLoader 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 70/83 [00:38<00:07,  1.83it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 71/83 [00:38<00:06,  1.83it/s][A
Validation DataLoader 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 72/83 [00:39<00:06,  1.83it/s][A
Validation DataLoader 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 73/83 [00:39<00:05,  1.83it/s][A
Validation DataLoader 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 74/83 [00:40<00:04,  1.83it/s][A
Validation DataLoader 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 75/83 [00:41<00:04,  1.83it/s][A
Validation DataLoader 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 76/83 [00:41<00:03,  1.83it/s][A
Validation DataLoader 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 77/83 [00:42<00:03,  1.83it/s][A
Validation DataLoader 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 78/83 [00:42<00:02,  1.83it/s][A
Validation DataLoader 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 79/83 [00:43<00:02,  1.83it/s][A
Validation DataLoader 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 80/83 [00:43<00:01,  1.83it/s][A
Validation DataLoader 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 81/83 [00:44<00:01,  1.83it/s][A
Validation DataLoader 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 82/83 [00:44<00:00,  1.83it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 83/83 [00:45<00:00,  1.83it/s][AError executing job with overrides: ['trainer.max_epochs=5', 'trainer.min_epochs=3', 'trainer.devices=2', 'trainer.strategy=ddp', 'data.batch_size=50']
Traceback (most recent call last):
  File "/data/home/acw572/hgann/HGANN/src/train.py", line 197, in <module>
    main()
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
    raise ex
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           ^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            ^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/_internal/hydra.py", line 132, in run
    _ = ret.return_value
        ^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/core/utils.py", line 260, in return_value
    raise self._return_value
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
                       ^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/hgann/HGANN/src/train.py", line 181, in main
    metrics,_ = train(cfg)
                ^^^^^^^^^^
  File "/data/home/acw572/hgann/HGANN/src/utils/utils.py", line 111, in wrap
    raise ex
  File "/data/home/acw572/hgann/HGANN/src/utils/utils.py", line 101, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
                               ^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/hgann/HGANN/src/train.py", line 115, in train
    trainer.fit(model=model, datamodule=datamodule)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 102, in launch
    return function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 989, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1035, in _run_stage
    self.fit_loop.run()
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 202, in run
    self.advance()
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 359, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 137, in run
    self.on_advance_end(data_fetcher)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 285, in on_advance_end
    self.val_loop.run()
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 141, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 253, in on_run_end
    self._on_evaluation_epoch_end()
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 329, in _on_evaluation_epoch_end
    call._call_lightning_module_hook(trainer, hook_name)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/hgann/HGANN/src/models/tagging_module_test.py", line 176, in on_validation_epoch_end
    self.val_mAP_best(metric_dict['mAP'], sync_dist=True)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/torchmetrics/metric.py", line 309, in forward
    self._forward_cache = self._forward_full_state_update(*args, **kwargs)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/torchmetrics/metric.py", line 324, in _forward_full_state_update
    self.update(*args, **kwargs)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/torchmetrics/metric.py", line 482, in wrapped_func
    update(*args, **kwargs)
TypeError: MaxMetric.update() got an unexpected keyword argument 'sync_dist'
[[36m2024-08-15 16:01:13,212[0m][[34mutils.utils[0m][[31mERROR[0m] - [rank: 0] [0m
Traceback (most recent call last):
  File "/data/home/acw572/hgann/HGANN/src/utils/utils.py", line 101, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
                               ^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/hgann/HGANN/src/train.py", line 115, in train
    trainer.fit(model=model, datamodule=datamodule)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 102, in launch
    return function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 989, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1035, in _run_stage
    self.fit_loop.run()
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 202, in run
    self.advance()
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 359, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 137, in run
    self.on_advance_end(data_fetcher)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 285, in on_advance_end
    self.val_loop.run()
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 141, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 253, in on_run_end
    self._on_evaluation_epoch_end()
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 329, in _on_evaluation_epoch_end
    call._call_lightning_module_hook(trainer, hook_name)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/hgann/HGANN/src/models/tagging_module_test.py", line 176, in on_validation_epoch_end
    self.val_mAP_best(metric_dict['mAP'], sync_dist=True)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/torchmetrics/metric.py", line 309, in forward
    self._forward_cache = self._forward_full_state_update(*args, **kwargs)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/torchmetrics/metric.py", line 324, in _forward_full_state_update
    self.update(*args, **kwargs)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/torchmetrics/metric.py", line 482, in wrapped_func
    update(*args, **kwargs)
TypeError: MaxMetric.update() got an unexpected keyword argument 'sync_dist'
[[36m2024-08-15 16:01:13,224[0m][[34mutils.utils[0m][[32mINFO[0m] - [rank: 0] Output dir: /data/scratch/acw572/LHGNN/logs/train/runs/2024-08-15_15-46-14[0m
[[36m2024-08-15 16:01:13,225[0m][[34mutils.utils[0m][[32mINFO[0m] - [rank: 0] Closing wandb![0m
wandb: - 0.007 MB of 0.007 MB uploadedwandb: \ 0.007 MB of 0.007 MB uploadedwandb: | 0.007 MB of 0.007 MB uploadedwandb: / 0.007 MB of 0.007 MB uploadedwandb: - 0.029 MB of 0.042 MB uploaded (0.002 MB deduped)wandb: \ 0.029 MB of 0.042 MB uploaded (0.002 MB deduped)wandb: | 0.107 MB of 0.107 MB uploaded (0.002 MB deduped)wandb:                                                                                
wandb: W&B sync reduced upload amount by 1.4%             
wandb: 
wandb: Run history:
wandb:               epoch â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     train/loss_step â–ˆâ–…â–ƒâ–â–â–â–â–â–â–â–â–â–â–
wandb: trainer/global_step â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–‡â–‡â–ˆ
wandb: 
wandb: Run summary:
wandb:               epoch 0
wandb:     train/loss_step 0.03587
wandb: trainer/global_step 699
wandb: 
wandb: ğŸš€ View run bright-totem-50 at: https://wandb.ai/shubhr/audioset-bal/runs/yw9alst8
wandb: ï¸âš¡ View job at https://wandb.ai/shubhr/audioset-bal/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjI0NzQ3OTYxNA==/version_details/v5
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: /data/scratch/acw572/LHGNN/logs/train/runs/2024-08-15_15-46-14/wandb/run-20240815_154645-yw9alst8/logs
Error executing job with overrides: ['trainer.max_epochs=5', 'trainer.min_epochs=3', 'trainer.devices=2', 'trainer.strategy=ddp', 'data.batch_size=50']
Traceback (most recent call last):
  File "/data/home/acw572/hgann/HGANN/src/train.py", line 197, in <module>
    main()
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
    raise ex
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           ^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            ^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/_internal/hydra.py", line 132, in run
    _ = ret.return_value
        ^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/core/utils.py", line 260, in return_value
    raise self._return_value
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
                       ^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/hgann/HGANN/src/train.py", line 181, in main
    metrics,_ = train(cfg)
                ^^^^^^^^^^
  File "/data/home/acw572/hgann/HGANN/src/utils/utils.py", line 111, in wrap
    raise ex
  File "/data/home/acw572/hgann/HGANN/src/utils/utils.py", line 101, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
                               ^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/hgann/HGANN/src/train.py", line 115, in train
    trainer.fit(model=model, datamodule=datamodule)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 102, in launch
    return function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 989, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1035, in _run_stage
    self.fit_loop.run()
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 202, in run
    self.advance()
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 359, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 137, in run
    self.on_advance_end(data_fetcher)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 285, in on_advance_end
    self.val_loop.run()
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 141, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 253, in on_run_end
    self._on_evaluation_epoch_end()
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 329, in _on_evaluation_epoch_end
    call._call_lightning_module_hook(trainer, hook_name)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/hgann/HGANN/src/models/tagging_module_test.py", line 176, in on_validation_epoch_end
    self.val_mAP_best(metric_dict['mAP'], sync_dist=True)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/torchmetrics/metric.py", line 309, in forward
    self._forward_cache = self._forward_full_state_update(*args, **kwargs)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/torchmetrics/metric.py", line 324, in _forward_full_state_update
    self.update(*args, **kwargs)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/torchmetrics/metric.py", line 482, in wrapped_func
    update(*args, **kwargs)
TypeError: MaxMetric.update() got an unexpected keyword argument 'sync_dist'
