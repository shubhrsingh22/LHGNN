Variable OMP_NUM_THREADS has been set to 24
--------------------
Hostname: rdg1
Thu Aug 15 15:45:22 BST 2024
Free GPU: 1 of 2
--------------------
GPU0: [92mNot in use.[39m
GPU1: [92mNot in use.[39m

User: [91macw572[39m JobID: [91m3795004[39m GPU Allocation: [91m2[39m Queue: [91mshort.q[39m
User: [91macw676[39m JobID: [91m3794933[39m GPU Allocation: [91m0[39m Queue: [91mshort.q[39m
[91mWarning! GPUs requested but not used![39m
In main
[[36m2024-08-15 15:46:14,553[0m][[34mutils.utils[0m][[32mINFO[0m] - [rank: 0] Enforcing tags! <cfg.extras.enforce_tags=True>[0m
[[36m2024-08-15 15:46:14,560[0m][[34mutils.utils[0m][[32mINFO[0m] - [rank: 0] Printing config tree with Rich! <cfg.extras.print_config=True>[0m
CONFIG
├── data
│   └── _target_: src.data.fsd_datamodule.FSDDataModule                         
│       json_path: /data/scratch/acw572/LHGNN/datafiles/                        
│       data_dir: /data/EECS-MachineListeningLab/datasets/AudioSet              
│       meta_path: /data/EECS-MachineListeningLab/datasets/AudioSet/ground_truth
│       label_csv_pth: /data/scratch/acw572/LHGNN/datafiles/class_labels_indices
│       samplr_csv_pth: /data/scratch/acw572/LHGNN/datafiles/fsd50k_tr_full_weig
│       balance_samplr: true                                                    
│       batch_size: 50                                                          
│       num_workers: 8                                                          
│       pin_memory: true                                                        
│       persistent_workers: true                                                
│       sr: 16000                                                               
│       fmin: 20                                                                
│       fmax: 8000                                                              
│       num_mels: 128                                                           
│       window_type: hanning                                                    
│       target_len: 1024                                                        
│       freqm: 48                                                               
│       timem: 192                                                              
│       mixup: 0.5                                                              
│       norm_mean: -4.6476                                                      
│       norm_std: 4.5699                                                        
│       num_devices: 2                                                          
│                                                                               
├── model
│   └── _target_: src.models.tagging_module_test.TaggingModule                  
│       optimizer:                                                              
│         _target_: torch.optim.Adam                                            
│         _partial_: true                                                       
│         lr: 0.0005                                                            
│         weight_decay: 5.0e-07                                                 
│         eps: 1.0e-08                                                          
│         betas:                                                                
│         - 0.95                                                                
│         - 0.999                                                               
│       scheduler:                                                              
│         _target_: torch.optim.lr_scheduler.MultiStepLR                        
│         _partial_: true                                                       
│         milestones:                                                           
│         - 10                                                                  
│         - 15                                                                  
│         - 20                                                                  
│         - 25                                                                  
│         - 30                                                                  
│         - 35                                                                  
│         - 40                                                                  
│         gamma: 0.5                                                            
│       net:                                                                    
│         _target_: src.models.components.Hypergraph.HGCN                       
│         k: 25                                                                 
│         act: gelu                                                             
│         norm: batch                                                           
│         bias: true                                                            
│         dropout: 0.0                                                          
│         dilation: true                                                        
│         epsilon: 0.2                                                          
│         drop_path: 0.1                                                        
│         size: s                                                               
│         num_class: 200                                                        
│         emb_dims: 1024                                                        
│         freq_num: 128                                                         
│         time_num: 1024                                                        
│       compile: false                                                          
│       loss: bce                                                               
│       opt_warmup: true                                                        
│       learning_rate: 0.0005                                                   
│       lr_rate:                                                                
│       - 0.05                                                                  
│       - 0.02                                                                  
│       - 0.01                                                                  
│       - 0.005                                                                 
│       - 0.002                                                                 
│       - 0.001                                                                 
│       - 0.0005                                                                
│       - 0.0002                                                                
│       lr_scheduler_epoch:                                                     
│       - 10                                                                    
│       - 15                                                                    
│       - 20                                                                    
│       - 25                                                                    
│       - 30                                                                    
│       - 35                                                                    
│       - 50                                                                    
│       - 45                                                                    
│                                                                               
├── callbacks
│   └── model_checkpoint:                                                       
│         _target_: pytorch_lightning.callbacks.ModelCheckpoint                 
│         dirpath: /data/scratch/acw572/LHGNN/logs/train/runs/2024-08-15_15-46-1
│         filename: epoch_{epoch:03d}                                           
│         monitor: val/mAP                                                      
│         verbose: false                                                        
│         save_last: true                                                       
│         save_top_k: 20                                                        
│         mode: max                                                             
│         auto_insert_metric_name: false                                        
│         save_weights_only: false                                              
│         every_n_train_steps: null                                             
│         train_time_interval: null                                             
│         every_n_epochs: null                                                  
│         save_on_train_epoch_end: null                                         
│       early_stopping:                                                         
│         _target_: pytorch_lightning.callbacks.EarlyStopping                   
│         monitor: val/loss                                                     
│         min_delta: 0.0                                                        
│         patience: 5                                                           
│         verbose: false                                                        
│         mode: min                                                             
│         strict: true                                                          
│         check_finite: true                                                    
│         stopping_threshold: null                                              
│         divergence_threshold: null                                            
│         check_on_train_epoch_end: null                                        
│       model_summary:                                                          
│         _target_: pytorch_lightning.callbacks.RichModelSummary                
│         max_depth: -1                                                         
│       tqdm_progress_bar:                                                      
│         _target_: pytorch_lightning.callbacks.TQDMProgressBar                 
│                                                                               
├── logger
│   └── wandb:                                                                  
│         _target_: pytorch_lightning.loggers.WandbLogger                       
│         save_dir: /data/scratch/acw572/LHGNN/logs/train/runs/2024-08-15_15-46-
│         offline: false                                                        
│         id: null                                                              
│         anonymous: null                                                       
│         project: audioset-bal                                                 
│         log_model: false                                                      
│         prefix: ''                                                            
│         group: Tagging                                                        
│         tags:                                                                 
│         - fsd                                                                 
│         - hgcn                                                                
│         job_type: ''                                                          
│                                                                               
├── trainer
│   └── _target_: pytorch_lightning.trainer.Trainer                             
│       default_root_dir: /data/scratch/acw572/LHGNN/logs/train/runs/2024-08-15_
│       num_sanity_val_steps: 0                                                 
│       min_epochs: 3                                                           
│       max_epochs: 5                                                           
│       accelerator: gpu                                                        
│       devices: 2                                                              
│       gradient_clip_val: 0.5                                                  
│       precision: 32                                                           
│       detect_anomaly: false                                                   
│       check_val_every_n_epoch: 1                                              
│       deterministic: false                                                    
│       strategy: ddp                                                           
│       num_nodes: 1                                                            
│       sync_batchnorm: false                                                   
│       use_distributed_sampler: false                                          
│                                                                               
├── paths
│   └── root_dir: /data/home/acw572/hgann/HGANN                                 
│       exp_dir: /data/scratch/acw572                                           
│       data_dir: /data/EECS-MachineListeningLab/datasets/AudioSet              
│       meta_dir: /data/EECS-MachineListeningLab/shubhr/hgann                   
│       log_dir: /data/scratch/acw572/LHGNN/logs/                               
│       output_dir: /data/scratch/acw572/LHGNN/logs/train/runs/2024-08-15_15-46-
│       work_dir: /data/home/acw572/hgann/HGANN                                 
│                                                                               
├── extras
│   └── ignore_warnings: false                                                  
│       enforce_tags: true                                                      
│       print_config: true                                                      
│                                                                               
├── task_name
│   └── train                                                                   
├── pretrained
│   └── img                                                                     
├── tags
│   └── ['dev']                                                                 
├── train
│   └── True                                                                    
├── eval
│   └── True                                                                    
├── wa
│   └── True                                                                    
├── ckpt_path
│   └── /data/EECS-MachineListeningLab/shubhr/imagenet_weights/model_best.pth.ta
└── seed
    └── None                                                                    
[[36m2024-08-15 15:46:14,685[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] In train[0m
[[36m2024-08-15 15:46:14,685[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating datamodule <src.data.fsd_datamodule.FSDDataModule>[0m
[[36m2024-08-15 15:46:16,266[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating model <src.models.tagging_module_test.TaggingModule>[0m
/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/utilities/parsing.py:198: Attribute 'net' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['net'])`.
norm is batch
bias is True
drop_path is 0.1
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
[[36m2024-08-15 15:46:43,045[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Loading img pretrained weights[0m
[[36m2024-08-15 15:46:43,045[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating callbacks...[0m
[[36m2024-08-15 15:46:43,045[0m][[34mutils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>[0m
[[36m2024-08-15 15:46:43,048[0m][[34mutils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <pytorch_lightning.callbacks.EarlyStopping>[0m
[[36m2024-08-15 15:46:43,049[0m][[34mutils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>[0m
[[36m2024-08-15 15:46:43,049[0m][[34mutils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <pytorch_lightning.callbacks.TQDMProgressBar>[0m
[[36m2024-08-15 15:46:43,050[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating loggers...[0m
[[36m2024-08-15 15:46:43,050[0m][[34mutils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating logger <pytorch_lightning.loggers.WandbLogger>[0m
[[36m2024-08-15 15:46:43,292[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating trainer <pytorch_lightning.trainer.Trainer>[0m
Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[[36m2024-08-15 15:46:43,475[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Logging hyperparameters![0m
wandb: Currently logged in as: shubhr. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.6 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.1
wandb: Run data is saved locally in /data/scratch/acw572/LHGNN/logs/train/runs/2024-08-15_15-46-14/wandb/run-20240815_154645-yw9alst8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-totem-50
wandb: ⭐️ View project at https://wandb.ai/shubhr/audioset-bal
wandb: 🚀 View run at https://wandb.ai/shubhr/audioset-bal/runs/yw9alst8
[[36m2024-08-15 15:47:03,565[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Starting training![0m
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━┳━━┓
┃   ┃ Name                                                              ┃ … ┃  ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━╇━━┩
│ 0 │ net                                                               │ … │  │
│ 1 │ net.stem                                                          │ … │  │
│ 2 │ net.stem.convs                                                    │ … │  │
│ 3 │ net.stem.convs.0                                                  │ … │  │
│ 4 │ net.stem.convs.1                                                  │ … │  │
│ 5 │ net.stem.convs.2                                                  │ … │  │
│ 6 │ net.stem.convs.3                                                  │ … │  │
│ 7 │ net.stem.convs.4                                                  │ … │  │
│ 8 │ net.stem.convs.5                                                  │ … │  │
│ 9 │ net.stem.convs.6                                                  │ … │  │
│ … │ net.stem.convs.7                                                  │ … │  │
│ … │ net.backbone                                                      │ … │  │
│ … │ net.backbone.0                                                    │ … │  │
│ … │ net.backbone.0.0                                                  │ … │  │
│ … │ net.backbone.0.0.fc1                                              │ … │  │
│ … │ net.backbone.0.0.fc1.0                                            │ … │  │
│ … │ net.backbone.0.0.fc1.1                                            │ … │  │
│ … │ net.backbone.0.0.graph_conv                                       │ … │  │
│ … │ net.backbone.0.0.graph_conv.gconv                                 │ … │  │
│ … │ net.backbone.0.0.graph_conv.gconv.nn                              │ … │  │
│ … │ net.backbone.0.0.graph_conv.gconv.nn.0                            │ … │  │
│ … │ net.backbone.0.0.graph_conv.gconv.nn.1                            │ … │  │
│ … │ net.backbone.0.0.graph_conv.gconv.nn.2                            │ … │  │
│ … │ net.backbone.0.0.graph_conv.gconv.get_centroids                   │ … │  │
│ … │ net.backbone.0.0.graph_conv.gconv.get_centroids.centers_proposal  │ … │  │
│ … │ net.backbone.0.0.graph_conv.dilated_knn_graph                     │ … │  │
│ … │ net.backbone.0.0.graph_conv.dilated_knn_graph._dilated            │ … │  │
│ … │ net.backbone.0.0.fc2                                              │ … │  │
│ … │ net.backbone.0.0.fc2.0                                            │ … │  │
│ … │ net.backbone.0.0.fc2.1                                            │ … │  │
│ … │ net.backbone.0.0.drop_path                                        │ … │  │
│ … │ net.backbone.0.1                                                  │ … │  │
│ … │ net.backbone.0.1.fc1                                              │ … │  │
│ … │ net.backbone.0.1.fc1.0                                            │ … │  │
│ … │ net.backbone.0.1.fc1.1                                            │ … │  │
│ … │ net.backbone.0.1.act                                              │ … │  │
│ … │ net.backbone.0.1.fc2                                              │ … │  │
│ … │ net.backbone.0.1.fc2.0                                            │ … │  │
│ … │ net.backbone.0.1.fc2.1                                            │ … │  │
│ … │ net.backbone.0.1.conv                                             │ … │  │
│ … │ net.backbone.0.1.conv.conv                                        │ … │  │
│ … │ net.backbone.0.1.drop_path                                        │ … │  │
│ … │ net.backbone.1                                                    │ … │  │
│ … │ net.backbone.1.0                                                  │ … │  │
│ … │ net.backbone.1.0.fc1                                              │ … │  │
│ … │ net.backbone.1.0.fc1.0                                            │ … │  │
│ … │ net.backbone.1.0.fc1.1                                            │ … │  │
│ … │ net.backbone.1.0.graph_conv                                       │ … │  │
│ … │ net.backbone.1.0.graph_conv.gconv                                 │ … │  │
│ … │ net.backbone.1.0.graph_conv.gconv.nn                              │ … │  │
│ … │ net.backbone.1.0.graph_conv.gconv.nn.0                            │ … │  │
│ … │ net.backbone.1.0.graph_conv.gconv.nn.1                            │ … │  │
│ … │ net.backbone.1.0.graph_conv.gconv.nn.2                            │ … │  │
│ … │ net.backbone.1.0.graph_conv.gconv.get_centroids                   │ … │  │
│ … │ net.backbone.1.0.graph_conv.gconv.get_centroids.centers_proposal  │ … │  │
│ … │ net.backbone.1.0.graph_conv.dilated_knn_graph                     │ … │  │
│ … │ net.backbone.1.0.graph_conv.dilated_knn_graph._dilated            │ … │  │
│ … │ net.backbone.1.0.fc2                                              │ … │  │
│ … │ net.backbone.1.0.fc2.0                                            │ … │  │
│ … │ net.backbone.1.0.fc2.1                                            │ … │  │
│ … │ net.backbone.1.0.drop_path                                        │ … │  │
│ … │ net.backbone.1.1                                                  │ … │  │
│ … │ net.backbone.1.1.fc1                                              │ … │  │
│ … │ net.backbone.1.1.fc1.0                                            │ … │  │
│ … │ net.backbone.1.1.fc1.1                                            │ … │  │
│ … │ net.backbone.1.1.act                                              │ … │  │
│ … │ net.backbone.1.1.fc2                                              │ … │  │
│ … │ net.backbone.1.1.fc2.0                                            │ … │  │
│ … │ net.backbone.1.1.fc2.1                                            │ … │  │
│ … │ net.backbone.1.1.conv                                             │ … │  │
│ … │ net.backbone.1.1.conv.conv                                        │ … │  │
│ … │ net.backbone.1.1.drop_path                                        │ … │  │
│ … │ net.backbone.2                                                    │ … │  │
│ … │ net.backbone.2.conv                                               │ … │  │
│ … │ net.backbone.2.conv.0                                             │ … │  │
│ … │ net.backbone.2.conv.1                                             │ … │  │
│ … │ net.backbone.3                                                    │ … │  │
│ … │ net.backbone.3.0                                                  │ … │  │
│ … │ net.backbone.3.0.fc1                                              │ … │  │
│ … │ net.backbone.3.0.fc1.0                                            │ … │  │
│ … │ net.backbone.3.0.fc1.1                                            │ … │  │
│ … │ net.backbone.3.0.graph_conv                                       │ … │  │
│ … │ net.backbone.3.0.graph_conv.gconv                                 │ … │  │
│ … │ net.backbone.3.0.graph_conv.gconv.nn                              │ … │  │
│ … │ net.backbone.3.0.graph_conv.gconv.nn.0                            │ … │  │
│ … │ net.backbone.3.0.graph_conv.gconv.nn.1                            │ … │  │
│ … │ net.backbone.3.0.graph_conv.gconv.nn.2                            │ … │  │
│ … │ net.backbone.3.0.graph_conv.gconv.get_centroids                   │ … │  │
│ … │ net.backbone.3.0.graph_conv.gconv.get_centroids.centers_proposal  │ … │  │
│ … │ net.backbone.3.0.graph_conv.dilated_knn_graph                     │ … │  │
│ … │ net.backbone.3.0.graph_conv.dilated_knn_graph._dilated            │ … │  │
│ … │ net.backbone.3.0.fc2                                              │ … │  │
│ … │ net.backbone.3.0.fc2.0                                            │ … │  │
│ … │ net.backbone.3.0.fc2.1                                            │ … │  │
│ … │ net.backbone.3.0.drop_path                                        │ … │  │
│ … │ net.backbone.3.1                                                  │ … │  │
│ … │ net.backbone.3.1.fc1                                              │ … │  │
│ … │ net.backbone.3.1.fc1.0                                            │ … │  │
│ … │ net.backbone.3.1.fc1.1                                            │ … │  │
│ … │ net.backbone.3.1.act                                              │ … │  │
│ … │ net.backbone.3.1.fc2                                              │ … │  │
│ … │ net.backbone.3.1.fc2.0                                            │ … │  │
│ … │ net.backbone.3.1.fc2.1                                            │ … │  │
│ … │ net.backbone.3.1.conv                                             │ … │  │
│ … │ net.backbone.3.1.conv.conv                                        │ … │  │
│ … │ net.backbone.3.1.drop_path                                        │ … │  │
│ … │ net.backbone.4                                                    │ … │  │
│ … │ net.backbone.4.0                                                  │ … │  │
│ … │ net.backbone.4.0.fc1                                              │ … │  │
│ … │ net.backbone.4.0.fc1.0                                            │ … │  │
│ … │ net.backbone.4.0.fc1.1                                            │ … │  │
│ … │ net.backbone.4.0.graph_conv                                       │ … │  │
│ … │ net.backbone.4.0.graph_conv.gconv                                 │ … │  │
│ … │ net.backbone.4.0.graph_conv.gconv.nn                              │ … │  │
│ … │ net.backbone.4.0.graph_conv.gconv.nn.0                            │ … │  │
│ … │ net.backbone.4.0.graph_conv.gconv.nn.1                            │ … │  │
│ … │ net.backbone.4.0.graph_conv.gconv.nn.2                            │ … │  │
│ … │ net.backbone.4.0.graph_conv.gconv.get_centroids                   │ … │  │
│ … │ net.backbone.4.0.graph_conv.gconv.get_centroids.centers_proposal  │ … │  │
│ … │ net.backbone.4.0.graph_conv.dilated_knn_graph                     │ … │  │
│ … │ net.backbone.4.0.graph_conv.dilated_knn_graph._dilated            │ … │  │
│ … │ net.backbone.4.0.fc2                                              │ … │  │
│ … │ net.backbone.4.0.fc2.0                                            │ … │  │
│ … │ net.backbone.4.0.fc2.1                                            │ … │  │
│ … │ net.backbone.4.0.drop_path                                        │ … │  │
│ … │ net.backbone.4.1                                                  │ … │  │
│ … │ net.backbone.4.1.fc1                                              │ … │  │
│ … │ net.backbone.4.1.fc1.0                                            │ … │  │
│ … │ net.backbone.4.1.fc1.1                                            │ … │  │
│ … │ net.backbone.4.1.act                                              │ … │  │
│ … │ net.backbone.4.1.fc2                                              │ … │  │
│ … │ net.backbone.4.1.fc2.0                                            │ … │  │
│ … │ net.backbone.4.1.fc2.1                                            │ … │  │
│ … │ net.backbone.4.1.conv                                             │ … │  │
│ … │ net.backbone.4.1.conv.conv                                        │ … │  │
│ … │ net.backbone.4.1.drop_path                                        │ … │  │
│ … │ net.backbone.5                                                    │ … │  │
│ … │ net.backbone.5.conv                                               │ … │  │
│ … │ net.backbone.5.conv.0                                             │ … │  │
│ … │ net.backbone.5.conv.1                                             │ … │  │
│ … │ net.backbone.6                                                    │ … │  │
│ … │ net.backbone.6.0                                                  │ … │  │
│ … │ net.backbone.6.0.fc1                                              │ … │  │
│ … │ net.backbone.6.0.fc1.0                                            │ … │  │
│ … │ net.backbone.6.0.fc1.1                                            │ … │  │
│ … │ net.backbone.6.0.graph_conv                                       │ … │  │
│ … │ net.backbone.6.0.graph_conv.gconv                                 │ … │  │
│ … │ net.backbone.6.0.graph_conv.gconv.nn                              │ … │  │
│ … │ net.backbone.6.0.graph_conv.gconv.nn.0                            │ … │  │
│ … │ net.backbone.6.0.graph_conv.gconv.nn.1                            │ … │  │
│ … │ net.backbone.6.0.graph_conv.gconv.nn.2                            │ … │  │
│ … │ net.backbone.6.0.graph_conv.gconv.get_centroids                   │ … │  │
│ … │ net.backbone.6.0.graph_conv.gconv.get_centroids.centers_proposal  │ … │  │
│ … │ net.backbone.6.0.graph_conv.dilated_knn_graph                     │ … │  │
│ … │ net.backbone.6.0.graph_conv.dilated_knn_graph._dilated            │ … │  │
│ … │ net.backbone.6.0.fc2                                              │ … │  │
│ … │ net.backbone.6.0.fc2.0                                            │ … │  │
│ … │ net.backbone.6.0.fc2.1                                            │ … │  │
│ … │ net.backbone.6.0.drop_path                                        │ … │  │
│ … │ net.backbone.6.1                                                  │ … │  │
│ … │ net.backbone.6.1.fc1                                              │ … │  │
│ … │ net.backbone.6.1.fc1.0                                            │ … │  │
│ … │ net.backbone.6.1.fc1.1                                            │ … │  │
│ … │ net.backbone.6.1.act                                              │ … │  │
│ … │ net.backbone.6.1.fc2                                              │ … │  │
│ … │ net.backbone.6.1.fc2.0                                            │ … │  │
│ … │ net.backbone.6.1.fc2.1                                            │ … │  │
│ … │ net.backbone.6.1.conv                                             │ … │  │
│ … │ net.backbone.6.1.conv.conv                                        │ … │  │
│ … │ net.backbone.6.1.drop_path                                        │ … │  │
│ … │ net.backbone.7                                                    │ … │  │
│ … │ net.backbone.7.0                                                  │ … │  │
│ … │ net.backbone.7.0.fc1                                              │ … │  │
│ … │ net.backbone.7.0.fc1.0                                            │ … │  │
│ … │ net.backbone.7.0.fc1.1                                            │ … │  │
│ … │ net.backbone.7.0.graph_conv                                       │ … │  │
│ … │ net.backbone.7.0.graph_conv.gconv                                 │ … │  │
│ … │ net.backbone.7.0.graph_conv.gconv.nn                              │ … │  │
│ … │ net.backbone.7.0.graph_conv.gconv.nn.0                            │ … │  │
│ … │ net.backbone.7.0.graph_conv.gconv.nn.1                            │ … │  │
│ … │ net.backbone.7.0.graph_conv.gconv.nn.2                            │ … │  │
│ … │ net.backbone.7.0.graph_conv.gconv.get_centroids                   │ … │  │
│ … │ net.backbone.7.0.graph_conv.gconv.get_centroids.centers_proposal  │ … │  │
│ … │ net.backbone.7.0.graph_conv.dilated_knn_graph                     │ … │  │
│ … │ net.backbone.7.0.graph_conv.dilated_knn_graph._dilated            │ … │  │
│ … │ net.backbone.7.0.fc2                                              │ … │  │
│ … │ net.backbone.7.0.fc2.0                                            │ … │  │
│ … │ net.backbone.7.0.fc2.1                                            │ … │  │
│ … │ net.backbone.7.0.drop_path                                        │ … │  │
│ … │ net.backbone.7.1                                                  │ … │  │
│ … │ net.backbone.7.1.fc1                                              │ … │  │
│ … │ net.backbone.7.1.fc1.0                                            │ … │  │
│ … │ net.backbone.7.1.fc1.1                                            │ … │  │
│ … │ net.backbone.7.1.act                                              │ … │  │
│ … │ net.backbone.7.1.fc2                                              │ … │  │
│ … │ net.backbone.7.1.fc2.0                                            │ … │  │
│ … │ net.backbone.7.1.fc2.1                                            │ … │  │
│ … │ net.backbone.7.1.conv                                             │ … │  │
│ … │ net.backbone.7.1.conv.conv                                        │ … │  │
│ … │ net.backbone.7.1.drop_path                                        │ … │  │
│ … │ net.backbone.8                                                    │ … │  │
│ … │ net.backbone.8.0                                                  │ … │  │
│ … │ net.backbone.8.0.fc1                                              │ … │  │
│ … │ net.backbone.8.0.fc1.0                                            │ … │  │
│ … │ net.backbone.8.0.fc1.1                                            │ … │  │
│ … │ net.backbone.8.0.graph_conv                                       │ … │  │
│ … │ net.backbone.8.0.graph_conv.gconv                                 │ … │  │
│ … │ net.backbone.8.0.graph_conv.gconv.nn                              │ … │  │
│ … │ net.backbone.8.0.graph_conv.gconv.nn.0                            │ … │  │
│ … │ net.backbone.8.0.graph_conv.gconv.nn.1                            │ … │  │
│ … │ net.backbone.8.0.graph_conv.gconv.nn.2                            │ … │  │
│ … │ net.backbone.8.0.graph_conv.gconv.get_centroids                   │ … │  │
│ … │ net.backbone.8.0.graph_conv.gconv.get_centroids.centers_proposal  │ … │  │
│ … │ net.backbone.8.0.graph_conv.dilated_knn_graph                     │ … │  │
│ … │ net.backbone.8.0.graph_conv.dilated_knn_graph._dilated            │ … │  │
│ … │ net.backbone.8.0.fc2                                              │ … │  │
│ … │ net.backbone.8.0.fc2.0                                            │ … │  │
│ … │ net.backbone.8.0.fc2.1                                            │ … │  │
│ … │ net.backbone.8.0.drop_path                                        │ … │  │
│ … │ net.backbone.8.1                                                  │ … │  │
│ … │ net.backbone.8.1.fc1                                              │ … │  │
│ … │ net.backbone.8.1.fc1.0                                            │ … │  │
│ … │ net.backbone.8.1.fc1.1                                            │ … │  │
│ … │ net.backbone.8.1.act                                              │ … │  │
│ … │ net.backbone.8.1.fc2                                              │ … │  │
│ … │ net.backbone.8.1.fc2.0                                            │ … │  │
│ … │ net.backbone.8.1.fc2.1                                            │ … │  │
│ … │ net.backbone.8.1.conv                                             │ … │  │
│ … │ net.backbone.8.1.conv.conv                                        │ … │  │
│ … │ net.backbone.8.1.drop_path                                        │ … │  │
│ … │ net.backbone.9                                                    │ … │  │
│ … │ net.backbone.9.0                                                  │ … │  │
│ … │ net.backbone.9.0.fc1                                              │ … │  │
│ … │ net.backbone.9.0.fc1.0                                            │ … │  │
│ … │ net.backbone.9.0.fc1.1                                            │ … │  │
│ … │ net.backbone.9.0.graph_conv                                       │ … │  │
│ … │ net.backbone.9.0.graph_conv.gconv                                 │ … │  │
│ … │ net.backbone.9.0.graph_conv.gconv.nn                              │ … │  │
│ … │ net.backbone.9.0.graph_conv.gconv.nn.0                            │ … │  │
│ … │ net.backbone.9.0.graph_conv.gconv.nn.1                            │ … │  │
│ … │ net.backbone.9.0.graph_conv.gconv.nn.2                            │ … │  │
│ … │ net.backbone.9.0.graph_conv.gconv.get_centroids                   │ … │  │
│ … │ net.backbone.9.0.graph_conv.gconv.get_centroids.centers_proposal  │ … │  │
│ … │ net.backbone.9.0.graph_conv.dilated_knn_graph                     │ … │  │
│ … │ net.backbone.9.0.graph_conv.dilated_knn_graph._dilated            │ … │  │
│ … │ net.backbone.9.0.fc2                                              │ … │  │
│ … │ net.backbone.9.0.fc2.0                                            │ … │  │
│ … │ net.backbone.9.0.fc2.1                                            │ … │  │
│ … │ net.backbone.9.0.drop_path                                        │ … │  │
│ … │ net.backbone.9.1                                                  │ … │  │
│ … │ net.backbone.9.1.fc1                                              │ … │  │
│ … │ net.backbone.9.1.fc1.0                                            │ … │  │
│ … │ net.backbone.9.1.fc1.1                                            │ … │  │
│ … │ net.backbone.9.1.act                                              │ … │  │
│ … │ net.backbone.9.1.fc2                                              │ … │  │
│ … │ net.backbone.9.1.fc2.0                                            │ … │  │
│ … │ net.backbone.9.1.fc2.1                                            │ … │  │
│ … │ net.backbone.9.1.conv                                             │ … │  │
│ … │ net.backbone.9.1.conv.conv                                        │ … │  │
│ … │ net.backbone.9.1.drop_path                                        │ … │  │
│ … │ net.backbone.10                                                   │ … │  │
│ … │ net.backbone.10.0                                                 │ … │  │
│ … │ net.backbone.10.0.fc1                                             │ … │  │
│ … │ net.backbone.10.0.fc1.0                                           │ … │  │
│ … │ net.backbone.10.0.fc1.1                                           │ … │  │
│ … │ net.backbone.10.0.graph_conv                                      │ … │  │
│ … │ net.backbone.10.0.graph_conv.gconv                                │ … │  │
│ … │ net.backbone.10.0.graph_conv.gconv.nn                             │ … │  │
│ … │ net.backbone.10.0.graph_conv.gconv.nn.0                           │ … │  │
│ … │ net.backbone.10.0.graph_conv.gconv.nn.1                           │ … │  │
│ … │ net.backbone.10.0.graph_conv.gconv.nn.2                           │ … │  │
│ … │ net.backbone.10.0.graph_conv.gconv.get_centroids                  │ … │  │
│ … │ net.backbone.10.0.graph_conv.gconv.get_centroids.centers_proposal │ … │  │
│ … │ net.backbone.10.0.graph_conv.dilated_knn_graph                    │ … │  │
│ … │ net.backbone.10.0.graph_conv.dilated_knn_graph._dilated           │ … │  │
│ … │ net.backbone.10.0.fc2                                             │ … │  │
│ … │ net.backbone.10.0.fc2.0                                           │ … │  │
│ … │ net.backbone.10.0.fc2.1                                           │ … │  │
│ … │ net.backbone.10.0.drop_path                                       │ … │  │
│ … │ net.backbone.10.1                                                 │ … │  │
│ … │ net.backbone.10.1.fc1                                             │ … │  │
│ … │ net.backbone.10.1.fc1.0                                           │ … │  │
│ … │ net.backbone.10.1.fc1.1                                           │ … │  │
│ … │ net.backbone.10.1.act                                             │ … │  │
│ … │ net.backbone.10.1.fc2                                             │ … │  │
│ … │ net.backbone.10.1.fc2.0                                           │ … │  │
│ … │ net.backbone.10.1.fc2.1                                           │ … │  │
│ … │ net.backbone.10.1.conv                                            │ … │  │
│ … │ net.backbone.10.1.conv.conv                                       │ … │  │
│ … │ net.backbone.10.1.drop_path                                       │ … │  │
│ … │ net.backbone.11                                                   │ … │  │
│ … │ net.backbone.11.0                                                 │ … │  │
│ … │ net.backbone.11.0.fc1                                             │ … │  │
│ … │ net.backbone.11.0.fc1.0                                           │ … │  │
│ … │ net.backbone.11.0.fc1.1                                           │ … │  │
│ … │ net.backbone.11.0.graph_conv                                      │ … │  │
│ … │ net.backbone.11.0.graph_conv.gconv                                │ … │  │
│ … │ net.backbone.11.0.graph_conv.gconv.nn                             │ … │  │
│ … │ net.backbone.11.0.graph_conv.gconv.nn.0                           │ … │  │
│ … │ net.backbone.11.0.graph_conv.gconv.nn.1                           │ … │  │
│ … │ net.backbone.11.0.graph_conv.gconv.nn.2                           │ … │  │
│ … │ net.backbone.11.0.graph_conv.gconv.get_centroids                  │ … │  │
│ … │ net.backbone.11.0.graph_conv.gconv.get_centroids.centers_proposal │ … │  │
│ … │ net.backbone.11.0.graph_conv.dilated_knn_graph                    │ … │  │
│ … │ net.backbone.11.0.graph_conv.dilated_knn_graph._dilated           │ … │  │
│ … │ net.backbone.11.0.fc2                                             │ … │  │
│ … │ net.backbone.11.0.fc2.0                                           │ … │  │
│ … │ net.backbone.11.0.fc2.1                                           │ … │  │
│ … │ net.backbone.11.0.drop_path                                       │ … │  │
│ … │ net.backbone.11.1                                                 │ … │  │
│ … │ net.backbone.11.1.fc1                                             │ … │  │
│ … │ net.backbone.11.1.fc1.0                                           │ … │  │
│ … │ net.backbone.11.1.fc1.1                                           │ … │  │
│ … │ net.backbone.11.1.act                                             │ … │  │
│ … │ net.backbone.11.1.fc2                                             │ … │  │
│ … │ net.backbone.11.1.fc2.0                                           │ … │  │
│ … │ net.backbone.11.1.fc2.1                                           │ … │  │
│ … │ net.backbone.11.1.conv                                            │ … │  │
│ … │ net.backbone.11.1.conv.conv                                       │ … │  │
│ … │ net.backbone.11.1.drop_path                                       │ … │  │
│ … │ net.backbone.12                                                   │ … │  │
│ … │ net.backbone.12.conv                                              │ … │  │
│ … │ net.backbone.12.conv.0                                            │ … │  │
│ … │ net.backbone.12.conv.1                                            │ … │  │
│ … │ net.backbone.13                                                   │ … │  │
│ … │ net.backbone.13.0                                                 │ … │  │
│ … │ net.backbone.13.0.fc1                                             │ … │  │
│ … │ net.backbone.13.0.fc1.0                                           │ … │  │
│ … │ net.backbone.13.0.fc1.1                                           │ … │  │
│ … │ net.backbone.13.0.graph_conv                                      │ … │  │
│ … │ net.backbone.13.0.graph_conv.gconv                                │ … │  │
│ … │ net.backbone.13.0.graph_conv.gconv.nn                             │ … │  │
│ … │ net.backbone.13.0.graph_conv.gconv.nn.0                           │ … │  │
│ … │ net.backbone.13.0.graph_conv.gconv.nn.1                           │ … │  │
│ … │ net.backbone.13.0.graph_conv.gconv.nn.2                           │ … │  │
│ … │ net.backbone.13.0.graph_conv.gconv.get_centroids                  │ … │  │
│ … │ net.backbone.13.0.graph_conv.gconv.get_centroids.centers_proposal │ … │  │
│ … │ net.backbone.13.0.graph_conv.dilated_knn_graph                    │ … │  │
│ … │ net.backbone.13.0.graph_conv.dilated_knn_graph._dilated           │ … │  │
│ … │ net.backbone.13.0.fc2                                             │ … │  │
│ … │ net.backbone.13.0.fc2.0                                           │ … │  │
│ … │ net.backbone.13.0.fc2.1                                           │ … │  │
│ … │ net.backbone.13.0.drop_path                                       │ … │  │
│ … │ net.backbone.13.1                                                 │ … │  │
│ … │ net.backbone.13.1.fc1                                             │ … │  │
│ … │ net.backbone.13.1.fc1.0                                           │ … │  │
│ … │ net.backbone.13.1.fc1.1                                           │ … │  │
│ … │ net.backbone.13.1.act                                             │ … │  │
│ … │ net.backbone.13.1.fc2                                             │ … │  │
│ … │ net.backbone.13.1.fc2.0                                           │ … │  │
│ … │ net.backbone.13.1.fc2.1                                           │ … │  │
│ … │ net.backbone.13.1.conv                                            │ … │  │
│ … │ net.backbone.13.1.conv.conv                                       │ … │  │
│ … │ net.backbone.13.1.drop_path                                       │ … │  │
│ … │ net.backbone.14                                                   │ … │  │
│ … │ net.backbone.14.0                                                 │ … │  │
│ … │ net.backbone.14.0.fc1                                             │ … │  │
│ … │ net.backbone.14.0.fc1.0                                           │ … │  │
│ … │ net.backbone.14.0.fc1.1                                           │ … │  │
│ … │ net.backbone.14.0.graph_conv                                      │ … │  │
│ … │ net.backbone.14.0.graph_conv.gconv                                │ … │  │
│ … │ net.backbone.14.0.graph_conv.gconv.nn                             │ … │  │
│ … │ net.backbone.14.0.graph_conv.gconv.nn.0                           │ … │  │
│ … │ net.backbone.14.0.graph_conv.gconv.nn.1                           │ … │  │
│ … │ net.backbone.14.0.graph_conv.gconv.nn.2                           │ … │  │
│ … │ net.backbone.14.0.graph_conv.gconv.get_centroids                  │ … │  │
│ … │ net.backbone.14.0.graph_conv.gconv.get_centroids.centers_proposal │ … │  │
│ … │ net.backbone.14.0.graph_conv.dilated_knn_graph                    │ … │  │
│ … │ net.backbone.14.0.graph_conv.dilated_knn_graph._dilated           │ … │  │
│ … │ net.backbone.14.0.fc2                                             │ … │  │
│ … │ net.backbone.14.0.fc2.0                                           │ … │  │
│ … │ net.backbone.14.0.fc2.1                                           │ … │  │
│ … │ net.backbone.14.0.drop_path                                       │ … │  │
│ … │ net.backbone.14.1                                                 │ … │  │
│ … │ net.backbone.14.1.fc1                                             │ … │  │
│ … │ net.backbone.14.1.fc1.0                                           │ … │  │
│ … │ net.backbone.14.1.fc1.1                                           │ … │  │
│ … │ net.backbone.14.1.act                                             │ … │  │
│ … │ net.backbone.14.1.fc2                                             │ … │  │
│ … │ net.backbone.14.1.fc2.0                                           │ … │  │
│ … │ net.backbone.14.1.fc2.1                                           │ … │  │
│ … │ net.backbone.14.1.conv                                            │ … │  │
│ … │ net.backbone.14.1.conv.conv                                       │ … │  │
│ … │ net.backbone.14.1.drop_path                                       │ … │  │
│ … │ net.prediction                                                    │ … │  │
│ … │ net.prediction.0                                                  │ … │  │
│ … │ net.prediction.1                                                  │ … │  │
│ … │ net.prediction.2                                                  │ … │  │
│ … │ net.prediction.3                                                  │ … │  │
│ … │ net.prediction.4                                                  │ … │  │
│ … │ criterion                                                         │ … │  │
│ … │ train_loss                                                        │ … │  │
│ … │ val_loss                                                          │ … │  │
│ … │ test_loss                                                         │ … │  │
│ … │ val_mAP                                                           │ … │  │
│ … │ test_mAP                                                          │ … │  │
│ … │ val_mAP_best                                                      │ … │  │
└───┴───────────────────────────────────────────────────────────────────┴───┴──┘
Trainable params: 31.1 M                                                        
Non-trainable params: 12.1 M                                                    
Total params: 43.2 M                                                            
Total estimated model params size (MB): 172                                     
In main
norm is batch
bias is True
drop_path is 0.1
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
using relative_pos
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/735 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/735 [00:00<?, ?it/s] hyperparameters: "compile":            False
"learning_rate":      0.0005
"loss":               bce
"lr_rate":            [0.05, 0.02, 0.01, 0.005, 0.002, 0.001, 0.0005, 0.0002]
"lr_scheduler_epoch": [10, 15, 20, 25, 30, 35, 50, 45]
"net":                HGCN(
  (stem): Stem_conv(
    (convs): Sequential(
      (0): Conv2d(1, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): GELU(approximate='none')
      (3): Conv2d(40, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (4): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): GELU(approximate='none')
      (6): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (backbone): Sequential(
    (0): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): Identity()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
        )
        (drop_path): Identity()
      )
    )
    (1): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
        )
        (drop_path): DropPath()
      )
    )
    (2): DownSample(
      (conv): Sequential(
        (0): Conv2d(80, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(480, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)
        )
        (drop_path): DropPath()
      )
    )
    (4): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(480, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)
        )
        (drop_path): DropPath()
      )
    )
    (5): DownSample(
      (conv): Sequential(
        (0): Conv2d(160, 400, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (7): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (8): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (9): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (10): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (11): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (12): DownSample(
      (conv): Sequential(
        (0): Conv2d(400, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (13): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1920, 1920, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(640, 2560, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(2560, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(2560, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(2560, 2560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2560)
        )
        (drop_path): DropPath()
      )
    )
    (14): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1920, 1920, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(640, 2560, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(2560, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(2560, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(2560, 2560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2560)
        )
        (drop_path): DropPath()
      )
    )
  )
  (prediction): Sequential(
    (0): Conv2d(640, 1024, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): GELU(approximate='none')
    (3): Dropout(p=0.0, inplace=False)
    (4): Conv2d(1024, 200, kernel_size=(1, 1), stride=(1, 1))
  )
)
"opt_warmup":         True
"optimizer":          functools.partial(<class 'torch.optim.adam.Adam'>, lr=0.0005, weight_decay=5e-07, eps=1e-08, betas=[0.95, 0.999])
"scheduler":          functools.partial(<class 'torch.optim.lr_scheduler.MultiStepLR'>, milestones=[10, 15, 20, 25, 30, 35, 40], gamma=0.5)
Epoch 0:   0%|          | 1/735 [00:15<3:05:14,  0.07it/s]Epoch 0:   0%|          | 1/735 [00:15<3:05:29,  0.07it/s, v_num=lst8, train/loss_step=0.790]Epoch 0:   0%|          | 2/735 [00:16<1:39:00,  0.12it/s, v_num=lst8, train/loss_step=0.790]Epoch 0:   0%|          | 2/735 [00:16<1:39:01,  0.12it/s, v_num=lst8, train/loss_step=0.791]Epoch 0:   0%|          | 3/735 [00:17<1:10:07,  0.17it/s, v_num=lst8, train/loss_step=0.791]Epoch 0:   0%|          | 3/735 [00:17<1:10:08,  0.17it/s, v_num=lst8, train/loss_step=0.786]Epoch 0:   1%|          | 4/735 [00:18<55:42,  0.22it/s, v_num=lst8, train/loss_step=0.786]  Epoch 0:   1%|          | 4/735 [00:18<55:42,  0.22it/s, v_num=lst8, train/loss_step=0.791]Epoch 0:   1%|          | 5/735 [00:19<47:10,  0.26it/s, v_num=lst8, train/loss_step=0.791]Epoch 0:   1%|          | 5/735 [00:19<47:10,  0.26it/s, v_num=lst8, train/loss_step=0.793]Epoch 0:   1%|          | 6/735 [00:20<41:24,  0.29it/s, v_num=lst8, train/loss_step=0.793]Epoch 0:   1%|          | 6/735 [00:20<41:25,  0.29it/s, v_num=lst8, train/loss_step=0.792]Epoch 0:   1%|          | 7/735 [00:21<37:14,  0.33it/s, v_num=lst8, train/loss_step=0.792]Epoch 0:   1%|          | 7/735 [00:21<37:14,  0.33it/s, v_num=lst8, train/loss_step=0.778]Epoch 0:   1%|          | 8/735 [00:22<34:05,  0.36it/s, v_num=lst8, train/loss_step=0.778]Epoch 0:   1%|          | 8/735 [00:22<34:05,  0.36it/s, v_num=lst8, train/loss_step=0.789]Epoch 0:   1%|          | 9/735 [00:23<31:38,  0.38it/s, v_num=lst8, train/loss_step=0.789]Epoch 0:   1%|          | 9/735 [00:23<31:38,  0.38it/s, v_num=lst8, train/loss_step=0.786]Epoch 0:   1%|▏         | 10/735 [00:24<29:42,  0.41it/s, v_num=lst8, train/loss_step=0.786]Epoch 0:   1%|▏         | 10/735 [00:24<29:43,  0.41it/s, v_num=lst8, train/loss_step=0.768]Epoch 0:   1%|▏         | 11/735 [00:25<28:08,  0.43it/s, v_num=lst8, train/loss_step=0.768]Epoch 0:   1%|▏         | 11/735 [00:25<28:08,  0.43it/s, v_num=lst8, train/loss_step=0.778]Epoch 0:   2%|▏         | 12/735 [00:26<26:49,  0.45it/s, v_num=lst8, train/loss_step=0.778]Epoch 0:   2%|▏         | 12/735 [00:26<26:49,  0.45it/s, v_num=lst8, train/loss_step=0.782]Epoch 0:   2%|▏         | 13/735 [00:27<25:41,  0.47it/s, v_num=lst8, train/loss_step=0.782]Epoch 0:   2%|▏         | 13/735 [00:27<25:41,  0.47it/s, v_num=lst8, train/loss_step=0.774]Epoch 0:   2%|▏         | 14/735 [00:28<24:43,  0.49it/s, v_num=lst8, train/loss_step=0.774]Epoch 0:   2%|▏         | 14/735 [00:28<24:43,  0.49it/s, v_num=lst8, train/loss_step=0.777]Epoch 0:   2%|▏         | 15/735 [00:29<23:52,  0.50it/s, v_num=lst8, train/loss_step=0.777]Epoch 0:   2%|▏         | 15/735 [00:29<23:52,  0.50it/s, v_num=lst8, train/loss_step=0.767]Epoch 0:   2%|▏         | 16/735 [00:30<23:07,  0.52it/s, v_num=lst8, train/loss_step=0.767]Epoch 0:   2%|▏         | 16/735 [00:30<23:07,  0.52it/s, v_num=lst8, train/loss_step=0.773]Epoch 0:   2%|▏         | 17/735 [00:31<22:27,  0.53it/s, v_num=lst8, train/loss_step=0.773]Epoch 0:   2%|▏         | 17/735 [00:31<22:28,  0.53it/s, v_num=lst8, train/loss_step=0.764]Epoch 0:   2%|▏         | 18/735 [00:32<21:52,  0.55it/s, v_num=lst8, train/loss_step=0.764]Epoch 0:   2%|▏         | 18/735 [00:32<21:53,  0.55it/s, v_num=lst8, train/loss_step=0.768]Epoch 0:   3%|▎         | 19/735 [00:34<21:21,  0.56it/s, v_num=lst8, train/loss_step=0.768]Epoch 0:   3%|▎         | 19/735 [00:34<21:21,  0.56it/s, v_num=lst8, train/loss_step=0.768]Epoch 0:   3%|▎         | 20/735 [00:35<20:52,  0.57it/s, v_num=lst8, train/loss_step=0.768]Epoch 0:   3%|▎         | 20/735 [00:35<20:52,  0.57it/s, v_num=lst8, train/loss_step=0.759]Epoch 0:   3%|▎         | 21/735 [00:36<20:26,  0.58it/s, v_num=lst8, train/loss_step=0.759]Epoch 0:   3%|▎         | 21/735 [00:36<20:26,  0.58it/s, v_num=lst8, train/loss_step=0.754]Epoch 0:   3%|▎         | 22/735 [00:37<20:03,  0.59it/s, v_num=lst8, train/loss_step=0.754]Epoch 0:   3%|▎         | 22/735 [00:37<20:03,  0.59it/s, v_num=lst8, train/loss_step=0.750]Epoch 0:   3%|▎         | 23/735 [00:38<19:41,  0.60it/s, v_num=lst8, train/loss_step=0.750]Epoch 0:   3%|▎         | 23/735 [00:38<19:41,  0.60it/s, v_num=lst8, train/loss_step=0.753]Epoch 0:   3%|▎         | 24/735 [00:39<19:21,  0.61it/s, v_num=lst8, train/loss_step=0.753]Epoch 0:   3%|▎         | 24/735 [00:39<19:21,  0.61it/s, v_num=lst8, train/loss_step=0.744]Epoch 0:   3%|▎         | 25/735 [00:40<19:03,  0.62it/s, v_num=lst8, train/loss_step=0.744]Epoch 0:   3%|▎         | 25/735 [00:40<19:03,  0.62it/s, v_num=lst8, train/loss_step=0.749]Epoch 0:   4%|▎         | 26/735 [00:41<18:46,  0.63it/s, v_num=lst8, train/loss_step=0.749]Epoch 0:   4%|▎         | 26/735 [00:41<18:46,  0.63it/s, v_num=lst8, train/loss_step=0.739]Epoch 0:   4%|▎         | 27/735 [00:42<18:30,  0.64it/s, v_num=lst8, train/loss_step=0.739]Epoch 0:   4%|▎         | 27/735 [00:42<18:30,  0.64it/s, v_num=lst8, train/loss_step=0.746]Epoch 0:   4%|▍         | 28/735 [00:43<18:15,  0.65it/s, v_num=lst8, train/loss_step=0.746]Epoch 0:   4%|▍         | 28/735 [00:43<18:15,  0.65it/s, v_num=lst8, train/loss_step=0.734]Epoch 0:   4%|▍         | 29/735 [00:44<18:01,  0.65it/s, v_num=lst8, train/loss_step=0.734]Epoch 0:   4%|▍         | 29/735 [00:44<18:01,  0.65it/s, v_num=lst8, train/loss_step=0.732]Epoch 0:   4%|▍         | 30/735 [00:45<17:48,  0.66it/s, v_num=lst8, train/loss_step=0.732]Epoch 0:   4%|▍         | 30/735 [00:45<17:48,  0.66it/s, v_num=lst8, train/loss_step=0.731]Epoch 0:   4%|▍         | 31/735 [00:46<17:36,  0.67it/s, v_num=lst8, train/loss_step=0.731]Epoch 0:   4%|▍         | 31/735 [00:46<17:36,  0.67it/s, v_num=lst8, train/loss_step=0.721]Epoch 0:   4%|▍         | 32/735 [00:47<17:25,  0.67it/s, v_num=lst8, train/loss_step=0.721]Epoch 0:   4%|▍         | 32/735 [00:47<17:25,  0.67it/s, v_num=lst8, train/loss_step=0.722]Epoch 0:   4%|▍         | 33/735 [00:48<17:14,  0.68it/s, v_num=lst8, train/loss_step=0.722]Epoch 0:   4%|▍         | 33/735 [00:48<17:14,  0.68it/s, v_num=lst8, train/loss_step=0.716]Epoch 0:   5%|▍         | 34/735 [00:49<17:03,  0.68it/s, v_num=lst8, train/loss_step=0.716]Epoch 0:   5%|▍         | 34/735 [00:49<17:03,  0.68it/s, v_num=lst8, train/loss_step=0.711]Epoch 0:   5%|▍         | 35/735 [00:50<16:54,  0.69it/s, v_num=lst8, train/loss_step=0.711]Epoch 0:   5%|▍         | 35/735 [00:50<16:54,  0.69it/s, v_num=lst8, train/loss_step=0.712]Epoch 0:   5%|▍         | 36/735 [00:51<16:44,  0.70it/s, v_num=lst8, train/loss_step=0.712]Epoch 0:   5%|▍         | 36/735 [00:51<16:44,  0.70it/s, v_num=lst8, train/loss_step=0.706]Epoch 0:   5%|▌         | 37/735 [00:52<16:36,  0.70it/s, v_num=lst8, train/loss_step=0.706]Epoch 0:   5%|▌         | 37/735 [00:52<16:36,  0.70it/s, v_num=lst8, train/loss_step=0.690]Epoch 0:   5%|▌         | 38/735 [00:53<16:27,  0.71it/s, v_num=lst8, train/loss_step=0.690]Epoch 0:   5%|▌         | 38/735 [00:53<16:27,  0.71it/s, v_num=lst8, train/loss_step=0.696]Epoch 0:   5%|▌         | 39/735 [00:54<16:18,  0.71it/s, v_num=lst8, train/loss_step=0.696]Epoch 0:   5%|▌         | 39/735 [00:54<16:18,  0.71it/s, v_num=lst8, train/loss_step=0.682]Epoch 0:   5%|▌         | 40/735 [00:55<16:10,  0.72it/s, v_num=lst8, train/loss_step=0.682]Epoch 0:   5%|▌         | 40/735 [00:55<16:10,  0.72it/s, v_num=lst8, train/loss_step=0.675]Epoch 0:   6%|▌         | 41/735 [00:56<16:03,  0.72it/s, v_num=lst8, train/loss_step=0.675]Epoch 0:   6%|▌         | 41/735 [00:56<16:03,  0.72it/s, v_num=lst8, train/loss_step=0.677]Epoch 0:   6%|▌         | 42/735 [00:57<15:56,  0.72it/s, v_num=lst8, train/loss_step=0.677]Epoch 0:   6%|▌         | 42/735 [00:57<15:56,  0.72it/s, v_num=lst8, train/loss_step=0.677]Epoch 0:   6%|▌         | 43/735 [00:58<15:49,  0.73it/s, v_num=lst8, train/loss_step=0.677]Epoch 0:   6%|▌         | 43/735 [00:58<15:49,  0.73it/s, v_num=lst8, train/loss_step=0.679]Epoch 0:   6%|▌         | 44/735 [01:00<15:42,  0.73it/s, v_num=lst8, train/loss_step=0.679]Epoch 0:   6%|▌         | 44/735 [01:00<15:42,  0.73it/s, v_num=lst8, train/loss_step=0.715]Epoch 0:   6%|▌         | 45/735 [01:01<15:36,  0.74it/s, v_num=lst8, train/loss_step=0.715]Epoch 0:   6%|▌         | 45/735 [01:01<15:36,  0.74it/s, v_num=lst8, train/loss_step=0.653]Epoch 0:   6%|▋         | 46/735 [01:02<15:30,  0.74it/s, v_num=lst8, train/loss_step=0.653]Epoch 0:   6%|▋         | 46/735 [01:02<15:30,  0.74it/s, v_num=lst8, train/loss_step=0.669]Epoch 0:   6%|▋         | 47/735 [01:03<15:24,  0.74it/s, v_num=lst8, train/loss_step=0.669]Epoch 0:   6%|▋         | 47/735 [01:03<15:24,  0.74it/s, v_num=lst8, train/loss_step=0.642]Epoch 0:   7%|▋         | 48/735 [01:04<15:19,  0.75it/s, v_num=lst8, train/loss_step=0.642]Epoch 0:   7%|▋         | 48/735 [01:04<15:19,  0.75it/s, v_num=lst8, train/loss_step=0.647]Epoch 0:   7%|▋         | 49/735 [01:05<15:13,  0.75it/s, v_num=lst8, train/loss_step=0.647]Epoch 0:   7%|▋         | 49/735 [01:05<15:13,  0.75it/s, v_num=lst8, train/loss_step=0.637]Epoch 0:   7%|▋         | 50/735 [01:06<15:08,  0.75it/s, v_num=lst8, train/loss_step=0.637]Epoch 0:   7%|▋         | 50/735 [01:06<15:08,  0.75it/s, v_num=lst8, train/loss_step=0.642]Epoch 0:   7%|▋         | 51/735 [01:07<15:03,  0.76it/s, v_num=lst8, train/loss_step=0.642]Epoch 0:   7%|▋         | 51/735 [01:07<15:03,  0.76it/s, v_num=lst8, train/loss_step=0.621]Epoch 0:   7%|▋         | 52/735 [01:08<14:58,  0.76it/s, v_num=lst8, train/loss_step=0.621]Epoch 0:   7%|▋         | 52/735 [01:08<14:58,  0.76it/s, v_num=lst8, train/loss_step=0.639]Epoch 0:   7%|▋         | 53/735 [01:09<14:53,  0.76it/s, v_num=lst8, train/loss_step=0.639]Epoch 0:   7%|▋         | 53/735 [01:09<14:53,  0.76it/s, v_num=lst8, train/loss_step=0.648]Epoch 0:   7%|▋         | 54/735 [01:10<14:49,  0.77it/s, v_num=lst8, train/loss_step=0.648]Epoch 0:   7%|▋         | 54/735 [01:10<14:49,  0.77it/s, v_num=lst8, train/loss_step=0.630]Epoch 0:   7%|▋         | 55/735 [01:11<14:44,  0.77it/s, v_num=lst8, train/loss_step=0.630]Epoch 0:   7%|▋         | 55/735 [01:11<14:44,  0.77it/s, v_num=lst8, train/loss_step=0.622]Epoch 0:   8%|▊         | 56/735 [01:12<14:40,  0.77it/s, v_num=lst8, train/loss_step=0.622]Epoch 0:   8%|▊         | 56/735 [01:12<14:40,  0.77it/s, v_num=lst8, train/loss_step=0.595]Epoch 0:   8%|▊         | 57/735 [01:13<14:36,  0.77it/s, v_num=lst8, train/loss_step=0.595]Epoch 0:   8%|▊         | 57/735 [01:13<14:36,  0.77it/s, v_num=lst8, train/loss_step=0.598]Epoch 0:   8%|▊         | 58/735 [01:14<14:31,  0.78it/s, v_num=lst8, train/loss_step=0.598]Epoch 0:   8%|▊         | 58/735 [01:14<14:31,  0.78it/s, v_num=lst8, train/loss_step=0.616]Epoch 0:   8%|▊         | 59/735 [01:15<14:27,  0.78it/s, v_num=lst8, train/loss_step=0.616]Epoch 0:   8%|▊         | 59/735 [01:15<14:27,  0.78it/s, v_num=lst8, train/loss_step=0.591]Epoch 0:   8%|▊         | 60/735 [01:16<14:23,  0.78it/s, v_num=lst8, train/loss_step=0.591]Epoch 0:   8%|▊         | 60/735 [01:16<14:23,  0.78it/s, v_num=lst8, train/loss_step=0.585]Epoch 0:   8%|▊         | 61/735 [01:17<14:20,  0.78it/s, v_num=lst8, train/loss_step=0.585]Epoch 0:   8%|▊         | 61/735 [01:17<14:20,  0.78it/s, v_num=lst8, train/loss_step=0.584]Epoch 0:   8%|▊         | 62/735 [01:18<14:16,  0.79it/s, v_num=lst8, train/loss_step=0.584]Epoch 0:   8%|▊         | 62/735 [01:18<14:16,  0.79it/s, v_num=lst8, train/loss_step=0.599]Epoch 0:   9%|▊         | 63/735 [01:19<14:12,  0.79it/s, v_num=lst8, train/loss_step=0.599]Epoch 0:   9%|▊         | 63/735 [01:19<14:12,  0.79it/s, v_num=lst8, train/loss_step=0.573]Epoch 0:   9%|▊         | 64/735 [01:20<14:09,  0.79it/s, v_num=lst8, train/loss_step=0.573]Epoch 0:   9%|▊         | 64/735 [01:20<14:09,  0.79it/s, v_num=lst8, train/loss_step=0.568]Epoch 0:   9%|▉         | 65/735 [01:22<14:05,  0.79it/s, v_num=lst8, train/loss_step=0.568]Epoch 0:   9%|▉         | 65/735 [01:22<14:05,  0.79it/s, v_num=lst8, train/loss_step=0.550]Epoch 0:   9%|▉         | 66/735 [01:23<14:02,  0.79it/s, v_num=lst8, train/loss_step=0.550]Epoch 0:   9%|▉         | 66/735 [01:23<14:02,  0.79it/s, v_num=lst8, train/loss_step=0.570]Epoch 0:   9%|▉         | 67/735 [01:24<13:58,  0.80it/s, v_num=lst8, train/loss_step=0.570]Epoch 0:   9%|▉         | 67/735 [01:24<13:58,  0.80it/s, v_num=lst8, train/loss_step=0.562]Epoch 0:   9%|▉         | 68/735 [01:25<13:55,  0.80it/s, v_num=lst8, train/loss_step=0.562]Epoch 0:   9%|▉         | 68/735 [01:25<13:55,  0.80it/s, v_num=lst8, train/loss_step=0.557]Epoch 0:   9%|▉         | 69/735 [01:26<13:52,  0.80it/s, v_num=lst8, train/loss_step=0.557]Epoch 0:   9%|▉         | 69/735 [01:26<13:52,  0.80it/s, v_num=lst8, train/loss_step=0.541]Epoch 0:  10%|▉         | 70/735 [01:27<13:49,  0.80it/s, v_num=lst8, train/loss_step=0.541]Epoch 0:  10%|▉         | 70/735 [01:27<13:49,  0.80it/s, v_num=lst8, train/loss_step=0.548]Epoch 0:  10%|▉         | 71/735 [01:28<13:46,  0.80it/s, v_num=lst8, train/loss_step=0.548]Epoch 0:  10%|▉         | 71/735 [01:28<13:46,  0.80it/s, v_num=lst8, train/loss_step=0.536]Epoch 0:  10%|▉         | 72/735 [01:29<13:43,  0.81it/s, v_num=lst8, train/loss_step=0.536]Epoch 0:  10%|▉         | 72/735 [01:29<13:43,  0.81it/s, v_num=lst8, train/loss_step=0.542]Epoch 0:  10%|▉         | 73/735 [01:30<13:40,  0.81it/s, v_num=lst8, train/loss_step=0.542]Epoch 0:  10%|▉         | 73/735 [01:30<13:40,  0.81it/s, v_num=lst8, train/loss_step=0.513]Epoch 0:  10%|█         | 74/735 [01:31<13:37,  0.81it/s, v_num=lst8, train/loss_step=0.513]Epoch 0:  10%|█         | 74/735 [01:31<13:37,  0.81it/s, v_num=lst8, train/loss_step=0.523]Epoch 0:  10%|█         | 75/735 [01:32<13:34,  0.81it/s, v_num=lst8, train/loss_step=0.523]Epoch 0:  10%|█         | 75/735 [01:32<13:34,  0.81it/s, v_num=lst8, train/loss_step=0.503]Epoch 0:  10%|█         | 76/735 [01:33<13:31,  0.81it/s, v_num=lst8, train/loss_step=0.503]Epoch 0:  10%|█         | 76/735 [01:33<13:31,  0.81it/s, v_num=lst8, train/loss_step=0.502]Epoch 0:  10%|█         | 77/735 [01:34<13:28,  0.81it/s, v_num=lst8, train/loss_step=0.502]Epoch 0:  10%|█         | 77/735 [01:34<13:28,  0.81it/s, v_num=lst8, train/loss_step=0.504]Epoch 0:  11%|█         | 78/735 [01:35<13:26,  0.81it/s, v_num=lst8, train/loss_step=0.504]Epoch 0:  11%|█         | 78/735 [01:35<13:26,  0.81it/s, v_num=lst8, train/loss_step=0.509]Epoch 0:  11%|█         | 79/735 [01:36<13:23,  0.82it/s, v_num=lst8, train/loss_step=0.509]Epoch 0:  11%|█         | 79/735 [01:36<13:23,  0.82it/s, v_num=lst8, train/loss_step=0.505]Epoch 0:  11%|█         | 80/735 [01:37<13:20,  0.82it/s, v_num=lst8, train/loss_step=0.505]Epoch 0:  11%|█         | 80/735 [01:37<13:20,  0.82it/s, v_num=lst8, train/loss_step=0.499]Epoch 0:  11%|█         | 81/735 [01:38<13:18,  0.82it/s, v_num=lst8, train/loss_step=0.499]Epoch 0:  11%|█         | 81/735 [01:38<13:18,  0.82it/s, v_num=lst8, train/loss_step=0.485]Epoch 0:  11%|█         | 82/735 [01:39<13:15,  0.82it/s, v_num=lst8, train/loss_step=0.485]Epoch 0:  11%|█         | 82/735 [01:39<13:15,  0.82it/s, v_num=lst8, train/loss_step=0.486]Epoch 0:  11%|█▏        | 83/735 [01:40<13:13,  0.82it/s, v_num=lst8, train/loss_step=0.486]Epoch 0:  11%|█▏        | 83/735 [01:40<13:13,  0.82it/s, v_num=lst8, train/loss_step=0.484]Epoch 0:  11%|█▏        | 84/735 [01:42<13:10,  0.82it/s, v_num=lst8, train/loss_step=0.484]Epoch 0:  11%|█▏        | 84/735 [01:42<13:10,  0.82it/s, v_num=lst8, train/loss_step=0.479]Epoch 0:  12%|█▏        | 85/735 [01:43<13:08,  0.82it/s, v_num=lst8, train/loss_step=0.479]Epoch 0:  12%|█▏        | 85/735 [01:43<13:08,  0.82it/s, v_num=lst8, train/loss_step=0.483]Epoch 0:  12%|█▏        | 86/735 [01:44<13:05,  0.83it/s, v_num=lst8, train/loss_step=0.483]Epoch 0:  12%|█▏        | 86/735 [01:44<13:05,  0.83it/s, v_num=lst8, train/loss_step=0.483]Epoch 0:  12%|█▏        | 87/735 [01:45<13:03,  0.83it/s, v_num=lst8, train/loss_step=0.483]Epoch 0:  12%|█▏        | 87/735 [01:45<13:03,  0.83it/s, v_num=lst8, train/loss_step=0.486]Epoch 0:  12%|█▏        | 88/735 [01:46<13:00,  0.83it/s, v_num=lst8, train/loss_step=0.486]Epoch 0:  12%|█▏        | 88/735 [01:46<13:00,  0.83it/s, v_num=lst8, train/loss_step=0.459]Epoch 0:  12%|█▏        | 89/735 [01:47<12:58,  0.83it/s, v_num=lst8, train/loss_step=0.459]Epoch 0:  12%|█▏        | 89/735 [01:47<12:58,  0.83it/s, v_num=lst8, train/loss_step=0.515]Epoch 0:  12%|█▏        | 90/735 [01:48<12:55,  0.83it/s, v_num=lst8, train/loss_step=0.515]Epoch 0:  12%|█▏        | 90/735 [01:48<12:55,  0.83it/s, v_num=lst8, train/loss_step=0.468]Epoch 0:  12%|█▏        | 91/735 [01:49<12:53,  0.83it/s, v_num=lst8, train/loss_step=0.468]Epoch 0:  12%|█▏        | 91/735 [01:49<12:53,  0.83it/s, v_num=lst8, train/loss_step=0.450]Epoch 0:  13%|█▎        | 92/735 [01:50<12:51,  0.83it/s, v_num=lst8, train/loss_step=0.450]Epoch 0:  13%|█▎        | 92/735 [01:50<12:51,  0.83it/s, v_num=lst8, train/loss_step=0.440]Epoch 0:  13%|█▎        | 93/735 [01:51<12:48,  0.84it/s, v_num=lst8, train/loss_step=0.440]Epoch 0:  13%|█▎        | 93/735 [01:51<12:48,  0.84it/s, v_num=lst8, train/loss_step=0.451]Epoch 0:  13%|█▎        | 94/735 [01:52<12:46,  0.84it/s, v_num=lst8, train/loss_step=0.451]Epoch 0:  13%|█▎        | 94/735 [01:52<12:46,  0.84it/s, v_num=lst8, train/loss_step=0.443]Epoch 0:  13%|█▎        | 95/735 [01:53<12:43,  0.84it/s, v_num=lst8, train/loss_step=0.443]Epoch 0:  13%|█▎        | 95/735 [01:53<12:43,  0.84it/s, v_num=lst8, train/loss_step=0.437]Epoch 0:  13%|█▎        | 96/735 [01:54<12:41,  0.84it/s, v_num=lst8, train/loss_step=0.437]Epoch 0:  13%|█▎        | 96/735 [01:54<12:41,  0.84it/s, v_num=lst8, train/loss_step=0.437]Epoch 0:  13%|█▎        | 97/735 [01:55<12:39,  0.84it/s, v_num=lst8, train/loss_step=0.437]Epoch 0:  13%|█▎        | 97/735 [01:55<12:39,  0.84it/s, v_num=lst8, train/loss_step=0.428]Epoch 0:  13%|█▎        | 98/735 [01:56<12:37,  0.84it/s, v_num=lst8, train/loss_step=0.428]Epoch 0:  13%|█▎        | 98/735 [01:56<12:37,  0.84it/s, v_num=lst8, train/loss_step=0.414]Epoch 0:  13%|█▎        | 99/735 [01:57<12:34,  0.84it/s, v_num=lst8, train/loss_step=0.414]Epoch 0:  13%|█▎        | 99/735 [01:57<12:34,  0.84it/s, v_num=lst8, train/loss_step=0.423]Epoch 0:  14%|█▎        | 100/735 [01:58<12:32,  0.84it/s, v_num=lst8, train/loss_step=0.423]Epoch 0:  14%|█▎        | 100/735 [01:58<12:32,  0.84it/s, v_num=lst8, train/loss_step=0.419]Epoch 0:  14%|█▎        | 101/735 [01:59<12:30,  0.84it/s, v_num=lst8, train/loss_step=0.419]Epoch 0:  14%|█▎        | 101/735 [01:59<12:30,  0.84it/s, v_num=lst8, train/loss_step=0.415]Epoch 0:  14%|█▍        | 102/735 [02:00<12:28,  0.85it/s, v_num=lst8, train/loss_step=0.415]Epoch 0:  14%|█▍        | 102/735 [02:00<12:28,  0.85it/s, v_num=lst8, train/loss_step=0.409]Epoch 0:  14%|█▍        | 103/735 [02:01<12:26,  0.85it/s, v_num=lst8, train/loss_step=0.409]Epoch 0:  14%|█▍        | 103/735 [02:01<12:26,  0.85it/s, v_num=lst8, train/loss_step=0.398]Epoch 0:  14%|█▍        | 104/735 [02:02<12:23,  0.85it/s, v_num=lst8, train/loss_step=0.398]Epoch 0:  14%|█▍        | 104/735 [02:02<12:23,  0.85it/s, v_num=lst8, train/loss_step=0.386]Epoch 0:  14%|█▍        | 105/735 [02:03<12:21,  0.85it/s, v_num=lst8, train/loss_step=0.386]Epoch 0:  14%|█▍        | 105/735 [02:03<12:21,  0.85it/s, v_num=lst8, train/loss_step=0.388]Epoch 0:  14%|█▍        | 106/735 [02:04<12:19,  0.85it/s, v_num=lst8, train/loss_step=0.388]Epoch 0:  14%|█▍        | 106/735 [02:04<12:19,  0.85it/s, v_num=lst8, train/loss_step=0.387]Epoch 0:  15%|█▍        | 107/735 [02:05<12:17,  0.85it/s, v_num=lst8, train/loss_step=0.387]Epoch 0:  15%|█▍        | 107/735 [02:05<12:17,  0.85it/s, v_num=lst8, train/loss_step=0.385]Epoch 0:  15%|█▍        | 108/735 [02:06<12:15,  0.85it/s, v_num=lst8, train/loss_step=0.385]Epoch 0:  15%|█▍        | 108/735 [02:06<12:15,  0.85it/s, v_num=lst8, train/loss_step=0.368]Epoch 0:  15%|█▍        | 109/735 [02:07<12:13,  0.85it/s, v_num=lst8, train/loss_step=0.368]Epoch 0:  15%|█▍        | 109/735 [02:07<12:13,  0.85it/s, v_num=lst8, train/loss_step=0.374]Epoch 0:  15%|█▍        | 110/735 [02:08<12:11,  0.85it/s, v_num=lst8, train/loss_step=0.374]Epoch 0:  15%|█▍        | 110/735 [02:08<12:11,  0.85it/s, v_num=lst8, train/loss_step=0.373]Epoch 0:  15%|█▌        | 111/735 [02:09<12:09,  0.86it/s, v_num=lst8, train/loss_step=0.373]Epoch 0:  15%|█▌        | 111/735 [02:09<12:09,  0.86it/s, v_num=lst8, train/loss_step=0.357]Epoch 0:  15%|█▌        | 112/735 [02:10<12:07,  0.86it/s, v_num=lst8, train/loss_step=0.357]Epoch 0:  15%|█▌        | 112/735 [02:10<12:07,  0.86it/s, v_num=lst8, train/loss_step=0.349]Epoch 0:  15%|█▌        | 113/735 [02:11<12:05,  0.86it/s, v_num=lst8, train/loss_step=0.349]Epoch 0:  15%|█▌        | 113/735 [02:11<12:05,  0.86it/s, v_num=lst8, train/loss_step=0.354]Epoch 0:  16%|█▌        | 114/735 [02:12<12:04,  0.86it/s, v_num=lst8, train/loss_step=0.354]Epoch 0:  16%|█▌        | 114/735 [02:12<12:04,  0.86it/s, v_num=lst8, train/loss_step=0.338]Epoch 0:  16%|█▌        | 115/735 [02:13<12:02,  0.86it/s, v_num=lst8, train/loss_step=0.338]Epoch 0:  16%|█▌        | 115/735 [02:13<12:02,  0.86it/s, v_num=lst8, train/loss_step=0.342]Epoch 0:  16%|█▌        | 116/735 [02:15<12:00,  0.86it/s, v_num=lst8, train/loss_step=0.342]Epoch 0:  16%|█▌        | 116/735 [02:15<12:00,  0.86it/s, v_num=lst8, train/loss_step=0.334]Epoch 0:  16%|█▌        | 117/735 [02:16<11:58,  0.86it/s, v_num=lst8, train/loss_step=0.334]Epoch 0:  16%|█▌        | 117/735 [02:16<11:58,  0.86it/s, v_num=lst8, train/loss_step=0.329]Epoch 0:  16%|█▌        | 118/735 [02:17<11:57,  0.86it/s, v_num=lst8, train/loss_step=0.329]Epoch 0:  16%|█▌        | 118/735 [02:17<11:57,  0.86it/s, v_num=lst8, train/loss_step=0.325]Epoch 0:  16%|█▌        | 119/735 [02:18<11:55,  0.86it/s, v_num=lst8, train/loss_step=0.325]Epoch 0:  16%|█▌        | 119/735 [02:18<11:55,  0.86it/s, v_num=lst8, train/loss_step=0.325]Epoch 0:  16%|█▋        | 120/735 [02:19<11:53,  0.86it/s, v_num=lst8, train/loss_step=0.325]Epoch 0:  16%|█▋        | 120/735 [02:19<11:53,  0.86it/s, v_num=lst8, train/loss_step=0.307]Epoch 0:  16%|█▋        | 121/735 [02:20<11:51,  0.86it/s, v_num=lst8, train/loss_step=0.307]Epoch 0:  16%|█▋        | 121/735 [02:20<11:51,  0.86it/s, v_num=lst8, train/loss_step=0.309]Epoch 0:  17%|█▋        | 122/735 [02:21<11:50,  0.86it/s, v_num=lst8, train/loss_step=0.309]Epoch 0:  17%|█▋        | 122/735 [02:21<11:50,  0.86it/s, v_num=lst8, train/loss_step=0.299]Epoch 0:  17%|█▋        | 123/735 [02:22<11:48,  0.86it/s, v_num=lst8, train/loss_step=0.299]Epoch 0:  17%|█▋        | 123/735 [02:22<11:48,  0.86it/s, v_num=lst8, train/loss_step=0.298]Epoch 0:  17%|█▋        | 124/735 [02:23<11:46,  0.86it/s, v_num=lst8, train/loss_step=0.298]Epoch 0:  17%|█▋        | 124/735 [02:23<11:46,  0.86it/s, v_num=lst8, train/loss_step=0.305]Epoch 0:  17%|█▋        | 125/735 [02:24<11:44,  0.87it/s, v_num=lst8, train/loss_step=0.305]Epoch 0:  17%|█▋        | 125/735 [02:24<11:44,  0.87it/s, v_num=lst8, train/loss_step=0.288]Epoch 0:  17%|█▋        | 126/735 [02:25<11:43,  0.87it/s, v_num=lst8, train/loss_step=0.288]Epoch 0:  17%|█▋        | 126/735 [02:25<11:43,  0.87it/s, v_num=lst8, train/loss_step=0.282]Epoch 0:  17%|█▋        | 127/735 [02:26<11:41,  0.87it/s, v_num=lst8, train/loss_step=0.282]Epoch 0:  17%|█▋        | 127/735 [02:26<11:41,  0.87it/s, v_num=lst8, train/loss_step=0.276]Epoch 0:  17%|█▋        | 128/735 [02:27<11:39,  0.87it/s, v_num=lst8, train/loss_step=0.276]Epoch 0:  17%|█▋        | 128/735 [02:27<11:39,  0.87it/s, v_num=lst8, train/loss_step=0.272]Epoch 0:  18%|█▊        | 129/735 [02:28<11:38,  0.87it/s, v_num=lst8, train/loss_step=0.272]Epoch 0:  18%|█▊        | 129/735 [02:28<11:38,  0.87it/s, v_num=lst8, train/loss_step=0.287]Epoch 0:  18%|█▊        | 130/735 [02:29<11:36,  0.87it/s, v_num=lst8, train/loss_step=0.287]Epoch 0:  18%|█▊        | 130/735 [02:29<11:36,  0.87it/s, v_num=lst8, train/loss_step=0.262]Epoch 0:  18%|█▊        | 131/735 [02:30<11:35,  0.87it/s, v_num=lst8, train/loss_step=0.262]Epoch 0:  18%|█▊        | 131/735 [02:30<11:35,  0.87it/s, v_num=lst8, train/loss_step=0.269]Epoch 0:  18%|█▊        | 132/735 [02:31<11:33,  0.87it/s, v_num=lst8, train/loss_step=0.269]Epoch 0:  18%|█▊        | 132/735 [02:31<11:33,  0.87it/s, v_num=lst8, train/loss_step=0.261]Epoch 0:  18%|█▊        | 133/735 [02:32<11:31,  0.87it/s, v_num=lst8, train/loss_step=0.261]Epoch 0:  18%|█▊        | 133/735 [02:32<11:31,  0.87it/s, v_num=lst8, train/loss_step=0.264]Epoch 0:  18%|█▊        | 134/735 [02:33<11:30,  0.87it/s, v_num=lst8, train/loss_step=0.264]Epoch 0:  18%|█▊        | 134/735 [02:33<11:30,  0.87it/s, v_num=lst8, train/loss_step=0.249]Epoch 0:  18%|█▊        | 135/735 [02:34<11:28,  0.87it/s, v_num=lst8, train/loss_step=0.249]Epoch 0:  18%|█▊        | 135/735 [02:34<11:28,  0.87it/s, v_num=lst8, train/loss_step=0.247]Epoch 0:  19%|█▊        | 136/735 [02:36<11:27,  0.87it/s, v_num=lst8, train/loss_step=0.247]Epoch 0:  19%|█▊        | 136/735 [02:36<11:27,  0.87it/s, v_num=lst8, train/loss_step=0.241]Epoch 0:  19%|█▊        | 137/735 [02:37<11:25,  0.87it/s, v_num=lst8, train/loss_step=0.241]Epoch 0:  19%|█▊        | 137/735 [02:37<11:25,  0.87it/s, v_num=lst8, train/loss_step=0.247]Epoch 0:  19%|█▉        | 138/735 [02:38<11:23,  0.87it/s, v_num=lst8, train/loss_step=0.247]Epoch 0:  19%|█▉        | 138/735 [02:38<11:23,  0.87it/s, v_num=lst8, train/loss_step=0.240]Epoch 0:  19%|█▉        | 139/735 [02:39<11:22,  0.87it/s, v_num=lst8, train/loss_step=0.240]Epoch 0:  19%|█▉        | 139/735 [02:39<11:22,  0.87it/s, v_num=lst8, train/loss_step=0.233]Epoch 0:  19%|█▉        | 140/735 [02:40<11:20,  0.87it/s, v_num=lst8, train/loss_step=0.233]Epoch 0:  19%|█▉        | 140/735 [02:40<11:20,  0.87it/s, v_num=lst8, train/loss_step=0.238]Epoch 0:  19%|█▉        | 141/735 [02:41<11:19,  0.87it/s, v_num=lst8, train/loss_step=0.238]Epoch 0:  19%|█▉        | 141/735 [02:41<11:19,  0.87it/s, v_num=lst8, train/loss_step=0.216]Epoch 0:  19%|█▉        | 142/735 [02:42<11:17,  0.88it/s, v_num=lst8, train/loss_step=0.216]Epoch 0:  19%|█▉        | 142/735 [02:42<11:17,  0.88it/s, v_num=lst8, train/loss_step=0.224]Epoch 0:  19%|█▉        | 143/735 [02:43<11:16,  0.88it/s, v_num=lst8, train/loss_step=0.224]Epoch 0:  19%|█▉        | 143/735 [02:43<11:16,  0.88it/s, v_num=lst8, train/loss_step=0.213]Epoch 0:  20%|█▉        | 144/735 [02:44<11:14,  0.88it/s, v_num=lst8, train/loss_step=0.213]Epoch 0:  20%|█▉        | 144/735 [02:44<11:14,  0.88it/s, v_num=lst8, train/loss_step=0.253]Epoch 0:  20%|█▉        | 145/735 [02:45<11:13,  0.88it/s, v_num=lst8, train/loss_step=0.253]Epoch 0:  20%|█▉        | 145/735 [02:45<11:13,  0.88it/s, v_num=lst8, train/loss_step=0.213]Epoch 0:  20%|█▉        | 146/735 [02:46<11:11,  0.88it/s, v_num=lst8, train/loss_step=0.213]Epoch 0:  20%|█▉        | 146/735 [02:46<11:11,  0.88it/s, v_num=lst8, train/loss_step=0.229]Epoch 0:  20%|██        | 147/735 [02:47<11:10,  0.88it/s, v_num=lst8, train/loss_step=0.229]Epoch 0:  20%|██        | 147/735 [02:47<11:10,  0.88it/s, v_num=lst8, train/loss_step=0.211]Epoch 0:  20%|██        | 148/735 [02:48<11:08,  0.88it/s, v_num=lst8, train/loss_step=0.211]Epoch 0:  20%|██        | 148/735 [02:48<11:08,  0.88it/s, v_num=lst8, train/loss_step=0.217]Epoch 0:  20%|██        | 149/735 [02:49<11:07,  0.88it/s, v_num=lst8, train/loss_step=0.217]Epoch 0:  20%|██        | 149/735 [02:49<11:07,  0.88it/s, v_num=lst8, train/loss_step=0.198]Epoch 0:  20%|██        | 150/735 [02:50<11:05,  0.88it/s, v_num=lst8, train/loss_step=0.198]Epoch 0:  20%|██        | 150/735 [02:50<11:05,  0.88it/s, v_num=lst8, train/loss_step=0.186]Epoch 0:  21%|██        | 151/735 [02:51<11:04,  0.88it/s, v_num=lst8, train/loss_step=0.186]Epoch 0:  21%|██        | 151/735 [02:51<11:04,  0.88it/s, v_num=lst8, train/loss_step=0.184]Epoch 0:  21%|██        | 152/735 [02:52<11:02,  0.88it/s, v_num=lst8, train/loss_step=0.184]Epoch 0:  21%|██        | 152/735 [02:52<11:02,  0.88it/s, v_num=lst8, train/loss_step=0.179]Epoch 0:  21%|██        | 153/735 [02:53<11:01,  0.88it/s, v_num=lst8, train/loss_step=0.179]Epoch 0:  21%|██        | 153/735 [02:53<11:01,  0.88it/s, v_num=lst8, train/loss_step=0.190]Epoch 0:  21%|██        | 154/735 [02:54<10:59,  0.88it/s, v_num=lst8, train/loss_step=0.190]Epoch 0:  21%|██        | 154/735 [02:54<10:59,  0.88it/s, v_num=lst8, train/loss_step=0.181]Epoch 0:  21%|██        | 155/735 [02:55<10:58,  0.88it/s, v_num=lst8, train/loss_step=0.181]Epoch 0:  21%|██        | 155/735 [02:55<10:58,  0.88it/s, v_num=lst8, train/loss_step=0.165]Epoch 0:  21%|██        | 156/735 [02:56<10:56,  0.88it/s, v_num=lst8, train/loss_step=0.165]Epoch 0:  21%|██        | 156/735 [02:56<10:56,  0.88it/s, v_num=lst8, train/loss_step=0.169]Epoch 0:  21%|██▏       | 157/735 [02:58<10:55,  0.88it/s, v_num=lst8, train/loss_step=0.169]Epoch 0:  21%|██▏       | 157/735 [02:58<10:55,  0.88it/s, v_num=lst8, train/loss_step=0.160]Epoch 0:  21%|██▏       | 158/735 [02:59<10:53,  0.88it/s, v_num=lst8, train/loss_step=0.160]Epoch 0:  21%|██▏       | 158/735 [02:59<10:53,  0.88it/s, v_num=lst8, train/loss_step=0.165]Epoch 0:  22%|██▏       | 159/735 [03:00<10:52,  0.88it/s, v_num=lst8, train/loss_step=0.165]Epoch 0:  22%|██▏       | 159/735 [03:00<10:52,  0.88it/s, v_num=lst8, train/loss_step=0.156]Epoch 0:  22%|██▏       | 160/735 [03:01<10:51,  0.88it/s, v_num=lst8, train/loss_step=0.156]Epoch 0:  22%|██▏       | 160/735 [03:01<10:51,  0.88it/s, v_num=lst8, train/loss_step=0.145]Epoch 0:  22%|██▏       | 161/735 [03:02<10:49,  0.88it/s, v_num=lst8, train/loss_step=0.145]Epoch 0:  22%|██▏       | 161/735 [03:02<10:49,  0.88it/s, v_num=lst8, train/loss_step=0.152]Epoch 0:  22%|██▏       | 162/735 [03:03<10:48,  0.88it/s, v_num=lst8, train/loss_step=0.152]Epoch 0:  22%|██▏       | 162/735 [03:03<10:48,  0.88it/s, v_num=lst8, train/loss_step=0.146]Epoch 0:  22%|██▏       | 163/735 [03:04<10:46,  0.88it/s, v_num=lst8, train/loss_step=0.146]Epoch 0:  22%|██▏       | 163/735 [03:04<10:46,  0.88it/s, v_num=lst8, train/loss_step=0.133]Epoch 0:  22%|██▏       | 164/735 [03:05<10:45,  0.88it/s, v_num=lst8, train/loss_step=0.133]Epoch 0:  22%|██▏       | 164/735 [03:05<10:45,  0.88it/s, v_num=lst8, train/loss_step=0.134]Epoch 0:  22%|██▏       | 165/735 [03:06<10:44,  0.89it/s, v_num=lst8, train/loss_step=0.134]Epoch 0:  22%|██▏       | 165/735 [03:06<10:44,  0.89it/s, v_num=lst8, train/loss_step=0.137]Epoch 0:  23%|██▎       | 166/735 [03:07<10:42,  0.89it/s, v_num=lst8, train/loss_step=0.137]Epoch 0:  23%|██▎       | 166/735 [03:07<10:42,  0.89it/s, v_num=lst8, train/loss_step=0.139]Epoch 0:  23%|██▎       | 167/735 [03:08<10:41,  0.89it/s, v_num=lst8, train/loss_step=0.139]Epoch 0:  23%|██▎       | 167/735 [03:08<10:41,  0.89it/s, v_num=lst8, train/loss_step=0.135]Epoch 0:  23%|██▎       | 168/735 [03:09<10:39,  0.89it/s, v_num=lst8, train/loss_step=0.135]Epoch 0:  23%|██▎       | 168/735 [03:09<10:39,  0.89it/s, v_num=lst8, train/loss_step=0.121]Epoch 0:  23%|██▎       | 169/735 [03:10<10:38,  0.89it/s, v_num=lst8, train/loss_step=0.121]Epoch 0:  23%|██▎       | 169/735 [03:10<10:38,  0.89it/s, v_num=lst8, train/loss_step=0.117]Epoch 0:  23%|██▎       | 170/735 [03:11<10:37,  0.89it/s, v_num=lst8, train/loss_step=0.117]Epoch 0:  23%|██▎       | 170/735 [03:11<10:37,  0.89it/s, v_num=lst8, train/loss_step=0.120]Epoch 0:  23%|██▎       | 171/735 [03:12<10:35,  0.89it/s, v_num=lst8, train/loss_step=0.120]Epoch 0:  23%|██▎       | 171/735 [03:12<10:35,  0.89it/s, v_num=lst8, train/loss_step=0.109]Epoch 0:  23%|██▎       | 172/735 [03:13<10:34,  0.89it/s, v_num=lst8, train/loss_step=0.109]Epoch 0:  23%|██▎       | 172/735 [03:13<10:34,  0.89it/s, v_num=lst8, train/loss_step=0.106]Epoch 0:  24%|██▎       | 173/735 [03:14<10:32,  0.89it/s, v_num=lst8, train/loss_step=0.106]Epoch 0:  24%|██▎       | 173/735 [03:14<10:32,  0.89it/s, v_num=lst8, train/loss_step=0.107]Epoch 0:  24%|██▎       | 174/735 [03:15<10:31,  0.89it/s, v_num=lst8, train/loss_step=0.107]Epoch 0:  24%|██▎       | 174/735 [03:15<10:31,  0.89it/s, v_num=lst8, train/loss_step=0.102]Epoch 0:  24%|██▍       | 175/735 [03:16<10:30,  0.89it/s, v_num=lst8, train/loss_step=0.102]Epoch 0:  24%|██▍       | 175/735 [03:16<10:30,  0.89it/s, v_num=lst8, train/loss_step=0.0974]Epoch 0:  24%|██▍       | 176/735 [03:17<10:28,  0.89it/s, v_num=lst8, train/loss_step=0.0974]Epoch 0:  24%|██▍       | 176/735 [03:17<10:28,  0.89it/s, v_num=lst8, train/loss_step=0.099] Epoch 0:  24%|██▍       | 177/735 [03:18<10:27,  0.89it/s, v_num=lst8, train/loss_step=0.099]Epoch 0:  24%|██▍       | 177/735 [03:18<10:27,  0.89it/s, v_num=lst8, train/loss_step=0.100]Epoch 0:  24%|██▍       | 178/735 [03:20<10:25,  0.89it/s, v_num=lst8, train/loss_step=0.100]Epoch 0:  24%|██▍       | 178/735 [03:20<10:25,  0.89it/s, v_num=lst8, train/loss_step=0.0889]Epoch 0:  24%|██▍       | 179/735 [03:21<10:24,  0.89it/s, v_num=lst8, train/loss_step=0.0889]Epoch 0:  24%|██▍       | 179/735 [03:21<10:24,  0.89it/s, v_num=lst8, train/loss_step=0.0886]Epoch 0:  24%|██▍       | 180/735 [03:22<10:23,  0.89it/s, v_num=lst8, train/loss_step=0.0886]Epoch 0:  24%|██▍       | 180/735 [03:22<10:23,  0.89it/s, v_num=lst8, train/loss_step=0.0904]Epoch 0:  25%|██▍       | 181/735 [03:23<10:21,  0.89it/s, v_num=lst8, train/loss_step=0.0904]Epoch 0:  25%|██▍       | 181/735 [03:23<10:21,  0.89it/s, v_num=lst8, train/loss_step=0.090] Epoch 0:  25%|██▍       | 182/735 [03:24<10:20,  0.89it/s, v_num=lst8, train/loss_step=0.090]Epoch 0:  25%|██▍       | 182/735 [03:24<10:20,  0.89it/s, v_num=lst8, train/loss_step=0.0842]Epoch 0:  25%|██▍       | 183/735 [03:25<10:19,  0.89it/s, v_num=lst8, train/loss_step=0.0842]Epoch 0:  25%|██▍       | 183/735 [03:25<10:19,  0.89it/s, v_num=lst8, train/loss_step=0.0861]Epoch 0:  25%|██▌       | 184/735 [03:26<10:17,  0.89it/s, v_num=lst8, train/loss_step=0.0861]Epoch 0:  25%|██▌       | 184/735 [03:26<10:17,  0.89it/s, v_num=lst8, train/loss_step=0.0818]Epoch 0:  25%|██▌       | 185/735 [03:27<10:16,  0.89it/s, v_num=lst8, train/loss_step=0.0818]Epoch 0:  25%|██▌       | 185/735 [03:27<10:16,  0.89it/s, v_num=lst8, train/loss_step=0.0792]Epoch 0:  25%|██▌       | 186/735 [03:28<10:15,  0.89it/s, v_num=lst8, train/loss_step=0.0792]Epoch 0:  25%|██▌       | 186/735 [03:28<10:15,  0.89it/s, v_num=lst8, train/loss_step=0.0852]Epoch 0:  25%|██▌       | 187/735 [03:29<10:13,  0.89it/s, v_num=lst8, train/loss_step=0.0852]Epoch 0:  25%|██▌       | 187/735 [03:29<10:13,  0.89it/s, v_num=lst8, train/loss_step=0.0782]Epoch 0:  26%|██▌       | 188/735 [03:30<10:12,  0.89it/s, v_num=lst8, train/loss_step=0.0782]Epoch 0:  26%|██▌       | 188/735 [03:30<10:12,  0.89it/s, v_num=lst8, train/loss_step=0.075] Epoch 0:  26%|██▌       | 189/735 [03:31<10:11,  0.89it/s, v_num=lst8, train/loss_step=0.075]Epoch 0:  26%|██▌       | 189/735 [03:31<10:11,  0.89it/s, v_num=lst8, train/loss_step=0.0793]Epoch 0:  26%|██▌       | 190/735 [03:32<10:09,  0.89it/s, v_num=lst8, train/loss_step=0.0793]Epoch 0:  26%|██▌       | 190/735 [03:32<10:09,  0.89it/s, v_num=lst8, train/loss_step=0.0731]Epoch 0:  26%|██▌       | 191/735 [03:33<10:08,  0.89it/s, v_num=lst8, train/loss_step=0.0731]Epoch 0:  26%|██▌       | 191/735 [03:33<10:08,  0.89it/s, v_num=lst8, train/loss_step=0.0733]Epoch 0:  26%|██▌       | 192/735 [03:34<10:07,  0.89it/s, v_num=lst8, train/loss_step=0.0733]Epoch 0:  26%|██▌       | 192/735 [03:34<10:07,  0.89it/s, v_num=lst8, train/loss_step=0.0702]Epoch 0:  26%|██▋       | 193/735 [03:35<10:05,  0.89it/s, v_num=lst8, train/loss_step=0.0702]Epoch 0:  26%|██▋       | 193/735 [03:35<10:05,  0.89it/s, v_num=lst8, train/loss_step=0.0696]Epoch 0:  26%|██▋       | 194/735 [03:36<10:04,  0.89it/s, v_num=lst8, train/loss_step=0.0696]Epoch 0:  26%|██▋       | 194/735 [03:36<10:04,  0.89it/s, v_num=lst8, train/loss_step=0.0724]Epoch 0:  27%|██▋       | 195/735 [03:37<10:03,  0.90it/s, v_num=lst8, train/loss_step=0.0724]Epoch 0:  27%|██▋       | 195/735 [03:37<10:03,  0.90it/s, v_num=lst8, train/loss_step=0.0681]Epoch 0:  27%|██▋       | 196/735 [03:39<10:02,  0.89it/s, v_num=lst8, train/loss_step=0.0681]Epoch 0:  27%|██▋       | 196/735 [03:39<10:02,  0.89it/s, v_num=lst8, train/loss_step=0.0678]Epoch 0:  27%|██▋       | 197/735 [03:40<10:00,  0.90it/s, v_num=lst8, train/loss_step=0.0678]Epoch 0:  27%|██▋       | 197/735 [03:40<10:00,  0.90it/s, v_num=lst8, train/loss_step=0.0689]Epoch 0:  27%|██▋       | 198/735 [03:41<09:59,  0.90it/s, v_num=lst8, train/loss_step=0.0689]Epoch 0:  27%|██▋       | 198/735 [03:41<09:59,  0.90it/s, v_num=lst8, train/loss_step=0.0694]Epoch 0:  27%|██▋       | 199/735 [03:42<09:58,  0.90it/s, v_num=lst8, train/loss_step=0.0694]Epoch 0:  27%|██▋       | 199/735 [03:42<09:58,  0.90it/s, v_num=lst8, train/loss_step=0.0795]Epoch 0:  27%|██▋       | 200/735 [03:43<09:56,  0.90it/s, v_num=lst8, train/loss_step=0.0795]Epoch 0:  27%|██▋       | 200/735 [03:43<09:56,  0.90it/s, v_num=lst8, train/loss_step=0.0695]Epoch 0:  27%|██▋       | 201/735 [03:44<09:55,  0.90it/s, v_num=lst8, train/loss_step=0.0695]Epoch 0:  27%|██▋       | 201/735 [03:44<09:55,  0.90it/s, v_num=lst8, train/loss_step=0.0655]Epoch 0:  27%|██▋       | 202/735 [03:45<09:54,  0.90it/s, v_num=lst8, train/loss_step=0.0655]Epoch 0:  27%|██▋       | 202/735 [03:45<09:54,  0.90it/s, v_num=lst8, train/loss_step=0.0666]Epoch 0:  28%|██▊       | 203/735 [03:46<09:52,  0.90it/s, v_num=lst8, train/loss_step=0.0666]Epoch 0:  28%|██▊       | 203/735 [03:46<09:52,  0.90it/s, v_num=lst8, train/loss_step=0.062] Epoch 0:  28%|██▊       | 204/735 [03:47<09:51,  0.90it/s, v_num=lst8, train/loss_step=0.062]Epoch 0:  28%|██▊       | 204/735 [03:47<09:51,  0.90it/s, v_num=lst8, train/loss_step=0.0598]Epoch 0:  28%|██▊       | 205/735 [03:48<09:50,  0.90it/s, v_num=lst8, train/loss_step=0.0598]Epoch 0:  28%|██▊       | 205/735 [03:48<09:50,  0.90it/s, v_num=lst8, train/loss_step=0.0606]Epoch 0:  28%|██▊       | 206/735 [03:49<09:48,  0.90it/s, v_num=lst8, train/loss_step=0.0606]Epoch 0:  28%|██▊       | 206/735 [03:49<09:48,  0.90it/s, v_num=lst8, train/loss_step=0.0639]Epoch 0:  28%|██▊       | 207/735 [03:50<09:47,  0.90it/s, v_num=lst8, train/loss_step=0.0639]Epoch 0:  28%|██▊       | 207/735 [03:50<09:47,  0.90it/s, v_num=lst8, train/loss_step=0.0584]Epoch 0:  28%|██▊       | 208/735 [03:51<09:46,  0.90it/s, v_num=lst8, train/loss_step=0.0584]Epoch 0:  28%|██▊       | 208/735 [03:51<09:46,  0.90it/s, v_num=lst8, train/loss_step=0.063] Epoch 0:  28%|██▊       | 209/735 [03:52<09:44,  0.90it/s, v_num=lst8, train/loss_step=0.063]Epoch 0:  28%|██▊       | 209/735 [03:52<09:44,  0.90it/s, v_num=lst8, train/loss_step=0.0624]Epoch 0:  29%|██▊       | 210/735 [03:53<09:43,  0.90it/s, v_num=lst8, train/loss_step=0.0624]Epoch 0:  29%|██▊       | 210/735 [03:53<09:43,  0.90it/s, v_num=lst8, train/loss_step=0.0589]Epoch 0:  29%|██▊       | 211/735 [03:54<09:42,  0.90it/s, v_num=lst8, train/loss_step=0.0589]Epoch 0:  29%|██▊       | 211/735 [03:54<09:42,  0.90it/s, v_num=lst8, train/loss_step=0.0607]Epoch 0:  29%|██▉       | 212/735 [03:55<09:40,  0.90it/s, v_num=lst8, train/loss_step=0.0607]Epoch 0:  29%|██▉       | 212/735 [03:55<09:40,  0.90it/s, v_num=lst8, train/loss_step=0.0592]Epoch 0:  29%|██▉       | 213/735 [03:56<09:39,  0.90it/s, v_num=lst8, train/loss_step=0.0592]Epoch 0:  29%|██▉       | 213/735 [03:56<09:39,  0.90it/s, v_num=lst8, train/loss_step=0.0616]Epoch 0:  29%|██▉       | 214/735 [03:57<09:38,  0.90it/s, v_num=lst8, train/loss_step=0.0616]Epoch 0:  29%|██▉       | 214/735 [03:57<09:38,  0.90it/s, v_num=lst8, train/loss_step=0.064] Epoch 0:  29%|██▉       | 215/735 [03:58<09:36,  0.90it/s, v_num=lst8, train/loss_step=0.064]Epoch 0:  29%|██▉       | 215/735 [03:58<09:36,  0.90it/s, v_num=lst8, train/loss_step=0.063]Epoch 0:  29%|██▉       | 216/735 [03:59<09:35,  0.90it/s, v_num=lst8, train/loss_step=0.063]Epoch 0:  29%|██▉       | 216/735 [03:59<09:35,  0.90it/s, v_num=lst8, train/loss_step=0.0595]Epoch 0:  30%|██▉       | 217/735 [04:00<09:34,  0.90it/s, v_num=lst8, train/loss_step=0.0595]Epoch 0:  30%|██▉       | 217/735 [04:00<09:34,  0.90it/s, v_num=lst8, train/loss_step=0.066] Epoch 0:  30%|██▉       | 218/735 [04:01<09:33,  0.90it/s, v_num=lst8, train/loss_step=0.066]Epoch 0:  30%|██▉       | 218/735 [04:01<09:33,  0.90it/s, v_num=lst8, train/loss_step=0.0602]Epoch 0:  30%|██▉       | 219/735 [04:02<09:31,  0.90it/s, v_num=lst8, train/loss_step=0.0602]Epoch 0:  30%|██▉       | 219/735 [04:02<09:31,  0.90it/s, v_num=lst8, train/loss_step=0.0618]Epoch 0:  30%|██▉       | 220/735 [04:03<09:30,  0.90it/s, v_num=lst8, train/loss_step=0.0618]Epoch 0:  30%|██▉       | 220/735 [04:03<09:30,  0.90it/s, v_num=lst8, train/loss_step=0.0616]Epoch 0:  30%|███       | 221/735 [04:04<09:29,  0.90it/s, v_num=lst8, train/loss_step=0.0616]Epoch 0:  30%|███       | 221/735 [04:04<09:29,  0.90it/s, v_num=lst8, train/loss_step=0.0576]Epoch 0:  30%|███       | 222/735 [04:05<09:27,  0.90it/s, v_num=lst8, train/loss_step=0.0576]Epoch 0:  30%|███       | 222/735 [04:05<09:27,  0.90it/s, v_num=lst8, train/loss_step=0.0631]Epoch 0:  30%|███       | 223/735 [04:06<09:26,  0.90it/s, v_num=lst8, train/loss_step=0.0631]Epoch 0:  30%|███       | 223/735 [04:06<09:26,  0.90it/s, v_num=lst8, train/loss_step=0.0569]Epoch 0:  30%|███       | 224/735 [04:07<09:25,  0.90it/s, v_num=lst8, train/loss_step=0.0569]Epoch 0:  30%|███       | 224/735 [04:07<09:25,  0.90it/s, v_num=lst8, train/loss_step=0.0567]Epoch 0:  31%|███       | 225/735 [04:08<09:24,  0.90it/s, v_num=lst8, train/loss_step=0.0567]Epoch 0:  31%|███       | 225/735 [04:08<09:24,  0.90it/s, v_num=lst8, train/loss_step=0.0569]Epoch 0:  31%|███       | 226/735 [04:09<09:22,  0.90it/s, v_num=lst8, train/loss_step=0.0569]Epoch 0:  31%|███       | 226/735 [04:09<09:22,  0.90it/s, v_num=lst8, train/loss_step=0.0577]Epoch 0:  31%|███       | 227/735 [04:10<09:21,  0.90it/s, v_num=lst8, train/loss_step=0.0577]Epoch 0:  31%|███       | 227/735 [04:10<09:21,  0.90it/s, v_num=lst8, train/loss_step=0.0553]Epoch 0:  31%|███       | 228/735 [04:12<09:20,  0.90it/s, v_num=lst8, train/loss_step=0.0553]Epoch 0:  31%|███       | 228/735 [04:12<09:20,  0.90it/s, v_num=lst8, train/loss_step=0.0617]Epoch 0:  31%|███       | 229/735 [04:13<09:19,  0.90it/s, v_num=lst8, train/loss_step=0.0617]Epoch 0:  31%|███       | 229/735 [04:13<09:19,  0.90it/s, v_num=lst8, train/loss_step=0.0564]Epoch 0:  31%|███▏      | 230/735 [04:14<09:17,  0.91it/s, v_num=lst8, train/loss_step=0.0564]Epoch 0:  31%|███▏      | 230/735 [04:14<09:17,  0.91it/s, v_num=lst8, train/loss_step=0.0521]Epoch 0:  31%|███▏      | 231/735 [04:15<09:16,  0.91it/s, v_num=lst8, train/loss_step=0.0521]Epoch 0:  31%|███▏      | 231/735 [04:15<09:16,  0.91it/s, v_num=lst8, train/loss_step=0.0565]Epoch 0:  32%|███▏      | 232/735 [04:16<09:15,  0.91it/s, v_num=lst8, train/loss_step=0.0565]Epoch 0:  32%|███▏      | 232/735 [04:16<09:15,  0.91it/s, v_num=lst8, train/loss_step=0.0531]Epoch 0:  32%|███▏      | 233/735 [04:17<09:14,  0.91it/s, v_num=lst8, train/loss_step=0.0531]Epoch 0:  32%|███▏      | 233/735 [04:17<09:14,  0.91it/s, v_num=lst8, train/loss_step=0.0521]Epoch 0:  32%|███▏      | 234/735 [04:18<09:13,  0.91it/s, v_num=lst8, train/loss_step=0.0521]Epoch 0:  32%|███▏      | 234/735 [04:18<09:13,  0.91it/s, v_num=lst8, train/loss_step=0.0557]Epoch 0:  32%|███▏      | 235/735 [04:19<09:11,  0.91it/s, v_num=lst8, train/loss_step=0.0557]Epoch 0:  32%|███▏      | 235/735 [04:19<09:11,  0.91it/s, v_num=lst8, train/loss_step=0.0555]Epoch 0:  32%|███▏      | 236/735 [04:20<09:10,  0.91it/s, v_num=lst8, train/loss_step=0.0555]Epoch 0:  32%|███▏      | 236/735 [04:20<09:10,  0.91it/s, v_num=lst8, train/loss_step=0.0573]Epoch 0:  32%|███▏      | 237/735 [04:21<09:09,  0.91it/s, v_num=lst8, train/loss_step=0.0573]Epoch 0:  32%|███▏      | 237/735 [04:21<09:09,  0.91it/s, v_num=lst8, train/loss_step=0.0559]Epoch 0:  32%|███▏      | 238/735 [04:22<09:08,  0.91it/s, v_num=lst8, train/loss_step=0.0559]Epoch 0:  32%|███▏      | 238/735 [04:22<09:08,  0.91it/s, v_num=lst8, train/loss_step=0.0558]Epoch 0:  33%|███▎      | 239/735 [04:23<09:06,  0.91it/s, v_num=lst8, train/loss_step=0.0558]Epoch 0:  33%|███▎      | 239/735 [04:23<09:06,  0.91it/s, v_num=lst8, train/loss_step=0.0576]Epoch 0:  33%|███▎      | 240/735 [04:24<09:05,  0.91it/s, v_num=lst8, train/loss_step=0.0576]Epoch 0:  33%|███▎      | 240/735 [04:24<09:05,  0.91it/s, v_num=lst8, train/loss_step=0.0543]Epoch 0:  33%|███▎      | 241/735 [04:25<09:04,  0.91it/s, v_num=lst8, train/loss_step=0.0543]Epoch 0:  33%|███▎      | 241/735 [04:25<09:04,  0.91it/s, v_num=lst8, train/loss_step=0.0496]Epoch 0:  33%|███▎      | 242/735 [04:26<09:02,  0.91it/s, v_num=lst8, train/loss_step=0.0496]Epoch 0:  33%|███▎      | 242/735 [04:26<09:02,  0.91it/s, v_num=lst8, train/loss_step=0.0548]Epoch 0:  33%|███▎      | 243/735 [04:27<09:01,  0.91it/s, v_num=lst8, train/loss_step=0.0548]Epoch 0:  33%|███▎      | 243/735 [04:27<09:01,  0.91it/s, v_num=lst8, train/loss_step=0.0537]Epoch 0:  33%|███▎      | 244/735 [04:28<09:00,  0.91it/s, v_num=lst8, train/loss_step=0.0537]Epoch 0:  33%|███▎      | 244/735 [04:28<09:00,  0.91it/s, v_num=lst8, train/loss_step=0.0501]Epoch 0:  33%|███▎      | 245/735 [04:29<08:59,  0.91it/s, v_num=lst8, train/loss_step=0.0501]Epoch 0:  33%|███▎      | 245/735 [04:29<08:59,  0.91it/s, v_num=lst8, train/loss_step=0.0525]Epoch 0:  33%|███▎      | 246/735 [04:30<08:57,  0.91it/s, v_num=lst8, train/loss_step=0.0525]Epoch 0:  33%|███▎      | 246/735 [04:30<08:57,  0.91it/s, v_num=lst8, train/loss_step=0.0554]Epoch 0:  34%|███▎      | 247/735 [04:31<08:56,  0.91it/s, v_num=lst8, train/loss_step=0.0554]Epoch 0:  34%|███▎      | 247/735 [04:31<08:56,  0.91it/s, v_num=lst8, train/loss_step=0.0556]Epoch 0:  34%|███▎      | 248/735 [04:32<08:55,  0.91it/s, v_num=lst8, train/loss_step=0.0556]Epoch 0:  34%|███▎      | 248/735 [04:32<08:55,  0.91it/s, v_num=lst8, train/loss_step=0.0557]Epoch 0:  34%|███▍      | 249/735 [04:33<08:54,  0.91it/s, v_num=lst8, train/loss_step=0.0557]Epoch 0:  34%|███▍      | 249/735 [04:33<08:54,  0.91it/s, v_num=lst8, train/loss_step=0.0534]Epoch 0:  34%|███▍      | 250/735 [04:34<08:52,  0.91it/s, v_num=lst8, train/loss_step=0.0534]Epoch 0:  34%|███▍      | 250/735 [04:34<08:52,  0.91it/s, v_num=lst8, train/loss_step=0.0541]Epoch 0:  34%|███▍      | 251/735 [04:35<08:51,  0.91it/s, v_num=lst8, train/loss_step=0.0541]Epoch 0:  34%|███▍      | 251/735 [04:35<08:51,  0.91it/s, v_num=lst8, train/loss_step=0.0531]Epoch 0:  34%|███▍      | 252/735 [04:36<08:50,  0.91it/s, v_num=lst8, train/loss_step=0.0531]Epoch 0:  34%|███▍      | 252/735 [04:36<08:50,  0.91it/s, v_num=lst8, train/loss_step=0.0518]Epoch 0:  34%|███▍      | 253/735 [04:37<08:49,  0.91it/s, v_num=lst8, train/loss_step=0.0518]Epoch 0:  34%|███▍      | 253/735 [04:37<08:49,  0.91it/s, v_num=lst8, train/loss_step=0.052] Epoch 0:  35%|███▍      | 254/735 [04:38<08:47,  0.91it/s, v_num=lst8, train/loss_step=0.052]Epoch 0:  35%|███▍      | 254/735 [04:38<08:47,  0.91it/s, v_num=lst8, train/loss_step=0.056]Epoch 0:  35%|███▍      | 255/735 [04:39<08:46,  0.91it/s, v_num=lst8, train/loss_step=0.056]Epoch 0:  35%|███▍      | 255/735 [04:39<08:46,  0.91it/s, v_num=lst8, train/loss_step=0.0488]Epoch 0:  35%|███▍      | 256/735 [04:40<08:45,  0.91it/s, v_num=lst8, train/loss_step=0.0488]Epoch 0:  35%|███▍      | 256/735 [04:40<08:45,  0.91it/s, v_num=lst8, train/loss_step=0.0548]Epoch 0:  35%|███▍      | 257/735 [04:41<08:44,  0.91it/s, v_num=lst8, train/loss_step=0.0548]Epoch 0:  35%|███▍      | 257/735 [04:41<08:44,  0.91it/s, v_num=lst8, train/loss_step=0.0576]Epoch 0:  35%|███▌      | 258/735 [04:42<08:43,  0.91it/s, v_num=lst8, train/loss_step=0.0576]Epoch 0:  35%|███▌      | 258/735 [04:42<08:43,  0.91it/s, v_num=lst8, train/loss_step=0.0496]Epoch 0:  35%|███▌      | 259/735 [04:43<08:41,  0.91it/s, v_num=lst8, train/loss_step=0.0496]Epoch 0:  35%|███▌      | 259/735 [04:43<08:41,  0.91it/s, v_num=lst8, train/loss_step=0.0505]Epoch 0:  35%|███▌      | 260/735 [04:44<08:40,  0.91it/s, v_num=lst8, train/loss_step=0.0505]Epoch 0:  35%|███▌      | 260/735 [04:44<08:40,  0.91it/s, v_num=lst8, train/loss_step=0.052] Epoch 0:  36%|███▌      | 261/735 [04:46<08:39,  0.91it/s, v_num=lst8, train/loss_step=0.052]Epoch 0:  36%|███▌      | 261/735 [04:46<08:39,  0.91it/s, v_num=lst8, train/loss_step=0.0542]Epoch 0:  36%|███▌      | 262/735 [04:47<08:38,  0.91it/s, v_num=lst8, train/loss_step=0.0542]Epoch 0:  36%|███▌      | 262/735 [04:47<08:38,  0.91it/s, v_num=lst8, train/loss_step=0.0523]Epoch 0:  36%|███▌      | 263/735 [04:48<08:37,  0.91it/s, v_num=lst8, train/loss_step=0.0523]Epoch 0:  36%|███▌      | 263/735 [04:48<08:37,  0.91it/s, v_num=lst8, train/loss_step=0.0573]Epoch 0:  36%|███▌      | 264/735 [04:49<08:35,  0.91it/s, v_num=lst8, train/loss_step=0.0573]Epoch 0:  36%|███▌      | 264/735 [04:49<08:35,  0.91it/s, v_num=lst8, train/loss_step=0.0525]Epoch 0:  36%|███▌      | 265/735 [04:50<08:34,  0.91it/s, v_num=lst8, train/loss_step=0.0525]Epoch 0:  36%|███▌      | 265/735 [04:50<08:34,  0.91it/s, v_num=lst8, train/loss_step=0.051] Epoch 0:  36%|███▌      | 266/735 [04:51<08:33,  0.91it/s, v_num=lst8, train/loss_step=0.051]Epoch 0:  36%|███▌      | 266/735 [04:51<08:33,  0.91it/s, v_num=lst8, train/loss_step=0.0521]Epoch 0:  36%|███▋      | 267/735 [04:52<08:32,  0.91it/s, v_num=lst8, train/loss_step=0.0521]Epoch 0:  36%|███▋      | 267/735 [04:52<08:32,  0.91it/s, v_num=lst8, train/loss_step=0.0483]Epoch 0:  36%|███▋      | 268/735 [04:53<08:31,  0.91it/s, v_num=lst8, train/loss_step=0.0483]Epoch 0:  36%|███▋      | 268/735 [04:53<08:31,  0.91it/s, v_num=lst8, train/loss_step=0.0593]Epoch 0:  37%|███▋      | 269/735 [04:54<08:30,  0.91it/s, v_num=lst8, train/loss_step=0.0593]Epoch 0:  37%|███▋      | 269/735 [04:54<08:30,  0.91it/s, v_num=lst8, train/loss_step=0.0553]Epoch 0:  37%|███▋      | 270/735 [04:55<08:28,  0.91it/s, v_num=lst8, train/loss_step=0.0553]Epoch 0:  37%|███▋      | 270/735 [04:55<08:28,  0.91it/s, v_num=lst8, train/loss_step=0.0557]Epoch 0:  37%|███▋      | 271/735 [04:56<08:27,  0.91it/s, v_num=lst8, train/loss_step=0.0557]Epoch 0:  37%|███▋      | 271/735 [04:56<08:27,  0.91it/s, v_num=lst8, train/loss_step=0.0537]Epoch 0:  37%|███▋      | 272/735 [04:57<08:26,  0.91it/s, v_num=lst8, train/loss_step=0.0537]Epoch 0:  37%|███▋      | 272/735 [04:57<08:26,  0.91it/s, v_num=lst8, train/loss_step=0.0569]Epoch 0:  37%|███▋      | 273/735 [04:58<08:25,  0.91it/s, v_num=lst8, train/loss_step=0.0569]Epoch 0:  37%|███▋      | 273/735 [04:58<08:25,  0.91it/s, v_num=lst8, train/loss_step=0.0526]Epoch 0:  37%|███▋      | 274/735 [04:59<08:24,  0.91it/s, v_num=lst8, train/loss_step=0.0526]Epoch 0:  37%|███▋      | 274/735 [04:59<08:24,  0.91it/s, v_num=lst8, train/loss_step=0.0572]Epoch 0:  37%|███▋      | 275/735 [05:00<08:22,  0.91it/s, v_num=lst8, train/loss_step=0.0572]Epoch 0:  37%|███▋      | 275/735 [05:00<08:22,  0.91it/s, v_num=lst8, train/loss_step=0.0575]Epoch 0:  38%|███▊      | 276/735 [05:01<08:21,  0.91it/s, v_num=lst8, train/loss_step=0.0575]Epoch 0:  38%|███▊      | 276/735 [05:01<08:21,  0.91it/s, v_num=lst8, train/loss_step=0.0522]Epoch 0:  38%|███▊      | 277/735 [05:02<08:20,  0.92it/s, v_num=lst8, train/loss_step=0.0522]Epoch 0:  38%|███▊      | 277/735 [05:02<08:20,  0.92it/s, v_num=lst8, train/loss_step=0.0533]Epoch 0:  38%|███▊      | 278/735 [05:03<08:19,  0.92it/s, v_num=lst8, train/loss_step=0.0533]Epoch 0:  38%|███▊      | 278/735 [05:03<08:19,  0.92it/s, v_num=lst8, train/loss_step=0.0505]Epoch 0:  38%|███▊      | 279/735 [05:04<08:18,  0.92it/s, v_num=lst8, train/loss_step=0.0505]Epoch 0:  38%|███▊      | 279/735 [05:04<08:18,  0.92it/s, v_num=lst8, train/loss_step=0.0498]Epoch 0:  38%|███▊      | 280/735 [05:05<08:17,  0.92it/s, v_num=lst8, train/loss_step=0.0498]Epoch 0:  38%|███▊      | 280/735 [05:05<08:17,  0.92it/s, v_num=lst8, train/loss_step=0.0556]Epoch 0:  38%|███▊      | 281/735 [05:06<08:15,  0.92it/s, v_num=lst8, train/loss_step=0.0556]Epoch 0:  38%|███▊      | 281/735 [05:06<08:15,  0.92it/s, v_num=lst8, train/loss_step=0.0513]Epoch 0:  38%|███▊      | 282/735 [05:07<08:14,  0.92it/s, v_num=lst8, train/loss_step=0.0513]Epoch 0:  38%|███▊      | 282/735 [05:07<08:14,  0.92it/s, v_num=lst8, train/loss_step=0.049] Epoch 0:  39%|███▊      | 283/735 [05:09<08:13,  0.92it/s, v_num=lst8, train/loss_step=0.049]Epoch 0:  39%|███▊      | 283/735 [05:09<08:13,  0.92it/s, v_num=lst8, train/loss_step=0.0568]Epoch 0:  39%|███▊      | 284/735 [05:10<08:12,  0.92it/s, v_num=lst8, train/loss_step=0.0568]Epoch 0:  39%|███▊      | 284/735 [05:10<08:12,  0.92it/s, v_num=lst8, train/loss_step=0.0485]Epoch 0:  39%|███▉      | 285/735 [05:11<08:11,  0.92it/s, v_num=lst8, train/loss_step=0.0485]Epoch 0:  39%|███▉      | 285/735 [05:11<08:11,  0.92it/s, v_num=lst8, train/loss_step=0.0542]Epoch 0:  39%|███▉      | 286/735 [05:12<08:10,  0.92it/s, v_num=lst8, train/loss_step=0.0542]Epoch 0:  39%|███▉      | 286/735 [05:12<08:10,  0.92it/s, v_num=lst8, train/loss_step=0.0529]Epoch 0:  39%|███▉      | 287/735 [05:13<08:08,  0.92it/s, v_num=lst8, train/loss_step=0.0529]Epoch 0:  39%|███▉      | 287/735 [05:13<08:08,  0.92it/s, v_num=lst8, train/loss_step=0.053] Epoch 0:  39%|███▉      | 288/735 [05:14<08:07,  0.92it/s, v_num=lst8, train/loss_step=0.053]Epoch 0:  39%|███▉      | 288/735 [05:14<08:07,  0.92it/s, v_num=lst8, train/loss_step=0.0502]Epoch 0:  39%|███▉      | 289/735 [05:15<08:06,  0.92it/s, v_num=lst8, train/loss_step=0.0502]Epoch 0:  39%|███▉      | 289/735 [05:15<08:06,  0.92it/s, v_num=lst8, train/loss_step=0.0571]Epoch 0:  39%|███▉      | 290/735 [05:16<08:05,  0.92it/s, v_num=lst8, train/loss_step=0.0571]Epoch 0:  39%|███▉      | 290/735 [05:16<08:05,  0.92it/s, v_num=lst8, train/loss_step=0.0561]Epoch 0:  40%|███▉      | 291/735 [05:17<08:04,  0.92it/s, v_num=lst8, train/loss_step=0.0561]Epoch 0:  40%|███▉      | 291/735 [05:17<08:04,  0.92it/s, v_num=lst8, train/loss_step=0.0638]Epoch 0:  40%|███▉      | 292/735 [05:18<08:03,  0.92it/s, v_num=lst8, train/loss_step=0.0638]Epoch 0:  40%|███▉      | 292/735 [05:18<08:03,  0.92it/s, v_num=lst8, train/loss_step=0.0569]Epoch 0:  40%|███▉      | 293/735 [05:19<08:01,  0.92it/s, v_num=lst8, train/loss_step=0.0569]Epoch 0:  40%|███▉      | 293/735 [05:19<08:01,  0.92it/s, v_num=lst8, train/loss_step=0.0485]Epoch 0:  40%|████      | 294/735 [05:20<08:00,  0.92it/s, v_num=lst8, train/loss_step=0.0485]Epoch 0:  40%|████      | 294/735 [05:20<08:00,  0.92it/s, v_num=lst8, train/loss_step=0.053] Epoch 0:  40%|████      | 295/735 [05:21<07:59,  0.92it/s, v_num=lst8, train/loss_step=0.053]Epoch 0:  40%|████      | 295/735 [05:21<07:59,  0.92it/s, v_num=lst8, train/loss_step=0.052]Epoch 0:  40%|████      | 296/735 [05:22<07:58,  0.92it/s, v_num=lst8, train/loss_step=0.052]Epoch 0:  40%|████      | 296/735 [05:22<07:58,  0.92it/s, v_num=lst8, train/loss_step=0.0535]Epoch 0:  40%|████      | 297/735 [05:23<07:57,  0.92it/s, v_num=lst8, train/loss_step=0.0535]Epoch 0:  40%|████      | 297/735 [05:23<07:57,  0.92it/s, v_num=lst8, train/loss_step=0.0518]Epoch 0:  41%|████      | 298/735 [05:24<07:56,  0.92it/s, v_num=lst8, train/loss_step=0.0518]Epoch 0:  41%|████      | 298/735 [05:24<07:56,  0.92it/s, v_num=lst8, train/loss_step=0.0509]Epoch 0:  41%|████      | 299/735 [05:25<07:55,  0.92it/s, v_num=lst8, train/loss_step=0.0509]Epoch 0:  41%|████      | 299/735 [05:25<07:55,  0.92it/s, v_num=lst8, train/loss_step=0.053] Epoch 0:  41%|████      | 300/735 [05:26<07:53,  0.92it/s, v_num=lst8, train/loss_step=0.053]Epoch 0:  41%|████      | 300/735 [05:26<07:53,  0.92it/s, v_num=lst8, train/loss_step=0.0528]Epoch 0:  41%|████      | 301/735 [05:27<07:52,  0.92it/s, v_num=lst8, train/loss_step=0.0528]Epoch 0:  41%|████      | 301/735 [05:27<07:52,  0.92it/s, v_num=lst8, train/loss_step=0.0527]Epoch 0:  41%|████      | 302/735 [05:28<07:51,  0.92it/s, v_num=lst8, train/loss_step=0.0527]Epoch 0:  41%|████      | 302/735 [05:28<07:51,  0.92it/s, v_num=lst8, train/loss_step=0.0539]Epoch 0:  41%|████      | 303/735 [05:29<07:50,  0.92it/s, v_num=lst8, train/loss_step=0.0539]Epoch 0:  41%|████      | 303/735 [05:29<07:50,  0.92it/s, v_num=lst8, train/loss_step=0.050] Epoch 0:  41%|████▏     | 304/735 [05:30<07:49,  0.92it/s, v_num=lst8, train/loss_step=0.050]Epoch 0:  41%|████▏     | 304/735 [05:30<07:49,  0.92it/s, v_num=lst8, train/loss_step=0.0511]Epoch 0:  41%|████▏     | 305/735 [05:31<07:48,  0.92it/s, v_num=lst8, train/loss_step=0.0511]Epoch 0:  41%|████▏     | 305/735 [05:31<07:48,  0.92it/s, v_num=lst8, train/loss_step=0.052] Epoch 0:  42%|████▏     | 306/735 [05:33<07:46,  0.92it/s, v_num=lst8, train/loss_step=0.052]Epoch 0:  42%|████▏     | 306/735 [05:33<07:46,  0.92it/s, v_num=lst8, train/loss_step=0.0453]Epoch 0:  42%|████▏     | 307/735 [05:34<07:45,  0.92it/s, v_num=lst8, train/loss_step=0.0453]Epoch 0:  42%|████▏     | 307/735 [05:34<07:45,  0.92it/s, v_num=lst8, train/loss_step=0.0473]Epoch 0:  42%|████▏     | 308/735 [05:35<07:44,  0.92it/s, v_num=lst8, train/loss_step=0.0473]Epoch 0:  42%|████▏     | 308/735 [05:35<07:44,  0.92it/s, v_num=lst8, train/loss_step=0.050] Epoch 0:  42%|████▏     | 309/735 [05:36<07:43,  0.92it/s, v_num=lst8, train/loss_step=0.050]Epoch 0:  42%|████▏     | 309/735 [05:36<07:43,  0.92it/s, v_num=lst8, train/loss_step=0.0519]Epoch 0:  42%|████▏     | 310/735 [05:37<07:42,  0.92it/s, v_num=lst8, train/loss_step=0.0519]Epoch 0:  42%|████▏     | 310/735 [05:37<07:42,  0.92it/s, v_num=lst8, train/loss_step=0.0541]Epoch 0:  42%|████▏     | 311/735 [05:38<07:41,  0.92it/s, v_num=lst8, train/loss_step=0.0541]Epoch 0:  42%|████▏     | 311/735 [05:38<07:41,  0.92it/s, v_num=lst8, train/loss_step=0.0532]Epoch 0:  42%|████▏     | 312/735 [05:39<07:40,  0.92it/s, v_num=lst8, train/loss_step=0.0532]Epoch 0:  42%|████▏     | 312/735 [05:39<07:40,  0.92it/s, v_num=lst8, train/loss_step=0.0507]Epoch 0:  43%|████▎     | 313/735 [05:40<07:38,  0.92it/s, v_num=lst8, train/loss_step=0.0507]Epoch 0:  43%|████▎     | 313/735 [05:40<07:38,  0.92it/s, v_num=lst8, train/loss_step=0.0533]Epoch 0:  43%|████▎     | 314/735 [05:41<07:37,  0.92it/s, v_num=lst8, train/loss_step=0.0533]Epoch 0:  43%|████▎     | 314/735 [05:41<07:37,  0.92it/s, v_num=lst8, train/loss_step=0.049] Epoch 0:  43%|████▎     | 315/735 [05:42<07:36,  0.92it/s, v_num=lst8, train/loss_step=0.049]Epoch 0:  43%|████▎     | 315/735 [05:42<07:36,  0.92it/s, v_num=lst8, train/loss_step=0.0477]Epoch 0:  43%|████▎     | 316/735 [05:43<07:35,  0.92it/s, v_num=lst8, train/loss_step=0.0477]Epoch 0:  43%|████▎     | 316/735 [05:43<07:35,  0.92it/s, v_num=lst8, train/loss_step=0.0506]Epoch 0:  43%|████▎     | 317/735 [05:44<07:34,  0.92it/s, v_num=lst8, train/loss_step=0.0506]Epoch 0:  43%|████▎     | 317/735 [05:44<07:34,  0.92it/s, v_num=lst8, train/loss_step=0.0508]Epoch 0:  43%|████▎     | 318/735 [05:45<07:33,  0.92it/s, v_num=lst8, train/loss_step=0.0508]Epoch 0:  43%|████▎     | 318/735 [05:45<07:33,  0.92it/s, v_num=lst8, train/loss_step=0.050] Epoch 0:  43%|████▎     | 319/735 [05:46<07:32,  0.92it/s, v_num=lst8, train/loss_step=0.050]Epoch 0:  43%|████▎     | 319/735 [05:46<07:32,  0.92it/s, v_num=lst8, train/loss_step=0.0528]Epoch 0:  44%|████▎     | 320/735 [05:47<07:30,  0.92it/s, v_num=lst8, train/loss_step=0.0528]Epoch 0:  44%|████▎     | 320/735 [05:47<07:30,  0.92it/s, v_num=lst8, train/loss_step=0.0544]Epoch 0:  44%|████▎     | 321/735 [05:48<07:29,  0.92it/s, v_num=lst8, train/loss_step=0.0544]Epoch 0:  44%|████▎     | 321/735 [05:48<07:29,  0.92it/s, v_num=lst8, train/loss_step=0.0469]Epoch 0:  44%|████▍     | 322/735 [05:49<07:28,  0.92it/s, v_num=lst8, train/loss_step=0.0469]Epoch 0:  44%|████▍     | 322/735 [05:49<07:28,  0.92it/s, v_num=lst8, train/loss_step=0.0476]Epoch 0:  44%|████▍     | 323/735 [05:50<07:27,  0.92it/s, v_num=lst8, train/loss_step=0.0476]Epoch 0:  44%|████▍     | 323/735 [05:50<07:27,  0.92it/s, v_num=lst8, train/loss_step=0.0499]Epoch 0:  44%|████▍     | 324/735 [05:51<07:26,  0.92it/s, v_num=lst8, train/loss_step=0.0499]Epoch 0:  44%|████▍     | 324/735 [05:51<07:26,  0.92it/s, v_num=lst8, train/loss_step=0.0488]Epoch 0:  44%|████▍     | 325/735 [05:52<07:25,  0.92it/s, v_num=lst8, train/loss_step=0.0488]Epoch 0:  44%|████▍     | 325/735 [05:52<07:25,  0.92it/s, v_num=lst8, train/loss_step=0.0484]Epoch 0:  44%|████▍     | 326/735 [05:54<07:24,  0.92it/s, v_num=lst8, train/loss_step=0.0484]Epoch 0:  44%|████▍     | 326/735 [05:54<07:24,  0.92it/s, v_num=lst8, train/loss_step=0.0497]Epoch 0:  44%|████▍     | 327/735 [05:55<07:23,  0.92it/s, v_num=lst8, train/loss_step=0.0497]Epoch 0:  44%|████▍     | 327/735 [05:55<07:23,  0.92it/s, v_num=lst8, train/loss_step=0.0468]Epoch 0:  45%|████▍     | 328/735 [05:56<07:21,  0.92it/s, v_num=lst8, train/loss_step=0.0468]Epoch 0:  45%|████▍     | 328/735 [05:56<07:21,  0.92it/s, v_num=lst8, train/loss_step=0.0485]Epoch 0:  45%|████▍     | 329/735 [05:57<07:20,  0.92it/s, v_num=lst8, train/loss_step=0.0485]Epoch 0:  45%|████▍     | 329/735 [05:57<07:20,  0.92it/s, v_num=lst8, train/loss_step=0.0502]Epoch 0:  45%|████▍     | 330/735 [05:58<07:19,  0.92it/s, v_num=lst8, train/loss_step=0.0502]Epoch 0:  45%|████▍     | 330/735 [05:58<07:19,  0.92it/s, v_num=lst8, train/loss_step=0.0495]Epoch 0:  45%|████▌     | 331/735 [05:59<07:18,  0.92it/s, v_num=lst8, train/loss_step=0.0495]Epoch 0:  45%|████▌     | 331/735 [05:59<07:18,  0.92it/s, v_num=lst8, train/loss_step=0.0497]Epoch 0:  45%|████▌     | 332/735 [06:00<07:17,  0.92it/s, v_num=lst8, train/loss_step=0.0497]Epoch 0:  45%|████▌     | 332/735 [06:00<07:17,  0.92it/s, v_num=lst8, train/loss_step=0.0538]Epoch 0:  45%|████▌     | 333/735 [06:01<07:16,  0.92it/s, v_num=lst8, train/loss_step=0.0538]Epoch 0:  45%|████▌     | 333/735 [06:01<07:16,  0.92it/s, v_num=lst8, train/loss_step=0.0491]Epoch 0:  45%|████▌     | 334/735 [06:02<07:15,  0.92it/s, v_num=lst8, train/loss_step=0.0491]Epoch 0:  45%|████▌     | 334/735 [06:02<07:15,  0.92it/s, v_num=lst8, train/loss_step=0.0532]Epoch 0:  46%|████▌     | 335/735 [06:03<07:13,  0.92it/s, v_num=lst8, train/loss_step=0.0532]Epoch 0:  46%|████▌     | 335/735 [06:03<07:13,  0.92it/s, v_num=lst8, train/loss_step=0.0505]Epoch 0:  46%|████▌     | 336/735 [06:04<07:12,  0.92it/s, v_num=lst8, train/loss_step=0.0505]Epoch 0:  46%|████▌     | 336/735 [06:04<07:12,  0.92it/s, v_num=lst8, train/loss_step=0.0507]Epoch 0:  46%|████▌     | 337/735 [06:05<07:11,  0.92it/s, v_num=lst8, train/loss_step=0.0507]Epoch 0:  46%|████▌     | 337/735 [06:05<07:11,  0.92it/s, v_num=lst8, train/loss_step=0.0493]Epoch 0:  46%|████▌     | 338/735 [06:06<07:10,  0.92it/s, v_num=lst8, train/loss_step=0.0493]Epoch 0:  46%|████▌     | 338/735 [06:06<07:10,  0.92it/s, v_num=lst8, train/loss_step=0.0481]Epoch 0:  46%|████▌     | 339/735 [06:07<07:09,  0.92it/s, v_num=lst8, train/loss_step=0.0481]Epoch 0:  46%|████▌     | 339/735 [06:07<07:09,  0.92it/s, v_num=lst8, train/loss_step=0.0477]Epoch 0:  46%|████▋     | 340/735 [06:08<07:08,  0.92it/s, v_num=lst8, train/loss_step=0.0477]Epoch 0:  46%|████▋     | 340/735 [06:08<07:08,  0.92it/s, v_num=lst8, train/loss_step=0.0508]Epoch 0:  46%|████▋     | 341/735 [06:09<07:07,  0.92it/s, v_num=lst8, train/loss_step=0.0508]Epoch 0:  46%|████▋     | 341/735 [06:09<07:07,  0.92it/s, v_num=lst8, train/loss_step=0.0441]Epoch 0:  47%|████▋     | 342/735 [06:10<07:06,  0.92it/s, v_num=lst8, train/loss_step=0.0441]Epoch 0:  47%|████▋     | 342/735 [06:10<07:06,  0.92it/s, v_num=lst8, train/loss_step=0.0457]Epoch 0:  47%|████▋     | 343/735 [06:11<07:04,  0.92it/s, v_num=lst8, train/loss_step=0.0457]Epoch 0:  47%|████▋     | 343/735 [06:11<07:04,  0.92it/s, v_num=lst8, train/loss_step=0.0443]Epoch 0:  47%|████▋     | 344/735 [06:12<07:03,  0.92it/s, v_num=lst8, train/loss_step=0.0443]Epoch 0:  47%|████▋     | 344/735 [06:12<07:03,  0.92it/s, v_num=lst8, train/loss_step=0.047] Epoch 0:  47%|████▋     | 345/735 [06:13<07:02,  0.92it/s, v_num=lst8, train/loss_step=0.047]Epoch 0:  47%|████▋     | 345/735 [06:13<07:02,  0.92it/s, v_num=lst8, train/loss_step=0.0473]Epoch 0:  47%|████▋     | 346/735 [06:14<07:01,  0.92it/s, v_num=lst8, train/loss_step=0.0473]Epoch 0:  47%|████▋     | 346/735 [06:14<07:01,  0.92it/s, v_num=lst8, train/loss_step=0.0481]Epoch 0:  47%|████▋     | 347/735 [06:15<07:00,  0.92it/s, v_num=lst8, train/loss_step=0.0481]Epoch 0:  47%|████▋     | 347/735 [06:15<07:00,  0.92it/s, v_num=lst8, train/loss_step=0.0481]Epoch 0:  47%|████▋     | 348/735 [06:16<06:59,  0.92it/s, v_num=lst8, train/loss_step=0.0481]Epoch 0:  47%|████▋     | 348/735 [06:16<06:59,  0.92it/s, v_num=lst8, train/loss_step=0.0487]Epoch 0:  47%|████▋     | 349/735 [06:17<06:58,  0.92it/s, v_num=lst8, train/loss_step=0.0487]Epoch 0:  47%|████▋     | 349/735 [06:17<06:58,  0.92it/s, v_num=lst8, train/loss_step=0.0544]Epoch 0:  48%|████▊     | 350/735 [06:18<06:56,  0.92it/s, v_num=lst8, train/loss_step=0.0544]Epoch 0:  48%|████▊     | 350/735 [06:18<06:56,  0.92it/s, v_num=lst8, train/loss_step=0.0507]Epoch 0:  48%|████▊     | 351/735 [06:20<06:55,  0.92it/s, v_num=lst8, train/loss_step=0.0507]Epoch 0:  48%|████▊     | 351/735 [06:20<06:55,  0.92it/s, v_num=lst8, train/loss_step=0.0471]Epoch 0:  48%|████▊     | 352/735 [06:21<06:54,  0.92it/s, v_num=lst8, train/loss_step=0.0471]Epoch 0:  48%|████▊     | 352/735 [06:21<06:54,  0.92it/s, v_num=lst8, train/loss_step=0.0463]Epoch 0:  48%|████▊     | 353/735 [06:22<06:53,  0.92it/s, v_num=lst8, train/loss_step=0.0463]Epoch 0:  48%|████▊     | 353/735 [06:22<06:53,  0.92it/s, v_num=lst8, train/loss_step=0.0502]Epoch 0:  48%|████▊     | 354/735 [06:23<06:52,  0.92it/s, v_num=lst8, train/loss_step=0.0502]Epoch 0:  48%|████▊     | 354/735 [06:23<06:52,  0.92it/s, v_num=lst8, train/loss_step=0.0499]Epoch 0:  48%|████▊     | 355/735 [06:24<06:51,  0.92it/s, v_num=lst8, train/loss_step=0.0499]Epoch 0:  48%|████▊     | 355/735 [06:24<06:51,  0.92it/s, v_num=lst8, train/loss_step=0.0528]Epoch 0:  48%|████▊     | 356/735 [06:25<06:50,  0.92it/s, v_num=lst8, train/loss_step=0.0528]Epoch 0:  48%|████▊     | 356/735 [06:25<06:50,  0.92it/s, v_num=lst8, train/loss_step=0.0475]Epoch 0:  49%|████▊     | 357/735 [06:26<06:49,  0.92it/s, v_num=lst8, train/loss_step=0.0475]Epoch 0:  49%|████▊     | 357/735 [06:26<06:49,  0.92it/s, v_num=lst8, train/loss_step=0.0474]Epoch 0:  49%|████▊     | 358/735 [06:27<06:47,  0.92it/s, v_num=lst8, train/loss_step=0.0474]Epoch 0:  49%|████▊     | 358/735 [06:27<06:47,  0.92it/s, v_num=lst8, train/loss_step=0.0511]Epoch 0:  49%|████▉     | 359/735 [06:28<06:46,  0.92it/s, v_num=lst8, train/loss_step=0.0511]Epoch 0:  49%|████▉     | 359/735 [06:28<06:46,  0.92it/s, v_num=lst8, train/loss_step=0.0497]Epoch 0:  49%|████▉     | 360/735 [06:29<06:45,  0.92it/s, v_num=lst8, train/loss_step=0.0497]Epoch 0:  49%|████▉     | 360/735 [06:29<06:45,  0.92it/s, v_num=lst8, train/loss_step=0.0452]Epoch 0:  49%|████▉     | 361/735 [06:30<06:44,  0.92it/s, v_num=lst8, train/loss_step=0.0452]Epoch 0:  49%|████▉     | 361/735 [06:30<06:44,  0.92it/s, v_num=lst8, train/loss_step=0.0479]Epoch 0:  49%|████▉     | 362/735 [06:31<06:43,  0.92it/s, v_num=lst8, train/loss_step=0.0479]Epoch 0:  49%|████▉     | 362/735 [06:31<06:43,  0.92it/s, v_num=lst8, train/loss_step=0.0463]Epoch 0:  49%|████▉     | 363/735 [06:32<06:42,  0.92it/s, v_num=lst8, train/loss_step=0.0463]Epoch 0:  49%|████▉     | 363/735 [06:32<06:42,  0.92it/s, v_num=lst8, train/loss_step=0.0547]Epoch 0:  50%|████▉     | 364/735 [06:33<06:41,  0.92it/s, v_num=lst8, train/loss_step=0.0547]Epoch 0:  50%|████▉     | 364/735 [06:33<06:41,  0.92it/s, v_num=lst8, train/loss_step=0.052] Epoch 0:  50%|████▉     | 365/735 [06:34<06:40,  0.92it/s, v_num=lst8, train/loss_step=0.052]Epoch 0:  50%|████▉     | 365/735 [06:34<06:40,  0.92it/s, v_num=lst8, train/loss_step=0.0491]Epoch 0:  50%|████▉     | 366/735 [06:35<06:39,  0.92it/s, v_num=lst8, train/loss_step=0.0491]Epoch 0:  50%|████▉     | 366/735 [06:35<06:39,  0.92it/s, v_num=lst8, train/loss_step=0.0506]Epoch 0:  50%|████▉     | 367/735 [06:36<06:37,  0.92it/s, v_num=lst8, train/loss_step=0.0506]Epoch 0:  50%|████▉     | 367/735 [06:36<06:37,  0.92it/s, v_num=lst8, train/loss_step=0.047] Epoch 0:  50%|█████     | 368/735 [06:37<06:36,  0.92it/s, v_num=lst8, train/loss_step=0.047]Epoch 0:  50%|█████     | 368/735 [06:37<06:36,  0.92it/s, v_num=lst8, train/loss_step=0.0508]Epoch 0:  50%|█████     | 369/735 [06:38<06:35,  0.92it/s, v_num=lst8, train/loss_step=0.0508]Epoch 0:  50%|█████     | 369/735 [06:38<06:35,  0.92it/s, v_num=lst8, train/loss_step=0.0468]Epoch 0:  50%|█████     | 370/735 [06:39<06:34,  0.93it/s, v_num=lst8, train/loss_step=0.0468]Epoch 0:  50%|█████     | 370/735 [06:39<06:34,  0.93it/s, v_num=lst8, train/loss_step=0.0458]Epoch 0:  50%|█████     | 371/735 [06:41<06:33,  0.93it/s, v_num=lst8, train/loss_step=0.0458]Epoch 0:  50%|█████     | 371/735 [06:41<06:33,  0.93it/s, v_num=lst8, train/loss_step=0.0519]Epoch 0:  51%|█████     | 372/735 [06:42<06:32,  0.93it/s, v_num=lst8, train/loss_step=0.0519]Epoch 0:  51%|█████     | 372/735 [06:42<06:32,  0.93it/s, v_num=lst8, train/loss_step=0.0541]Epoch 0:  51%|█████     | 373/735 [06:43<06:31,  0.93it/s, v_num=lst8, train/loss_step=0.0541]Epoch 0:  51%|█████     | 373/735 [06:43<06:31,  0.93it/s, v_num=lst8, train/loss_step=0.0439]Epoch 0:  51%|█████     | 374/735 [06:44<06:30,  0.93it/s, v_num=lst8, train/loss_step=0.0439]Epoch 0:  51%|█████     | 374/735 [06:44<06:30,  0.93it/s, v_num=lst8, train/loss_step=0.0458]Epoch 0:  51%|█████     | 375/735 [06:45<06:29,  0.93it/s, v_num=lst8, train/loss_step=0.0458]Epoch 0:  51%|█████     | 375/735 [06:45<06:29,  0.93it/s, v_num=lst8, train/loss_step=0.0481]Epoch 0:  51%|█████     | 376/735 [06:46<06:27,  0.93it/s, v_num=lst8, train/loss_step=0.0481]Epoch 0:  51%|█████     | 376/735 [06:46<06:27,  0.93it/s, v_num=lst8, train/loss_step=0.044] Epoch 0:  51%|█████▏    | 377/735 [06:47<06:26,  0.93it/s, v_num=lst8, train/loss_step=0.044]Epoch 0:  51%|█████▏    | 377/735 [06:47<06:26,  0.93it/s, v_num=lst8, train/loss_step=0.0481]Epoch 0:  51%|█████▏    | 378/735 [06:48<06:25,  0.93it/s, v_num=lst8, train/loss_step=0.0481]Epoch 0:  51%|█████▏    | 378/735 [06:48<06:25,  0.93it/s, v_num=lst8, train/loss_step=0.0496]Epoch 0:  52%|█████▏    | 379/735 [06:49<06:24,  0.93it/s, v_num=lst8, train/loss_step=0.0496]Epoch 0:  52%|█████▏    | 379/735 [06:49<06:24,  0.93it/s, v_num=lst8, train/loss_step=0.044] Epoch 0:  52%|█████▏    | 380/735 [06:50<06:23,  0.93it/s, v_num=lst8, train/loss_step=0.044]Epoch 0:  52%|█████▏    | 380/735 [06:50<06:23,  0.93it/s, v_num=lst8, train/loss_step=0.0453]Epoch 0:  52%|█████▏    | 381/735 [06:51<06:22,  0.93it/s, v_num=lst8, train/loss_step=0.0453]Epoch 0:  52%|█████▏    | 381/735 [06:51<06:22,  0.93it/s, v_num=lst8, train/loss_step=0.0423]Epoch 0:  52%|█████▏    | 382/735 [06:52<06:21,  0.93it/s, v_num=lst8, train/loss_step=0.0423]Epoch 0:  52%|█████▏    | 382/735 [06:52<06:21,  0.93it/s, v_num=lst8, train/loss_step=0.0457]Epoch 0:  52%|█████▏    | 383/735 [06:53<06:20,  0.93it/s, v_num=lst8, train/loss_step=0.0457]Epoch 0:  52%|█████▏    | 383/735 [06:53<06:20,  0.93it/s, v_num=lst8, train/loss_step=0.0459]Epoch 0:  52%|█████▏    | 384/735 [06:54<06:18,  0.93it/s, v_num=lst8, train/loss_step=0.0459]Epoch 0:  52%|█████▏    | 384/735 [06:54<06:18,  0.93it/s, v_num=lst8, train/loss_step=0.0478]Epoch 0:  52%|█████▏    | 385/735 [06:55<06:17,  0.93it/s, v_num=lst8, train/loss_step=0.0478]Epoch 0:  52%|█████▏    | 385/735 [06:55<06:17,  0.93it/s, v_num=lst8, train/loss_step=0.0488]Epoch 0:  53%|█████▎    | 386/735 [06:56<06:16,  0.93it/s, v_num=lst8, train/loss_step=0.0488]Epoch 0:  53%|█████▎    | 386/735 [06:56<06:16,  0.93it/s, v_num=lst8, train/loss_step=0.0471]Epoch 0:  53%|█████▎    | 387/735 [06:57<06:15,  0.93it/s, v_num=lst8, train/loss_step=0.0471]Epoch 0:  53%|█████▎    | 387/735 [06:57<06:15,  0.93it/s, v_num=lst8, train/loss_step=0.0511]Epoch 0:  53%|█████▎    | 388/735 [06:58<06:14,  0.93it/s, v_num=lst8, train/loss_step=0.0511]Epoch 0:  53%|█████▎    | 388/735 [06:58<06:14,  0.93it/s, v_num=lst8, train/loss_step=0.042] Epoch 0:  53%|█████▎    | 389/735 [06:59<06:13,  0.93it/s, v_num=lst8, train/loss_step=0.042]Epoch 0:  53%|█████▎    | 389/735 [06:59<06:13,  0.93it/s, v_num=lst8, train/loss_step=0.042]Epoch 0:  53%|█████▎    | 390/735 [07:00<06:12,  0.93it/s, v_num=lst8, train/loss_step=0.042]Epoch 0:  53%|█████▎    | 390/735 [07:00<06:12,  0.93it/s, v_num=lst8, train/loss_step=0.0447]Epoch 0:  53%|█████▎    | 391/735 [07:01<06:11,  0.93it/s, v_num=lst8, train/loss_step=0.0447]Epoch 0:  53%|█████▎    | 391/735 [07:01<06:11,  0.93it/s, v_num=lst8, train/loss_step=0.0413]Epoch 0:  53%|█████▎    | 392/735 [07:03<06:10,  0.93it/s, v_num=lst8, train/loss_step=0.0413]Epoch 0:  53%|█████▎    | 392/735 [07:03<06:10,  0.93it/s, v_num=lst8, train/loss_step=0.0422]Epoch 0:  53%|█████▎    | 393/735 [07:04<06:09,  0.93it/s, v_num=lst8, train/loss_step=0.0422]Epoch 0:  53%|█████▎    | 393/735 [07:04<06:09,  0.93it/s, v_num=lst8, train/loss_step=0.0464]Epoch 0:  54%|█████▎    | 394/735 [07:05<06:07,  0.93it/s, v_num=lst8, train/loss_step=0.0464]Epoch 0:  54%|█████▎    | 394/735 [07:05<06:07,  0.93it/s, v_num=lst8, train/loss_step=0.0414]Epoch 0:  54%|█████▎    | 395/735 [07:06<06:06,  0.93it/s, v_num=lst8, train/loss_step=0.0414]Epoch 0:  54%|█████▎    | 395/735 [07:06<06:06,  0.93it/s, v_num=lst8, train/loss_step=0.0444]Epoch 0:  54%|█████▍    | 396/735 [07:07<06:05,  0.93it/s, v_num=lst8, train/loss_step=0.0444]Epoch 0:  54%|█████▍    | 396/735 [07:07<06:05,  0.93it/s, v_num=lst8, train/loss_step=0.0418]Epoch 0:  54%|█████▍    | 397/735 [07:08<06:04,  0.93it/s, v_num=lst8, train/loss_step=0.0418]Epoch 0:  54%|█████▍    | 397/735 [07:08<06:04,  0.93it/s, v_num=lst8, train/loss_step=0.0494]Epoch 0:  54%|█████▍    | 398/735 [07:09<06:03,  0.93it/s, v_num=lst8, train/loss_step=0.0494]Epoch 0:  54%|█████▍    | 398/735 [07:09<06:03,  0.93it/s, v_num=lst8, train/loss_step=0.044] Epoch 0:  54%|█████▍    | 399/735 [07:10<06:02,  0.93it/s, v_num=lst8, train/loss_step=0.044]Epoch 0:  54%|█████▍    | 399/735 [07:10<06:02,  0.93it/s, v_num=lst8, train/loss_step=0.0471]Epoch 0:  54%|█████▍    | 400/735 [07:11<06:01,  0.93it/s, v_num=lst8, train/loss_step=0.0471]Epoch 0:  54%|█████▍    | 400/735 [07:11<06:01,  0.93it/s, v_num=lst8, train/loss_step=0.0485]Epoch 0:  55%|█████▍    | 401/735 [07:12<06:00,  0.93it/s, v_num=lst8, train/loss_step=0.0485]Epoch 0:  55%|█████▍    | 401/735 [07:12<06:00,  0.93it/s, v_num=lst8, train/loss_step=0.047] Epoch 0:  55%|█████▍    | 402/735 [07:13<05:59,  0.93it/s, v_num=lst8, train/loss_step=0.047]Epoch 0:  55%|█████▍    | 402/735 [07:13<05:59,  0.93it/s, v_num=lst8, train/loss_step=0.0455]Epoch 0:  55%|█████▍    | 403/735 [07:14<05:58,  0.93it/s, v_num=lst8, train/loss_step=0.0455]Epoch 0:  55%|█████▍    | 403/735 [07:14<05:58,  0.93it/s, v_num=lst8, train/loss_step=0.0405]Epoch 0:  55%|█████▍    | 404/735 [07:15<05:56,  0.93it/s, v_num=lst8, train/loss_step=0.0405]Epoch 0:  55%|█████▍    | 404/735 [07:15<05:56,  0.93it/s, v_num=lst8, train/loss_step=0.0516]Epoch 0:  55%|█████▌    | 405/735 [07:16<05:55,  0.93it/s, v_num=lst8, train/loss_step=0.0516]Epoch 0:  55%|█████▌    | 405/735 [07:16<05:55,  0.93it/s, v_num=lst8, train/loss_step=0.0471]Epoch 0:  55%|█████▌    | 406/735 [07:17<05:54,  0.93it/s, v_num=lst8, train/loss_step=0.0471]Epoch 0:  55%|█████▌    | 406/735 [07:17<05:54,  0.93it/s, v_num=lst8, train/loss_step=0.0447]Epoch 0:  55%|█████▌    | 407/735 [07:18<05:53,  0.93it/s, v_num=lst8, train/loss_step=0.0447]Epoch 0:  55%|█████▌    | 407/735 [07:18<05:53,  0.93it/s, v_num=lst8, train/loss_step=0.0446]Epoch 0:  56%|█████▌    | 408/735 [07:19<05:52,  0.93it/s, v_num=lst8, train/loss_step=0.0446]Epoch 0:  56%|█████▌    | 408/735 [07:19<05:52,  0.93it/s, v_num=lst8, train/loss_step=0.0496]Epoch 0:  56%|█████▌    | 409/735 [07:20<05:51,  0.93it/s, v_num=lst8, train/loss_step=0.0496]Epoch 0:  56%|█████▌    | 409/735 [07:20<05:51,  0.93it/s, v_num=lst8, train/loss_step=0.0501]Epoch 0:  56%|█████▌    | 410/735 [07:21<05:50,  0.93it/s, v_num=lst8, train/loss_step=0.0501]Epoch 0:  56%|█████▌    | 410/735 [07:21<05:50,  0.93it/s, v_num=lst8, train/loss_step=0.0499]Epoch 0:  56%|█████▌    | 411/735 [07:22<05:49,  0.93it/s, v_num=lst8, train/loss_step=0.0499]Epoch 0:  56%|█████▌    | 411/735 [07:22<05:49,  0.93it/s, v_num=lst8, train/loss_step=0.0455]Epoch 0:  56%|█████▌    | 412/735 [07:23<05:48,  0.93it/s, v_num=lst8, train/loss_step=0.0455]Epoch 0:  56%|█████▌    | 412/735 [07:23<05:48,  0.93it/s, v_num=lst8, train/loss_step=0.0466]Epoch 0:  56%|█████▌    | 413/735 [07:25<05:46,  0.93it/s, v_num=lst8, train/loss_step=0.0466]Epoch 0:  56%|█████▌    | 413/735 [07:25<05:46,  0.93it/s, v_num=lst8, train/loss_step=0.048] Epoch 0:  56%|█████▋    | 414/735 [07:26<05:45,  0.93it/s, v_num=lst8, train/loss_step=0.048]Epoch 0:  56%|█████▋    | 414/735 [07:26<05:45,  0.93it/s, v_num=lst8, train/loss_step=0.0496]Epoch 0:  56%|█████▋    | 415/735 [07:27<05:44,  0.93it/s, v_num=lst8, train/loss_step=0.0496]Epoch 0:  56%|█████▋    | 415/735 [07:27<05:44,  0.93it/s, v_num=lst8, train/loss_step=0.0443]Epoch 0:  57%|█████▋    | 416/735 [07:28<05:43,  0.93it/s, v_num=lst8, train/loss_step=0.0443]Epoch 0:  57%|█████▋    | 416/735 [07:28<05:43,  0.93it/s, v_num=lst8, train/loss_step=0.0454]Epoch 0:  57%|█████▋    | 417/735 [07:29<05:42,  0.93it/s, v_num=lst8, train/loss_step=0.0454]Epoch 0:  57%|█████▋    | 417/735 [07:29<05:42,  0.93it/s, v_num=lst8, train/loss_step=0.045] Epoch 0:  57%|█████▋    | 418/735 [07:30<05:41,  0.93it/s, v_num=lst8, train/loss_step=0.045]Epoch 0:  57%|█████▋    | 418/735 [07:30<05:41,  0.93it/s, v_num=lst8, train/loss_step=0.0444]Epoch 0:  57%|█████▋    | 419/735 [07:31<05:40,  0.93it/s, v_num=lst8, train/loss_step=0.0444]Epoch 0:  57%|█████▋    | 419/735 [07:31<05:40,  0.93it/s, v_num=lst8, train/loss_step=0.0417]Epoch 0:  57%|█████▋    | 420/735 [07:32<05:39,  0.93it/s, v_num=lst8, train/loss_step=0.0417]Epoch 0:  57%|█████▋    | 420/735 [07:32<05:39,  0.93it/s, v_num=lst8, train/loss_step=0.0412]Epoch 0:  57%|█████▋    | 421/735 [07:33<05:38,  0.93it/s, v_num=lst8, train/loss_step=0.0412]Epoch 0:  57%|█████▋    | 421/735 [07:33<05:38,  0.93it/s, v_num=lst8, train/loss_step=0.045] Epoch 0:  57%|█████▋    | 422/735 [07:34<05:37,  0.93it/s, v_num=lst8, train/loss_step=0.045]Epoch 0:  57%|█████▋    | 422/735 [07:34<05:37,  0.93it/s, v_num=lst8, train/loss_step=0.0442]Epoch 0:  58%|█████▊    | 423/735 [07:35<05:35,  0.93it/s, v_num=lst8, train/loss_step=0.0442]Epoch 0:  58%|█████▊    | 423/735 [07:35<05:35,  0.93it/s, v_num=lst8, train/loss_step=0.045] Epoch 0:  58%|█████▊    | 424/735 [07:36<05:34,  0.93it/s, v_num=lst8, train/loss_step=0.045]Epoch 0:  58%|█████▊    | 424/735 [07:36<05:34,  0.93it/s, v_num=lst8, train/loss_step=0.0464]Epoch 0:  58%|█████▊    | 425/735 [07:37<05:33,  0.93it/s, v_num=lst8, train/loss_step=0.0464]Epoch 0:  58%|█████▊    | 425/735 [07:37<05:33,  0.93it/s, v_num=lst8, train/loss_step=0.0462]Epoch 0:  58%|█████▊    | 426/735 [07:38<05:32,  0.93it/s, v_num=lst8, train/loss_step=0.0462]Epoch 0:  58%|█████▊    | 426/735 [07:38<05:32,  0.93it/s, v_num=lst8, train/loss_step=0.0438]Epoch 0:  58%|█████▊    | 427/735 [07:39<05:31,  0.93it/s, v_num=lst8, train/loss_step=0.0438]Epoch 0:  58%|█████▊    | 427/735 [07:39<05:31,  0.93it/s, v_num=lst8, train/loss_step=0.0473]Epoch 0:  58%|█████▊    | 428/735 [07:40<05:30,  0.93it/s, v_num=lst8, train/loss_step=0.0473]Epoch 0:  58%|█████▊    | 428/735 [07:40<05:30,  0.93it/s, v_num=lst8, train/loss_step=0.0422]Epoch 0:  58%|█████▊    | 429/735 [07:41<05:29,  0.93it/s, v_num=lst8, train/loss_step=0.0422]Epoch 0:  58%|█████▊    | 429/735 [07:41<05:29,  0.93it/s, v_num=lst8, train/loss_step=0.0436]Epoch 0:  59%|█████▊    | 430/735 [07:42<05:28,  0.93it/s, v_num=lst8, train/loss_step=0.0436]Epoch 0:  59%|█████▊    | 430/735 [07:42<05:28,  0.93it/s, v_num=lst8, train/loss_step=0.0461]Epoch 0:  59%|█████▊    | 431/735 [07:43<05:27,  0.93it/s, v_num=lst8, train/loss_step=0.0461]Epoch 0:  59%|█████▊    | 431/735 [07:43<05:27,  0.93it/s, v_num=lst8, train/loss_step=0.0443]Epoch 0:  59%|█████▉    | 432/735 [07:44<05:26,  0.93it/s, v_num=lst8, train/loss_step=0.0443]Epoch 0:  59%|█████▉    | 432/735 [07:44<05:26,  0.93it/s, v_num=lst8, train/loss_step=0.0452]Epoch 0:  59%|█████▉    | 433/735 [07:45<05:25,  0.93it/s, v_num=lst8, train/loss_step=0.0452]Epoch 0:  59%|█████▉    | 433/735 [07:45<05:25,  0.93it/s, v_num=lst8, train/loss_step=0.0428]Epoch 0:  59%|█████▉    | 434/735 [07:47<05:23,  0.93it/s, v_num=lst8, train/loss_step=0.0428]Epoch 0:  59%|█████▉    | 434/735 [07:47<05:23,  0.93it/s, v_num=lst8, train/loss_step=0.0405]Epoch 0:  59%|█████▉    | 435/735 [07:48<05:22,  0.93it/s, v_num=lst8, train/loss_step=0.0405]Epoch 0:  59%|█████▉    | 435/735 [07:48<05:22,  0.93it/s, v_num=lst8, train/loss_step=0.0546]Epoch 0:  59%|█████▉    | 436/735 [07:49<05:21,  0.93it/s, v_num=lst8, train/loss_step=0.0546]Epoch 0:  59%|█████▉    | 436/735 [07:49<05:21,  0.93it/s, v_num=lst8, train/loss_step=0.0441]Epoch 0:  59%|█████▉    | 437/735 [07:50<05:20,  0.93it/s, v_num=lst8, train/loss_step=0.0441]Epoch 0:  59%|█████▉    | 437/735 [07:50<05:20,  0.93it/s, v_num=lst8, train/loss_step=0.0427]Epoch 0:  60%|█████▉    | 438/735 [07:51<05:19,  0.93it/s, v_num=lst8, train/loss_step=0.0427]Epoch 0:  60%|█████▉    | 438/735 [07:51<05:19,  0.93it/s, v_num=lst8, train/loss_step=0.0417]Epoch 0:  60%|█████▉    | 439/735 [07:52<05:18,  0.93it/s, v_num=lst8, train/loss_step=0.0417]Epoch 0:  60%|█████▉    | 439/735 [07:52<05:18,  0.93it/s, v_num=lst8, train/loss_step=0.0435]Epoch 0:  60%|█████▉    | 440/735 [07:53<05:17,  0.93it/s, v_num=lst8, train/loss_step=0.0435]Epoch 0:  60%|█████▉    | 440/735 [07:53<05:17,  0.93it/s, v_num=lst8, train/loss_step=0.0459]Epoch 0:  60%|██████    | 441/735 [07:54<05:16,  0.93it/s, v_num=lst8, train/loss_step=0.0459]Epoch 0:  60%|██████    | 441/735 [07:54<05:16,  0.93it/s, v_num=lst8, train/loss_step=0.0462]Epoch 0:  60%|██████    | 442/735 [07:55<05:15,  0.93it/s, v_num=lst8, train/loss_step=0.0462]Epoch 0:  60%|██████    | 442/735 [07:55<05:15,  0.93it/s, v_num=lst8, train/loss_step=0.038] Epoch 0:  60%|██████    | 443/735 [07:56<05:13,  0.93it/s, v_num=lst8, train/loss_step=0.038]Epoch 0:  60%|██████    | 443/735 [07:56<05:13,  0.93it/s, v_num=lst8, train/loss_step=0.042]Epoch 0:  60%|██████    | 444/735 [07:57<05:12,  0.93it/s, v_num=lst8, train/loss_step=0.042]Epoch 0:  60%|██████    | 444/735 [07:57<05:12,  0.93it/s, v_num=lst8, train/loss_step=0.0431]Epoch 0:  61%|██████    | 445/735 [07:58<05:11,  0.93it/s, v_num=lst8, train/loss_step=0.0431]Epoch 0:  61%|██████    | 445/735 [07:58<05:11,  0.93it/s, v_num=lst8, train/loss_step=0.0474]Epoch 0:  61%|██████    | 446/735 [07:59<05:10,  0.93it/s, v_num=lst8, train/loss_step=0.0474]Epoch 0:  61%|██████    | 446/735 [07:59<05:10,  0.93it/s, v_num=lst8, train/loss_step=0.0428]Epoch 0:  61%|██████    | 447/735 [08:00<05:09,  0.93it/s, v_num=lst8, train/loss_step=0.0428]Epoch 0:  61%|██████    | 447/735 [08:00<05:09,  0.93it/s, v_num=lst8, train/loss_step=0.0424]Epoch 0:  61%|██████    | 448/735 [08:01<05:08,  0.93it/s, v_num=lst8, train/loss_step=0.0424]Epoch 0:  61%|██████    | 448/735 [08:01<05:08,  0.93it/s, v_num=lst8, train/loss_step=0.041] Epoch 0:  61%|██████    | 449/735 [08:02<05:07,  0.93it/s, v_num=lst8, train/loss_step=0.041]Epoch 0:  61%|██████    | 449/735 [08:02<05:07,  0.93it/s, v_num=lst8, train/loss_step=0.0474]Epoch 0:  61%|██████    | 450/735 [08:03<05:06,  0.93it/s, v_num=lst8, train/loss_step=0.0474]Epoch 0:  61%|██████    | 450/735 [08:03<05:06,  0.93it/s, v_num=lst8, train/loss_step=0.0428]Epoch 0:  61%|██████▏   | 451/735 [08:04<05:05,  0.93it/s, v_num=lst8, train/loss_step=0.0428]Epoch 0:  61%|██████▏   | 451/735 [08:04<05:05,  0.93it/s, v_num=lst8, train/loss_step=0.0494]Epoch 0:  61%|██████▏   | 452/735 [08:05<05:04,  0.93it/s, v_num=lst8, train/loss_step=0.0494]Epoch 0:  61%|██████▏   | 452/735 [08:05<05:04,  0.93it/s, v_num=lst8, train/loss_step=0.0428]Epoch 0:  62%|██████▏   | 453/735 [08:06<05:03,  0.93it/s, v_num=lst8, train/loss_step=0.0428]Epoch 0:  62%|██████▏   | 453/735 [08:06<05:03,  0.93it/s, v_num=lst8, train/loss_step=0.046] Epoch 0:  62%|██████▏   | 454/735 [08:07<05:01,  0.93it/s, v_num=lst8, train/loss_step=0.046]Epoch 0:  62%|██████▏   | 454/735 [08:07<05:01,  0.93it/s, v_num=lst8, train/loss_step=0.049]Epoch 0:  62%|██████▏   | 455/735 [08:08<05:00,  0.93it/s, v_num=lst8, train/loss_step=0.049]Epoch 0:  62%|██████▏   | 455/735 [08:08<05:00,  0.93it/s, v_num=lst8, train/loss_step=0.0449]Epoch 0:  62%|██████▏   | 456/735 [08:09<04:59,  0.93it/s, v_num=lst8, train/loss_step=0.0449]Epoch 0:  62%|██████▏   | 456/735 [08:09<04:59,  0.93it/s, v_num=lst8, train/loss_step=0.0412]Epoch 0:  62%|██████▏   | 457/735 [08:10<04:58,  0.93it/s, v_num=lst8, train/loss_step=0.0412]Epoch 0:  62%|██████▏   | 457/735 [08:10<04:58,  0.93it/s, v_num=lst8, train/loss_step=0.0451]Epoch 0:  62%|██████▏   | 458/735 [08:12<04:57,  0.93it/s, v_num=lst8, train/loss_step=0.0451]Epoch 0:  62%|██████▏   | 458/735 [08:12<04:57,  0.93it/s, v_num=lst8, train/loss_step=0.048] Epoch 0:  62%|██████▏   | 459/735 [08:13<04:56,  0.93it/s, v_num=lst8, train/loss_step=0.048]Epoch 0:  62%|██████▏   | 459/735 [08:13<04:56,  0.93it/s, v_num=lst8, train/loss_step=0.045]Epoch 0:  63%|██████▎   | 460/735 [08:14<04:55,  0.93it/s, v_num=lst8, train/loss_step=0.045]Epoch 0:  63%|██████▎   | 460/735 [08:14<04:55,  0.93it/s, v_num=lst8, train/loss_step=0.0357]Epoch 0:  63%|██████▎   | 461/735 [08:15<04:54,  0.93it/s, v_num=lst8, train/loss_step=0.0357]Epoch 0:  63%|██████▎   | 461/735 [08:15<04:54,  0.93it/s, v_num=lst8, train/loss_step=0.0431]Epoch 0:  63%|██████▎   | 462/735 [08:16<04:53,  0.93it/s, v_num=lst8, train/loss_step=0.0431]Epoch 0:  63%|██████▎   | 462/735 [08:16<04:53,  0.93it/s, v_num=lst8, train/loss_step=0.0417]Epoch 0:  63%|██████▎   | 463/735 [08:17<04:52,  0.93it/s, v_num=lst8, train/loss_step=0.0417]Epoch 0:  63%|██████▎   | 463/735 [08:17<04:52,  0.93it/s, v_num=lst8, train/loss_step=0.0438]Epoch 0:  63%|██████▎   | 464/735 [08:18<04:51,  0.93it/s, v_num=lst8, train/loss_step=0.0438]Epoch 0:  63%|██████▎   | 464/735 [08:18<04:51,  0.93it/s, v_num=lst8, train/loss_step=0.0405]Epoch 0:  63%|██████▎   | 465/735 [08:19<04:49,  0.93it/s, v_num=lst8, train/loss_step=0.0405]Epoch 0:  63%|██████▎   | 465/735 [08:19<04:49,  0.93it/s, v_num=lst8, train/loss_step=0.0438]Epoch 0:  63%|██████▎   | 466/735 [08:20<04:48,  0.93it/s, v_num=lst8, train/loss_step=0.0438]Epoch 0:  63%|██████▎   | 466/735 [08:20<04:48,  0.93it/s, v_num=lst8, train/loss_step=0.0481]Epoch 0:  64%|██████▎   | 467/735 [08:21<04:47,  0.93it/s, v_num=lst8, train/loss_step=0.0481]Epoch 0:  64%|██████▎   | 467/735 [08:21<04:47,  0.93it/s, v_num=lst8, train/loss_step=0.0419]Epoch 0:  64%|██████▎   | 468/735 [08:22<04:46,  0.93it/s, v_num=lst8, train/loss_step=0.0419]Epoch 0:  64%|██████▎   | 468/735 [08:22<04:46,  0.93it/s, v_num=lst8, train/loss_step=0.044] Epoch 0:  64%|██████▍   | 469/735 [08:23<04:45,  0.93it/s, v_num=lst8, train/loss_step=0.044]Epoch 0:  64%|██████▍   | 469/735 [08:23<04:45,  0.93it/s, v_num=lst8, train/loss_step=0.0424]Epoch 0:  64%|██████▍   | 470/735 [08:24<04:44,  0.93it/s, v_num=lst8, train/loss_step=0.0424]Epoch 0:  64%|██████▍   | 470/735 [08:24<04:44,  0.93it/s, v_num=lst8, train/loss_step=0.0474]Epoch 0:  64%|██████▍   | 471/735 [08:25<04:43,  0.93it/s, v_num=lst8, train/loss_step=0.0474]Epoch 0:  64%|██████▍   | 471/735 [08:25<04:43,  0.93it/s, v_num=lst8, train/loss_step=0.0418]Epoch 0:  64%|██████▍   | 472/735 [08:26<04:42,  0.93it/s, v_num=lst8, train/loss_step=0.0418]Epoch 0:  64%|██████▍   | 472/735 [08:26<04:42,  0.93it/s, v_num=lst8, train/loss_step=0.0373]Epoch 0:  64%|██████▍   | 473/735 [08:27<04:41,  0.93it/s, v_num=lst8, train/loss_step=0.0373]Epoch 0:  64%|██████▍   | 473/735 [08:27<04:41,  0.93it/s, v_num=lst8, train/loss_step=0.0459]Epoch 0:  64%|██████▍   | 474/735 [08:28<04:39,  0.93it/s, v_num=lst8, train/loss_step=0.0459]Epoch 0:  64%|██████▍   | 474/735 [08:28<04:39,  0.93it/s, v_num=lst8, train/loss_step=0.0443]Epoch 0:  65%|██████▍   | 475/735 [08:29<04:38,  0.93it/s, v_num=lst8, train/loss_step=0.0443]Epoch 0:  65%|██████▍   | 475/735 [08:29<04:38,  0.93it/s, v_num=lst8, train/loss_step=0.038] Epoch 0:  65%|██████▍   | 476/735 [08:30<04:37,  0.93it/s, v_num=lst8, train/loss_step=0.038]Epoch 0:  65%|██████▍   | 476/735 [08:30<04:37,  0.93it/s, v_num=lst8, train/loss_step=0.0396]Epoch 0:  65%|██████▍   | 477/735 [08:31<04:36,  0.93it/s, v_num=lst8, train/loss_step=0.0396]Epoch 0:  65%|██████▍   | 477/735 [08:31<04:36,  0.93it/s, v_num=lst8, train/loss_step=0.0434]Epoch 0:  65%|██████▌   | 478/735 [08:32<04:35,  0.93it/s, v_num=lst8, train/loss_step=0.0434]Epoch 0:  65%|██████▌   | 478/735 [08:32<04:35,  0.93it/s, v_num=lst8, train/loss_step=0.0444]Epoch 0:  65%|██████▌   | 479/735 [08:33<04:34,  0.93it/s, v_num=lst8, train/loss_step=0.0444]Epoch 0:  65%|██████▌   | 479/735 [08:33<04:34,  0.93it/s, v_num=lst8, train/loss_step=0.0432]Epoch 0:  65%|██████▌   | 480/735 [08:34<04:33,  0.93it/s, v_num=lst8, train/loss_step=0.0432]Epoch 0:  65%|██████▌   | 480/735 [08:34<04:33,  0.93it/s, v_num=lst8, train/loss_step=0.0369]Epoch 0:  65%|██████▌   | 481/735 [08:35<04:32,  0.93it/s, v_num=lst8, train/loss_step=0.0369]Epoch 0:  65%|██████▌   | 481/735 [08:35<04:32,  0.93it/s, v_num=lst8, train/loss_step=0.0402]Epoch 0:  66%|██████▌   | 482/735 [08:36<04:31,  0.93it/s, v_num=lst8, train/loss_step=0.0402]Epoch 0:  66%|██████▌   | 482/735 [08:36<04:31,  0.93it/s, v_num=lst8, train/loss_step=0.0452]Epoch 0:  66%|██████▌   | 483/735 [08:37<04:30,  0.93it/s, v_num=lst8, train/loss_step=0.0452]Epoch 0:  66%|██████▌   | 483/735 [08:37<04:30,  0.93it/s, v_num=lst8, train/loss_step=0.0503]Epoch 0:  66%|██████▌   | 484/735 [08:38<04:29,  0.93it/s, v_num=lst8, train/loss_step=0.0503]Epoch 0:  66%|██████▌   | 484/735 [08:38<04:29,  0.93it/s, v_num=lst8, train/loss_step=0.0402]Epoch 0:  66%|██████▌   | 485/735 [08:40<04:28,  0.93it/s, v_num=lst8, train/loss_step=0.0402]Epoch 0:  66%|██████▌   | 485/735 [08:40<04:28,  0.93it/s, v_num=lst8, train/loss_step=0.0452]Epoch 0:  66%|██████▌   | 486/735 [08:41<04:26,  0.93it/s, v_num=lst8, train/loss_step=0.0452]Epoch 0:  66%|██████▌   | 486/735 [08:41<04:26,  0.93it/s, v_num=lst8, train/loss_step=0.0454]Epoch 0:  66%|██████▋   | 487/735 [08:42<04:25,  0.93it/s, v_num=lst8, train/loss_step=0.0454]Epoch 0:  66%|██████▋   | 487/735 [08:42<04:25,  0.93it/s, v_num=lst8, train/loss_step=0.0424]Epoch 0:  66%|██████▋   | 488/735 [08:43<04:24,  0.93it/s, v_num=lst8, train/loss_step=0.0424]Epoch 0:  66%|██████▋   | 488/735 [08:43<04:24,  0.93it/s, v_num=lst8, train/loss_step=0.0465]Epoch 0:  67%|██████▋   | 489/735 [08:44<04:23,  0.93it/s, v_num=lst8, train/loss_step=0.0465]Epoch 0:  67%|██████▋   | 489/735 [08:44<04:23,  0.93it/s, v_num=lst8, train/loss_step=0.0368]Epoch 0:  67%|██████▋   | 490/735 [08:45<04:22,  0.93it/s, v_num=lst8, train/loss_step=0.0368]Epoch 0:  67%|██████▋   | 490/735 [08:45<04:22,  0.93it/s, v_num=lst8, train/loss_step=0.0367]Epoch 0:  67%|██████▋   | 491/735 [08:46<04:21,  0.93it/s, v_num=lst8, train/loss_step=0.0367]Epoch 0:  67%|██████▋   | 491/735 [08:46<04:21,  0.93it/s, v_num=lst8, train/loss_step=0.0383]Epoch 0:  67%|██████▋   | 492/735 [08:47<04:20,  0.93it/s, v_num=lst8, train/loss_step=0.0383]Epoch 0:  67%|██████▋   | 492/735 [08:47<04:20,  0.93it/s, v_num=lst8, train/loss_step=0.0403]Epoch 0:  67%|██████▋   | 493/735 [08:48<04:19,  0.93it/s, v_num=lst8, train/loss_step=0.0403]Epoch 0:  67%|██████▋   | 493/735 [08:48<04:19,  0.93it/s, v_num=lst8, train/loss_step=0.0399]Epoch 0:  67%|██████▋   | 494/735 [08:49<04:18,  0.93it/s, v_num=lst8, train/loss_step=0.0399]Epoch 0:  67%|██████▋   | 494/735 [08:49<04:18,  0.93it/s, v_num=lst8, train/loss_step=0.0364]Epoch 0:  67%|██████▋   | 495/735 [08:50<04:17,  0.93it/s, v_num=lst8, train/loss_step=0.0364]Epoch 0:  67%|██████▋   | 495/735 [08:50<04:17,  0.93it/s, v_num=lst8, train/loss_step=0.0357]Epoch 0:  67%|██████▋   | 496/735 [08:51<04:16,  0.93it/s, v_num=lst8, train/loss_step=0.0357]Epoch 0:  67%|██████▋   | 496/735 [08:51<04:16,  0.93it/s, v_num=lst8, train/loss_step=0.043] Epoch 0:  68%|██████▊   | 497/735 [08:52<04:15,  0.93it/s, v_num=lst8, train/loss_step=0.043]Epoch 0:  68%|██████▊   | 497/735 [08:52<04:15,  0.93it/s, v_num=lst8, train/loss_step=0.0451]Epoch 0:  68%|██████▊   | 498/735 [08:53<04:13,  0.93it/s, v_num=lst8, train/loss_step=0.0451]Epoch 0:  68%|██████▊   | 498/735 [08:53<04:13,  0.93it/s, v_num=lst8, train/loss_step=0.0439]Epoch 0:  68%|██████▊   | 499/735 [08:54<04:12,  0.93it/s, v_num=lst8, train/loss_step=0.0439]Epoch 0:  68%|██████▊   | 499/735 [08:54<04:12,  0.93it/s, v_num=lst8, train/loss_step=0.036] Epoch 0:  68%|██████▊   | 500/735 [08:55<04:11,  0.93it/s, v_num=lst8, train/loss_step=0.036]Epoch 0:  68%|██████▊   | 500/735 [08:55<04:11,  0.93it/s, v_num=lst8, train/loss_step=0.0403]Epoch 0:  68%|██████▊   | 501/735 [08:56<04:10,  0.93it/s, v_num=lst8, train/loss_step=0.0403]Epoch 0:  68%|██████▊   | 501/735 [08:56<04:10,  0.93it/s, v_num=lst8, train/loss_step=0.0386]Epoch 0:  68%|██████▊   | 502/735 [08:57<04:09,  0.93it/s, v_num=lst8, train/loss_step=0.0386]Epoch 0:  68%|██████▊   | 502/735 [08:57<04:09,  0.93it/s, v_num=lst8, train/loss_step=0.0406]Epoch 0:  68%|██████▊   | 503/735 [08:58<04:08,  0.93it/s, v_num=lst8, train/loss_step=0.0406]Epoch 0:  68%|██████▊   | 503/735 [08:58<04:08,  0.93it/s, v_num=lst8, train/loss_step=0.0385]Epoch 0:  69%|██████▊   | 504/735 [08:59<04:07,  0.93it/s, v_num=lst8, train/loss_step=0.0385]Epoch 0:  69%|██████▊   | 504/735 [08:59<04:07,  0.93it/s, v_num=lst8, train/loss_step=0.0386]Epoch 0:  69%|██████▊   | 505/735 [09:00<04:06,  0.93it/s, v_num=lst8, train/loss_step=0.0386]Epoch 0:  69%|██████▊   | 505/735 [09:00<04:06,  0.93it/s, v_num=lst8, train/loss_step=0.037] Epoch 0:  69%|██████▉   | 506/735 [09:01<04:05,  0.93it/s, v_num=lst8, train/loss_step=0.037]Epoch 0:  69%|██████▉   | 506/735 [09:01<04:05,  0.93it/s, v_num=lst8, train/loss_step=0.0431]Epoch 0:  69%|██████▉   | 507/735 [09:03<04:04,  0.93it/s, v_num=lst8, train/loss_step=0.0431]Epoch 0:  69%|██████▉   | 507/735 [09:03<04:04,  0.93it/s, v_num=lst8, train/loss_step=0.0449]Epoch 0:  69%|██████▉   | 508/735 [09:04<04:03,  0.93it/s, v_num=lst8, train/loss_step=0.0449]Epoch 0:  69%|██████▉   | 508/735 [09:04<04:03,  0.93it/s, v_num=lst8, train/loss_step=0.0396]Epoch 0:  69%|██████▉   | 509/735 [09:05<04:02,  0.93it/s, v_num=lst8, train/loss_step=0.0396]Epoch 0:  69%|██████▉   | 509/735 [09:05<04:02,  0.93it/s, v_num=lst8, train/loss_step=0.0453]Epoch 0:  69%|██████▉   | 510/735 [09:06<04:00,  0.93it/s, v_num=lst8, train/loss_step=0.0453]Epoch 0:  69%|██████▉   | 510/735 [09:06<04:00,  0.93it/s, v_num=lst8, train/loss_step=0.0384]Epoch 0:  70%|██████▉   | 511/735 [09:07<03:59,  0.93it/s, v_num=lst8, train/loss_step=0.0384]Epoch 0:  70%|██████▉   | 511/735 [09:07<03:59,  0.93it/s, v_num=lst8, train/loss_step=0.0359]Epoch 0:  70%|██████▉   | 512/735 [09:08<03:58,  0.93it/s, v_num=lst8, train/loss_step=0.0359]Epoch 0:  70%|██████▉   | 512/735 [09:08<03:58,  0.93it/s, v_num=lst8, train/loss_step=0.0397]Epoch 0:  70%|██████▉   | 513/735 [09:09<03:57,  0.93it/s, v_num=lst8, train/loss_step=0.0397]Epoch 0:  70%|██████▉   | 513/735 [09:09<03:57,  0.93it/s, v_num=lst8, train/loss_step=0.0426]Epoch 0:  70%|██████▉   | 514/735 [09:10<03:56,  0.93it/s, v_num=lst8, train/loss_step=0.0426]Epoch 0:  70%|██████▉   | 514/735 [09:10<03:56,  0.93it/s, v_num=lst8, train/loss_step=0.0437]Epoch 0:  70%|███████   | 515/735 [09:11<03:55,  0.93it/s, v_num=lst8, train/loss_step=0.0437]Epoch 0:  70%|███████   | 515/735 [09:11<03:55,  0.93it/s, v_num=lst8, train/loss_step=0.0408]Epoch 0:  70%|███████   | 516/735 [09:12<03:54,  0.93it/s, v_num=lst8, train/loss_step=0.0408]Epoch 0:  70%|███████   | 516/735 [09:12<03:54,  0.93it/s, v_num=lst8, train/loss_step=0.0371]Epoch 0:  70%|███████   | 517/735 [09:13<03:53,  0.93it/s, v_num=lst8, train/loss_step=0.0371]Epoch 0:  70%|███████   | 517/735 [09:13<03:53,  0.93it/s, v_num=lst8, train/loss_step=0.042] Epoch 0:  70%|███████   | 518/735 [09:14<03:52,  0.93it/s, v_num=lst8, train/loss_step=0.042]Epoch 0:  70%|███████   | 518/735 [09:14<03:52,  0.93it/s, v_num=lst8, train/loss_step=0.0432]Epoch 0:  71%|███████   | 519/735 [09:15<03:51,  0.93it/s, v_num=lst8, train/loss_step=0.0432]Epoch 0:  71%|███████   | 519/735 [09:15<03:51,  0.93it/s, v_num=lst8, train/loss_step=0.0403]Epoch 0:  71%|███████   | 520/735 [09:16<03:50,  0.93it/s, v_num=lst8, train/loss_step=0.0403]Epoch 0:  71%|███████   | 520/735 [09:16<03:50,  0.93it/s, v_num=lst8, train/loss_step=0.0404]Epoch 0:  71%|███████   | 521/735 [09:17<03:49,  0.93it/s, v_num=lst8, train/loss_step=0.0404]Epoch 0:  71%|███████   | 521/735 [09:17<03:49,  0.93it/s, v_num=lst8, train/loss_step=0.0369]Epoch 0:  71%|███████   | 522/735 [09:18<03:47,  0.93it/s, v_num=lst8, train/loss_step=0.0369]Epoch 0:  71%|███████   | 522/735 [09:18<03:47,  0.93it/s, v_num=lst8, train/loss_step=0.0515]Epoch 0:  71%|███████   | 523/735 [09:19<03:46,  0.93it/s, v_num=lst8, train/loss_step=0.0515]Epoch 0:  71%|███████   | 523/735 [09:19<03:46,  0.93it/s, v_num=lst8, train/loss_step=0.0384]Epoch 0:  71%|███████▏  | 524/735 [09:20<03:45,  0.93it/s, v_num=lst8, train/loss_step=0.0384]Epoch 0:  71%|███████▏  | 524/735 [09:20<03:45,  0.93it/s, v_num=lst8, train/loss_step=0.0362]Epoch 0:  71%|███████▏  | 525/735 [09:21<03:44,  0.93it/s, v_num=lst8, train/loss_step=0.0362]Epoch 0:  71%|███████▏  | 525/735 [09:21<03:44,  0.93it/s, v_num=lst8, train/loss_step=0.0489]Epoch 0:  72%|███████▏  | 526/735 [09:22<03:43,  0.93it/s, v_num=lst8, train/loss_step=0.0489]Epoch 0:  72%|███████▏  | 526/735 [09:22<03:43,  0.93it/s, v_num=lst8, train/loss_step=0.0378]Epoch 0:  72%|███████▏  | 527/735 [09:23<03:42,  0.93it/s, v_num=lst8, train/loss_step=0.0378]Epoch 0:  72%|███████▏  | 527/735 [09:23<03:42,  0.93it/s, v_num=lst8, train/loss_step=0.0417]Epoch 0:  72%|███████▏  | 528/735 [09:24<03:41,  0.93it/s, v_num=lst8, train/loss_step=0.0417]Epoch 0:  72%|███████▏  | 528/735 [09:24<03:41,  0.93it/s, v_num=lst8, train/loss_step=0.0425]Epoch 0:  72%|███████▏  | 529/735 [09:25<03:40,  0.93it/s, v_num=lst8, train/loss_step=0.0425]Epoch 0:  72%|███████▏  | 529/735 [09:25<03:40,  0.93it/s, v_num=lst8, train/loss_step=0.0386]Epoch 0:  72%|███████▏  | 530/735 [09:26<03:39,  0.93it/s, v_num=lst8, train/loss_step=0.0386]Epoch 0:  72%|███████▏  | 530/735 [09:26<03:39,  0.93it/s, v_num=lst8, train/loss_step=0.0474]Epoch 0:  72%|███████▏  | 531/735 [09:27<03:38,  0.94it/s, v_num=lst8, train/loss_step=0.0474]Epoch 0:  72%|███████▏  | 531/735 [09:27<03:38,  0.94it/s, v_num=lst8, train/loss_step=0.0395]Epoch 0:  72%|███████▏  | 532/735 [09:28<03:37,  0.94it/s, v_num=lst8, train/loss_step=0.0395]Epoch 0:  72%|███████▏  | 532/735 [09:28<03:37,  0.94it/s, v_num=lst8, train/loss_step=0.0422]Epoch 0:  73%|███████▎  | 533/735 [09:29<03:36,  0.94it/s, v_num=lst8, train/loss_step=0.0422]Epoch 0:  73%|███████▎  | 533/735 [09:29<03:36,  0.94it/s, v_num=lst8, train/loss_step=0.0378]Epoch 0:  73%|███████▎  | 534/735 [09:31<03:34,  0.94it/s, v_num=lst8, train/loss_step=0.0378]Epoch 0:  73%|███████▎  | 534/735 [09:31<03:34,  0.94it/s, v_num=lst8, train/loss_step=0.037] Epoch 0:  73%|███████▎  | 535/735 [09:32<03:33,  0.94it/s, v_num=lst8, train/loss_step=0.037]Epoch 0:  73%|███████▎  | 535/735 [09:32<03:33,  0.94it/s, v_num=lst8, train/loss_step=0.0409]Epoch 0:  73%|███████▎  | 536/735 [09:33<03:32,  0.94it/s, v_num=lst8, train/loss_step=0.0409]Epoch 0:  73%|███████▎  | 536/735 [09:33<03:32,  0.94it/s, v_num=lst8, train/loss_step=0.0392]Epoch 0:  73%|███████▎  | 537/735 [09:34<03:31,  0.94it/s, v_num=lst8, train/loss_step=0.0392]Epoch 0:  73%|███████▎  | 537/735 [09:34<03:31,  0.94it/s, v_num=lst8, train/loss_step=0.0417]Epoch 0:  73%|███████▎  | 538/735 [09:35<03:30,  0.94it/s, v_num=lst8, train/loss_step=0.0417]Epoch 0:  73%|███████▎  | 538/735 [09:35<03:30,  0.94it/s, v_num=lst8, train/loss_step=0.0342]Epoch 0:  73%|███████▎  | 539/735 [09:36<03:29,  0.94it/s, v_num=lst8, train/loss_step=0.0342]Epoch 0:  73%|███████▎  | 539/735 [09:36<03:29,  0.94it/s, v_num=lst8, train/loss_step=0.0391]Epoch 0:  73%|███████▎  | 540/735 [09:37<03:28,  0.94it/s, v_num=lst8, train/loss_step=0.0391]Epoch 0:  73%|███████▎  | 540/735 [09:37<03:28,  0.94it/s, v_num=lst8, train/loss_step=0.0416]Epoch 0:  74%|███████▎  | 541/735 [09:38<03:27,  0.94it/s, v_num=lst8, train/loss_step=0.0416]Epoch 0:  74%|███████▎  | 541/735 [09:38<03:27,  0.94it/s, v_num=lst8, train/loss_step=0.038] Epoch 0:  74%|███████▎  | 542/735 [09:39<03:26,  0.94it/s, v_num=lst8, train/loss_step=0.038]Epoch 0:  74%|███████▎  | 542/735 [09:39<03:26,  0.94it/s, v_num=lst8, train/loss_step=0.0479]Epoch 0:  74%|███████▍  | 543/735 [09:40<03:25,  0.94it/s, v_num=lst8, train/loss_step=0.0479]Epoch 0:  74%|███████▍  | 543/735 [09:40<03:25,  0.94it/s, v_num=lst8, train/loss_step=0.0455]Epoch 0:  74%|███████▍  | 544/735 [09:41<03:24,  0.94it/s, v_num=lst8, train/loss_step=0.0455]Epoch 0:  74%|███████▍  | 544/735 [09:41<03:24,  0.94it/s, v_num=lst8, train/loss_step=0.0403]Epoch 0:  74%|███████▍  | 545/735 [09:42<03:23,  0.94it/s, v_num=lst8, train/loss_step=0.0403]Epoch 0:  74%|███████▍  | 545/735 [09:42<03:23,  0.94it/s, v_num=lst8, train/loss_step=0.0383]Epoch 0:  74%|███████▍  | 546/735 [09:43<03:22,  0.94it/s, v_num=lst8, train/loss_step=0.0383]Epoch 0:  74%|███████▍  | 546/735 [09:43<03:22,  0.94it/s, v_num=lst8, train/loss_step=0.0374]Epoch 0:  74%|███████▍  | 547/735 [09:44<03:20,  0.94it/s, v_num=lst8, train/loss_step=0.0374]Epoch 0:  74%|███████▍  | 547/735 [09:44<03:20,  0.94it/s, v_num=lst8, train/loss_step=0.0432]Epoch 0:  75%|███████▍  | 548/735 [09:45<03:19,  0.94it/s, v_num=lst8, train/loss_step=0.0432]Epoch 0:  75%|███████▍  | 548/735 [09:45<03:19,  0.94it/s, v_num=lst8, train/loss_step=0.0421]Epoch 0:  75%|███████▍  | 549/735 [09:46<03:18,  0.94it/s, v_num=lst8, train/loss_step=0.0421]Epoch 0:  75%|███████▍  | 549/735 [09:46<03:18,  0.94it/s, v_num=lst8, train/loss_step=0.0411]Epoch 0:  75%|███████▍  | 550/735 [09:47<03:17,  0.94it/s, v_num=lst8, train/loss_step=0.0411]Epoch 0:  75%|███████▍  | 550/735 [09:47<03:17,  0.94it/s, v_num=lst8, train/loss_step=0.0378]Epoch 0:  75%|███████▍  | 551/735 [09:48<03:16,  0.94it/s, v_num=lst8, train/loss_step=0.0378]Epoch 0:  75%|███████▍  | 551/735 [09:48<03:16,  0.94it/s, v_num=lst8, train/loss_step=0.0436]Epoch 0:  75%|███████▌  | 552/735 [09:49<03:15,  0.94it/s, v_num=lst8, train/loss_step=0.0436]Epoch 0:  75%|███████▌  | 552/735 [09:49<03:15,  0.94it/s, v_num=lst8, train/loss_step=0.0411]Epoch 0:  75%|███████▌  | 553/735 [09:50<03:14,  0.94it/s, v_num=lst8, train/loss_step=0.0411]Epoch 0:  75%|███████▌  | 553/735 [09:50<03:14,  0.94it/s, v_num=lst8, train/loss_step=0.0422]Epoch 0:  75%|███████▌  | 554/735 [09:51<03:13,  0.94it/s, v_num=lst8, train/loss_step=0.0422]Epoch 0:  75%|███████▌  | 554/735 [09:51<03:13,  0.94it/s, v_num=lst8, train/loss_step=0.043] Epoch 0:  76%|███████▌  | 555/735 [09:52<03:12,  0.94it/s, v_num=lst8, train/loss_step=0.043]Epoch 0:  76%|███████▌  | 555/735 [09:52<03:12,  0.94it/s, v_num=lst8, train/loss_step=0.0405]Epoch 0:  76%|███████▌  | 556/735 [09:53<03:11,  0.94it/s, v_num=lst8, train/loss_step=0.0405]Epoch 0:  76%|███████▌  | 556/735 [09:53<03:11,  0.94it/s, v_num=lst8, train/loss_step=0.0431]Epoch 0:  76%|███████▌  | 557/735 [09:54<03:10,  0.94it/s, v_num=lst8, train/loss_step=0.0431]Epoch 0:  76%|███████▌  | 557/735 [09:54<03:10,  0.94it/s, v_num=lst8, train/loss_step=0.0358]Epoch 0:  76%|███████▌  | 558/735 [09:56<03:09,  0.94it/s, v_num=lst8, train/loss_step=0.0358]Epoch 0:  76%|███████▌  | 558/735 [09:56<03:09,  0.94it/s, v_num=lst8, train/loss_step=0.0455]Epoch 0:  76%|███████▌  | 559/735 [09:57<03:07,  0.94it/s, v_num=lst8, train/loss_step=0.0455]Epoch 0:  76%|███████▌  | 559/735 [09:57<03:07,  0.94it/s, v_num=lst8, train/loss_step=0.0389]Epoch 0:  76%|███████▌  | 560/735 [09:58<03:06,  0.94it/s, v_num=lst8, train/loss_step=0.0389]Epoch 0:  76%|███████▌  | 560/735 [09:58<03:06,  0.94it/s, v_num=lst8, train/loss_step=0.0456]Epoch 0:  76%|███████▋  | 561/735 [09:59<03:05,  0.94it/s, v_num=lst8, train/loss_step=0.0456]Epoch 0:  76%|███████▋  | 561/735 [09:59<03:05,  0.94it/s, v_num=lst8, train/loss_step=0.0393]Epoch 0:  76%|███████▋  | 562/735 [10:00<03:04,  0.94it/s, v_num=lst8, train/loss_step=0.0393]Epoch 0:  76%|███████▋  | 562/735 [10:00<03:04,  0.94it/s, v_num=lst8, train/loss_step=0.0405]Epoch 0:  77%|███████▋  | 563/735 [10:01<03:03,  0.94it/s, v_num=lst8, train/loss_step=0.0405]Epoch 0:  77%|███████▋  | 563/735 [10:01<03:03,  0.94it/s, v_num=lst8, train/loss_step=0.042] Epoch 0:  77%|███████▋  | 564/735 [10:02<03:02,  0.94it/s, v_num=lst8, train/loss_step=0.042]Epoch 0:  77%|███████▋  | 564/735 [10:02<03:02,  0.94it/s, v_num=lst8, train/loss_step=0.0395]Epoch 0:  77%|███████▋  | 565/735 [10:03<03:01,  0.94it/s, v_num=lst8, train/loss_step=0.0395]Epoch 0:  77%|███████▋  | 565/735 [10:03<03:01,  0.94it/s, v_num=lst8, train/loss_step=0.0409]Epoch 0:  77%|███████▋  | 566/735 [10:04<03:00,  0.94it/s, v_num=lst8, train/loss_step=0.0409]Epoch 0:  77%|███████▋  | 566/735 [10:04<03:00,  0.94it/s, v_num=lst8, train/loss_step=0.0419]Epoch 0:  77%|███████▋  | 567/735 [10:05<02:59,  0.94it/s, v_num=lst8, train/loss_step=0.0419]Epoch 0:  77%|███████▋  | 567/735 [10:05<02:59,  0.94it/s, v_num=lst8, train/loss_step=0.0374]Epoch 0:  77%|███████▋  | 568/735 [10:06<02:58,  0.94it/s, v_num=lst8, train/loss_step=0.0374]Epoch 0:  77%|███████▋  | 568/735 [10:06<02:58,  0.94it/s, v_num=lst8, train/loss_step=0.044] Epoch 0:  77%|███████▋  | 569/735 [10:07<02:57,  0.94it/s, v_num=lst8, train/loss_step=0.044]Epoch 0:  77%|███████▋  | 569/735 [10:07<02:57,  0.94it/s, v_num=lst8, train/loss_step=0.0348]Epoch 0:  78%|███████▊  | 570/735 [10:08<02:56,  0.94it/s, v_num=lst8, train/loss_step=0.0348]Epoch 0:  78%|███████▊  | 570/735 [10:08<02:56,  0.94it/s, v_num=lst8, train/loss_step=0.0383]Epoch 0:  78%|███████▊  | 571/735 [10:09<02:55,  0.94it/s, v_num=lst8, train/loss_step=0.0383]Epoch 0:  78%|███████▊  | 571/735 [10:09<02:55,  0.94it/s, v_num=lst8, train/loss_step=0.0377]Epoch 0:  78%|███████▊  | 572/735 [10:10<02:54,  0.94it/s, v_num=lst8, train/loss_step=0.0377]Epoch 0:  78%|███████▊  | 572/735 [10:10<02:54,  0.94it/s, v_num=lst8, train/loss_step=0.0432]Epoch 0:  78%|███████▊  | 573/735 [10:11<02:52,  0.94it/s, v_num=lst8, train/loss_step=0.0432]Epoch 0:  78%|███████▊  | 573/735 [10:11<02:52,  0.94it/s, v_num=lst8, train/loss_step=0.048] Epoch 0:  78%|███████▊  | 574/735 [10:12<02:51,  0.94it/s, v_num=lst8, train/loss_step=0.048]Epoch 0:  78%|███████▊  | 574/735 [10:12<02:51,  0.94it/s, v_num=lst8, train/loss_step=0.0431]Epoch 0:  78%|███████▊  | 575/735 [10:13<02:50,  0.94it/s, v_num=lst8, train/loss_step=0.0431]Epoch 0:  78%|███████▊  | 575/735 [10:13<02:50,  0.94it/s, v_num=lst8, train/loss_step=0.0463]Epoch 0:  78%|███████▊  | 576/735 [10:14<02:49,  0.94it/s, v_num=lst8, train/loss_step=0.0463]Epoch 0:  78%|███████▊  | 576/735 [10:14<02:49,  0.94it/s, v_num=lst8, train/loss_step=0.0396]Epoch 0:  79%|███████▊  | 577/735 [10:15<02:48,  0.94it/s, v_num=lst8, train/loss_step=0.0396]Epoch 0:  79%|███████▊  | 577/735 [10:15<02:48,  0.94it/s, v_num=lst8, train/loss_step=0.0411]Epoch 0:  79%|███████▊  | 578/735 [10:17<02:47,  0.94it/s, v_num=lst8, train/loss_step=0.0411]Epoch 0:  79%|███████▊  | 578/735 [10:17<02:47,  0.94it/s, v_num=lst8, train/loss_step=0.0388]Epoch 0:  79%|███████▉  | 579/735 [10:18<02:46,  0.94it/s, v_num=lst8, train/loss_step=0.0388]Epoch 0:  79%|███████▉  | 579/735 [10:18<02:46,  0.94it/s, v_num=lst8, train/loss_step=0.0376]Epoch 0:  79%|███████▉  | 580/735 [10:19<02:45,  0.94it/s, v_num=lst8, train/loss_step=0.0376]Epoch 0:  79%|███████▉  | 580/735 [10:19<02:45,  0.94it/s, v_num=lst8, train/loss_step=0.0443]Epoch 0:  79%|███████▉  | 581/735 [10:20<02:44,  0.94it/s, v_num=lst8, train/loss_step=0.0443]Epoch 0:  79%|███████▉  | 581/735 [10:20<02:44,  0.94it/s, v_num=lst8, train/loss_step=0.0429]Epoch 0:  79%|███████▉  | 582/735 [10:21<02:43,  0.94it/s, v_num=lst8, train/loss_step=0.0429]Epoch 0:  79%|███████▉  | 582/735 [10:21<02:43,  0.94it/s, v_num=lst8, train/loss_step=0.0381]Epoch 0:  79%|███████▉  | 583/735 [10:22<02:42,  0.94it/s, v_num=lst8, train/loss_step=0.0381]Epoch 0:  79%|███████▉  | 583/735 [10:22<02:42,  0.94it/s, v_num=lst8, train/loss_step=0.0374]Epoch 0:  79%|███████▉  | 584/735 [10:23<02:41,  0.94it/s, v_num=lst8, train/loss_step=0.0374]Epoch 0:  79%|███████▉  | 584/735 [10:23<02:41,  0.94it/s, v_num=lst8, train/loss_step=0.0401]Epoch 0:  80%|███████▉  | 585/735 [10:24<02:40,  0.94it/s, v_num=lst8, train/loss_step=0.0401]Epoch 0:  80%|███████▉  | 585/735 [10:24<02:40,  0.94it/s, v_num=lst8, train/loss_step=0.0405]Epoch 0:  80%|███████▉  | 586/735 [10:25<02:39,  0.94it/s, v_num=lst8, train/loss_step=0.0405]Epoch 0:  80%|███████▉  | 586/735 [10:25<02:39,  0.94it/s, v_num=lst8, train/loss_step=0.0357]Epoch 0:  80%|███████▉  | 587/735 [10:26<02:37,  0.94it/s, v_num=lst8, train/loss_step=0.0357]Epoch 0:  80%|███████▉  | 587/735 [10:26<02:37,  0.94it/s, v_num=lst8, train/loss_step=0.0384]Epoch 0:  80%|████████  | 588/735 [10:27<02:36,  0.94it/s, v_num=lst8, train/loss_step=0.0384]Epoch 0:  80%|████████  | 588/735 [10:27<02:36,  0.94it/s, v_num=lst8, train/loss_step=0.0382]Epoch 0:  80%|████████  | 589/735 [10:28<02:35,  0.94it/s, v_num=lst8, train/loss_step=0.0382]Epoch 0:  80%|████████  | 589/735 [10:28<02:35,  0.94it/s, v_num=lst8, train/loss_step=0.0371]Epoch 0:  80%|████████  | 590/735 [10:29<02:34,  0.94it/s, v_num=lst8, train/loss_step=0.0371]Epoch 0:  80%|████████  | 590/735 [10:29<02:34,  0.94it/s, v_num=lst8, train/loss_step=0.0333]Epoch 0:  80%|████████  | 591/735 [10:30<02:33,  0.94it/s, v_num=lst8, train/loss_step=0.0333]Epoch 0:  80%|████████  | 591/735 [10:30<02:33,  0.94it/s, v_num=lst8, train/loss_step=0.0406]Epoch 0:  81%|████████  | 592/735 [10:31<02:32,  0.94it/s, v_num=lst8, train/loss_step=0.0406]Epoch 0:  81%|████████  | 592/735 [10:31<02:32,  0.94it/s, v_num=lst8, train/loss_step=0.0354]Epoch 0:  81%|████████  | 593/735 [10:32<02:31,  0.94it/s, v_num=lst8, train/loss_step=0.0354]Epoch 0:  81%|████████  | 593/735 [10:32<02:31,  0.94it/s, v_num=lst8, train/loss_step=0.0368]Epoch 0:  81%|████████  | 594/735 [10:33<02:30,  0.94it/s, v_num=lst8, train/loss_step=0.0368]Epoch 0:  81%|████████  | 594/735 [10:33<02:30,  0.94it/s, v_num=lst8, train/loss_step=0.0415]Epoch 0:  81%|████████  | 595/735 [10:34<02:29,  0.94it/s, v_num=lst8, train/loss_step=0.0415]Epoch 0:  81%|████████  | 595/735 [10:34<02:29,  0.94it/s, v_num=lst8, train/loss_step=0.0429]Epoch 0:  81%|████████  | 596/735 [10:35<02:28,  0.94it/s, v_num=lst8, train/loss_step=0.0429]Epoch 0:  81%|████████  | 596/735 [10:35<02:28,  0.94it/s, v_num=lst8, train/loss_step=0.0401]Epoch 0:  81%|████████  | 597/735 [10:36<02:27,  0.94it/s, v_num=lst8, train/loss_step=0.0401]Epoch 0:  81%|████████  | 597/735 [10:36<02:27,  0.94it/s, v_num=lst8, train/loss_step=0.0446]Epoch 0:  81%|████████▏ | 598/735 [10:37<02:26,  0.94it/s, v_num=lst8, train/loss_step=0.0446]Epoch 0:  81%|████████▏ | 598/735 [10:37<02:26,  0.94it/s, v_num=lst8, train/loss_step=0.0379]Epoch 0:  81%|████████▏ | 599/735 [10:38<02:25,  0.94it/s, v_num=lst8, train/loss_step=0.0379]Epoch 0:  81%|████████▏ | 599/735 [10:38<02:25,  0.94it/s, v_num=lst8, train/loss_step=0.0385]Epoch 0:  82%|████████▏ | 600/735 [10:39<02:23,  0.94it/s, v_num=lst8, train/loss_step=0.0385]Epoch 0:  82%|████████▏ | 600/735 [10:39<02:23,  0.94it/s, v_num=lst8, train/loss_step=0.0399]Epoch 0:  82%|████████▏ | 601/735 [10:40<02:22,  0.94it/s, v_num=lst8, train/loss_step=0.0399]Epoch 0:  82%|████████▏ | 601/735 [10:40<02:22,  0.94it/s, v_num=lst8, train/loss_step=0.0384]Epoch 0:  82%|████████▏ | 602/735 [10:41<02:21,  0.94it/s, v_num=lst8, train/loss_step=0.0384]Epoch 0:  82%|████████▏ | 602/735 [10:41<02:21,  0.94it/s, v_num=lst8, train/loss_step=0.0378]Epoch 0:  82%|████████▏ | 603/735 [10:42<02:20,  0.94it/s, v_num=lst8, train/loss_step=0.0378]Epoch 0:  82%|████████▏ | 603/735 [10:42<02:20,  0.94it/s, v_num=lst8, train/loss_step=0.0411]Epoch 0:  82%|████████▏ | 604/735 [10:43<02:19,  0.94it/s, v_num=lst8, train/loss_step=0.0411]Epoch 0:  82%|████████▏ | 604/735 [10:43<02:19,  0.94it/s, v_num=lst8, train/loss_step=0.0399]Epoch 0:  82%|████████▏ | 605/735 [10:44<02:18,  0.94it/s, v_num=lst8, train/loss_step=0.0399]Epoch 0:  82%|████████▏ | 605/735 [10:44<02:18,  0.94it/s, v_num=lst8, train/loss_step=0.0373]Epoch 0:  82%|████████▏ | 606/735 [10:45<02:17,  0.94it/s, v_num=lst8, train/loss_step=0.0373]Epoch 0:  82%|████████▏ | 606/735 [10:45<02:17,  0.94it/s, v_num=lst8, train/loss_step=0.0402]Epoch 0:  83%|████████▎ | 607/735 [10:47<02:16,  0.94it/s, v_num=lst8, train/loss_step=0.0402]Epoch 0:  83%|████████▎ | 607/735 [10:47<02:16,  0.94it/s, v_num=lst8, train/loss_step=0.0357]Epoch 0:  83%|████████▎ | 608/735 [10:48<02:15,  0.94it/s, v_num=lst8, train/loss_step=0.0357]Epoch 0:  83%|████████▎ | 608/735 [10:48<02:15,  0.94it/s, v_num=lst8, train/loss_step=0.0379]Epoch 0:  83%|████████▎ | 609/735 [10:49<02:14,  0.94it/s, v_num=lst8, train/loss_step=0.0379]Epoch 0:  83%|████████▎ | 609/735 [10:49<02:14,  0.94it/s, v_num=lst8, train/loss_step=0.0407]Epoch 0:  83%|████████▎ | 610/735 [10:50<02:13,  0.94it/s, v_num=lst8, train/loss_step=0.0407]Epoch 0:  83%|████████▎ | 610/735 [10:50<02:13,  0.94it/s, v_num=lst8, train/loss_step=0.0392]Epoch 0:  83%|████████▎ | 611/735 [10:51<02:12,  0.94it/s, v_num=lst8, train/loss_step=0.0392]Epoch 0:  83%|████████▎ | 611/735 [10:51<02:12,  0.94it/s, v_num=lst8, train/loss_step=0.0386]Epoch 0:  83%|████████▎ | 612/735 [10:52<02:11,  0.94it/s, v_num=lst8, train/loss_step=0.0386]Epoch 0:  83%|████████▎ | 612/735 [10:52<02:11,  0.94it/s, v_num=lst8, train/loss_step=0.042] Epoch 0:  83%|████████▎ | 613/735 [10:53<02:10,  0.94it/s, v_num=lst8, train/loss_step=0.042]Epoch 0:  83%|████████▎ | 613/735 [10:53<02:10,  0.94it/s, v_num=lst8, train/loss_step=0.0404]Epoch 0:  84%|████████▎ | 614/735 [10:54<02:08,  0.94it/s, v_num=lst8, train/loss_step=0.0404]Epoch 0:  84%|████████▎ | 614/735 [10:54<02:08,  0.94it/s, v_num=lst8, train/loss_step=0.0403]Epoch 0:  84%|████████▎ | 615/735 [10:55<02:07,  0.94it/s, v_num=lst8, train/loss_step=0.0403]Epoch 0:  84%|████████▎ | 615/735 [10:55<02:07,  0.94it/s, v_num=lst8, train/loss_step=0.0357]Epoch 0:  84%|████████▍ | 616/735 [10:56<02:06,  0.94it/s, v_num=lst8, train/loss_step=0.0357]Epoch 0:  84%|████████▍ | 616/735 [10:56<02:06,  0.94it/s, v_num=lst8, train/loss_step=0.0385]Epoch 0:  84%|████████▍ | 617/735 [10:57<02:05,  0.94it/s, v_num=lst8, train/loss_step=0.0385]Epoch 0:  84%|████████▍ | 617/735 [10:57<02:05,  0.94it/s, v_num=lst8, train/loss_step=0.0392]Epoch 0:  84%|████████▍ | 618/735 [10:58<02:04,  0.94it/s, v_num=lst8, train/loss_step=0.0392]Epoch 0:  84%|████████▍ | 618/735 [10:58<02:04,  0.94it/s, v_num=lst8, train/loss_step=0.0392]Epoch 0:  84%|████████▍ | 619/735 [10:59<02:03,  0.94it/s, v_num=lst8, train/loss_step=0.0392]Epoch 0:  84%|████████▍ | 619/735 [10:59<02:03,  0.94it/s, v_num=lst8, train/loss_step=0.037] Epoch 0:  84%|████████▍ | 620/735 [11:00<02:02,  0.94it/s, v_num=lst8, train/loss_step=0.037]Epoch 0:  84%|████████▍ | 620/735 [11:00<02:02,  0.94it/s, v_num=lst8, train/loss_step=0.0376]Epoch 0:  84%|████████▍ | 621/735 [11:01<02:01,  0.94it/s, v_num=lst8, train/loss_step=0.0376]Epoch 0:  84%|████████▍ | 621/735 [11:01<02:01,  0.94it/s, v_num=lst8, train/loss_step=0.0398]Epoch 0:  85%|████████▍ | 622/735 [11:02<02:00,  0.94it/s, v_num=lst8, train/loss_step=0.0398]Epoch 0:  85%|████████▍ | 622/735 [11:02<02:00,  0.94it/s, v_num=lst8, train/loss_step=0.0404]Epoch 0:  85%|████████▍ | 623/735 [11:03<01:59,  0.94it/s, v_num=lst8, train/loss_step=0.0404]Epoch 0:  85%|████████▍ | 623/735 [11:03<01:59,  0.94it/s, v_num=lst8, train/loss_step=0.0431]Epoch 0:  85%|████████▍ | 624/735 [11:04<01:58,  0.94it/s, v_num=lst8, train/loss_step=0.0431]Epoch 0:  85%|████████▍ | 624/735 [11:04<01:58,  0.94it/s, v_num=lst8, train/loss_step=0.0378]Epoch 0:  85%|████████▌ | 625/735 [11:05<01:57,  0.94it/s, v_num=lst8, train/loss_step=0.0378]Epoch 0:  85%|████████▌ | 625/735 [11:05<01:57,  0.94it/s, v_num=lst8, train/loss_step=0.0455]Epoch 0:  85%|████████▌ | 626/735 [11:06<01:56,  0.94it/s, v_num=lst8, train/loss_step=0.0455]Epoch 0:  85%|████████▌ | 626/735 [11:06<01:56,  0.94it/s, v_num=lst8, train/loss_step=0.0491]Epoch 0:  85%|████████▌ | 627/735 [11:07<01:54,  0.94it/s, v_num=lst8, train/loss_step=0.0491]Epoch 0:  85%|████████▌ | 627/735 [11:07<01:54,  0.94it/s, v_num=lst8, train/loss_step=0.0378]Epoch 0:  85%|████████▌ | 628/735 [11:08<01:53,  0.94it/s, v_num=lst8, train/loss_step=0.0378]Epoch 0:  85%|████████▌ | 628/735 [11:08<01:53,  0.94it/s, v_num=lst8, train/loss_step=0.0407]Epoch 0:  86%|████████▌ | 629/735 [11:09<01:52,  0.94it/s, v_num=lst8, train/loss_step=0.0407]Epoch 0:  86%|████████▌ | 629/735 [11:09<01:52,  0.94it/s, v_num=lst8, train/loss_step=0.0415]Epoch 0:  86%|████████▌ | 630/735 [11:10<01:51,  0.94it/s, v_num=lst8, train/loss_step=0.0415]Epoch 0:  86%|████████▌ | 630/735 [11:10<01:51,  0.94it/s, v_num=lst8, train/loss_step=0.0357]Epoch 0:  86%|████████▌ | 631/735 [11:11<01:50,  0.94it/s, v_num=lst8, train/loss_step=0.0357]Epoch 0:  86%|████████▌ | 631/735 [11:11<01:50,  0.94it/s, v_num=lst8, train/loss_step=0.0372]Epoch 0:  86%|████████▌ | 632/735 [11:12<01:49,  0.94it/s, v_num=lst8, train/loss_step=0.0372]Epoch 0:  86%|████████▌ | 632/735 [11:12<01:49,  0.94it/s, v_num=lst8, train/loss_step=0.0416]Epoch 0:  86%|████████▌ | 633/735 [11:13<01:48,  0.94it/s, v_num=lst8, train/loss_step=0.0416]Epoch 0:  86%|████████▌ | 633/735 [11:13<01:48,  0.94it/s, v_num=lst8, train/loss_step=0.0405]Epoch 0:  86%|████████▋ | 634/735 [11:14<01:47,  0.94it/s, v_num=lst8, train/loss_step=0.0405]Epoch 0:  86%|████████▋ | 634/735 [11:14<01:47,  0.94it/s, v_num=lst8, train/loss_step=0.0338]Epoch 0:  86%|████████▋ | 635/735 [11:15<01:46,  0.94it/s, v_num=lst8, train/loss_step=0.0338]Epoch 0:  86%|████████▋ | 635/735 [11:15<01:46,  0.94it/s, v_num=lst8, train/loss_step=0.0362]Epoch 0:  87%|████████▋ | 636/735 [11:16<01:45,  0.94it/s, v_num=lst8, train/loss_step=0.0362]Epoch 0:  87%|████████▋ | 636/735 [11:16<01:45,  0.94it/s, v_num=lst8, train/loss_step=0.0426]Epoch 0:  87%|████████▋ | 637/735 [11:17<01:44,  0.94it/s, v_num=lst8, train/loss_step=0.0426]Epoch 0:  87%|████████▋ | 637/735 [11:17<01:44,  0.94it/s, v_num=lst8, train/loss_step=0.0401]Epoch 0:  87%|████████▋ | 638/735 [11:18<01:43,  0.94it/s, v_num=lst8, train/loss_step=0.0401]Epoch 0:  87%|████████▋ | 638/735 [11:18<01:43,  0.94it/s, v_num=lst8, train/loss_step=0.0396]Epoch 0:  87%|████████▋ | 639/735 [11:19<01:42,  0.94it/s, v_num=lst8, train/loss_step=0.0396]Epoch 0:  87%|████████▋ | 639/735 [11:19<01:42,  0.94it/s, v_num=lst8, train/loss_step=0.0373]Epoch 0:  87%|████████▋ | 640/735 [11:20<01:41,  0.94it/s, v_num=lst8, train/loss_step=0.0373]Epoch 0:  87%|████████▋ | 640/735 [11:20<01:41,  0.94it/s, v_num=lst8, train/loss_step=0.040] Epoch 0:  87%|████████▋ | 641/735 [11:22<01:40,  0.94it/s, v_num=lst8, train/loss_step=0.040]Epoch 0:  87%|████████▋ | 641/735 [11:22<01:40,  0.94it/s, v_num=lst8, train/loss_step=0.038]Epoch 0:  87%|████████▋ | 642/735 [11:23<01:38,  0.94it/s, v_num=lst8, train/loss_step=0.038]Epoch 0:  87%|████████▋ | 642/735 [11:23<01:38,  0.94it/s, v_num=lst8, train/loss_step=0.0389]Epoch 0:  87%|████████▋ | 643/735 [11:24<01:37,  0.94it/s, v_num=lst8, train/loss_step=0.0389]Epoch 0:  87%|████████▋ | 643/735 [11:24<01:37,  0.94it/s, v_num=lst8, train/loss_step=0.0427]Epoch 0:  88%|████████▊ | 644/735 [11:25<01:36,  0.94it/s, v_num=lst8, train/loss_step=0.0427]Epoch 0:  88%|████████▊ | 644/735 [11:25<01:36,  0.94it/s, v_num=lst8, train/loss_step=0.0384]Epoch 0:  88%|████████▊ | 645/735 [11:26<01:35,  0.94it/s, v_num=lst8, train/loss_step=0.0384]Epoch 0:  88%|████████▊ | 645/735 [11:26<01:35,  0.94it/s, v_num=lst8, train/loss_step=0.0392]Epoch 0:  88%|████████▊ | 646/735 [11:27<01:34,  0.94it/s, v_num=lst8, train/loss_step=0.0392]Epoch 0:  88%|████████▊ | 646/735 [11:27<01:34,  0.94it/s, v_num=lst8, train/loss_step=0.0373]Epoch 0:  88%|████████▊ | 647/735 [11:28<01:33,  0.94it/s, v_num=lst8, train/loss_step=0.0373]Epoch 0:  88%|████████▊ | 647/735 [11:28<01:33,  0.94it/s, v_num=lst8, train/loss_step=0.0409]Epoch 0:  88%|████████▊ | 648/735 [11:29<01:32,  0.94it/s, v_num=lst8, train/loss_step=0.0409]Epoch 0:  88%|████████▊ | 648/735 [11:29<01:32,  0.94it/s, v_num=lst8, train/loss_step=0.0379]Epoch 0:  88%|████████▊ | 649/735 [11:30<01:31,  0.94it/s, v_num=lst8, train/loss_step=0.0379]Epoch 0:  88%|████████▊ | 649/735 [11:30<01:31,  0.94it/s, v_num=lst8, train/loss_step=0.0358]Epoch 0:  88%|████████▊ | 650/735 [11:31<01:30,  0.94it/s, v_num=lst8, train/loss_step=0.0358]Epoch 0:  88%|████████▊ | 650/735 [11:31<01:30,  0.94it/s, v_num=lst8, train/loss_step=0.040] Epoch 0:  89%|████████▊ | 651/735 [11:32<01:29,  0.94it/s, v_num=lst8, train/loss_step=0.040]Epoch 0:  89%|████████▊ | 651/735 [11:32<01:29,  0.94it/s, v_num=lst8, train/loss_step=0.0398]Epoch 0:  89%|████████▊ | 652/735 [11:33<01:28,  0.94it/s, v_num=lst8, train/loss_step=0.0398]Epoch 0:  89%|████████▊ | 652/735 [11:33<01:28,  0.94it/s, v_num=lst8, train/loss_step=0.0321]Epoch 0:  89%|████████▉ | 653/735 [11:34<01:27,  0.94it/s, v_num=lst8, train/loss_step=0.0321]Epoch 0:  89%|████████▉ | 653/735 [11:34<01:27,  0.94it/s, v_num=lst8, train/loss_step=0.0342]Epoch 0:  89%|████████▉ | 654/735 [11:35<01:26,  0.94it/s, v_num=lst8, train/loss_step=0.0342]Epoch 0:  89%|████████▉ | 654/735 [11:35<01:26,  0.94it/s, v_num=lst8, train/loss_step=0.0368]Epoch 0:  89%|████████▉ | 655/735 [11:36<01:25,  0.94it/s, v_num=lst8, train/loss_step=0.0368]Epoch 0:  89%|████████▉ | 655/735 [11:36<01:25,  0.94it/s, v_num=lst8, train/loss_step=0.0418]Epoch 0:  89%|████████▉ | 656/735 [11:37<01:24,  0.94it/s, v_num=lst8, train/loss_step=0.0418]Epoch 0:  89%|████████▉ | 656/735 [11:37<01:24,  0.94it/s, v_num=lst8, train/loss_step=0.0409]Epoch 0:  89%|████████▉ | 657/735 [11:38<01:22,  0.94it/s, v_num=lst8, train/loss_step=0.0409]Epoch 0:  89%|████████▉ | 657/735 [11:38<01:22,  0.94it/s, v_num=lst8, train/loss_step=0.0376]Epoch 0:  90%|████████▉ | 658/735 [11:39<01:21,  0.94it/s, v_num=lst8, train/loss_step=0.0376]Epoch 0:  90%|████████▉ | 658/735 [11:39<01:21,  0.94it/s, v_num=lst8, train/loss_step=0.0391]Epoch 0:  90%|████████▉ | 659/735 [11:40<01:20,  0.94it/s, v_num=lst8, train/loss_step=0.0391]Epoch 0:  90%|████████▉ | 659/735 [11:40<01:20,  0.94it/s, v_num=lst8, train/loss_step=0.0425]Epoch 0:  90%|████████▉ | 660/735 [11:41<01:19,  0.94it/s, v_num=lst8, train/loss_step=0.0425]Epoch 0:  90%|████████▉ | 660/735 [11:41<01:19,  0.94it/s, v_num=lst8, train/loss_step=0.0361]Epoch 0:  90%|████████▉ | 661/735 [11:42<01:18,  0.94it/s, v_num=lst8, train/loss_step=0.0361]Epoch 0:  90%|████████▉ | 661/735 [11:42<01:18,  0.94it/s, v_num=lst8, train/loss_step=0.0297]Epoch 0:  90%|█████████ | 662/735 [11:43<01:17,  0.94it/s, v_num=lst8, train/loss_step=0.0297]Epoch 0:  90%|█████████ | 662/735 [11:43<01:17,  0.94it/s, v_num=lst8, train/loss_step=0.0316]Epoch 0:  90%|█████████ | 663/735 [11:44<01:16,  0.94it/s, v_num=lst8, train/loss_step=0.0316]Epoch 0:  90%|█████████ | 663/735 [11:44<01:16,  0.94it/s, v_num=lst8, train/loss_step=0.0356]Epoch 0:  90%|█████████ | 664/735 [11:45<01:15,  0.94it/s, v_num=lst8, train/loss_step=0.0356]Epoch 0:  90%|█████████ | 664/735 [11:45<01:15,  0.94it/s, v_num=lst8, train/loss_step=0.0361]Epoch 0:  90%|█████████ | 665/735 [11:47<01:14,  0.94it/s, v_num=lst8, train/loss_step=0.0361]Epoch 0:  90%|█████████ | 665/735 [11:47<01:14,  0.94it/s, v_num=lst8, train/loss_step=0.0411]Epoch 0:  91%|█████████ | 666/735 [11:48<01:13,  0.94it/s, v_num=lst8, train/loss_step=0.0411]Epoch 0:  91%|█████████ | 666/735 [11:48<01:13,  0.94it/s, v_num=lst8, train/loss_step=0.0422]Epoch 0:  91%|█████████ | 667/735 [11:49<01:12,  0.94it/s, v_num=lst8, train/loss_step=0.0422]Epoch 0:  91%|█████████ | 667/735 [11:49<01:12,  0.94it/s, v_num=lst8, train/loss_step=0.0375]Epoch 0:  91%|█████████ | 668/735 [11:50<01:11,  0.94it/s, v_num=lst8, train/loss_step=0.0375]Epoch 0:  91%|█████████ | 668/735 [11:50<01:11,  0.94it/s, v_num=lst8, train/loss_step=0.0418]Epoch 0:  91%|█████████ | 669/735 [11:51<01:10,  0.94it/s, v_num=lst8, train/loss_step=0.0418]Epoch 0:  91%|█████████ | 669/735 [11:51<01:10,  0.94it/s, v_num=lst8, train/loss_step=0.0341]Epoch 0:  91%|█████████ | 670/735 [11:52<01:09,  0.94it/s, v_num=lst8, train/loss_step=0.0341]Epoch 0:  91%|█████████ | 670/735 [11:52<01:09,  0.94it/s, v_num=lst8, train/loss_step=0.0371]Epoch 0:  91%|█████████▏| 671/735 [11:53<01:08,  0.94it/s, v_num=lst8, train/loss_step=0.0371]Epoch 0:  91%|█████████▏| 671/735 [11:53<01:08,  0.94it/s, v_num=lst8, train/loss_step=0.0404]Epoch 0:  91%|█████████▏| 672/735 [11:54<01:06,  0.94it/s, v_num=lst8, train/loss_step=0.0404]Epoch 0:  91%|█████████▏| 672/735 [11:54<01:06,  0.94it/s, v_num=lst8, train/loss_step=0.0393]Epoch 0:  92%|█████████▏| 673/735 [11:55<01:05,  0.94it/s, v_num=lst8, train/loss_step=0.0393]Epoch 0:  92%|█████████▏| 673/735 [11:55<01:05,  0.94it/s, v_num=lst8, train/loss_step=0.0359]Epoch 0:  92%|█████████▏| 674/735 [11:56<01:04,  0.94it/s, v_num=lst8, train/loss_step=0.0359]Epoch 0:  92%|█████████▏| 674/735 [11:56<01:04,  0.94it/s, v_num=lst8, train/loss_step=0.0403]Epoch 0:  92%|█████████▏| 675/735 [11:57<01:03,  0.94it/s, v_num=lst8, train/loss_step=0.0403]Epoch 0:  92%|█████████▏| 675/735 [11:57<01:03,  0.94it/s, v_num=lst8, train/loss_step=0.0356]Epoch 0:  92%|█████████▏| 676/735 [11:58<01:02,  0.94it/s, v_num=lst8, train/loss_step=0.0356]Epoch 0:  92%|█████████▏| 676/735 [11:58<01:02,  0.94it/s, v_num=lst8, train/loss_step=0.0344]Epoch 0:  92%|█████████▏| 677/735 [11:59<01:01,  0.94it/s, v_num=lst8, train/loss_step=0.0344]Epoch 0:  92%|█████████▏| 677/735 [11:59<01:01,  0.94it/s, v_num=lst8, train/loss_step=0.0347]Epoch 0:  92%|█████████▏| 678/735 [12:00<01:00,  0.94it/s, v_num=lst8, train/loss_step=0.0347]Epoch 0:  92%|█████████▏| 678/735 [12:00<01:00,  0.94it/s, v_num=lst8, train/loss_step=0.0401]Epoch 0:  92%|█████████▏| 679/735 [12:01<00:59,  0.94it/s, v_num=lst8, train/loss_step=0.0401]Epoch 0:  92%|█████████▏| 679/735 [12:01<00:59,  0.94it/s, v_num=lst8, train/loss_step=0.0383]Epoch 0:  93%|█████████▎| 680/735 [12:02<00:58,  0.94it/s, v_num=lst8, train/loss_step=0.0383]Epoch 0:  93%|█████████▎| 680/735 [12:02<00:58,  0.94it/s, v_num=lst8, train/loss_step=0.0432]Epoch 0:  93%|█████████▎| 681/735 [12:03<00:57,  0.94it/s, v_num=lst8, train/loss_step=0.0432]Epoch 0:  93%|█████████▎| 681/735 [12:03<00:57,  0.94it/s, v_num=lst8, train/loss_step=0.0364]Epoch 0:  93%|█████████▎| 682/735 [12:04<00:56,  0.94it/s, v_num=lst8, train/loss_step=0.0364]Epoch 0:  93%|█████████▎| 682/735 [12:04<00:56,  0.94it/s, v_num=lst8, train/loss_step=0.0407]Epoch 0:  93%|█████████▎| 683/735 [12:05<00:55,  0.94it/s, v_num=lst8, train/loss_step=0.0407]Epoch 0:  93%|█████████▎| 683/735 [12:05<00:55,  0.94it/s, v_num=lst8, train/loss_step=0.0373]Epoch 0:  93%|█████████▎| 684/735 [12:06<00:54,  0.94it/s, v_num=lst8, train/loss_step=0.0373]Epoch 0:  93%|█████████▎| 684/735 [12:06<00:54,  0.94it/s, v_num=lst8, train/loss_step=0.0382]Epoch 0:  93%|█████████▎| 685/735 [12:07<00:53,  0.94it/s, v_num=lst8, train/loss_step=0.0382]Epoch 0:  93%|█████████▎| 685/735 [12:07<00:53,  0.94it/s, v_num=lst8, train/loss_step=0.0392]Epoch 0:  93%|█████████▎| 686/735 [12:08<00:52,  0.94it/s, v_num=lst8, train/loss_step=0.0392]Epoch 0:  93%|█████████▎| 686/735 [12:08<00:52,  0.94it/s, v_num=lst8, train/loss_step=0.0378]Epoch 0:  93%|█████████▎| 687/735 [12:10<00:51,  0.94it/s, v_num=lst8, train/loss_step=0.0378]Epoch 0:  93%|█████████▎| 687/735 [12:10<00:51,  0.94it/s, v_num=lst8, train/loss_step=0.0393]Epoch 0:  94%|█████████▎| 688/735 [12:11<00:49,  0.94it/s, v_num=lst8, train/loss_step=0.0393]Epoch 0:  94%|█████████▎| 688/735 [12:11<00:49,  0.94it/s, v_num=lst8, train/loss_step=0.0411]Epoch 0:  94%|█████████▎| 689/735 [12:12<00:48,  0.94it/s, v_num=lst8, train/loss_step=0.0411]Epoch 0:  94%|█████████▎| 689/735 [12:12<00:48,  0.94it/s, v_num=lst8, train/loss_step=0.0368]Epoch 0:  94%|█████████▍| 690/735 [12:13<00:47,  0.94it/s, v_num=lst8, train/loss_step=0.0368]Epoch 0:  94%|█████████▍| 690/735 [12:13<00:47,  0.94it/s, v_num=lst8, train/loss_step=0.0386]Epoch 0:  94%|█████████▍| 691/735 [12:14<00:46,  0.94it/s, v_num=lst8, train/loss_step=0.0386]Epoch 0:  94%|█████████▍| 691/735 [12:14<00:46,  0.94it/s, v_num=lst8, train/loss_step=0.0402]Epoch 0:  94%|█████████▍| 692/735 [12:15<00:45,  0.94it/s, v_num=lst8, train/loss_step=0.0402]Epoch 0:  94%|█████████▍| 692/735 [12:15<00:45,  0.94it/s, v_num=lst8, train/loss_step=0.0393]Epoch 0:  94%|█████████▍| 693/735 [12:16<00:44,  0.94it/s, v_num=lst8, train/loss_step=0.0393]Epoch 0:  94%|█████████▍| 693/735 [12:16<00:44,  0.94it/s, v_num=lst8, train/loss_step=0.0372]Epoch 0:  94%|█████████▍| 694/735 [12:17<00:43,  0.94it/s, v_num=lst8, train/loss_step=0.0372]Epoch 0:  94%|█████████▍| 694/735 [12:17<00:43,  0.94it/s, v_num=lst8, train/loss_step=0.0417]Epoch 0:  95%|█████████▍| 695/735 [12:18<00:42,  0.94it/s, v_num=lst8, train/loss_step=0.0417]Epoch 0:  95%|█████████▍| 695/735 [12:18<00:42,  0.94it/s, v_num=lst8, train/loss_step=0.0393]Epoch 0:  95%|█████████▍| 696/735 [12:19<00:41,  0.94it/s, v_num=lst8, train/loss_step=0.0393]Epoch 0:  95%|█████████▍| 696/735 [12:19<00:41,  0.94it/s, v_num=lst8, train/loss_step=0.0394]Epoch 0:  95%|█████████▍| 697/735 [12:20<00:40,  0.94it/s, v_num=lst8, train/loss_step=0.0394]Epoch 0:  95%|█████████▍| 697/735 [12:20<00:40,  0.94it/s, v_num=lst8, train/loss_step=0.0434]Epoch 0:  95%|█████████▍| 698/735 [12:21<00:39,  0.94it/s, v_num=lst8, train/loss_step=0.0434]Epoch 0:  95%|█████████▍| 698/735 [12:21<00:39,  0.94it/s, v_num=lst8, train/loss_step=0.0423]Epoch 0:  95%|█████████▌| 699/735 [12:22<00:38,  0.94it/s, v_num=lst8, train/loss_step=0.0423]Epoch 0:  95%|█████████▌| 699/735 [12:22<00:38,  0.94it/s, v_num=lst8, train/loss_step=0.0339]Epoch 0:  95%|█████████▌| 700/735 [12:23<00:37,  0.94it/s, v_num=lst8, train/loss_step=0.0339]Epoch 0:  95%|█████████▌| 700/735 [12:23<00:37,  0.94it/s, v_num=lst8, train/loss_step=0.0359]Epoch 0:  95%|█████████▌| 701/735 [12:24<00:36,  0.94it/s, v_num=lst8, train/loss_step=0.0359]Epoch 0:  95%|█████████▌| 701/735 [12:24<00:36,  0.94it/s, v_num=lst8, train/loss_step=0.0378]Epoch 0:  96%|█████████▌| 702/735 [12:25<00:35,  0.94it/s, v_num=lst8, train/loss_step=0.0378]Epoch 0:  96%|█████████▌| 702/735 [12:25<00:35,  0.94it/s, v_num=lst8, train/loss_step=0.0374]Epoch 0:  96%|█████████▌| 703/735 [12:26<00:33,  0.94it/s, v_num=lst8, train/loss_step=0.0374]Epoch 0:  96%|█████████▌| 703/735 [12:26<00:33,  0.94it/s, v_num=lst8, train/loss_step=0.0357]Epoch 0:  96%|█████████▌| 704/735 [12:27<00:32,  0.94it/s, v_num=lst8, train/loss_step=0.0357]Epoch 0:  96%|█████████▌| 704/735 [12:27<00:32,  0.94it/s, v_num=lst8, train/loss_step=0.0392]Epoch 0:  96%|█████████▌| 705/735 [12:28<00:31,  0.94it/s, v_num=lst8, train/loss_step=0.0392]Epoch 0:  96%|█████████▌| 705/735 [12:28<00:31,  0.94it/s, v_num=lst8, train/loss_step=0.0357]Epoch 0:  96%|█████████▌| 706/735 [12:29<00:30,  0.94it/s, v_num=lst8, train/loss_step=0.0357]Epoch 0:  96%|█████████▌| 706/735 [12:29<00:30,  0.94it/s, v_num=lst8, train/loss_step=0.0377]Epoch 0:  96%|█████████▌| 707/735 [12:30<00:29,  0.94it/s, v_num=lst8, train/loss_step=0.0377]Epoch 0:  96%|█████████▌| 707/735 [12:30<00:29,  0.94it/s, v_num=lst8, train/loss_step=0.0343]Epoch 0:  96%|█████████▋| 708/735 [12:31<00:28,  0.94it/s, v_num=lst8, train/loss_step=0.0343]Epoch 0:  96%|█████████▋| 708/735 [12:31<00:28,  0.94it/s, v_num=lst8, train/loss_step=0.0393]Epoch 0:  96%|█████████▋| 709/735 [12:32<00:27,  0.94it/s, v_num=lst8, train/loss_step=0.0393]Epoch 0:  96%|█████████▋| 709/735 [12:32<00:27,  0.94it/s, v_num=lst8, train/loss_step=0.0348]Epoch 0:  97%|█████████▋| 710/735 [12:34<00:26,  0.94it/s, v_num=lst8, train/loss_step=0.0348]Epoch 0:  97%|█████████▋| 710/735 [12:34<00:26,  0.94it/s, v_num=lst8, train/loss_step=0.0336]Epoch 0:  97%|█████████▋| 711/735 [12:35<00:25,  0.94it/s, v_num=lst8, train/loss_step=0.0336]Epoch 0:  97%|█████████▋| 711/735 [12:35<00:25,  0.94it/s, v_num=lst8, train/loss_step=0.0346]Epoch 0:  97%|█████████▋| 712/735 [12:36<00:24,  0.94it/s, v_num=lst8, train/loss_step=0.0346]Epoch 0:  97%|█████████▋| 712/735 [12:36<00:24,  0.94it/s, v_num=lst8, train/loss_step=0.0399]Epoch 0:  97%|█████████▋| 713/735 [12:37<00:23,  0.94it/s, v_num=lst8, train/loss_step=0.0399]Epoch 0:  97%|█████████▋| 713/735 [12:37<00:23,  0.94it/s, v_num=lst8, train/loss_step=0.0384]Epoch 0:  97%|█████████▋| 714/735 [12:38<00:22,  0.94it/s, v_num=lst8, train/loss_step=0.0384]Epoch 0:  97%|█████████▋| 714/735 [12:38<00:22,  0.94it/s, v_num=lst8, train/loss_step=0.0331]Epoch 0:  97%|█████████▋| 715/735 [12:39<00:21,  0.94it/s, v_num=lst8, train/loss_step=0.0331]Epoch 0:  97%|█████████▋| 715/735 [12:39<00:21,  0.94it/s, v_num=lst8, train/loss_step=0.0341]Epoch 0:  97%|█████████▋| 716/735 [12:40<00:20,  0.94it/s, v_num=lst8, train/loss_step=0.0341]Epoch 0:  97%|█████████▋| 716/735 [12:40<00:20,  0.94it/s, v_num=lst8, train/loss_step=0.0383]Epoch 0:  98%|█████████▊| 717/735 [12:41<00:19,  0.94it/s, v_num=lst8, train/loss_step=0.0383]Epoch 0:  98%|█████████▊| 717/735 [12:41<00:19,  0.94it/s, v_num=lst8, train/loss_step=0.0458]Epoch 0:  98%|█████████▊| 718/735 [12:42<00:18,  0.94it/s, v_num=lst8, train/loss_step=0.0458]Epoch 0:  98%|█████████▊| 718/735 [12:42<00:18,  0.94it/s, v_num=lst8, train/loss_step=0.037] Epoch 0:  98%|█████████▊| 719/735 [12:43<00:16,  0.94it/s, v_num=lst8, train/loss_step=0.037]Epoch 0:  98%|█████████▊| 719/735 [12:43<00:16,  0.94it/s, v_num=lst8, train/loss_step=0.0385]Epoch 0:  98%|█████████▊| 720/735 [12:44<00:15,  0.94it/s, v_num=lst8, train/loss_step=0.0385]Epoch 0:  98%|█████████▊| 720/735 [12:44<00:15,  0.94it/s, v_num=lst8, train/loss_step=0.0406]Epoch 0:  98%|█████████▊| 721/735 [12:45<00:14,  0.94it/s, v_num=lst8, train/loss_step=0.0406]Epoch 0:  98%|█████████▊| 721/735 [12:45<00:14,  0.94it/s, v_num=lst8, train/loss_step=0.042] Epoch 0:  98%|█████████▊| 722/735 [12:46<00:13,  0.94it/s, v_num=lst8, train/loss_step=0.042]Epoch 0:  98%|█████████▊| 722/735 [12:46<00:13,  0.94it/s, v_num=lst8, train/loss_step=0.0381]Epoch 0:  98%|█████████▊| 723/735 [12:47<00:12,  0.94it/s, v_num=lst8, train/loss_step=0.0381]Epoch 0:  98%|█████████▊| 723/735 [12:47<00:12,  0.94it/s, v_num=lst8, train/loss_step=0.0314]Epoch 0:  99%|█████████▊| 724/735 [12:48<00:11,  0.94it/s, v_num=lst8, train/loss_step=0.0314]Epoch 0:  99%|█████████▊| 724/735 [12:48<00:11,  0.94it/s, v_num=lst8, train/loss_step=0.0358]Epoch 0:  99%|█████████▊| 725/735 [12:49<00:10,  0.94it/s, v_num=lst8, train/loss_step=0.0358]Epoch 0:  99%|█████████▊| 725/735 [12:49<00:10,  0.94it/s, v_num=lst8, train/loss_step=0.0384]Epoch 0:  99%|█████████▉| 726/735 [12:50<00:09,  0.94it/s, v_num=lst8, train/loss_step=0.0384]Epoch 0:  99%|█████████▉| 726/735 [12:50<00:09,  0.94it/s, v_num=lst8, train/loss_step=0.0389]Epoch 0:  99%|█████████▉| 727/735 [12:51<00:08,  0.94it/s, v_num=lst8, train/loss_step=0.0389]Epoch 0:  99%|█████████▉| 727/735 [12:51<00:08,  0.94it/s, v_num=lst8, train/loss_step=0.0336]Epoch 0:  99%|█████████▉| 728/735 [12:52<00:07,  0.94it/s, v_num=lst8, train/loss_step=0.0336]Epoch 0:  99%|█████████▉| 728/735 [12:52<00:07,  0.94it/s, v_num=lst8, train/loss_step=0.0408]Epoch 0:  99%|█████████▉| 729/735 [12:53<00:06,  0.94it/s, v_num=lst8, train/loss_step=0.0408]Epoch 0:  99%|█████████▉| 729/735 [12:53<00:06,  0.94it/s, v_num=lst8, train/loss_step=0.0309]Epoch 0:  99%|█████████▉| 730/735 [12:54<00:05,  0.94it/s, v_num=lst8, train/loss_step=0.0309]Epoch 0:  99%|█████████▉| 730/735 [12:54<00:05,  0.94it/s, v_num=lst8, train/loss_step=0.0363]Epoch 0:  99%|█████████▉| 731/735 [12:55<00:04,  0.94it/s, v_num=lst8, train/loss_step=0.0363]Epoch 0:  99%|█████████▉| 731/735 [12:55<00:04,  0.94it/s, v_num=lst8, train/loss_step=0.0364]Epoch 0: 100%|█████████▉| 732/735 [12:56<00:03,  0.94it/s, v_num=lst8, train/loss_step=0.0364]Epoch 0: 100%|█████████▉| 732/735 [12:56<00:03,  0.94it/s, v_num=lst8, train/loss_step=0.0365]Epoch 0: 100%|█████████▉| 733/735 [12:57<00:02,  0.94it/s, v_num=lst8, train/loss_step=0.0365]Epoch 0: 100%|█████████▉| 733/735 [12:57<00:02,  0.94it/s, v_num=lst8, train/loss_step=0.0367]Epoch 0: 100%|█████████▉| 734/735 [12:59<00:01,  0.94it/s, v_num=lst8, train/loss_step=0.0367]Epoch 0: 100%|█████████▉| 734/735 [12:59<00:01,  0.94it/s, v_num=lst8, train/loss_step=0.0332]Epoch 0: 100%|██████████| 735/735 [13:00<00:00,  0.94it/s, v_num=lst8, train/loss_step=0.0332]Epoch 0: 100%|██████████| 735/735 [13:00<00:00,  0.94it/s, v_num=lst8, train/loss_step=0.0344]hyperparameters: "compile":            False
"learning_rate":      0.0005
"loss":               bce
"lr_rate":            [0.05, 0.02, 0.01, 0.005, 0.002, 0.001, 0.0005, 0.0002]
"lr_scheduler_epoch": [10, 15, 20, 25, 30, 35, 50, 45]
"net":                HGCN(
  (stem): Stem_conv(
    (convs): Sequential(
      (0): Conv2d(1, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): GELU(approximate='none')
      (3): Conv2d(40, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (4): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): GELU(approximate='none')
      (6): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (backbone): Sequential(
    (0): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): Identity()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
        )
        (drop_path): Identity()
      )
    )
    (1): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
        )
        (drop_path): DropPath()
      )
    )
    (2): DownSample(
      (conv): Sequential(
        (0): Conv2d(80, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(480, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)
        )
        (drop_path): DropPath()
      )
    )
    (4): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(480, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)
        )
        (drop_path): DropPath()
      )
    )
    (5): DownSample(
      (conv): Sequential(
        (0): Conv2d(160, 400, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (7): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (8): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (9): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (10): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (11): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1200, 1200, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1200, 400, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(1600, 1600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1600)
        )
        (drop_path): DropPath()
      )
    )
    (12): DownSample(
      (conv): Sequential(
        (0): Conv2d(400, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (13): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1920, 1920, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(640, 2560, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(2560, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(2560, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(2560, 2560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2560)
        )
        (drop_path): DropPath()
      )
    )
    (14): Sequential(
      (0): Grapher(
        (fc1): Sequential(
          (0): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (graph_conv): DyGraphConv2d(
          (gconv): MRConv2d(
            (nn): BasicConv(
              (0): Conv2d(1920, 1920, kernel_size=(1, 1), stride=(1, 1), groups=4)
              (1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): GELU(approximate='none')
            )
            (get_centroids): HyperedgeConstruction(
              (centers_proposal): AdaptiveAvgPool2d(output_size=(5, 10))
            )
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
        (fc2): Sequential(
          (0): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop_path): DropPath()
      )
      (1): ConvFFN(
        (fc1): Sequential(
          (0): Conv2d(640, 2560, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(2560, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): GELU(approximate='none')
        (fc2): Sequential(
          (0): Conv2d(2560, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv): ResDWC(
          (conv): Conv2d(2560, 2560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2560)
        )
        (drop_path): DropPath()
      )
    )
  )
  (prediction): Sequential(
    (0): Conv2d(640, 1024, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): GELU(approximate='none')
    (3): Dropout(p=0.0, inplace=False)
    (4): Conv2d(1024, 200, kernel_size=(1, 1), stride=(1, 1))
  )
)
"opt_warmup":         True
"optimizer":          functools.partial(<class 'torch.optim.adam.Adam'>, lr=0.0005, weight_decay=5e-07, eps=1e-08, betas=[0.95, 0.999])
"scheduler":          functools.partial(<class 'torch.optim.lr_scheduler.MultiStepLR'>, milestones=[10, 15, 20, 25, 30, 35, 40], gamma=0.5)

Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/83 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/83 [00:00<?, ?it/s][A
Validation DataLoader 0:   1%|          | 1/83 [00:00<00:59,  1.37it/s][A
Validation DataLoader 0:   2%|▏         | 2/83 [00:01<00:52,  1.53it/s][A
Validation DataLoader 0:   4%|▎         | 3/83 [00:01<00:49,  1.62it/s][A
Validation DataLoader 0:   5%|▍         | 4/83 [00:02<00:47,  1.66it/s][A
Validation DataLoader 0:   6%|▌         | 5/83 [00:02<00:46,  1.68it/s][A
Validation DataLoader 0:   7%|▋         | 6/83 [00:03<00:45,  1.70it/s][A
Validation DataLoader 0:   8%|▊         | 7/83 [00:04<00:44,  1.72it/s][A
Validation DataLoader 0:  10%|▉         | 8/83 [00:04<00:43,  1.73it/s][A
Validation DataLoader 0:  11%|█         | 9/83 [00:05<00:42,  1.74it/s][A
Validation DataLoader 0:  12%|█▏        | 10/83 [00:05<00:41,  1.75it/s][A
Validation DataLoader 0:  13%|█▎        | 11/83 [00:06<00:40,  1.76it/s][A
Validation DataLoader 0:  14%|█▍        | 12/83 [00:06<00:40,  1.77it/s][A
Validation DataLoader 0:  16%|█▌        | 13/83 [00:07<00:39,  1.77it/s][A
Validation DataLoader 0:  17%|█▋        | 14/83 [00:07<00:38,  1.78it/s][A
Validation DataLoader 0:  18%|█▊        | 15/83 [00:08<00:38,  1.78it/s][A
Validation DataLoader 0:  19%|█▉        | 16/83 [00:08<00:37,  1.78it/s][A
Validation DataLoader 0:  20%|██        | 17/83 [00:09<00:36,  1.79it/s][A
Validation DataLoader 0:  22%|██▏       | 18/83 [00:10<00:36,  1.79it/s][A
Validation DataLoader 0:  23%|██▎       | 19/83 [00:10<00:35,  1.79it/s][A
Validation DataLoader 0:  24%|██▍       | 20/83 [00:11<00:35,  1.80it/s][A
Validation DataLoader 0:  25%|██▌       | 21/83 [00:11<00:34,  1.80it/s][A
Validation DataLoader 0:  27%|██▋       | 22/83 [00:12<00:33,  1.80it/s][A
Validation DataLoader 0:  28%|██▊       | 23/83 [00:12<00:33,  1.80it/s][A
Validation DataLoader 0:  29%|██▉       | 24/83 [00:13<00:32,  1.80it/s][A
Validation DataLoader 0:  30%|███       | 25/83 [00:13<00:32,  1.81it/s][A
Validation DataLoader 0:  31%|███▏      | 26/83 [00:14<00:31,  1.81it/s][A
Validation DataLoader 0:  33%|███▎      | 27/83 [00:14<00:30,  1.81it/s][A
Validation DataLoader 0:  34%|███▎      | 28/83 [00:15<00:30,  1.81it/s][A
Validation DataLoader 0:  35%|███▍      | 29/83 [00:16<00:29,  1.81it/s][A
Validation DataLoader 0:  36%|███▌      | 30/83 [00:16<00:29,  1.81it/s][A
Validation DataLoader 0:  37%|███▋      | 31/83 [00:17<00:28,  1.81it/s][A
Validation DataLoader 0:  39%|███▊      | 32/83 [00:17<00:28,  1.81it/s][A
Validation DataLoader 0:  40%|███▉      | 33/83 [00:18<00:27,  1.81it/s][A
Validation DataLoader 0:  41%|████      | 34/83 [00:18<00:27,  1.81it/s][A
Validation DataLoader 0:  42%|████▏     | 35/83 [00:19<00:26,  1.81it/s][A
Validation DataLoader 0:  43%|████▎     | 36/83 [00:19<00:25,  1.82it/s][A
Validation DataLoader 0:  45%|████▍     | 37/83 [00:20<00:25,  1.82it/s][A
Validation DataLoader 0:  46%|████▌     | 38/83 [00:20<00:24,  1.82it/s][A
Validation DataLoader 0:  47%|████▋     | 39/83 [00:21<00:24,  1.82it/s][A
Validation DataLoader 0:  48%|████▊     | 40/83 [00:22<00:23,  1.82it/s][A
Validation DataLoader 0:  49%|████▉     | 41/83 [00:22<00:23,  1.82it/s][A
Validation DataLoader 0:  51%|█████     | 42/83 [00:23<00:22,  1.82it/s][A
Validation DataLoader 0:  52%|█████▏    | 43/83 [00:23<00:21,  1.82it/s][A
Validation DataLoader 0:  53%|█████▎    | 44/83 [00:24<00:21,  1.82it/s][A
Validation DataLoader 0:  54%|█████▍    | 45/83 [00:24<00:20,  1.82it/s][A
Validation DataLoader 0:  55%|█████▌    | 46/83 [00:25<00:20,  1.82it/s][A
Validation DataLoader 0:  57%|█████▋    | 47/83 [00:25<00:19,  1.82it/s][A
Validation DataLoader 0:  58%|█████▊    | 48/83 [00:26<00:19,  1.82it/s][A
Validation DataLoader 0:  59%|█████▉    | 49/83 [00:26<00:18,  1.82it/s][A
Validation DataLoader 0:  60%|██████    | 50/83 [00:27<00:18,  1.82it/s][A
Validation DataLoader 0:  61%|██████▏   | 51/83 [00:28<00:17,  1.82it/s][A
Validation DataLoader 0:  63%|██████▎   | 52/83 [00:28<00:17,  1.82it/s][A
Validation DataLoader 0:  64%|██████▍   | 53/83 [00:29<00:16,  1.82it/s][A
Validation DataLoader 0:  65%|██████▌   | 54/83 [00:29<00:15,  1.82it/s][A
Validation DataLoader 0:  66%|██████▋   | 55/83 [00:30<00:15,  1.82it/s][A
Validation DataLoader 0:  67%|██████▋   | 56/83 [00:30<00:14,  1.82it/s][A
Validation DataLoader 0:  69%|██████▊   | 57/83 [00:31<00:14,  1.82it/s][A
Validation DataLoader 0:  70%|██████▉   | 58/83 [00:31<00:13,  1.82it/s][A
Validation DataLoader 0:  71%|███████   | 59/83 [00:32<00:13,  1.82it/s][A
Validation DataLoader 0:  72%|███████▏  | 60/83 [00:32<00:12,  1.82it/s][A
Validation DataLoader 0:  73%|███████▎  | 61/83 [00:33<00:12,  1.82it/s][A
Validation DataLoader 0:  75%|███████▍  | 62/83 [00:34<00:11,  1.82it/s][A
Validation DataLoader 0:  76%|███████▌  | 63/83 [00:34<00:10,  1.82it/s][A
Validation DataLoader 0:  77%|███████▋  | 64/83 [00:35<00:10,  1.82it/s][A
Validation DataLoader 0:  78%|███████▊  | 65/83 [00:35<00:09,  1.82it/s][A
Validation DataLoader 0:  80%|███████▉  | 66/83 [00:36<00:09,  1.82it/s][A
Validation DataLoader 0:  81%|████████  | 67/83 [00:36<00:08,  1.82it/s][A
Validation DataLoader 0:  82%|████████▏ | 68/83 [00:37<00:08,  1.82it/s][A
Validation DataLoader 0:  83%|████████▎ | 69/83 [00:37<00:07,  1.82it/s][A
Validation DataLoader 0:  84%|████████▍ | 70/83 [00:38<00:07,  1.83it/s][A
Validation DataLoader 0:  86%|████████▌ | 71/83 [00:38<00:06,  1.83it/s][A
Validation DataLoader 0:  87%|████████▋ | 72/83 [00:39<00:06,  1.83it/s][A
Validation DataLoader 0:  88%|████████▊ | 73/83 [00:39<00:05,  1.83it/s][A
Validation DataLoader 0:  89%|████████▉ | 74/83 [00:40<00:04,  1.83it/s][A
Validation DataLoader 0:  90%|█████████ | 75/83 [00:41<00:04,  1.83it/s][A
Validation DataLoader 0:  92%|█████████▏| 76/83 [00:41<00:03,  1.83it/s][A
Validation DataLoader 0:  93%|█████████▎| 77/83 [00:42<00:03,  1.83it/s][A
Validation DataLoader 0:  94%|█████████▍| 78/83 [00:42<00:02,  1.83it/s][A
Validation DataLoader 0:  95%|█████████▌| 79/83 [00:43<00:02,  1.83it/s][A
Validation DataLoader 0:  96%|█████████▋| 80/83 [00:43<00:01,  1.83it/s][A
Validation DataLoader 0:  98%|█████████▊| 81/83 [00:44<00:01,  1.83it/s][A
Validation DataLoader 0:  99%|█████████▉| 82/83 [00:44<00:00,  1.83it/s][A
Validation DataLoader 0: 100%|██████████| 83/83 [00:45<00:00,  1.83it/s][AError executing job with overrides: ['trainer.max_epochs=5', 'trainer.min_epochs=3', 'trainer.devices=2', 'trainer.strategy=ddp', 'data.batch_size=50']
Traceback (most recent call last):
  File "/data/home/acw572/hgann/HGANN/src/train.py", line 197, in <module>
    main()
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
    raise ex
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           ^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            ^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/_internal/hydra.py", line 132, in run
    _ = ret.return_value
        ^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/core/utils.py", line 260, in return_value
    raise self._return_value
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
                       ^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/hgann/HGANN/src/train.py", line 181, in main
    metrics,_ = train(cfg)
                ^^^^^^^^^^
  File "/data/home/acw572/hgann/HGANN/src/utils/utils.py", line 111, in wrap
    raise ex
  File "/data/home/acw572/hgann/HGANN/src/utils/utils.py", line 101, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
                               ^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/hgann/HGANN/src/train.py", line 115, in train
    trainer.fit(model=model, datamodule=datamodule)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 102, in launch
    return function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 989, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1035, in _run_stage
    self.fit_loop.run()
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 202, in run
    self.advance()
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 359, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 137, in run
    self.on_advance_end(data_fetcher)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 285, in on_advance_end
    self.val_loop.run()
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 141, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 253, in on_run_end
    self._on_evaluation_epoch_end()
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 329, in _on_evaluation_epoch_end
    call._call_lightning_module_hook(trainer, hook_name)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/hgann/HGANN/src/models/tagging_module_test.py", line 176, in on_validation_epoch_end
    self.val_mAP_best(metric_dict['mAP'], sync_dist=True)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/torchmetrics/metric.py", line 309, in forward
    self._forward_cache = self._forward_full_state_update(*args, **kwargs)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/torchmetrics/metric.py", line 324, in _forward_full_state_update
    self.update(*args, **kwargs)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/torchmetrics/metric.py", line 482, in wrapped_func
    update(*args, **kwargs)
TypeError: MaxMetric.update() got an unexpected keyword argument 'sync_dist'
[[36m2024-08-15 16:01:13,212[0m][[34mutils.utils[0m][[31mERROR[0m] - [rank: 0] [0m
Traceback (most recent call last):
  File "/data/home/acw572/hgann/HGANN/src/utils/utils.py", line 101, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
                               ^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/hgann/HGANN/src/train.py", line 115, in train
    trainer.fit(model=model, datamodule=datamodule)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 102, in launch
    return function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 989, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1035, in _run_stage
    self.fit_loop.run()
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 202, in run
    self.advance()
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 359, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 137, in run
    self.on_advance_end(data_fetcher)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 285, in on_advance_end
    self.val_loop.run()
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 141, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 253, in on_run_end
    self._on_evaluation_epoch_end()
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 329, in _on_evaluation_epoch_end
    call._call_lightning_module_hook(trainer, hook_name)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/hgann/HGANN/src/models/tagging_module_test.py", line 176, in on_validation_epoch_end
    self.val_mAP_best(metric_dict['mAP'], sync_dist=True)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/torchmetrics/metric.py", line 309, in forward
    self._forward_cache = self._forward_full_state_update(*args, **kwargs)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/torchmetrics/metric.py", line 324, in _forward_full_state_update
    self.update(*args, **kwargs)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/torchmetrics/metric.py", line 482, in wrapped_func
    update(*args, **kwargs)
TypeError: MaxMetric.update() got an unexpected keyword argument 'sync_dist'
[[36m2024-08-15 16:01:13,224[0m][[34mutils.utils[0m][[32mINFO[0m] - [rank: 0] Output dir: /data/scratch/acw572/LHGNN/logs/train/runs/2024-08-15_15-46-14[0m
[[36m2024-08-15 16:01:13,225[0m][[34mutils.utils[0m][[32mINFO[0m] - [rank: 0] Closing wandb![0m
wandb: - 0.007 MB of 0.007 MB uploadedwandb: \ 0.007 MB of 0.007 MB uploadedwandb: | 0.007 MB of 0.007 MB uploadedwandb: / 0.007 MB of 0.007 MB uploadedwandb: - 0.029 MB of 0.042 MB uploaded (0.002 MB deduped)wandb: \ 0.029 MB of 0.042 MB uploaded (0.002 MB deduped)wandb: | 0.107 MB of 0.107 MB uploaded (0.002 MB deduped)wandb:                                                                                
wandb: W&B sync reduced upload amount by 1.4%             
wandb: 
wandb: Run history:
wandb:               epoch ▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train/loss_step █▅▃▁▁▁▁▁▁▁▁▁▁▁
wandb: trainer/global_step ▁▂▂▃▃▄▄▅▅▆▆▇▇█
wandb: 
wandb: Run summary:
wandb:               epoch 0
wandb:     train/loss_step 0.03587
wandb: trainer/global_step 699
wandb: 
wandb: 🚀 View run bright-totem-50 at: https://wandb.ai/shubhr/audioset-bal/runs/yw9alst8
wandb: ️⚡ View job at https://wandb.ai/shubhr/audioset-bal/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjI0NzQ3OTYxNA==/version_details/v5
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: /data/scratch/acw572/LHGNN/logs/train/runs/2024-08-15_15-46-14/wandb/run-20240815_154645-yw9alst8/logs
Error executing job with overrides: ['trainer.max_epochs=5', 'trainer.min_epochs=3', 'trainer.devices=2', 'trainer.strategy=ddp', 'data.batch_size=50']
Traceback (most recent call last):
  File "/data/home/acw572/hgann/HGANN/src/train.py", line 197, in <module>
    main()
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
    raise ex
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           ^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            ^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/_internal/hydra.py", line 132, in run
    _ = ret.return_value
        ^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/core/utils.py", line 260, in return_value
    raise self._return_value
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
                       ^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/hgann/HGANN/src/train.py", line 181, in main
    metrics,_ = train(cfg)
                ^^^^^^^^^^
  File "/data/home/acw572/hgann/HGANN/src/utils/utils.py", line 111, in wrap
    raise ex
  File "/data/home/acw572/hgann/HGANN/src/utils/utils.py", line 101, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
                               ^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/hgann/HGANN/src/train.py", line 115, in train
    trainer.fit(model=model, datamodule=datamodule)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 102, in launch
    return function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 989, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1035, in _run_stage
    self.fit_loop.run()
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 202, in run
    self.advance()
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 359, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 137, in run
    self.on_advance_end(data_fetcher)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 285, in on_advance_end
    self.val_loop.run()
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 141, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 253, in on_run_end
    self._on_evaluation_epoch_end()
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 329, in _on_evaluation_epoch_end
    call._call_lightning_module_hook(trainer, hook_name)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/hgann/HGANN/src/models/tagging_module_test.py", line 176, in on_validation_epoch_end
    self.val_mAP_best(metric_dict['mAP'], sync_dist=True)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/torchmetrics/metric.py", line 309, in forward
    self._forward_cache = self._forward_full_state_update(*args, **kwargs)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/torchmetrics/metric.py", line 324, in _forward_full_state_update
    self.update(*args, **kwargs)
  File "/data/home/acw572/.conda/envs/hgann/lib/python3.12/site-packages/torchmetrics/metric.py", line 482, in wrapped_func
    update(*args, **kwargs)
TypeError: MaxMetric.update() got an unexpected keyword argument 'sync_dist'
